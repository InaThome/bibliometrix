
@article{ ISI:000589622700001,
Author = {Fazekas, Judit and Jessop, Andrew and Pine, Julian and Rowland, Caroline},
Title = {{Do children learn from their prediction mistakes? A registered report
   evaluating error-based theories of language acquisition}},
Journal = {{ROYAL SOCIETY OPEN SCIENCE}},
Year = {{2020}},
Volume = {{7}},
Number = {{11}},
Month = {{NOV 4}},
Abstract = {{Error-based theories of language acquisition suggest that children, like
   adults, continuously make and evaluate predictions in order to reach an
   adult-like state of language use. However, while these theories have
   become extremely influential, their central claim-that unpredictable
   input leads to higher rates of lasting change in linguistic
   representations-has scarcely been tested. We designed a prime
   surprisal-based intervention study to assess this claim. As predicted,
   both 5- to 6-year-old children (n = 72) and adults (n = 72) showed a
   pre- to post-test shift towards producing the dative syntactic structure
   they were exposed to in surprising sentences. The effect was significant
   in both age groups together, and in the child group separately when
   participants with ceiling performance in the pre-test were excluded.
   Secondary predictions were not upheld: we found no verb-based learning
   effects and there was only reliable evidence for immediate prime
   surprisal effects in the adult, but not in the child group. To our
   knowledge, this is the first published study demonstrating enhanced
   learning rates for the same syntactic structure when it appeared in
   surprising as opposed to predictable contexts, thus providing crucial
   support for error-based theories of language acquisition.}},
Publisher = {{ROYAL SOC}},
Address = {{6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Fazekas, J (Corresponding Author), Max Planck Inst Psycholinguist, Language Dev Dept, Nijmegen, Gelderland, Netherlands.
   Fazekas, Judit; Jessop, Andrew; Rowland, Caroline, Max Planck Inst Psycholinguist, Language Dev Dept, Nijmegen, Gelderland, Netherlands.
   Pine, Julian; Rowland, Caroline, Univ Liverpool, Psychol Sci, Inst Psychol Hlth \& Soc, Liverpool, Merseyside, England.}},
DOI = {{10.1098/rsos.180877}},
Article-Number = {{180877}},
ISSN = {{2054-5703}},
Keywords = {{prediction; error-based learning; language acquisition}},
Keywords-Plus = {{EXPECTATION; PERSISTENCE; VERBS}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{Judit.Fazekas@mpi.nl}},
Funding-Acknowledgement = {{ESRCEconomic \& Social Research Council (ESRC)}},
Funding-Text = {{J.F.'s work was enabled by an ESRC PhD Studentship. J.P., C.R. and A.J.
   received no grants or funding in support of this project.}},
Cited-References = {{Ambridge B, 2018, COLLABRA-PSYCHOL, V4, DOI 10.1525/collabra.133.
   Ambridge B, 2014, LANG COGN NEUROSCI, V29, P218, DOI 10.1080/01690965.2012.738300.
   {[}Anonymous], 2000, E PRIM 2 0.
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005.
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001.
   Bates D, 2015, PARSIMONIOUS MIXED M.
   Bishop DV, 2003, TEST RECEPTION GRAMM.
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6.
   Borovsky A, 2014, DEV PSYCHOL, V50, P1600, DOI 10.1037/a0035591.
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005.
   Branigan HP, 2016, COGNITION, V157, P250, DOI 10.1016/j.cognition.2016.09.004.
   Campbell AL, 2001, APPL PSYCHOLINGUIST, V22, P253, DOI 10.1017/S0142716401002065.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104.
   Conwell E, 2007, COGNITION, V103, P163, DOI 10.1016/j.cognition.2006.03.003.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   Fazekas J, 2020, DRYAD DIGITAL REPOSI, DOI {[}10.5061/dryad.3n5tb2rdq, DOI 10.5061/DRYAD.3N5TB2RDQ].
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661.
   Fisher J, 2017, TLS-TIMES LIT SUPPL, P39.
   Gambi C, 2016, COGNITION, V157, P340, DOI 10.1016/j.cognition.2016.10.003.
   Gelman A, 2008, ANN APPL STAT, V2, P1360, DOI 10.1214/08-AOAS191.
   Hoedemaker RS, 2019, J EXP PSYCHOL LEARN, V45, P732, DOI 10.1037/xlm0000603.
   Huang YT, 2013, J MEM LANG, V69, P589, DOI 10.1016/j.jml.2013.08.002.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013.
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007.
   Kaschak MP, 2011, PSYCHON B REV, V18, P1133, DOI 10.3758/s13423-011-0157-y.
   Kidd E, 2012, APPL PSYCHOLINGUIST, V33, P393, DOI 10.1017/S0142716411000415.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Lew-Williams C, 2007, PSYCHOL SCI, V18, P193, DOI 10.1111/j.1467-9280.2007.01871.x.
   Lukyanenko C, 2016, COGNITION, V146, P349, DOI 10.1016/j.cognition.2015.10.012.
   MacWhinney B, 2000, CHILDES PROJECT TOOL.
   Magyari L, 2014, J COGNITIVE NEUROSCI, V26, P2530, DOI 10.1162/jocn\_a\_00673.
   Mani N, 2016, Q J EXP PSYCHOL, V69, P2189, DOI 10.1080/17470218.2015.1111395.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Messenger K, 2012, J MEM LANG, V66, P568, DOI 10.1016/j.jml.2012.03.008.
   Morey RD, 2016, PSYCHON B REV, V23, P103, DOI 10.3758/s13423-015-0947-8.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Neter J, 1985, APPL LINEAR STAT MOD.
   Nicenboim B, 2016, LANG LINGUIST COMPAS, V10, P591, DOI 10.1111/lnc3.12207.
   Novembre G, 2011, CONSCIOUS COGN, V20, P1232, DOI 10.1016/j.concog.2011.03.009.
   O'Reilly R.C., 2017, DEEP PREDICTIVE LEAR.
   Peter M, 2015, J MEM LANG, V81, P1, DOI 10.1016/j.jml.2014.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Pickering MJ, 1998, J MEM LANG, V39, P633, DOI 10.1006/jmla.1998.2592.
   R Core Team, 2012, R LANG ENV STAT COMP.
   Rabagliati H, 2016, LANG COGN NEUROSCI, V31, P94, DOI 10.1080/23273798.2015.1077979.
   Ramscar M, 2013, LANGUAGE, V89, P760, DOI 10.1353/lan.2013.0068.
   Rowland CF, 2012, COGNITION, V125, P49, DOI 10.1016/j.cognition.2012.06.008.
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318, DOI {[}DOI 10.1016/B978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2].
   Savage C, 2006, LANG LEARN DEV, V2, P27, DOI 10.1207/s15473341lld0201\_2.
   Schad DJ, 2020, J MEM LANG, V110, DOI 10.1016/j.jml.2019.104038.
   Seeff-Gabriel BK, 2008, EARLY REPETITION BAT.
   Stahl AE, 2015, SCIENCE, V348, P91, DOI 10.1126/science.aaa3799.
   Stan Development Team, 2020, RSTAN R INT STAN.
   Urgesi C, 2012, PSYCHOL RES-PSYCH FO, V76, P542, DOI 10.1007/s00426-011-0383-y.
   Wendorf C. A., 2004, Understanding Statistics, V3, P47, DOI 10.1207/s15328031us0301\_3.}},
Number-of-Cited-References = {{58}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{R. Soc. Open Sci.}},
Doc-Delivery-Number = {{OR7BP}},
Unique-ID = {{ISI:000589622700001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000583058600028,
Author = {Easwar, Vijayalakshmi and Birstler, Jen and Harrison, Adrienne and
   Scollie, Susan and Purcell, David},
Title = {{The Accuracy of Envelope Following Responses in Predicting Speech
   Audibility}},
Journal = {{EAR AND HEARING}},
Year = {{2020}},
Volume = {{41}},
Number = {{6}},
Pages = {{1732-1746}},
Month = {{NOV-DEC}},
Abstract = {{Objectives:
   The present study aimed to (1) evaluate the accuracy of envelope
   following responses (EFRs) in predicting speech audibility as a function
   of the statistical indicator used for objective response detection,
   stimulus phoneme, frequency, and level, and (2) quantify the minimum
   sensation level (SL; stimulus level above behavioral threshold) needed
   for detecting EFRs.
   Design:
   In 21 participants with normal hearing, EFRs were elicited by 8
   band-limited phonemes in the male-spoken token /susa integral i/ (2.05
   sec) presented between 20 and 65 dB SPL in 15 dB increments. Vowels in
   /susa integral i/ were modified to elicit two EFRs simultaneously by
   selectively lowering the fundamental frequency (f(0)) in the first
   formant (F1) region. The modified vowels elicited one EFR from the
   low-frequency F1 and another from the mid-frequency second and higher
   formants (F2+). Fricatives were amplitude-modulated at the average f(0).
   EFRs were extracted from single-channel EEG recorded between the vertex
   (C-z) and the nape of the neck when /susa integral i/ was presented
   monaurally for 450 sweeps. The performance of the three statistical
   indicators, F-test, Hotelling's T-2, and phase coherence, was compared
   against behaviorally determined audibility (estimated SL, SL >= 0 dB =
   audible) using area under the receiver operating characteristics (AUROC)
   curve, sensitivity (the proportion of audible speech with a detectable
   EFR {[}true positive rate]), and specificity (the proportion of
   inaudible speech with an undetectable EFR {[}true negative rate]). The
   influence of stimulus phoneme, frequency, and level on the accuracy of
   EFRs in predicting speech audibility was assessed by comparing
   sensitivity, specificity, positive predictive value (PPV; the proportion
   of detected EFRs elicited by audible stimuli) and negative predictive
   value (NPV; the proportion of undetected EFRs elicited by inaudible
   stimuli). The minimum SL needed for detection was evaluated using a
   linear mixed-effects model with the predictor variables stimulus and EFR
   detection p value.
   Results:
   of the 3 statistical indicators were similar; however, at the type I
   error rate of 5\%, the sensitivities of Hotelling's T-2 (68.4\%) and
   phase coherence (68.8\%) were significantly higher than the F-test
   (59.5\%). In contrast, the specificity of the F-test (97.3\%) was
   significantly higher than the Hotelling's T-2 (88.4\%). When analyzed
   using Hotelling's T-2 as a function of stimulus, fricatives offered
   higher sensitivity (88.6 to 90.6\%) and NPV (57.9 to 76.0\%) compared
   with most vowel stimuli (51.9 to 71.4\% and 11.6 to 51.3\%,
   respectively). When analyzed as a function of frequency band (F1, F2+,
   and fricatives aggregated as low-, mid- and high-frequencies,
   respectively), high-frequency stimuli offered the highest sensitivity
   (96.9\%) and NPV (88.9\%). When analyzed as a function of test level,
   sensitivity improved with increases in stimulus level (99.4\% at 65 dB
   SPL). The minimum SL for EFR detection ranged between 13.4 and 21.7 dB
   for F1 stimuli, 7.8 to 12.2 dB for F2+ stimuli, and 2.3 to 3.9 dB for
   fricative stimuli.
   Conclusions:
   EFR-based inference of speech audibility requires consideration of the
   statistical indicator used, phoneme, stimulus frequency, and stimulus
   level.}},
Publisher = {{LIPPINCOTT WILLIAMS \& WILKINS}},
Address = {{TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Easwar, V (Corresponding Author), Univ Wisconsin, Dept Commun Sci \& Disorders, 541 Waisman Ctr,1500 Highland Ave, Madison, WI 53705 USA.
   Easwar, V (Corresponding Author), Univ Wisconsin, Waisman Ctr, 541 Waisman Ctr,1500 Highland Ave, Madison, WI 53705 USA.
   Easwar, Vijayalakshmi, Univ Wisconsin, Dept Commun Sci \& Disorders, 541 Waisman Ctr,1500 Highland Ave, Madison, WI 53705 USA.
   Easwar, Vijayalakshmi, Univ Wisconsin, Waisman Ctr, 541 Waisman Ctr,1500 Highland Ave, Madison, WI 53705 USA.
   Easwar, Vijayalakshmi; Scollie, Susan; Purcell, David, Western Univ, Natl Ctr Audiol, London, ON, Canada.
   Birstler, Jen, Univ Wisconsin, Dept Biostat \& Med Informat, Madison, WI USA.
   Harrison, Adrienne, Western Univ, Hlth \& Rehabil Sci, London, ON, Canada.
   Scollie, Susan; Purcell, David, Western Univ, Sch Commun Sci \& Disorders, London, ON, Canada.}},
DOI = {{10.1097/AUD.0000000000000892}},
ISSN = {{0196-0202}},
EISSN = {{1538-4667}},
Keywords = {{Formant; Frequency following response; Fricative; Hotelling\&\#8217; s
   T-2; Negative predictive value; Phase coherence; Positive predictive
   value; Receiver operating characteristics curve; Sensitivity;
   Specificity; Vowel}},
Keywords-Plus = {{STEADY-STATE RESPONSES; AUDITORY-EVOKED POTENTIALS; FREQUENCY-FOLLOWING
   RESPONSES; HEARING-AID GAIN; SPECTRAL DISTRIBUTION; OBJECTIVE DETECTION;
   STIMULUS LEVEL; PHASE; ADULTS; WAVE}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Otorhinolaryngology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Otorhinolaryngology}},
Author-Email = {{veaswar@wisc.edu}},
Funding-Acknowledgement = {{Collaborative Health Research Project grant from the Canadian Institutes
   of Health ResearchCanadian Institutes of Health Research (CIHR); Natural
   Sciences and Engineering Research Council of CanadaNatural Sciences and
   Engineering Research Council of CanadaCGIAR {[}493836-2016]; Clinical
   and Translational Science Award (CTSA) program, through the NIH National
   Center for Advancing Translational Sciences (NCATS)United States
   Department of Health \& Human ServicesNational Institutes of Health
   (NIH) - USANIH National Center for Advancing Translational Sciences
   (NCATS) {[}UL1TR002373]}},
Funding-Text = {{This study was funded by a Collaborative Health Research Project grant
   from the Canadian Institutes of Health Research and the Natural Sciences
   and Engineering Research Council of Canada (grant no. 493836-2016;
   Western University) and by the Clinical and Translational Science Award
   (CTSA) program, through the NIH National Center for Advancing
   Translational Sciences (NCATS; grant no. UL1TR002373; University of
   Wisconsin-Madison).}},
Cited-References = {{Agresti A, 1998, AM STAT, V52, P119, DOI 10.2307/2685469.
   Aiken SJ, 2006, AUDIOL NEURO-OTOL, V11, P213, DOI 10.1159/000092589.
   Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004.
   Anderson S, 2015, J ACOUST SOC AM, V137, P3346, DOI 10.1121/1.4921032.
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x.
   Bidelman GM, 2018, NEUROIMAGE, V175, P56, DOI 10.1016/j.neuroimage.2018.03.060.
   Boersma P., 2017, PRAAT DOING PHONETIC.
   BOOTHROYD A, 1992, EAR HEARING, V13, P150, DOI 10.1097/00003446-199206000-00003.
   BOOTHROYD A, 1994, EAR HEARING, V15, P432, DOI 10.1097/00003446-199412000-00004.
   Carter L, 2010, J AM ACAD AUDIOL, V21, P347, DOI 10.3766/jaaa.21.5.6.
   Cebulla M, 2006, J AM ACAD AUDIOL, V17, P93, DOI 10.3766/jaaa.17.2.3.
   Chang HW, 2012, INT J AUDIOL, V51, P663, DOI 10.3109/14992027.2012.690076.
   Choi JM, 2013, EAR HEARING, V34, P637, DOI 10.1097/AUD.0b013e31828e4dad.
   Choi JM, 2011, EAR HEARING, V32, P593, DOI 10.1097/AUD.0b013e318212085e.
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595.
   DOBIE RA, 1994, ELECTROEN CLIN NEURO, V92, P405, DOI 10.1016/0168-5597(94)90017-5.
   DOBIE RA, 1993, ELECTROEN CLIN NEURO, V88, P516, DOI 10.1016/0168-5597(93)90040-V.
   Easwar V., 2012, INT J OTOLARYNGOL, V2012, P518202.
   Easwar V, 2019, HEARING RES, V380, P35, DOI 10.1016/j.heares.2019.05.005.
   Easwar V, 2020, EAR HEARING, V41, P150, DOI 10.1097/AUD.0000000000000739.
   Easwar V, 2018, EUR J NEUROSCI, V48, P3126, DOI 10.1111/ejn.14161.
   Easwar V, 2018, NEUROSCI LETT, V665, P257, DOI 10.1016/j.neulet.2017.12.014.
   Easwar V, 2015, EAR HEARING, V36, P635, DOI 10.1097/AUD.0000000000000199.
   Easwar V, 2015, EAR HEARING, V36, P619, DOI 10.1097/AUD.0000000000000188.
   Easwar V, 2015, HEARING RES, V320, P38, DOI 10.1016/j.heares.2014.11.008.
   Elberling C., 2007, AUDITORY EVOKED POTE, P102.
   Elberling C, 2007, J ACOUST SOC AM, V122, P2772, DOI 10.1121/1.2783985.
   Gardner-Berry Kirsty, 2016, Seminars in Hearing, V37, P53, DOI 10.1055/s-0035-1570330.
   Glista D, 2014, J AM ACAD AUDIOL, V25, P1008, DOI 10.3766/jaaa.25.10.9.
   Guerit F, 2017, J ACOUST SOC AM, V142, pEL395, DOI 10.1121/1.5007757.
   Henning RW, 2005, EAR HEARING, V26, P409, DOI 10.1097/00003446-200508000-00004.
   Holube I, 2010, INT J AUDIOL, V49, P891, DOI 10.3109/14992027.2010.506889.
   Jafari Z, 2009, J AM ACAD AUDIOL, V20, P621, DOI 10.3766/jaaa.20.10.4.
   Jeng FC, 2011, EAR HEARING, V32, P699, DOI 10.1097/AUD.0b013e31821cc0df.
   John S. M., 2008, AUDITORY STEADY STAT, P11.
   Laugesen S, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518789302.
   Lins OG, 1996, EAR HEARING, V17, P81, DOI 10.1097/00003446-199604000-00001.
   Mardia KV, 2000, DIRECTIONAL STAT.
   Munro KJ, 2011, EAR HEARING, V32, P782, DOI 10.1097/AUD.0b013e318220377e.
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x.
   Picton T. W., 2007, AUDITORY EVOKED POTE, P441.
   Picton Terence W, 2005, J Am Acad Audiol, V16, P140, DOI 10.3766/jaaa.16.3.3.
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316.
   PICTON TW, 1987, ELECTROEN CLIN NEURO, V68, P119, DOI 10.1016/0168-5597(87)90039-6.
   Picton TW, 2001, CLIN NEUROPHYSIOL, V112, P1698, DOI 10.1016/S1388-2457(01)00608-3.
   Pinheiro J, 2018, NLME LINEAR NONLINEA, V3, P1, DOI DOI 10.1111/J.1654-1103.2009.05548.X.
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7.
   Purdy S, 2005, SOUND FDN EARLY AMPL, P115.
   R Core Team, 2016, R LANG ENV STAT COMP.
   Rance G, 2002, EAR HEARING, V23, P239, DOI 10.1097/00003446-200206000-00008.
   Rance Gary, 2002, J Am Acad Audiol, V13, P236.
   Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77.
   Scollie SD, 2002, EAR HEARING, V23, P477, DOI 10.1097/00003446-200210000-00009.
   Sininger YS, 2009, J AM ACAD AUDIOL, V20, P49, DOI 10.3766/jaaa.20.1.5.
   Stapells D. R., 2000, J SPEECH LANGUAGE PA, V24, P74.
   STAPELLS DR, 1987, ELECTROEN CLIN NEURO, V67, P260, DOI 10.1016/0013-4694(87)90024-1.
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556.
   Stelmachowicz PG, 1996, EAR HEARING, V17, P520, DOI 10.1097/00003446-199612000-00007.
   STONE MA, 1992, BRIT J AUDIOL, V26, P351, DOI 10.3109/03005369209076659.
   Tlumak AI, 2007, INT J AUDIOL, V46, P692, DOI 10.1080/14992020701482480.
   Trevethan R, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00307.
   Uus K, 2006, PEDIATRICS, V117, pE887, DOI 10.1542/peds.2005-1064.
   Valdes JL, 1997, EAR HEARING, V18, P420, DOI 10.1097/00003446-199710000-00007.
   Van Dun B, 2012, AUDIOL RES, V2, P65, DOI 10.4081/audiores.2012.e13.
   Van Dyke KB, 2017, J SPEECH LANG HEAR R, V60, P2740, DOI 10.1044/2017\_JSLHR-H-16-0263.
   Vanheusden F. J., 2019, INT J AUDIOL, V45, P1.
   Vanheusden FJ, 2019, EAR HEARING, V40, P116, DOI 10.1097/AUD.0000000000000598.
   VICTOR JD, 1991, ELECTROEN CLIN NEURO, V78, P378, DOI 10.1016/0013-4694(91)90099-P.
   YOUDEN WJ, 1950, CANCER, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3.}},
Number-of-Cited-References = {{69}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Ear Hear.}},
Doc-Delivery-Number = {{OI1PD}},
Unique-ID = {{ISI:000583058600028}},
DA = {{2020-12-06}},
}

@article{ ISI:000587697900001,
Author = {Michon, Maeva and Boncompte, Gonzalo and Lopez, Vladimir},
Title = {{Electrophysiological Dynamics of Visual Speech Processing and the Role
   of Orofacial Effectors for Cross-Modal Predictions}},
Journal = {{FRONTIERS IN HUMAN NEUROSCIENCE}},
Year = {{2020}},
Volume = {{14}},
Month = {{OCT 27}},
Abstract = {{The human brain generates predictions about future events. During
   face-to-face conversations, visemic information is used to predict
   upcoming auditory input. Recent studies suggest that the speech motor
   system plays a role in these cross-modal predictions, however, usually
   only audio-visual paradigms are employed. Here we tested whether speech
   sounds can be predicted on the basis of visemic information only, and to
   what extent interfering with orofacial articulatory effectors can affect
   these predictions. We registered EEG and employed N400 as an index of
   such predictions. Our results show that N400's amplitude was strongly
   modulated by visemic salience, coherent with cross-modal speech
   predictions. Additionally, N400 ceased to be evoked when syllables'
   visemes were presented backwards, suggesting that predictions occur only
   when the observed viseme matched an existing articuleme in the
   observer's speech motor system (i.e., the articulatory neural sequence
   required to produce a particular phoneme/viseme). Importantly, we found
   that interfering with the motor articulatory system strongly disrupted
   cross-modal predictions. We also observed a late P1000 that was evoked
   only for syllable-related visual stimuli, but whose amplitude was not
   modulated by interfering with the motor system. The present study
   provides further evidence of the importance of the speech production
   system for speech sounds predictions based on visemic information at the
   pre-lexical level. The implications of these results are discussed in
   the context of a hypothesized trimodal repertoire for speech, in which
   speech perception is conceived as a highly interactive process that
   involves not only your ears but also your eyes, lips and tongue.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Michon, M (Corresponding Author), Pontificia Univ Catolica Chile, Lab Neurociencia Cognit \& Evolutiva, Escuela Med, Santiago, Chile.
   Michon, M (Corresponding Author), Univ Diego Portales, Lab Neurociencia Cognit \& Social, Fac Psicol, Santiago, Chile.
   Michon, Maeva, Pontificia Univ Catolica Chile, Lab Neurociencia Cognit \& Evolutiva, Escuela Med, Santiago, Chile.
   Michon, Maeva, Univ Diego Portales, Lab Neurociencia Cognit \& Social, Fac Psicol, Santiago, Chile.
   Boncompte, Gonzalo, Pontificia Univ Catolica Chile, Lab Neurodinam Cogn, Escuela Med, Santiago, Chile.
   Lopez, Vladimir, Pontificia Univ Catolica Chile, Lab Psicol Expt, Escuela Psicol, Santiago, Chile.}},
DOI = {{10.3389/fnhum.2020.538619}},
Article-Number = {{538619}},
ISSN = {{1662-5161}},
Keywords = {{orofacial movements; place of articulation; ERPs; viseme; articuleme;
   speech motor system; cross-modal prediction}},
Keywords-Plus = {{AUDITORY-CORTEX; LANGUAGE DISCRIMINATION; MOTOR THEORY; PERCEPTION;
   HEARING; INFORMATION; ACTIVATION; MECHANISMS; COMPREHENSION; RECOGNITION}},
Research-Areas = {{Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Neurosciences; Psychology}},
Author-Email = {{mmichon@uc.cl}},
Funding-Acknowledgement = {{Agencia Nacional de Investigacion y Desarrollo (ANID) from the Chilean
   government {[}3201057, 3200248, 1150241]}},
Funding-Text = {{This research was supported by a post-doctoral fellowship from the
   Agencia Nacional de Investigacion y Desarrollo (ANID) from the Chilean
   government to MM (Grant No. 3201057) and GB (Grant No. 3200248) and by a
   regular grant to VL (Grant No. 1150241).}},
Cited-References = {{Archila-Melendez ME, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0252-17.2018.
   {[}Ардила А. Ardila A.], 2020, {[}Неврология, нейропсихиатрия, психосоматика, Neurology, Neuropsychiatry, Psychosomatics, Nevrologiya, neiropsikhiatriya, psikhosomatika], V12, P4, DOI 10.14412/2074-2711-2020-1-4-12.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009.
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842.
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080).
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683.
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546.
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386.
   Blank H, 2013, NEUROIMAGE, V65, P109, DOI 10.1016/j.neuroimage.2012.09.047.
   Bourguignon M., 2018, HEARING LIP READING, DOI {[}10.1101/395483, DOI 10.1101/395483].
   Bourguignon M, 2020, J NEUROSCI, V40, P1053, DOI 10.1523/JNEUROSCI.1101-19.2019.
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112.
   Brunelliere A, 2013, INT J PSYCHOPHYSIOL, V89, P136, DOI 10.1016/j.ijpsycho.2013.06.016.
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828.
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593.
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436.
   Chennu S, 2016, J NEUROSCI, V36, P8305, DOI 10.1523/JNEUROSCI.1125-16.2016.
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015.
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017.
   DeLong KA, 2020, LANG COGN NEUROSCI, V35, P1044, DOI 10.1080/23273798.2019.1708960.
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009.
   Dole M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00030.
   Duffau H, 2018, J CHEM NEUROANAT, V89, P73, DOI 10.1016/j.jchemneu.2017.04.003.
   Gambi C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00340.
   Garrod S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00751.
   Glenberg AM, 2012, CORTEX, V48, P905, DOI 10.1016/j.cortex.2011.04.010.
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013.
   Gomez-Marin A, 2019, NEURON, V104, P25, DOI 10.1016/j.neuron.2019.09.017.
   Hauswald A, 2018, CURR BIOL, V28, P1453, DOI 10.1016/j.cub.2018.03.044.
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243).
   JASP Team, 2020, JASP VERS 0 12 2 COM.
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209.
   Kaganovich N, 2019, J EXP CHILD PSYCHOL, V184, P98, DOI 10.1016/j.jecp.2019.03.009.
   Kaganovich N, 2016, BRAIN LANG, V157, P14, DOI 10.1016/j.bandl.2016.04.010.
   Kilner James M, 2007, Cogn Process, V8, P159, DOI 10.1007/s10339-007-0170-2.
   Kuperberg GR, 2020, J COGNITIVE NEUROSCI, V32, P12, DOI 10.1162/jocn\_a\_01465.
   KUTAS M, 1980, BIOL PSYCHOL, V11, P99, DOI 10.1016/0301-0511(80)90046-0.
   Letourneau SM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00319.
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109.
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6.
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213.
   Luria A R, 1965, J Neurol Sci, V2, P278, DOI 10.1016/0022-510X(65)90112-7.
   LURIA AR, 1973, NEUROPSYCHOLOGIA, V11, P417, DOI 10.1016/0028-3932(73)90028-6.
   Martin CD, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19499-4.
   Massaro DW, 2008, PSYCHON B REV, V15, P453, DOI 10.3758/PBR.15.2.453.
   Maturana H. R., 1987, TREE KNOWLEDGE BIOL.
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0.
   Michon M, 2019, PROG BRAIN RES, V250, P345, DOI 10.1016/bs.pbr.2019.01.005.
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5.
   Nuttall HE, 2018, BRAIN LANG, V187, P74, DOI 10.1016/j.bandl.2017.12.002.
   Okada K, 2018, PSYCHON B REV, V25, P423, DOI 10.3758/s13423-017-1284-x.
   Okland H. S., 2018, PREDICTING AUDIOVISU, DOI {[}10.1101/360578, DOI 10.1101/360578].
   Paris T, 2017, NEUROSCIENCE, V343, P157, DOI 10.1016/j.neuroscience.2016.09.023.
   Paris T, 2013, BRAIN LANG, V126, P350, DOI 10.1016/j.bandl.2013.06.008.
   Park Hyojin, 2018, Lang Cogn Neurosci, V35, P739, DOI 10.1080/23273798.2018.1506589.
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521.
   Peelle J. E., 2019, ROUTLEDGE HDB PHONET.
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006.
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008.
   Pekkola J, 2005, NEUROREPORT, V16, P125, DOI 10.1097/00001756-200502080-00010.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Poeppel D, 2020, NAT REV NEUROSCI, V21, P322, DOI 10.1038/s41583-020-0304-4.
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103.
   Pulvermuller F., 2016, HDB NEUROBIOLOGY LAN, P311, DOI 10.1016/C2011-0-07351-9.
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811.
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024.
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F.
   Sato M, 2010, SPEECH COMMUN, V52, P533, DOI 10.1016/j.specom.2009.12.004.
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817.
   Seth AK, 2013, TRENDS COGN SCI, V17, P565, DOI 10.1016/j.tics.2013.09.007.
   Shahin AJ, 2018, J NEUROSCI, V38, P1835, DOI 10.1523/JNEUROSCI.1566-17.2017.
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006.
   Stokes RC, 2019, PSYCHON B REV, V26, P1354, DOI 10.3758/s13423-019-01580-2.
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309.
   Swaminathan S, 2013, BRAIN LANG, V126, P1, DOI 10.1016/j.bandl.2013.03.002.
   ten Oever S, 2014, NEUROPSYCHOLOGIA, V63, P43, DOI 10.1016/j.neuropsychologia.2014.08.008.
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x.
   Thompson E., 2011, PHILOS TOPICS, V39, P163, DOI DOI 10.5840/PHILT0PICS201139119).
   Tremblay P, 2016, BRAIN LANG, V162, P60, DOI 10.1016/j.bandl.2016.08.004.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.
   van Wassenhove V., 2007, P 16 ICPHS.
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001.
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388.
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0.
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686.
   Worster E, 2018, LANG LEARN, V68, P159, DOI 10.1111/lang.12264.}},
Number-of-Cited-References = {{91}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Front. Hum. Neurosci.}},
Doc-Delivery-Number = {{OO9MQ}},
Unique-ID = {{ISI:000587697900001}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000585340000001,
Author = {Banellis, Leah and Sokoliuk, Rodika and Wild, Conor J. and Bowman,
   Howard and Cruse, Damian},
Title = {{Event-related potentials reflect prediction errors and pop-out during
   comprehension of degraded speech}},
Journal = {{NEUROSCIENCE OF CONSCIOUSNESS}},
Year = {{2020}},
Volume = {{6}},
Number = {{1}},
Month = {{OCT 25}},
Abstract = {{Comprehension of degraded speech requires higher-order expectations
   informed by prior knowledge. Accurate top-down expectations of incoming
   degraded speech cause a subjective semantic `pop-out' or conscious
   breakthrough experience. Indeed, the same stimulus can be perceived as
   meaningless when no expectations are made in advance. We investigated
   the event-related potential (ERP) correlates of these top-down
   expectations, their error signals and the subjective pop-out experience
   in healthy participants. We manipulated expectations in a word-pair
   priming degraded (noise-vocoded) speech task and investigated the role
   of top-down expectation with a between-groups attention manipulation.
   Consistent with the role of expectations in comprehension, repetition
   priming significantly enhanced perceptual intelligibility of the
   noise-vocoded degraded targets for attentive participants. An early ERP
   was larger for mismatched (i.e. unexpected) targets than matched
   targets, indicative of an initial error signal not reliant on top-down
   expectations. Subsequently, a P3a-like ERP was larger to matched targets
   than mismatched targets only for attending participants-i.e. a pop-out
   effect-while a later ERP was larger for mismatched targets and did not
   significantly interact with attention. Rather than relying on complex
   post hoc interactions between prediction error and precision to explain
   this apredictive pattern, we consider our data to be consistent with
   prediction error minimization accounts for early stages of processing
   followed by Global Neuronal Workspace-like breakthrough and processing
   in service of task goals.}},
Publisher = {{OXFORD UNIV PRESS}},
Address = {{GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Banellis, L (Corresponding Author), Univ Birmingham, Sch Psychol, Edgbaston B15 2TT, England.
   Banellis, L (Corresponding Author), Univ Birmingham, Ctr Human Brain Hlth, Edgbaston B15 2TT, England.
   Banellis, Leah; Sokoliuk, Rodika; Bowman, Howard; Cruse, Damian, Univ Birmingham, Sch Psychol, Edgbaston B15 2TT, England.
   Banellis, Leah; Sokoliuk, Rodika; Bowman, Howard; Cruse, Damian, Univ Birmingham, Ctr Human Brain Hlth, Edgbaston B15 2TT, England.
   Wild, Conor J., Univ Western Ontario, Brain \& Mind Inst, London, ON N6A 3K7, Canada.
   Bowman, Howard, Univ Kent, Sch Comp, Canterbury CT2 7NF, Kent, England.}},
DOI = {{10.1093/nc/niaa022}},
Article-Number = {{niaa022}},
EISSN = {{2057-2107}},
Keywords = {{conscious pop-out; prediction error minimization; global neuronal
   workspace breakthrough}},
Keywords-Plus = {{PERCEIVED CLARITY; COMPONENT; CONSCIOUSNESS; DISORDERS; ATTENTION;
   KNOWLEDGE; RESPONSES; CORTEX; MEMORY}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Biological}},
Author-Email = {{LXB681@student.bham.ac.uk}},
Funding-Acknowledgement = {{Medical Research Council IMPACT Doctoral Training Programme at the
   University of Birmingham; Medical Research Council New Investigator
   Research Grant {[}MR/P013228/1]}},
Funding-Text = {{This work was supported by generous funding from the Medical Research
   Council IMPACT Doctoral Training Programme at the University of
   Birmingham (Scholarship to L.B.) and a Medical Research Council New
   Investigator Research Grant (MR/P013228/1; Principal investigator:
   D.C.).}},
Cited-References = {{Alsufyani A, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13279.
   Aru J, 2012, NEUROSCI BIOBEHAV R, V36, P737, DOI 10.1016/j.neubiorev.2011.12.003.
   Atkinson RC, 1974, CONT DEV MATH PSYCHO, Vxiii, P299.
   Auksztulewicz R, 2015, CEREB CORTEX, V25, P4273, DOI 10.1093/cercor/bhu323.
   Bekinschtein TA, 2009, NAT NEUROSCI, V12, P1343, DOI 10.1038/nn.2391.
   Beukema S, 2016, NEUROIMAGE-CLIN, V12, P359, DOI 10.1016/j.nicl.2016.08.003.
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577.
   Bornkessel-Schlesewsky I, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00298.
   Bowman H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054258.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222.
   Dehaene S, 2011, RES PER NEUROSCI, P1, DOI 10.1007/978-3-642-18015-6.
   Dehaene S, 1998, NATURE, V395, P597, DOI 10.1038/26967.
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009.
   DONCHIN E, 1988, BEHAV BRAIN SCI, V11, P357, DOI 10.1017/S0140525X00058027.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Haatveit BC, 2010, J CLIN EXP NEUROPSYC, V32, P871, DOI 10.1080/13803391003596421.
   Heilbron M, 2018, NEUROSCIENCE, V389, P54, DOI 10.1016/j.neuroscience.2017.07.061.
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460.
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280.
   Hohwy J, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00096.
   Ibanez A, 2006, BRAIN LANG, V98, P264, DOI 10.1016/j.bandl.2006.05.005.
   JASP Team, JASP VERS 0 7 1 COMP.
   Jeffreys H, 1961, THEORY PROBABILITY.
   Kok P, 2012, CEREB CORTEX, V22, P2197, DOI 10.1093/cercor/bhr310.
   Kotchoubey B, 2005, CLIN NEUROPHYSIOL, V116, P2441, DOI 10.1016/j.clinph.2005.03.028.
   KUTAS M, 1984, ANN NY ACAD SCI, V425, P236, DOI 10.1111/j.1749-6632.1984.tb23540.x.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024.
   McGettigan C, 2012, TRENDS COGN SCI, V16, P269, DOI 10.1016/j.tics.2012.04.006.
   Mognon A, 2011, PSYCHOPHYSIOLOGY, V48, P229, DOI 10.1111/j.1469-8986.2010.01061.x.
   Morey RD, BAYESFACTOR VERSION.
   Murzin V, 2013, J NEUROSCI METH, V218, P96, DOI 10.1016/j.jneumeth.2013.05.001.
   Nolan H, 2010, J NEUROSCI METH, V192, P152, DOI 10.1016/j.jneumeth.2010.07.015.
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/156869.
   Paczynski M, 2012, J MEM LANG, V67, P426, DOI 10.1016/j.jml.2012.07.003.
   Pitts MA, 2014, NEUROIMAGE, V101, P337, DOI 10.1016/j.neuroimage.2014.07.024.
   Popov T, 2018, NEUROIMAGE, V181, P728, DOI 10.1016/j.neuroimage.2018.07.067.
   Rama P, 2010, NEUROSCI LETT, V474, P88, DOI 10.1016/j.neulet.2010.03.012.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Ritchey M, 2015, ELIFE, V4, DOI 10.7554/eLife.05025.
   Robinson SE, 1999, RECENT ADV BIOMAGNET, P302.
   Rohaut B, 2015, NEUROPSYCHOLOGIA, V66, P279, DOI 10.1016/j.neuropsychologia.2014.10.014.
   Schelonka K, 2017, CONSCIOUS COGN, V54, P56, DOI 10.1016/j.concog.2017.04.009.
   Sergent C, 2005, NAT NEUROSCI, V8, P1391, DOI 10.1038/nn1549.
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303.
   SKRANDIES W, 1990, Brain Topography, V3, P137, DOI 10.1007/BF01128870.
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Sokoliuk R, 2019, J NEUROSCI, V39, P7183, DOI 10.1523/JNEUROSCI.1993-18.2019.
   Sussman E, 2001, COGNITIVE BRAIN RES, V12, P431, DOI 10.1016/S0926-6410(01)00067-2.
   Tadel F, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/879716.
   van Gaal S, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0212.
   vanDrongelen W, 1996, BRAIN TOPOGR, V9, P39, DOI 10.1007/BF01191641.
   VanVeen BD, 1997, IEEE T BIO-MED ENG, V44, P867, DOI 10.1109/10.623056.
   von Kriegstein K, 2003, COGNITIVE BRAIN RES, V17, P48, DOI 10.1016/S0926-6410(03)00079-X.
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012.
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035.
   Yonelinas AP, 1997, RECOLLECTION FAMILIA.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{NEUROSCI. CONSCIOUS.}},
Doc-Delivery-Number = {{OL4VP}},
Unique-ID = {{ISI:000585340000001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000576564600001,
Author = {Bieck, Richard and Heuermann, Katharina and Pirlich, Markus and Neumann,
   Juliane and Neumuth, Thomas},
Title = {{Language-based translation and prediction of surgical navigation steps
   for endoscopic wayfinding assistance in minimally invasive surgery}},
Journal = {{INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY}},
Year = {{2020}},
Volume = {{15}},
Number = {{12}},
Pages = {{2089-2100}},
Month = {{DEC}},
Abstract = {{Purpose In the context of aviation and automotive navigation technology,
   assistance functions are associated with predictive planning and
   wayfinding tasks. In endoscopic minimally invasive surgery, however,
   assistance so far relies primarily on image-based localization and
   classification. We show that navigation workflows can be described and
   used for the prediction of navigation steps. Methods A natural
   description vocabulary for observable anatomical landmarks in endoscopic
   images was defined to create 3850 navigation workflow sentences from 22
   annotated functional endoscopic sinus surgery (FESS) recordings.
   Resulting FESS navigation workflows showed an imbalanced data
   distribution with over-represented landmarks in the ethmoidal sinus. A
   transformer model was trained to predict navigation sentences in
   sequence-to-sequence tasks. The training was performed with the Adam
   optimizer and label smoothing in a leave-one-out cross-validation study.
   The sentences were generated using an adapted beam search algorithm with
   exponential decay beam rescoring. The transformer model was compared to
   a standard encoder-decoder-model, as well as HMM and LSTM baseline
   models. Results The transformer model reached the highest prediction
   accuracy for navigation steps at 0.53, followed by 0.35 of the LSTM and
   0.32 for the standard encoder-decoder-network. With an accuracy of
   sentence generation of 0.83, the prediction of navigation steps at
   sentence-level benefits from the additional semantic information. While
   standard class representation predictions suffer from an imbalanced data
   distribution, the attention mechanism also considered underrepresented
   classes reasonably well. Conclusion We implemented a natural
   language-based prediction method for sentence-level navigation steps in
   endoscopic surgery. The sentence-level prediction method showed a
   potential that word relations to navigation tasks can be learned and
   used for predicting future steps. Further studies are needed to
   investigate the functionality of path prediction. The prediction
   approach is a first step in the field of visuo-linguistic navigation
   assistance for endoscopic minimally invasive surgery.}},
Publisher = {{SPRINGER HEIDELBERG}},
Address = {{TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bieck, R (Corresponding Author), Univ Leipzig, Innovat Ctr Comp Assisted Surg ICCAS, Semmelweisstr 14, D-04103 Leipzig, Germany.
   Bieck, Richard; Neumann, Juliane; Neumuth, Thomas, Univ Leipzig, Innovat Ctr Comp Assisted Surg ICCAS, Semmelweisstr 14, D-04103 Leipzig, Germany.
   Heuermann, Katharina; Pirlich, Markus, Univ Leipzig, Dept Ear Nose \& Throat Surg, Med Ctr, Leipzig, Germany.}},
DOI = {{10.1007/s11548-020-02264-2}},
Early Access Date = {{OCT 2020}},
ISSN = {{1861-6410}},
EISSN = {{1861-6429}},
Keywords = {{Natural language processing; Endoscopic navigation; Machine translation;
   Workflow prediction; Deep learning; Attention networks; FESS}},
Keywords-Plus = {{RECOGNITION}},
Research-Areas = {{Engineering; Radiology, Nuclear Medicine \& Medical Imaging; Surgery}},
Web-of-Science-Categories  = {{Engineering, Biomedical; Radiology, Nuclear Medicine \& Medical Imaging;
   Surgery}},
Author-Email = {{Richard.bieck@medizin.uni-leipzig.de}},
Funding-Acknowledgement = {{Projekt DEAL; German Federal Ministry of Education and Research (BMBF)
   in the strategic innovation program ``KMU
   Innovativ-Mensch-Technik-Interaktion{''}Federal Ministry of Education \&
   Research (BMBF) {[}16SV8017]}},
Funding-Text = {{Open Access funding enabled and organized by Projekt DEAL. This work is
   funded by the German Federal Ministry of Education and Research (BMBF)
   in the strategic innovation program ``KMU
   Innovativ-Mensch-Technik-Interaktion{''} under the grant number
   16SV8017.}},
Cited-References = {{Ahmad J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0836-y.
   Anderson P, 2018, ARXIV171107280CS.
   Bagnall A, 2015, IEEE T KNOWL DATA EN, V27, P2522, DOI 10.1109/TKDE.2015.2416723.
   Bodenstedt S, 2017, ARXIV170203684CS.
   Bodenstedt S, 2019, INT J COMPUT ASS RAD, V14, P1089, DOI 10.1007/s11548-019-01966-6.
   Chan W, 2015, ARXIV150801211CSSTAT.
   Devlin J, 2019, ARXIV181004805CS.
   Franke S, 2013, J BIOMED INFORM, V46, P152, DOI 10.1016/j.jbi.2012.10.002.
   Froehlich J, 2008, SAE WORLD C EXH, P2008, DOI 10.4271/2008-01-0201.
   Fuentes-Hurtado F, 2019, INT J COMPUT ASS RAD, V14, P1247, DOI 10.1007/s11548-019-02003-2.
   Funke I, 2019, INT J COMPUT ASS RAD, V14, P1217, DOI 10.1007/s11548-019-01995-1.
   Gowda T, 2020, ARXIV200402334CSSTAT.
   He Q, 2020, INT J COMPUT ASS RAD, V15, P1085, DOI 10.1007/s11548-020-02148-5.
   Katic D, 2013, PROC SPIE, V8671, DOI 10.1117/12.2007895.
   Klein G, 2017, ARXIV170102810CS.
   Lalys F, 2014, INT J COMPUT ASS RAD, V9, P495, DOI 10.1007/s11548-013-0940-5.
   Leonard S, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217279.
   Lin C. Y., 2004, P 42 ANN M ASS COMP, P605, DOI DOI 10.3115/1218955.1219032.
   Luo XB, 2018, ANNU REV BIOMED ENG, V20, P221, DOI {[}10.1146/annurev-bioeng-062117-120917, 10.1146/annurev-bioeng-062117120917].
   Nakawala H, 2019, INT J COMPUT ASS RAD, V14, P685, DOI 10.1007/s11548-018-1882-8.
   Neumuth T, 2006, LECT NOTES COMPUT SC, V4080, P602.
   Padoy N, 2012, MED IMAGE ANAL, V16, P632, DOI 10.1016/j.media.2010.10.001.
   Paszke A, PYTORCH IMPERATIVE S, P12.
   Ramalingam N, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9496.
   Siemoleit S, 2017, JOWO, V2050, P5.
   Sinha A, 2018, LECT NOTES COMPUT SC, V11073, P64, DOI 10.1007/978-3-030-00937-3\_8.
   Speidel S, 2020, HDB MED IMAGE COMPUT, P721.
   Szegedy C, 2015, ARXIV151200567CS.
   Tanzi L, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2136.
   Vaswani A, 2017, ARXIV170603762CS.
   Wei J, 2019, ARXIV190111196CS.
   Williams I, 2018, INTERSPEECH, P2227, DOI 10.21437/Interspeech.2018-2416.
   Ye ML, 2014, LECT NOTES COMPUT SC, V8674, P316, DOI 10.1007/978-3-319-10470-6\_40.
   Yepes JL, 2007, J GUID CONTROL DYNAM, V30, P370, DOI 10.2514/1.26750.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Int. J. Comput. Assist. Radiol. Surg.}},
Doc-Delivery-Number = {{OS6LX}},
Unique-ID = {{ISI:000576564600001}},
OA = {{Other Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000565624900020,
Author = {Watkins, Greg D. and Swanson, Brett A. and Suaning, Gregg J.},
Title = {{Prediction of Individual Cochlear Implant Recipient Speech Perception
   With the Output Signal to Noise Ratio Metric}},
Journal = {{EAR AND HEARING}},
Year = {{2020}},
Volume = {{41}},
Number = {{5}},
Pages = {{1270-1281}},
Month = {{SEP-OCT}},
Abstract = {{Objectives: A cochlear implant (CI) implements a variety of sound
   processing algorithms that seek to improve speech intelligibility.
   Typically, only a small number of parameter combinations are evaluated
   with recipients but the optimal configuration may differ for
   individuals. The present study evaluates a novel methodology which uses
   the output signal to noise ratio (OSNR) to predict complete psychometric
   functions that relate speech recognition to signal to noise ratio for
   individual CI recipients. Design: Speech scores from sentence-in-noise
   tests in a ``reference{''} condition were mapped to OSNR and a
   psychometric function was fitted. The reference variability was defined
   as the root mean square error between the reference scores and the
   fitted curve. To predict individual scores in a different condition,
   OSNRs in that condition were calculated and the corresponding scores
   were read from the reference psychometric function. In a retrospective
   experiment, scores were predicted for each condition and subject in
   three existing data sets of sentence scores. The prediction error was
   defined as the root mean square error between observed and predicted
   scores. In data set 1, sentences were mixed with 20 talker babble or
   speech weighted noise and presented at 65 dB sound pressure level (SPL).
   An adaptive test procedure was used. Sound processing was advanced
   combinatorial encoding (ACE, Cochlear Limited) and ACE with ideal binary
   mask processing, with five different threshold settings. In data set 2,
   sentences were mixed with speech weighted noise, street-side city noise
   or cocktail party noise and presented at 65 dB SPL. An adaptive test
   procedure was used. Sound processing was ACE and ACE with two different
   noise reduction schemes. In data set 3, sentences were mixed with
   four-talker babble at two input SNRs and presented at levels of 55-89 dB
   SPL. Sound processing utilised three different automatic gain control
   configurations. Results: For data set 1, the median of individual
   prediction errors across all subjects, noise types and conditions, was
   12\% points, slightly better than the reference variability. The OSNR
   prediction method was inaccurate for the specific condition with a gain
   threshold of +10 dB. For data set 2, the median of individual prediction
   errors was 17\% points and the reference variability was 11\% points.
   For data set 3, the median prediction error was 9\% points and the
   reference variability was 7\% points. A Monte Carlo simulation found
   that the OSNR prediction method, which used reference scores and OSNR to
   predict individual scores in other conditions, was significantly more
   accurate (p< 0.01) than simply using reference scores as predictors.
   Conclusions: The results supported the hypothesis that the OSNR
   prediction method could accurately predict individual recipient scores
   for a range of algorithms and noise types, for all but one condition.
   The medians of the individual prediction errors for each data set were
   accurate within 6\% points of the reference variability and compared
   favourably with prediction methodologies in other recent studies.
   Overall, the novel OSNR-based prediction method shows promise as a tool
   to assist researchers and clinicians in the development or fitting of CI
   sound processors.}},
Publisher = {{LIPPINCOTT WILLIAMS \& WILKINS}},
Address = {{TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Watkins, GD (Corresponding Author), Univ Sydney, Sch Biomed Engn, Fac Engn, Sydney, NSW 2006, Australia.
   Watkins, Greg D.; Suaning, Gregg J., Univ Sydney, Sch Biomed Engn, Fac Engn, Sydney, NSW 2006, Australia.
   Swanson, Brett A., Cochlear Ltd, Sydney, NSW, Australia.
   Suaning, Gregg J., Univ Sydney, Sydney Nano Inst, Sydney, NSW, Australia.
   Suaning, Gregg J., Univ Sydney, Brain \& Mind Ctr, Sydney, NSW, Australia.}},
DOI = {{10.1097/AUD.0000000000000846}},
ISSN = {{0196-0202}},
EISSN = {{1538-4667}},
Keywords = {{Cochlear implants; Individual prediction; Objective measure; Output
   signal to noise; Prediction; Speech intelligibility}},
Keywords-Plus = {{RECEPTION THRESHOLD; TRANSMISSION INDEX; INTELLIGIBILITY; USERS}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Otorhinolaryngology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Otorhinolaryngology}},
Author-Email = {{greg.watkins@sydney.edu.au}},
ORCID-Numbers = {{Watkins, Greg/0000-0003-4790-6486}},
Funding-Acknowledgement = {{Australian Government Research Training Program ScholarshipAustralian
   GovernmentDepartment of Industry, Innovation and Science}},
Funding-Text = {{G. D. W. studies are supported by an Australian Government Research
   Training Program Scholarship. G. D. W. received partial conference
   travel funding from the Conference of Implantable Auditory Prostheses
   (CIAP) to present of aspects of this research at CIAP 2019. There is no
   publication from CIAP 2019. B. A. S. is employed by Cochlear Limited.}},
Cited-References = {{American National Standards Institute, 1997, METH CALC SPEECH INT.
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189.
   Boyle PJ, 2013, EAR HEARING, V34, P203, DOI 10.1097/AUD.0b013e31826a8e82.
   Dawson PW, 2013, EAR HEARING, V34, P592, DOI 10.1097/AUD.0b013e31828576fb.
   Dawson PW, 2011, EAR HEARING, V32, P382, DOI 10.1097/AUD.0b013e318201c200.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203.
   Hu GN, 2004, IEEE T NEURAL NETWOR, V15, P1135, DOI 10.1109/TNN.2004.832812.
   Hu Y, 2007, J ACOUST SOC AM, V122, pEL128, DOI 10.1121/1.2772401.
   Jurgens T, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193842.
   Khing PP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082263.
   Khing PP, 2013, INT CONF ACOUST SPEE, P8061, DOI 10.1109/ICASSP.2013.6639235.
   Kressner AA, 2016, J ACOUST SOC AM, V139, P800, DOI 10.1121/1.4941567.
   Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Mauger SJ, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/6/065007.
   Mauger SJ, 2012, J ACOUST SOC AM, V131, P327, DOI 10.1121/1.3665990.
   MCAULAY RJ, 1980, IEEE T ACOUST SPEECH, V28, P137, DOI 10.1109/TASSP.1980.1163394.
   MCDERMOTT HJ, 1992, J ACOUST SOC AM, V91, P3367, DOI 10.1121/1.402826.
   Montazeri V, 2018, J ACOUST SOC AM, V144, pEL59, DOI 10.1121/1.5046442.
   Montazeri V, 2017, SPEECH COMMUN, V89, P47, DOI 10.1016/j.specom.2017.02.007.
   Patrick James F, 2006, Trends Amplif, V10, P175, DOI 10.1177/1084713806296386.
   Petrie A, 2009, MED STAT GLANCE.
   PLOMP R, 1979, AUDIOLOGY, V18, P43.
   Prodi N, 2019, APPL ACOUST, V152, P63, DOI 10.1016/j.apacoust.2019.03.026.
   Rhebergen KS, 2009, J ACOUST SOC AM, V126, P3236, DOI 10.1121/1.3257225.
   Santos JF, 2013, SPEECH COMMUN, V55, P815, DOI 10.1016/j.specom.2013.04.001.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Wang DK, 2019, INT CONF OPTIC MEMS, P180, DOI 10.1109/OMN.2019.8925039.
   Watkins Greg D, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P1206, DOI 10.1109/EMBC.2018.8512471.
   Watkins GD, 2018, EAR HEARING, V39, P958, DOI 10.1097/AUD.0000000000000556.
   Watkins GD, 2016, IEEE ENG MED BIO, P4715, DOI 10.1109/EMBC.2016.7591780.
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544.
   Yousefian N, 2012, J ACOUST SOC AM, V132, P3399, DOI 10.1121/1.4754539.
   Zirn S, 2016, INT J AUDIOL, V55, P295, DOI 10.3109/14992027.2015.1128124.}},
Number-of-Cited-References = {{38}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Ear Hear.}},
Doc-Delivery-Number = {{NI8VL}},
Unique-ID = {{ISI:000565624900020}},
DA = {{2020-12-06}},
}

@article{ ISI:000572851800005,
Author = {Corps, Ruth E. and Rabagliati, Hugh},
Title = {{How top-down processing enhances comprehension of noise-vocoded speech:
   Predictions about meaning are more important than predictions about form}},
Journal = {{JOURNAL OF MEMORY AND LANGUAGE}},
Year = {{2020}},
Volume = {{113}},
Month = {{AUG}},
Abstract = {{Listeners quickly learn to understand speech that has been distorted,
   and this process is enhanced when comprehension is constrained by
   higher-level knowledge. In three experiments, we investigated whether
   this knowledge enhances comprehension of distorted speech because it
   allows listeners to predict (1) the meaning of the distorted utterance,
   or (2) the lower-level wordforms. Participants listened to
   question-answer sequences, in which questions were clearly-spoken but
   answers were noise-vocoded. Comprehension (Experiment 1) and learning
   (Experiment 2) were enhanced when listeners could use the question to
   predict the semantics of the distorted answer, but were not enhanced by
   predictions of answer form. Form predictions enhanced comprehension only
   when questions and answers were significantly separated by time and
   intervening linguistic material (Experiment 3). Together, these results
   suggest that high-level semantic predictions enhance comprehension and
   learning, with form predictions playing only a minimal role.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Corps, RE (Corresponding Author), Univ Edinburgh, Sch Philosophy Psychol \& Language Sci, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.
   Corps, Ruth E.; Rabagliati, Hugh, Univ Edinburgh, Sch Philosophy Psychol \& Language Sci, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.}},
DOI = {{10.1016/j.jml.2020.104114}},
Article-Number = {{104114}},
ISSN = {{0749-596X}},
EISSN = {{1096-0821}},
Keywords = {{Perceptual learning; Noise-vocoding; Prediction; Speech; Dialogue}},
Keywords-Plus = {{PERCEIVED CLARITY; RECOGNITION; INFORMATION; FEEDBACK}},
Research-Areas = {{Linguistics; Psychology}},
Web-of-Science-Categories  = {{Linguistics; Psychology; Psychology, Experimental}},
Author-Email = {{Ruth.Corps@ed.ac.uk}},
Funding-Acknowledgement = {{Economic and Social Research CouncilEconomic \& Social Research Council
   (ESRC) {[}ES/L01064X/1, ES/J500136/1]; Leverhulme TrustLeverhulme Trust
   {[}RPG-2014-253]}},
Funding-Text = {{Ruth Corps was supported by the Economic and Social Research Council
   {[}grant number ES/J500136/1]. Hugh Rabagliati was supported by grants
   from the Economic and Social Research Council {[}ES/L01064X/1] and the
   Leverhulme Trust {[}RPG-2014-253]. We thank Matthew Davis for sharing
   Matlab scripts used for vocoding.}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001.
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01.
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577.
   Christiansen M. H., 2016, BEHAV BRAIN SCI, V31, P489.
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131.
   Davis MH, 2011, J COGNITIVE NEUROSCI, V23, P3914, DOI {[}10.1097/JOM.0b013e31820805d5, 10.1162/jocn\_a\_00084].
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222.
   Davis MH, 2003, J NEUROSCI, V23, P3423.
   de Leeuw JR, 2015, BEHAV RES METHODS, V47, P1, DOI 10.3758/s13428-014-0458-y.
   DeCarlo LT, 1998, PSYCHOL METHODS, V3, P186, DOI 10.1037/1082-989X.3.2.186.
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9.
   Dupoux E, 1997, J EXP PSYCHOL HUMAN, V23, P914, DOI 10.1037/0096-1523.23.3.914.
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940.
   Giraud AL, 2004, CEREB CORTEX, V14, P247, DOI 10.1093/cercor/bhg124.
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585.
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460.
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007.
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572.
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008.
   Magnuson JS, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00369.
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   McGettigan C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00018.
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000\_79.
   MEYER AS, 1991, J EXP PSYCHOL LEARN, V17, P1146, DOI 10.1037/0278-7393.17.6.1146.
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823.
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241.
   Pickering MJ, 2018, PSYCHOL BULL, V144, P1002, DOI 10.1037/bul0000158.
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303.
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562.
   Signoret C, 2018, J EXP PSYCHOL HUMAN, V44, P277, DOI 10.1037/xhp0000442.
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035.
   Wright DB, 2009, BEHAV RES METHODS, V41, P257, DOI 10.3758/BRM.41.2.257.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{J. Mem. Lang.}},
Doc-Delivery-Number = {{NT3NK}},
Unique-ID = {{ISI:000572851800005}},
DA = {{2020-12-06}},
}

@article{ ISI:000547079100001,
Author = {Shang, Xiaoqi and Xie, Guixia},
Title = {{Aptitude for interpreting revisited: predictive validity of recall
   across languages}},
Journal = {{INTERPRETER AND TRANSLATOR TRAINER}},
Year = {{2020}},
Volume = {{14}},
Number = {{3}},
Pages = {{344-361}},
Month = {{JUL 2}},
Abstract = {{As a form of aptitude testing for interpreting, recall across languages
   has long been considered as a valid means of assessing candidates'
   linguistic, cognitive and communicative abilities. However, most of the
   existing research on this topic is only derived from the consensus among
   or the professional experience of interpreting researchers,
   practitioners and trainers. There is still a paucity of grounded
   research on the validity of the recall tests. Empirical research on this
   topic remains scant. To fill this gap, the present study adopts a
   data-driven approach to exploring the predictive validity of the recall
   tests as a whole as well as to what extent each of the four assessment
   parameters (fidelity, language, coherence and delivery) can predict the
   candidates' end-of-year interpreting performance in the Chinese context.
   Data analysis suggests that candidates' performance on the recall tests
   could predict their overall interpreting performance in both language
   directions, with the criterion of language as a more powerful predictor
   (beta(1) = .45) than the criterion of fidelity (beta(2) = .30) in the
   C-E recall and fidelity as a more powerful predictor (beta(1) = .44)
   than language (beta(2) = .31) in the E-C recall. Implications of the
   findings of this study were also discussed.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Xie, GX (Corresponding Author), Sun Yat Sen Univ, Sch Int Studies, Zhuhai, Xiangzhou, Peoples R China.
   Shang, Xiaoqi, Shenzhen Univ, Sch Foreign Languages, Shenzhen, Nanshan, Peoples R China.
   Xie, Guixia, Sun Yat Sen Univ, Sch Int Studies, Zhuhai, Xiangzhou, Peoples R China.}},
DOI = {{10.1080/1750399X.2020.1790970}},
Early Access Date = {{JUL 2020}},
ISSN = {{1750-399X}},
EISSN = {{1757-0417}},
Keywords = {{Aptitude testing; recall across languages; assessment parameters;
   predictive validity}},
Research-Areas = {{Linguistics}},
Web-of-Science-Categories  = {{Linguistics; Language \& Linguistics}},
Author-Email = {{xiegx@mail.sysu.edu.cn}},
Cited-References = {{Angelelli CV, 2009, AM TRANSLAT AS SCH, V14, P1.
   Angelelli CV, 2007, TRANSLATOR, V13, P63, DOI 10.1080/13556509.2007.10799229.
   Arjona-Tseng E., 1994, BRIDGING GAP EMPIRIC, P69.
   Baker D., 1989, LANGUAGE TESTING CRI.
   Bowen D., 1989, THEORETICAL PRACTICA, P109.
   Boyle J., 2007, ED TESTING COMPETENC.
   Brannen J, 2005, MIXED METHODS RES DI.
   Carroll J. B., 1978, LANGUAGE INTERPRETAT, P119.
   Cheng YH, 2007, COMM COM INF SC, V2, P1.
   Congdon PJ, 2000, J EDUC MEAS, V37, P163, DOI 10.1111/j.1745-3984.2000.tb01081.x.
   Cronbach L. J., 1977, APTITUDES INSTRUCTIO.
   Dodds J. M., 1990, INTERPRETERS NEWSLET, V8, P41.
   Donovan C., 2003, FORUM, V1, P17.
   Fulcher G., 2012, ROUTLEDGE HDB LANGUA.
   GERVER D, 1984, J OCCUP PSYCHOL, V57, P17, DOI 10.1111/j.2044-8325.1984.tb00144.x.
   GERVER David., 1989, META, V34, P724, DOI DOI 10.7202/002884AR.
   Grbic Nadja, 2015, ROUTLEDGE ENCY INTER, P333.
   Johnson R. L., 2009, ASSESSING PERFORMANC.
   Keiser W., 1965, AIIC C ENS INT, P18.
   Lambert S., 1992, INTERPRETERS NEWSLET, V4, P25.
   Linacre J. M., 2005, USERS GUIDE FACETS R.
   Longley P., 1989, THEORETICAL PRACTICA, P105.
   Lumley T., 1995, LANG TEST, V12, P54, DOI DOI 10.1177/026553229501200104.
   Moser-Mercer B, 1994, BRIDGING GAP EMPIRIC, P57, DOI DOI 10.1075/BTL.3.07M0S.
   MOSERMERCER B, 1985, META, V30, P97, DOI DOI 10.7202/003631AR.
   Pochhacker F, 2011, INTERPRETING, V13, P106, DOI 10.1075/intp.13.1.07poc.
   Qin X., 2003, STAT ANAL QUANTITATI.
   Qiu KJ, 2015, IEEE INT CON AUTO SC, P200, DOI 10.1109/CoASE.2015.7294062.
   Russo M, 2014, INTERPRETING, V16, P1, DOI 10.1075/intp.16.1.01rus.
   Russo M, 2011, INTERPRETING, V13, P5, DOI 10.1075/intp.13.1.02rus.
   Russo Mariachiara, 1989, INTERPRETERS NEWSLET, V2, P57.
   Russo Mariachiara, 1993, INTERPRETERS NEWSLET, V5, P68.
   Sawyer D., 2004, FUNDAMENTALS ASPECTS.
   Schjoldager A., 1995, TEACHING TRANSLATION, P187, DOI DOI 10.1075/BTL.16.26SCH.
   Setton R., 2016, C INT TRAIN GUID.
   Shang X., 2018, THESIS.
   Shlesinger M, 2011, INTERPRETING, V13, P1, DOI 10.1075/intp.13.1.01int.
   Shohamy E., 1985, PRACTICAL HDB LANGUA.
   Sunnari M., 2002, TEACHING SIMULTANEOU, P23.
   Timarova S, 2009, AM TRANSLAT AS SCH, V14, P225.
   Tryuk M., 2002, TRANSLATION MEANIN 6, P421.
   Weigle S. C., 2002, ASSESSING WRITING.
   Xing X., 2015, FOREIGN LANGUAGE TES, V3, P9.
   Xu H., 2013, STAT ANAL RES 2 LANG.}},
Number-of-Cited-References = {{44}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Interpret. Transl. Train.}},
Doc-Delivery-Number = {{OM4YT}},
Unique-ID = {{ISI:000547079100001}},
DA = {{2020-12-06}},
}

@article{ ISI:000541744500001,
Author = {Hayiou-Thomas, Marianna E. and Smith-Woolley, Emily and Dale, Philip S.},
Title = {{Breadth versus depth: Cumulative risk model and continuous measure
   prediction of poor language and reading outcomes at 12}},
Journal = {{DEVELOPMENTAL SCIENCE}},
Abstract = {{This study examines whether, and how, multiple risks in early childhood
   are associated with an increased likelihood of a poor language or
   literacy outcome in early adolescence. Using data from 210 participants
   in the longitudinal Twins Early Developmental Study, we focus on the
   following risk factors at age 4: family risk, and poor language, speech,
   emergent literacy and nonverbal skills. The outcomes of interest at age
   12 are language, reading fluency and reading comprehension. We contrast
   a `cumulative risk' model, counting the presence or absence of each risk
   factor (breadth), with a model that also considers the severity of the
   early deficits (depth). A `cumulative risk index' correlated modestly
   but significantly with outcome (r = 0.32-0.40). Odds ratios confirmed
   that having many risk factors (3-6) confers a higher probability of a
   poor outcome (OR 7.86-17.71) than having one or two (OR 3.65-7.28).
   Logistic regression models showed that predictive validity is not
   improved by including information about the severity of each deficit.
   Even with rich information on children's risk status at age 4, we can
   make only a moderately accurate prediction of the likelihood of a
   language or literacy disorder 8 years later (Area Under the Curve =
   0.74-0.84; Positive Predictive Value = 0.33-0.55, Negative Predictive
   Value = 0.86-0.91). Taken together, and consistent with the idea of
   `cumulative risk', these results suggest that the breadth of risk is a
   core predictor of outcome, and furthermore, that the severity of early
   deficits does not add significantly to this prediction.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Hayiou-Thomas, ME (Corresponding Author), Univ York, Dept Psychol, York, N Yorkshire, England.
   Hayiou-Thomas, Marianna E., Univ York, Dept Psychol, York, N Yorkshire, England.
   Smith-Woolley, Emily, Physiol Soc, London, England.
   Dale, Philip S., Univ New Mexico, Dept Speech \& Hearing Sci, Albuquerque, NM 87131 USA.}},
DOI = {{10.1111/desc.12998}},
Early Access Date = {{JUN 2020}},
Article-Number = {{e12998}},
ISSN = {{1363-755X}},
EISSN = {{1467-7687}},
Keywords = {{language; outcome; prediction; reading; risk}},
Keywords-Plus = {{FOLLOW-UP; LITERACY DEVELOPMENT; COGNITIVE-ABILITIES; CHILDREN;
   IMPAIRMENT; SPEECH; DYSLEXIA; SKILLS; STABILITY; ETIOLOGY}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Developmental; Psychology, Experimental}},
Author-Email = {{emma.hayiou-thomas@york.ac.uk}},
ResearcherID-Numbers = {{Dale, Philip S/A-2254-2009
   }},
ORCID-Numbers = {{Dale, Philip S/0000-0002-7697-8510
   Hayiou-Thomas, Emma/0000-0003-1163-2671}},
Funding-Acknowledgement = {{Medical Research CouncilMedical Research Council UK (MRC) {[}G0901245,
   MR/M021475/1]}},
Funding-Text = {{Medical Research Council, Grant/Award Number: G0901245 and MR/M021475/1}},
Cited-References = {{Armstrong R, 2018, J SPEECH LANG HEAR R, V61, DOI {[}10.1044/2018\_JSLHR-L-17-0210, 10.1123/jsr.2018-0216].
   BEITCHMAN JH, 1994, J AM ACAD CHILD PSY, V33, P1322, DOI 10.1097/00004583-199411000-00015.
   BIRD J, 1995, J SPEECH HEAR RES, V38, P446, DOI 10.1044/jshr.3802.446.
   Bishop DVM, 2008, GENES BRAIN BEHAV, V7, P365, DOI 10.1111/j.1601-183X.2007.00360.x.
   Bishop DVM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158753.
   Bishop DVM, 2009, CHILD DEV, V80, P593, DOI 10.1111/j.1467-8624.2009.01281.x.
   BISHOP DVM, 1990, J CHILD PSYCHOL PSYC, V31, P1027, DOI 10.1111/j.1469-7610.1990.tb00844.x.
   Bornstein MH, 2016, J CHILD PSYCHOL PSYC, V57, P1434, DOI 10.1111/jcpp.12632.
   Caravolas M, 2012, PSYCHOL SCI, V23, P678, DOI 10.1177/0956797611434536.
   Carroll JM, 2016, J CHILD PSYCHOL PSYC, V57, P750, DOI 10.1111/jcpp.12488.
   Carroll JM, 2014, DEVELOPMENTAL SCI, V17, P727, DOI 10.1111/desc.12153.
   Caspi A, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-016-0005.
   Catts HW, 2006, J SPEECH LANG HEAR R, V49, P278, DOI 10.1044/1092-4388(2006/023).
   Catts HW, 2005, J SPEECH LANG HEAR R, V48, P1378, DOI 10.1044/1092-4388(2005/096).
   Catts HW, 2002, J SPEECH LANG HEAR R, V45, P1142, DOI 10.1044/1092-4388(2002/093).
   Chow BWY, 2013, DEVELOPMENTAL SCI, V16, P260, DOI 10.1111/desc.12022.
   Dale PS, 2010, J SPEECH LANG HEAR R, V53, P982, DOI 10.1044/1092-4388(2009/09-0108).
   DALE PS, 2005, READING WRITING INTE, V18, P385, DOI DOI 10.1007/S11145-004-8130-Z.
   Dockrell J., 2007, ED CHILD PSYCHOL, V24, P14.
   ELLIOT CD, 1996, VERBAL COMPREHENSION.
   Evans GW, 2013, PSYCHOL BULL, V139, P1342, DOI 10.1037/a0031808.
   Flax JF, 2003, J SPEECH LANG HEAR R, V46, P530, DOI 10.1044/1092-4388(2003/043).
   Fuchs D, 2012, J LEARN DISABIL-US, V45, P217, DOI 10.1177/0022219412442154.
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940.
   GOAL plc, 2002, GOAL FORM ASS LIT KE.
   Goldman R., 1986, GOLDMAN FRISTOE TEST.
   HAMMILL DD, 1994, TEST ADOLESCENT ADUL.
   HANLEY JA, 1983, RADIOLOGY, V148, P839, DOI 10.1148/radiology.148.3.6878708.
   Haworth CMA, 2007, TWIN RES HUM GENET, V10, P554, DOI 10.1375/twin.10.4.554.
   Haworth CMA, 2013, TWIN RES HUM GENET, V16, P117, DOI 10.1017/thg.2012.91.
   Hayiou-Thomas ME, 2006, J CHILD LANG, V33, P339, DOI 10.1017/S0305000906007331.
   Hayiou-Thomas ME, 2017, J CHILD PSYCHOL PSYC, V58, P197, DOI 10.1111/jcpp.12648.
   Hayiou-Thomas ME, 2014, J SPEECH LANG HEAR R, V57, P850, DOI 10.1044/2013\_JSLHR-L-12-0240.
   Hayiou-Thomas ME, 2010, J SPEECH LANG HEAR R, V53, P311, DOI 10.1044/1092-4388(2009/07-0145).
   Hulme C, 2002, J EXP CHILD PSYCHOL, V82, P2, DOI 10.1006/jecp.2002.2670.
   Johnson CJ, 1999, J SPEECH LANG HEAR R, V42, P744, DOI 10.1044/jslhr.4203.744.
   Kamhi AG, 2012, LANGUAGE READING DIS.
   Kaplan E., 1999, WECHSLER INTELLIGENC.
   Koon S., 2014, 2014036 REL NAT CTR.
   Law J, 2009, J SPEECH LANG HEAR R, V52, P1401, DOI 10.1044/1092-4388(2009/08-0142).
   Leitao S, 2004, INT J LANG COMM DIS, V39, P245, DOI 10.1080/13682820310001619478.
   Markwardt F. C., 1997, PEABODY INDIVIDUAL A.
   McCarthy D., 1972, MCCARTHY SCALES CHIL.
   McKean C, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-1684.
   Nation K, 2004, J SPEECH LANG HEAR R, V47, P199, DOI 10.1044/1092-4388(2004/017).
   Norbury CF, 2017, J CHILD PSYCHOL PSYC, V58, P1092, DOI 10.1111/jcpp.12793.
   Olson RK, 2014, SCI STUD READ, V18, P38, DOI 10.1080/10888438.2013.800521.
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008.
   Pennington BF, 2012, J ABNORM PSYCHOL, V121, P212, DOI 10.1037/a0025823.
   Pennington BF, 2009, ANNU REV PSYCHOL, V60, P283, DOI 10.1146/annurev.psych.60.110707.163548.
   Peterson RL, 2009, J SPEECH LANG HEAR R, V52, P1175, DOI 10.1044/1092-4388(2009/08-0024).
   Puolakanaho A, 2007, J CHILD PSYCHOL PSYC, V48, P923, DOI 10.1111/j.1469-7610.2007.01763.x.
   Renfrew C., 1997, ACTION PICTURE TEST.
   Renfrew C. E., 1997, BUS STORY TEST.
   Rescorla L., 2013, LATE TALKERS.
   Rice ML, 2008, J SPEECH LANG HEAR R, V51, P394, DOI 10.1044/1092-4388(2008/029).
   Siegel LS, 2003, J LEARN DISABIL-US, V36, P2, DOI 10.1177/00222194030360010101.
   Snowling MJ, 2019, CHILD DEV, V90, pE548, DOI 10.1111/cdev.13216.
   Snowling MJ, 2016, J CHILD PSYCHOL PSYC, V57, P1360, DOI 10.1111/jcpp.12497.
   Snowling MJ, 2016, PSYCHOL BULL, V142, P498, DOI 10.1037/bul0000037.
   Stothard SE, 1998, J SPEECH LANG HEAR R, V41, P407, DOI 10.1044/jslhr.4102.407.
   Thompson PA, 2015, J CHILD PSYCHOL PSYC, V56, P976, DOI 10.1111/jcpp.12412.
   Tomblin JB, 2003, J SPEECH LANG HEAR R, V46, P1283, DOI 10.1044/1092-4388(2003/100).
   Torgesen J., 1999, TEST WORD READING EF.
   van Bergen E, 2014, J LEARN DISABIL-US, V47, P475, DOI 10.1177/0022219413479673.
   Viding E, 2003, J SPEECH LANG HEAR R, V46, P1271, DOI 10.1044/1092-4388(2003/099).
   Wiig E., 1989, TEST LANGUAGE COMPET.
   Woodcock W., 2001, WOODCOCKJOHNSON 3.}},
Number-of-Cited-References = {{68}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Dev. Sci.}},
Doc-Delivery-Number = {{MA2KD}},
Unique-ID = {{ISI:000541744500001}},
OA = {{Other Gold, Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000542949800001,
Author = {Buschmann, Anke and Ziegler, Christina},
Title = {{Predicting Language Outcomes of Late Talkers at 3 Years of Age}},
Journal = {{SPRACHE-STIMME-GEHOR}},
Year = {{2020}},
Volume = {{44}},
Number = {{2}},
Pages = {{E1-E7}},
Month = {{JUN}},
Abstract = {{Background The purpose of this study was to examine the language
   development of late talkers who had been identified at the age of 24
   months and showed continued language delay at 21/2 years. Another aim
   was to find prognostic factors that differentiate between children who
   catch up by the age of 3 years and those who do not. Method The
   predictive value of various language related and sociodemographic
   variables was assessed in a sample of 43 late-talking children using
   logistic regression analyses. Results At 3 years of age, 37 \% of the
   former late talkers had caught up, 28 \% showed language difficulties
   and 35 \% met the criteria of specific language impairment. Sentence
   production ability at 2 1/2 years proved to be a significant predictor.
   Almost all children with very low scores (T <= 35) in a standardized
   sentence production test at the age of 21/2 showed persisting language
   deficits at the age of 3. Discussion Children meeting the criteria of
   language delay at the age of 24 months should be reassessed at the age
   of 21/2 years with regard to their sentence production abilities. In
   case of considerable deficits, an early intervention needs to be
   implemented.}},
Publisher = {{GEORG THIEME VERLAG KG}},
Address = {{RUDIGERSTR 14, D-70469 STUTTGART, GERMANY}},
Type = {{Article}},
Language = {{German}},
Affiliation = {{Buschmann, A (Corresponding Author), ZEL Zentrum Entwicklung \& Lernen, Kaiserstr 36, D-69115 Heidelberg, Germany.
   Buschmann, Anke; Ziegler, Christina, ZEL Zentrum Entwicklung \& Lernen, Kaiserstr 36, D-69115 Heidelberg, Germany.}},
DOI = {{10.1055/a-0867-7927}},
ISSN = {{0342-0477}},
EISSN = {{1439-1260}},
Keywords = {{late talkers; language delay; specific language impairment; prediction}},
Keywords-Plus = {{LATE-TALKING; DELAY; CHILDREN; RISK}},
Research-Areas = {{Otorhinolaryngology; Rehabilitation}},
Web-of-Science-Categories  = {{Otorhinolaryngology; Rehabilitation}},
Author-Email = {{Buschmann@zel-heidelberg.de}},
Cited-References = {{Bello A, 2018, RES DEV DISABIL, V75, P40, DOI 10.1016/j.ridd.2018.02.006.
   Buschmann A, 2012, SPRACHE-STIMME-GEHOR, V36, P135, DOI 10.1055/s-0032-1316320.
   Buschmann A, 2017, ELTERNTRAINING FRUHE.
   Buschmann A, 2008, DEV MED CHILD NEUROL, V50, P223, DOI 10.1111/j.1469-8749.2008.02034.x.
   Dale PS, 2003, J SPEECH LANG HEAR R, V46, P544, DOI 10.1044/1092-4388(2003/044).
   Fisher EL, 2017, J SPEECH LANG HEAR R, V60, P2935, DOI 10.1044/2017\_JSLHR-L-16-0310.
   Geissmann H, 2013, KOMMUNIKATION SOZIAL.
   Grimm H, 2001, SETK 3 5 SPRACHENTWI.
   Grimm H, 2000, ELTERNFRAGEBOGEN FRU.
   Grimm H., 2000, SPRACHENTWICKLUNGSTE.
   Korpilahti P, 2016, INFANT BEHAV DEV, V42, P27, DOI 10.1016/j.infbeh.2015.08.008.
   Lyytinen P, 2001, J SPEECH LANG HEAR R, V44, P873, DOI 10.1044/1092-4388(2001/070).
   McKean C, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-1684.
   Peyre H, 2014, PEERJ, V2, DOI 10.7717/peerj.335.
   Reilly S, 2010, PEDIATRICS, V126, pE1530, DOI 10.1542/peds.2010-0254.
   Rescorla L, 2000, J CHILD LANG, V27, P293, DOI 10.1017/S030500090000413X.
   Rescorla L, 2011, DEV DISABIL RES REV, V17, P141, DOI 10.1002/ddrr.1108.
   Sachse S, 2009, KINDERARZTL PRAX, V80, P318.
   Van der Meulen B F, 2002, SCALES INFANT DEV 2.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Sprache-Stimme-Gehor}},
Doc-Delivery-Number = {{MB9XC}},
Unique-ID = {{ISI:000542949800001}},
DA = {{2020-12-06}},
}

@article{ ISI:000531571300004,
Author = {Kale, Swati and Kamble, Meghana Wadnerkar and Spalding, Nicola},
Title = {{Predictive validity of multiple mini interview scores for future
   academic and clinical placement performance in physiotherapy,
   occupational therapy and speech and language therapy programmes}},
Journal = {{INTERNATIONAL JOURNAL OF THERAPY AND REHABILITATION}},
Year = {{2020}},
Volume = {{27}},
Number = {{4}},
Month = {{APR 2}},
Abstract = {{Background/Aims Limited research exists on the predictive validity of
   multiple mini interviews when used during the selection process for
   physiotherapy, occupational therapy and speech and language therapy
   programmes. Traditional interviews were replaced by multiple mini
   interviews in the selection process for these three undergraduate
   programmes in one UK university. The purpose of secondary data analysis
   was to determine whether multiple mini interviews can predict academic
   and clinical placement performance during the first and second year of
   study.
   Methods Secondary data analysis was performed using the admissions data
   from 169 students. Data analysed comprised predictors (entry tariff, age
   and multiple mini interview scores) and outcomes (academic and placement
   achievement in years 1 and 2 over a period of 2 years from 2014 to
   2016).
   Results Multiple standard regression analyses revealed that, overall,
   multiple mini interview score was not a significant predictor of
   academic achievement or clinical placement performance in years 1 and 2
   for any of the three professions. Pearson's correlations indicated that
   age and entry tariff were frequently and significantly correlated with
   academic achievements for all cohorts.
   Conclusions Performance in the multiple mini interview is not a
   predictor of academic achievement or clinical placement performance in
   this specific cohort of students. Entry tariff showed a significant
   correlation with academic achievement. Additional studies with larger
   cohorts are recommended.}},
Publisher = {{MARK ALLEN GROUP}},
Address = {{ST JUDES CHURCH, DULWICH RD, LONDON, SE24 0PB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kale, S (Corresponding Author), Univ East Anglia, Sch Hlth Sci, Norwich, Norfolk, England.
   Kale, Swati; Kamble, Meghana Wadnerkar; Spalding, Nicola, Univ East Anglia, Sch Hlth Sci, Norwich, Norfolk, England.}},
DOI = {{10.12968/ijtr.2018.0149}},
ISSN = {{1741-1645}},
EISSN = {{1759-779X}},
Keywords = {{Multiple mini interview; Occupational therapy; Physiotherapy; Predictive
   validity; Speech and language therapy}},
Keywords-Plus = {{SELECTION; ADMISSIONS; RELIABILITY; MMI}},
Research-Areas = {{Rehabilitation}},
Web-of-Science-Categories  = {{Rehabilitation}},
Author-Email = {{s.kale@uea.ac.uk}},
Cited-References = {{Alaki SM, 2016, J DENT EDUC, V80, P1376.
   Callwood A, 2018, INT J NURS STUD, V77, P138, DOI 10.1016/j.ijnurstu.2017.10.003.
   Callwood A, 2014, NURS EDUC TODAY, V34, P1450, DOI 10.1016/j.nedt.2014.04.023.
   Cameron AJ, 2017, MED EDUC, V51, P379, DOI 10.1111/medu.13222.
   Edgar S, 2014, PHYSIOTHERAPY, V100, P331, DOI 10.1016/j.physio.2014.03.002.
   Eva KW, 2009, MED EDUC, V43, P767, DOI 10.1111/j.1365-2923.2009.03407.x.
   Eva KW, 2004, MED EDUC, V38, P314, DOI 10.1046/j.1365-2923.2004.01776.x.
   Gale J, 2016, NURS EDUC TODAY, V40, P123, DOI 10.1016/j.nedt.2016.01.031.
   Grice Kimatha Oxford, 2014, J Allied Health, V43, P57.
   Griffin B, 2012, ADV HEALTH SCI EDUC, V17, P377, DOI 10.1007/s10459-011-9316-1.
   Health and Care Professions Council, 2018, STAND ED TRAIN.
   Health Education England, 2019, NHS CONST VAL HUM.
   Health Education England, 2016, VAL BAS RECR FRAM.
   Husbands A, 2013, MED EDUC, V47, P717, DOI 10.1111/medu.12193.
   Knorr M, 2014, MED EDUC, V48, P1157, DOI 10.1111/medu.12535.
   Lee Hee Jae, 2016, BMC Res Notes, V9, P93, DOI 10.1186/s13104-016-1866-0.
   Lemay JF, 2007, MED EDUC, V41, P573, DOI 10.1111/j.1365-2923.2007.02767.x.
   Mercer A, 2011, MED TEACH, V33, P997, DOI 10.3109/0142159X.2011.577123.
   O'Brien A, 2011, MED TEACH, V33, P397, DOI 10.3109/0142159X.2010.541532.
   Pau A, 2013, MED TEACH, V35, P1027, DOI 10.3109/0142159X.2013.829912.
   Perkins A, 2013, NURS EDUC TODAY, V33, P465, DOI 10.1016/j.nedt.2012.04.023.
   Power A., 2015, BRIT J MIDWIFERY, V23, P818.
   Razack S, 2009, MED EDUC, V43, P993, DOI 10.1111/j.1365-2923.2009.03447.x.
   Rees EL, 2016, MED TEACH, V38, P443, DOI 10.3109/0142159X.2016.1158799.
   Shulruf B, 2012, J EDUC EVAL HEALTH P, V9, DOI 10.3352/jeehp.2012.9.7.
   Siu E, 2009, ADV HEALTH SCI EDUC, V14, P759, DOI 10.1007/s10459-009-9160-8.
   Sladek RM, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0692-3.
   Thomas A, 2017, BRIT J OCCUP THER, V80, P558, DOI 10.1177/0308022617713980.
   Traynor M, 2017, J ADV NURS, V73, P1443, DOI 10.1111/jan.13227.
   Universities and College Admissions Service (UCAS), 2019, UCAS TARIFF POINTS.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Int. J. Ther. Rehabil.}},
Doc-Delivery-Number = {{LL5BF}},
Unique-ID = {{ISI:000531571300004}},
DA = {{2020-12-06}},
}

@article{ ISI:000542957100007,
Author = {Cummins, Nicholas and Sethu, Vidhyasaharan and Epps, Julien and
   Williamson, James R. and Quatieri, Thomas and Krajewski, Jarek},
Title = {{Generalized Two-Stage Rank Regression Framework for Depression Score
   Prediction from Speech}},
Journal = {{IEEE TRANSACTIONS ON AFFECTIVE COMPUTING}},
Year = {{2020}},
Volume = {{11}},
Number = {{2}},
Pages = {{272-283}},
Month = {{APR-JUN}},
Abstract = {{This paper introduces a novel speech-based depression score prediction
   paradigm, the 2-stage ranking prediction framework, and highlights the
   benefits it brings to depression prediction. Conventional regression
   approaches aim to discern a single functional relationship between
   speech features and depression scores, making an implicit assumption
   about the existence of a single fixed relationship between the features
   and scores. However, as the relationship between severity of depression
   and the clinical score may vary over the range of the assessment scale,
   this style of analysis may not be suited to depression prediction. The
   proposed framework on the other hand, imposes a series of partitions on
   the feature space, with each partition corresponding to a distinct
   predefined range of depression scores, and predicts the score based on
   measures of membership to each partition. This approach provides
   additional flexibility by allowing different rankings to be learnt for
   different depression scores, and relaxes assumptions made by
   conventional regression approaches. Results demonstrate the framework's
   suitability for depression score prediction: different 2-stage
   implementations, based on heterogeneous feature extraction and modelling
   approaches, produce state-of-the-art results on the AVEC-2013 dataset.
   It is also demonstrated that, unlike fusion of conventional regression
   systems, the fusion of two-stage systems consistently improves
   prediction performance.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cummins, N (Corresponding Author), Univ New South Wales, UNSW Sydney, Sch Elect Engn \& Telecommun, Sydney, NSW 2052, Australia.
   Cummins, Nicholas; Sethu, Vidhyasaharan; Epps, Julien, Univ New South Wales, UNSW Sydney, Sch Elect Engn \& Telecommun, Sydney, NSW 2052, Australia.
   Epps, Julien, Data61 CSIRO, Australian Technol Pk,Level 5,13 Garden St, Eveleigh, NSW 2015, Australia.
   Williamson, James R.; Quatieri, Thomas, MIT, Lincoln Lab, 244 Wood St, Lexington, MA 02421 USA.
   Krajewski, Jarek, Expt Ind Psychol, D-42119 Wuppertal, Germany.
   Krajewski, Jarek, Rhenish Univ Appl Sci, Ind Psychol, D-50678 Cologne, Germany.}},
DOI = {{10.1109/TAFFC.2017.2766145}},
ISSN = {{1949-3045}},
Keywords = {{Speech; Feature extraction; Acoustics; Indexes; Tools; Predictive
   models; Signal processing; Bayesian; conditional ranking functions;
   depression; fusion; gaussian; marginalization; paralinguistics;
   prediction; speech; two-stage regression}},
Keywords-Plus = {{SPACE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Cybernetics}},
Author-Email = {{nicholas.cummins@ieee.org
   v.sethu@unsw.edu.au
   j.epps@unsw.edu.au
   jrw@ll.mit.edu
   quatieri@ll.mit.edu
   krajewsk@uni-wuppertal.de}},
ResearcherID-Numbers = {{Sethu, Vidhyasaharan/B-5197-2013
   }},
ORCID-Numbers = {{Sethu, Vidhyasaharan/0000-0001-8492-1787
   Epps, Julien/0000-0001-6624-5551}},
Funding-Acknowledgement = {{Data61-CSIRO - Australian GovernmentAustralian Government; Australian
   Research Council through the ICT Centre of Excellence programAustralian
   Research Council; Australian Research CouncilAustralian Research Council
   {[}DP110105240, DP120100641]; Air Force {[}FA8721-05-C-0002]; German
   Federal Ministry of Research (BMBF)Federal Ministry of Education \&
   Research (BMBF) {[}FKZ 01IS15024D]; EUEuropean Union (EU) {[}689592]}},
Funding-Text = {{Julien Epps work is supported by Data61-CSIRO funded by the Australian
   Government as represented by the Department of Broadband, Communication
   and the Digital Economy and the Australian Research Council through the
   ICT Centre of Excellence program. He is also supported by the Australian
   Research Council through Discovery Projects DP110105240 and DP120100641.
   James R. Williamson and Thomas F. Quatieri work are sponsored by the
   Assistant Secretary of Defense for Research and Engineering under Air
   Force Contract FA8721-05-C-0002. Opinions, interpretations, conclusions,
   and recommendations are those of the author and are not necessarily
   endorsed by the United States Government. Jarek Krajewski work is partly
   funded by the Horizon 2020, EU.3.1., No 689592, and the German Federal
   Ministry of Research (BMBF), FKZ 01IS15024D.}},
Cited-References = {{Beck AT, 1996, J PERS ASSESS, V67, P588, DOI 10.1207/s15327752jpa6703\_13.
   Brummer N, 2007, IEEE T AUDIO SPEECH, V15, P2072, DOI 10.1109/TASL.2007.902870.
   Cummins N., 2013, P 3 ACM INT WORKSH A, P11, DOI DOI 10.1145/2512530.2512535.
   Cummins N., 2016, THESIS.
   Cummins N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P110.
   Cummins N, 2015, SPEECH COMMUN, V75, P27, DOI 10.1016/j.specom.2015.09.003.
   Cummins N, 2015, INT CONF ACOUST SPEE, P4779, DOI 10.1109/ICASSP.2015.7178878.
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004.
   Cummins N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3008.
   Eyben F., 2010, P 18 ACM INT C MULT, P1459, DOI DOI 10.1145/1873951.1874246.
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417.
   FLINT AJ, 1993, J PSYCHIAT RES, V27, P309, DOI 10.1016/0022-3956(93)90041-Y.
   Girard JM, 2014, IMAGE VISION COMPUT, V32, P641, DOI 10.1016/j.imavis.2013.12.007.
   Helfer BS, 2013, INTERSPEECH, P2171.
   Karam Zahi N, 2014, Proc IEEE Int Conf Acoust Speech Signal Process, V2014, P4858, DOI 10.1109/ICASSP.2014.6854525.
   Kaya Heysem, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3729, DOI 10.1109/ICASSP.2014.6854298.
   Kaya Y, 2014, ISTANB J SOCIOL STUD, P19.
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009.
   Kua JMK, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P34.
   Kua JMK, 2011, INT CONF ACOUST SPEE, P5452.
   Low LSA, 2010, INT CONF ACOUST SPEE, P5154, DOI 10.1109/ICASSP.2010.5495018.
   Luxton DD, 2011, PROF PSYCHOL-RES PR, V42, P505, DOI 10.1037/a0024485.
   Mathers CD, 2006, PLOS MED, V3, DOI 10.1371/journal.pmed.0030442.
   Maust D, 2012, HAND CLINIC, V106, P227, DOI 10.1016/B978-0-444-52002-9.00013-9.
   Merz CJ, 1999, MACH LEARN, V36, P9, DOI 10.1023/A:1007507221352.
   Perez Y, 2014, DEEP METAZOAN PHYLOGENY: THE BACKBONE OF THE TREE OF LIFE, P49.
   Price M, 2014, CLIN PSYCHOL PSYCHOT, V21, P427, DOI 10.1002/cpp.1855.
   Quatieri TF, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1058.
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361.
   Santos JF, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P55, DOI 10.1109/IWAENC.2014.6953337.
   Scherer S., 2014, IMAGE VISION COMPUT, V32, P1.
   Scherer S, 2016, IEEE T AFFECT COMPUT, V7, P59, DOI 10.1109/TAFFC.2015.2440264.
   Scherer S, 2013, INTERSPEECH, P847.
   Schuller B., 2013, COMPUTATIONAL PARALI.
   Sethu V., 2014, SPEECH AUDIO PROCESS, P197.
   Tipping ME, 2004, LECT NOTES ARTIF INT, V3176, P41.
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236.
   Valstar M., 2014, P 4 INT WORKSH AUD V, P3, DOI DOI 10.1145/2661806.2661807.
   Valstar M., 2013, P 3 ACM INT WORKSH A, P3, DOI DOI 10.1145/2512530.2512533.
   Williamson J. R., 2013, P 3 ACM INT WORKSH A, P41, DOI DOI 10.1145/2512530.2512531.
   Williamson J. R., 2014, P 4 INT WORKSH AUD V, P65, DOI DOI 10.1145/2661806.2661809.
   Yu B, 2014, INTERSPEECH, P1038.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{IEEE Trans. Affect. Comput.}},
Doc-Delivery-Number = {{MB9ZP}},
Unique-ID = {{ISI:000542957100007}},
DA = {{2020-12-06}},
}

@article{ ISI:000531089000014,
Author = {Nakatani, Hayao and Nakao, Masatoshi and Uchiyama, Hidefumi and
   Toyoshiba, Hiroyoshi and Ochiai, Chikayuki},
Title = {{Predicting Inpatient Falls Using Natural Language Processing of Nursing
   Records Obtained From Japanese Electronic Medical Records: Case-Control
   Study}},
Journal = {{JMIR MEDICAL INFORMATICS}},
Year = {{2020}},
Volume = {{8}},
Number = {{4}},
Month = {{APR}},
Abstract = {{Background: Falls in hospitals are the most common risk factor that
   affects the safety of inpatients and can result in severe harm.
   Therefore, preventing falls is one of the most important areas of risk
   management for health care organizations. However, existing methods for
   predicting falls are laborious and costly.
   Objective: The objective of this study is to verify whether hospital
   inpatient falls can be predicted through the analysis of a single
   input-unstructured nursing records obtained from Japanese electronic
   medical records (EMRs)-using a natural language processing (NLP)
   algorithm and machine learning.
   Methods: The nursing records of 335 fallers and 408 nonfallers for a
   12-month period were extracted from the EMRs of an acute care hospital
   and randomly divided into a learning data set and test data set. The
   former data set was subjected to NLP and machine learning to extract
   morphemes that contributed to separating fallers from nonfallers to
   construct a model for predicting falls. Then, the latter data set was
   used to determine the predictive value of the model using receiver
   operating characteristic (ROC) analysis.
   Results: The prediction of falls using the test data set showed high
   accuracy, with an area under the ROC curve, sensitivity, specificity,
   and odds ratio of mean 0.834 (SD 0.005), mean 0.769 (SD 0.013), mean
   0.785 (SD 0.020), and mean 12.27 (SD 1.11) for five independent
   experiments, respectively. The morphemes incorporated into the final
   model included many words closely related to known risk factors for
   falls, such as the use of psychotropic drugs, state of consciousness,
   and mobility, thereby demonstrating that an NLP algorithm combined with
   machine learning can effectively extract risk factors for falls from
   nursing records.
   Conclusions: We successfully established that falls among hospital
   inpatients can be predicted by analyzing nursing records using an NLP
   algorithm and machine learning. Therefore, it may be possible to develop
   a fall risk monitoring system that analyzes nursing records daily and
   alerts health care professionals when the fall risk of an inpatient is
   increased.}},
Publisher = {{JMIR PUBLICATIONS, INC}},
Address = {{130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Uchiyama, H (Corresponding Author), Neopharma Japan Co Ltd, Pharmaceut Res Dept, Global Pharmaceut R\&D Div, Chiyoda Ku, Iidabashi Grand Bloom 4F,2-10-2 Fujimi, Tokyo 1020071, Japan.
   Nakatani, Hayao; Nakao, Masatoshi; Ochiai, Chikayuki, NTT Med Ctr Tokyo, Tokyo, Japan.
   Uchiyama, Hidefumi, Neopharma Japan Co Ltd, Pharmaceut Res Dept, Global Pharmaceut R\&D Div, Tokyo, Japan.
   Uchiyama, Hidefumi; Toyoshiba, Hiroyoshi, FRONTEO Inc, Res Dev Dept, Lifesci AI Business Div, Tokyo, Japan.
   Ochiai, Chikayuki, Tokyo Healthcare Univ, Tokyo, Japan.}},
DOI = {{10.2196/16970}},
Article-Number = {{e16970}},
EISSN = {{2291-9694}},
Keywords = {{fall; risk factor; prediction; nursing record; natural language
   processing; machine learning}},
Keywords-Plus = {{RISK-FACTORS; PREVENTION; STRATIFY; TOOLS; MODEL; CARE}},
Research-Areas = {{Medical Informatics}},
Web-of-Science-Categories  = {{Medical Informatics}},
Author-Email = {{huchiyam@gmail.com}},
ORCID-Numbers = {{Uchiyama, Hidefumi/0000-0002-5767-110X}},
Cited-References = {{Afzal N, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P126, DOI 10.1109/BHI.2016.7455851.
   Aranda-Gallardo M, 2013, BMC HEALTH SERV RES, V13, DOI 10.1186/1472-6963-13-122.
   BALLINGER BR, 1975, BRIT J PSYCHIAT, V126, P462, DOI 10.1192/bjp.126.5.462.
   Bjarnadottir Ragnhildur I, 2018, EGEMS (Wash DC), V6, P21, DOI 10.5334/egems.237.
   Bouldin ELD, 2013, J PATIENT SAF, V9, P13, DOI 10.1097/PTS.0b013e3182699b64.
   Cameron ID, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005465.pub3.
   Chase HS, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0418-4.
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953.
   Chu LW, 1999, J GERONTOL A-BIOL, V54, pM38, DOI 10.1093/gerona/54.1.M38.
   Cracknell Alison, 2016, Future Hosp J, V3, ps31, DOI 10.7861/futurehosp.3-2s-s31.
   Dai A. M., 2015, DOCUMENT EMBEDDING P.
   GALES BJ, 1995, ANN PHARMACOTHER, V29, P354, DOI 10.1177/106002809502900402.
   Gluck T, 1996, GERONTOLOGY, V42, P104, DOI 10.1159/000213779.
   HENDRICH A, 1995, APPL NURS RES, V8, P129, DOI 10.1016/S0897-1897(95)80592-3.
   Hendrich AL, 2003, APPL NURS RES, V16, P9, DOI 10.1053/apnr.2003.YAPNR2.
   Japan Federation of Democratic Medical Institutions, 2016, RAT FALL INC REP QUA.
   Joint Commission. Sentinel Event Alert, 2015, PREV FALLS FALL REL.
   Jones KJ, 2015, J RURAL HEALTH, V31, P135, DOI 10.1111/jrh.12088.
   Kudo Taku, MECAB YET ANOTHER PA.
   LICHTENSTEIN MJ, 1994, AM J EPIDEMIOL, V140, P830, DOI 10.1093/oxfordjournals.aje.a117331.
   Matarese M, 2015, J ADV NURS, V71, P1198, DOI 10.1111/jan.12542.
   Miake-Lye IM, 2013, ANN INTERN MED, V158, P390, DOI 10.7326/0003-4819-158-5-201303051-00005.
   Mikolov T., 2013, EFFICIENT ESTIMATION.
   Morris R, 2017, CLIN MED, V17, P360, DOI 10.7861/clinmedicine.17-4-360.
   MORSE JM, 1987, GERONTOLOGIST, V27, P516, DOI 10.1093/geront/27.4.516.
   Oliver D, 1997, BMJ-BRIT MED J, V315, P1049, DOI 10.1136/bmj.315.7115.1049.
   Oliver D, 2004, AGE AGEING, V33, P122, DOI 10.1093/ageing/afh017.
   Oliver D, 2008, AGE AGEING, V37, P621, DOI 10.1093/ageing/afn203.
   Oliver D, 2007, BRIT MED J, V334, P82, DOI 10.1136/bmj.39049.706493.55.
   Oliver D, 2010, CLIN GERIATR MED, V26, P645, DOI 10.1016/j.cger.2010.06.005.
   Passaro A, 2000, J CLIN EPIDEMIOL, V53, P1222, DOI 10.1016/S0895-4356(00)00254-7.
   Pennington J, 2014, 2014 C EMP METH NAT, DOI {[}10.3115/v1/d14-1162, DOI 10.3115/V1/D14-1162].
   Sahota O, 2014, AGE AGEING, V43, P247, DOI 10.1093/ageing/aft155.
   SALGADO R, 1994, GERONTOLOGY, V40, P325, DOI 10.1159/000213607.
   SCHMID NA, 1990, MIL MED, V155, P202.
   Stevens Sue, 2010, Community Eye Health, V23, P44.
   Wi CI, 2017, AM J RESP CRIT CARE, V196, P430, DOI 10.1164/rccm.201610-2006OC.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{JMIR Med. Inf.}},
Doc-Delivery-Number = {{LK8CX}},
Unique-ID = {{ISI:000531089000014}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000519336500005,
Author = {Liu, Zhaowei and Shu, Su and Lu, Lingxi and Ge, Jianqiao and Gao,
   Jia-Hong},
Title = {{Spatiotemporal dynamics of predictive brain mechanisms during speech
   processing: an MEG study}},
Journal = {{BRAIN AND LANGUAGE}},
Year = {{2020}},
Volume = {{203}},
Month = {{APR}},
Abstract = {{Rapid and efficient speech processing benefits from the prediction
   derived from prior expectations based on the identification of
   individual words. It is known that speech processing is carried out
   within a distributed frontotemporal network. However, the spatiotemporal
   causal dynamics of predictive brain mechanisms in sound-to-meaning
   mapping within this network remain unclear. Using
   magnetoencephalography, we adopted a semantic anomaly paradigm which
   consists of expected, unexpected and time-reversed Mandarin Chinese
   speech, and localized the effects of violated expectation in
   frontotemporal brain regions, the sensorimotor cortex and the
   supramarginal gyrus from 250 ms relative to the target words. By further
   investigating the causal cortical dynamics, we provided the description
   of the causal dynamic network within the framework of the dual stream
   model, and highlighted the importance of the connections within the
   ventral pathway, the top-down modulation from the left inferior frontal
   gyrus and the cross-stream integration during the speech processing of
   violated expectation.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ge, JQ; Gao, JH (Corresponding Author), Peking Univ, Integrated Sci Res Ctr, Room 202,5 Yiheyuan Rd, Beijing 100871, Peoples R China.
   Liu, Zhaowei; Shu, Su; Gao, Jia-Hong, Peking Univ, Sch Phys, Inst Heavy Ion Phys, Beijing City Key Lab Med Phys \& Engn, Beijing, Peoples R China.
   Liu, Zhaowei; Shu, Su; Lu, Lingxi; Ge, Jianqiao; Gao, Jia-Hong, Peking Univ, Acad Adv Interdisciplinary Studies, Ctr MRI Res, Beijing, Peoples R China.
   Liu, Zhaowei; Shu, Su; Lu, Lingxi; Ge, Jianqiao; Gao, Jia-Hong, Peking Univ, McGovern Inst Brain Res, Beijing, Peoples R China.}},
DOI = {{10.1016/j.bandl.2020.104755}},
Article-Number = {{104755}},
ISSN = {{0093-934X}},
EISSN = {{1090-2155}},
Keywords = {{Speech; Expectation; Magnetoencephalography; Connectivity; Chinese}},
Keywords-Plus = {{CORTICAL DYNAMICS; LANGUAGE; MAGNETOENCEPHALOGRAPHY; ENHANCEMENT;
   INTEGRATION; POTENTIALS; REGIONS; CORTEX; GAMMA}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences \&
   Neurology; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental}},
Author-Email = {{gejq@pku.edu.cn
   jgao@pku.edu.cn}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2017YFC0108901]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}31421003, 31771253,
   81727808, 81790650, 81790651]; Beijing Municipal Science \& Technology
   CommissionBeijing Municipal Science \& Technology Commission
   {[}Z171100000117012]; Guangdong key basic research grant
   {[}2018B030332001]; Guangdong Pearl River Talents Plan {[}2016ZT06S220]}},
Funding-Text = {{This work was supported by the National Key Research and Development
   Program of China (2017YFC0108901); the National Natural Science
   Foundation of China (31421003, 31771253, 81727808, 81790650 and
   81790651); Beijing Municipal Science \& Technology Commission
   (Z171100000117012); the Guangdong key basic research grant
   (2018B030332001); the Guangdong Pearl River Talents Plan (2016ZT06S220).
   We thank the National Center for Protein Sciences at Peking University
   in Beijing, China, for assistance with the MEG and MRI data acquisition
   and data analyses.}},
Cited-References = {{AKAIKE H, 1978, ANN I STAT MATH, V30, P9, DOI 10.1007/BF02480194.
   {[}Anonymous], 2019, CORPUS LINGUISTICS, V6, P71.
   Armeni K, 2019, NEUROIMAGE, V198, P283, DOI 10.1016/j.neuroimage.2019.04.083.
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512.
   Blinowska KJ, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.050902.
   CHEUNG YW, 1995, J BUS ECON STAT, V13, P277, DOI 10.2307/1392187.
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021.
   Di Liberto GM, 2018, NEUROIMAGE, V166, P247, DOI 10.1016/j.neuroimage.2017.10.066.
   Durschmid S, 2016, P NATL ACAD SCI USA, V113, P6755, DOI 10.1073/pnas.1525030113.
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308.
   Florin E, 2010, NEUROIMAGE, V50, P577, DOI 10.1016/j.neuroimage.2009.12.050.
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8.
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011.
   Friston KJ, 2013, CURR OPIN NEUROBIOL, V23, P172, DOI 10.1016/j.conb.2012.11.010.
   Friston KJ, 2003, NEUROIMAGE, V19, P1273, DOI 10.1016/S1053-8119(03)00202-7.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Ge JQ, 2015, P NATL ACAD SCI USA, V112, P2972, DOI 10.1073/pnas.1416000112.
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267.
   Gross J, 2013, NEUROIMAGE, V65, P349, DOI 10.1016/j.neuroimage.2012.10.001.
   Halgren E, 2002, NEUROIMAGE, V17, P1101, DOI 10.1006/nimg.2002.1268.
   HAMALAINEN M, 1993, REV MOD PHYS, V65, P413, DOI 10.1103/RevModPhys.65.413.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032.
   Huang MX, 1999, PHYS MED BIOL, V44, P423, DOI 10.1088/0031-9155/44/2/010.
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Lau E, 2009, BRAIN LANG, V111, P161, DOI 10.1016/j.bandl.2009.08.007.
   Lau EF, 2019, BRAIN LANG, V199, DOI 10.1016/j.bandl.2019.104697.
   Lau EF, 2016, CEREB CORTEX, V26, P1377, DOI 10.1093/cercor/bhu219.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Leff AP, 2008, J NEUROSCI, V28, P13209, DOI 10.1523/JNEUROSCI.2903-08.2008.
   Leon-Cabrera P, 2017, NEUROPSYCHOLOGIA, V99, P326, DOI 10.1016/j.neuropsychologia.2017.02.026.
   Liu YY, 2010, J NEUROLINGUIST, V23, P615, DOI 10.1016/j.jneuroling.2010.06.001.
   Lyu BJ, 2019, P NATL ACAD SCI USA, V116, P21318, DOI 10.1073/pnas.1903402116.
   Lyu BJ, 2016, J NEUROSCI, V36, P10813, DOI 10.1523/JNEUROSCI.0583-16.2016.
   MacGregor LJ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1715.
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024.
   Martin A, 2007, ANNU REV PSYCHOL, V58, P25, DOI 10.1146/annurev.psych.57.102904.190143.
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007.
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062.
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331.
   Schwartz MF, 2012, BRAIN, V135, P3799, DOI 10.1093/brain/aws300.
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400.
   Tadel F, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/879716.
   Taulu S, 2005, J APPL PHYS, V97, DOI 10.1063/1.1935742.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Wang L, 2018, J COGNITIVE NEUROSCI, V30, P1075, DOI 10.1162/jocn\_a\_01275.
   Wang L, 2018, J COGNITIVE NEUROSCI, V30, P432, DOI 10.1162/jocn\_a\_01190.
   Yang J, 2016, NEUROPSYCHOLOGIA, V87, P12, DOI 10.1016/j.neuropsychologia.2016.04.029.}},
Number-of-Cited-References = {{52}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Brain Lang.}},
Doc-Delivery-Number = {{KT9MQ}},
Unique-ID = {{ISI:000519336500005}},
DA = {{2020-12-06}},
}

@article{ ISI:000516886300009,
Author = {Nixon, Jessie S.},
Title = {{Of mice and men: Speech sound acquisition as discriminative learning
   from prediction error, not just statistical tracking}},
Journal = {{COGNITION}},
Year = {{2020}},
Volume = {{197}},
Month = {{APR}},
Abstract = {{Despite burgeoning evidence that listeners are highly sensitive to
   statistical distributions of speech cues, the mechanism underlying
   learning may not be purely statistical tracking. Decades of research in
   animal learning suggest that learning results from prediction and
   prediction error. Two artificial language learning experiments test two
   predictions that distinguish error-driven from purely statistical
   models; namely, cue competition specifically, Kamin's (1968) `blocking'
   effect (Experiment 1) and the predictive structure of learning events
   (Experiment 2).
   In Experiment 1, prior knowledge of an informative cue blocked learning
   of a second cue. This finding may help explain second language learners'
   difficulty in acquiring native-level perception of non-native speech
   cues. In Experiment 2, learning was better with a discriminative (cue
   outcome) order compared to a non-discriminative (outcome cue) order.
   Experiment 2 suggests that learning speech cues, including reversing
   effects of blocking, depends on (un)learning from prediction error and
   depends on the temporal order of auditory cues versus semantic outcomes.
   Together, these results show that (a) existing knowledge of acoustic
   cues can block later learning of new cues, and (b) speech sound
   acquisition depends on the predictive structure of learning events. When
   feedback from prediction error is available, this drives learners to
   ignore salient non-discriminative cues and effectively learn to use
   target cue dimensions. These findings may have considerable implications
   for the field of speech acquisition.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Nixon, JS (Corresponding Author), Eberhard Karls Univ Tubingen, Quantitat Linguist Grp, Tubingen, Germany.
   Nixon, Jessie S., Eberhard Karls Univ Tubingen, Quantitat Linguist Grp, Tubingen, Germany.}},
DOI = {{10.1016/j.cognition.2019.104081}},
Article-Number = {{104081}},
ISSN = {{0010-0277}},
EISSN = {{1873-7838}},
Keywords = {{Discriminative learning; Error-driven learning; Learning theory; Kamin
   blocking effect; Speech acquisition; Prediction error}},
Keywords-Plus = {{VOICE ONSET TIME; PERCEPTUAL REORGANIZATION; VERTICAL-BAR; LANGUAGE;
   ENGLISH; ABSENCE; COMPREHENSION; CONTINGENCY; CONTRASTS; JAPANESE}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{jessie.nixon@uni-tuebingen.de}},
Funding-Acknowledgement = {{John Templeton Foundation {[}36617]; ERC Advanced GrantEuropean Research
   Council (ERC) {[}742545]}},
Funding-Text = {{The present experiments were conceived and largely designed while the
   author was based at the New Zealand Institute of Language, Brain and
   Behaviour (NZILBB), University of Canterbury. Many thanks to Clay
   Beckner and Robert Fromont for invaluable technical support and advice,
   Jen Hay and other members of NZILBB and members of the Quantitative
   Linguistics Group, University of Tubingen for much valuable discussion
   during experiment set up, to our speaker for producing the stimuli, to
   Michael Ramscar, Yu-Ying Chuang and Fabian Tomaschek and to Padraic
   Monaghan and two additional anonymous reviewers for very helpful
   suggestions on earlier versions of this manuscript. Also to Harald
   Baayen for the `Of mice and men' title suggestion. The roofrunner
   experimental platform was developed by Chun-Liang Chan and the visuals
   created by Kayo Takasugi. This project was made possible through the
   support of a subaward under a grant to Northwestern University from the
   John Templeton Foundation (Award ID 36617) and an ERC Advanced Grant
   (Grant number 742545). The opinions expressed in this publication are
   those of the author and do not necessarily reflect the views of the John
   Templeton Foundation or the ERC.}},
Cited-References = {{Apfelbaum KS, 2017, COGNITIVE SCI, V41, P706, DOI 10.1111/cogs.12401.
   Arnold D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174623.
   Arnon I, 2012, COGNITION, V122, P292, DOI 10.1016/j.cognition.2011.10.009.
   Baayen RH, 2016, LANG COGN NEUROSCI, V31, P106, DOI 10.1080/23273798.2015.1065336.
   Baayen RH, 2011, PSYCHOL REV, V118, P438, DOI 10.1037/a0023851.
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01.
   Beckner C, 2017, J LANG EVOL, V2, P160, DOI 10.1093/jole/lzx001.
   Best C. T., 1995, SPEECH PERCEPTION LI, P171.
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345.
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378.
   Cartmill EA, 2013, P NATL ACAD SCI USA, V110, P11278, DOI 10.1073/pnas.1309518110.
   Cheng S, 2007, J NEUROPHYSIOL, V97, P3057, DOI 10.1152/jn.00897.2006.
   Chung K. K. H., 2003, J BEHAV EDUC, V12, P207.
   Clair St., 2009, COGNITIVE SCI, V33, P1317.
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004.
   Colunga E, 2009, LANG COGN, V1, P197, DOI 10.1515/LANGCOG.2009.010.
   Cristia A, 2011, J PHONETICS, V39, P388, DOI 10.1016/j.wocn.2011.02.004.
   De Houwer J, 2002, Q J EXP PSYCHOL-B, V55, P289, DOI 10.1080/02724990244000034.
   DICKINSON A, 1984, Q J EXP PSYCHOL-A, V36, P29, DOI 10.1080/14640748408401502.
   EIMAS PD, 1985, SCI AM, V252, P46, DOI 10.1038/scientificamerican0185-46.
   Ellis NC, 2010, STUD SECOND LANG ACQ, V32, P553, DOI 10.1017/S0272263110000264.
   Feldman NH, 2013, PSYCHOL REV, V120, P751, DOI 10.1037/a0034245.
   Flege J. E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR.
   FLEGE JE, 1995, LANG SPEECH, V38, P25, DOI 10.1177/002383099503800102.
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6.
   Goto H., 1971, NEUROPSYCHOLOGIA.
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296.
   Hebb D. O., 1949, ORG BEHAV NEUROPSYCH.
   Hoppe D., 2016, THESIS.
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1.
   Kamin L. J., 1969, PUNISHMENT AVERSIVE.
   Kamin L. J., 1968, MIAM S PRED BEH AV S, P9.
   Kapatsinski V, 2018, CHANGING MINDS CHANGING TOOLS: FROM LEARNING THEORY TO LANGUAGE ACQUISITION TO LANGUAGE CHANGE.
   Kopp B, 2000, BIOL PSYCHOL, V51, P223, DOI 10.1016/S0301-0511(99)00039-3.
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x.
   Logan J. S., 1991, J ACOUSTICAL SOC AM, V89.
   Lotto A. J, 2004, FROM SOUND TO SENSE, V50, pC381.
   Maclagan M, 2009, LANG VAR CHANGE, V21, P175, DOI 10.1017/S095439450999007X.
   Magloire J, 1999, PHONETICA, V56, P158, DOI 10.1159/000028449.
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3.
   Maye J., 2008, DEV SCI, V11.
   Maye J., 2000, P 24 ANN BOST U C LA.
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x.
   Milin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171935.
   MILLER RR, 1995, PSYCHOL BULL, V117, P363, DOI 10.1037/0033-2909.117.3.363.
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209.
   Monaghan P., 2017, 39 ANN C COGN SCI SO, P817.
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299.
   Nixon J. S., 2018, P 9 INT C SPEECH PRO, P493.
   Nixon JS, 2016, J MEM LANG, V90, P103, DOI 10.1016/j.jml.2016.03.005.
   Ohala J. J., 1997, P 4 SEOUL INT C LING, P98, DOI DOI 10.1525/JLIN.1996.6.1.109.
   OHALA JJ, 1983, PHONETICA, V40, P1, DOI 10.1159/000261678.
   Olejarczuk P, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0020.
   Pegg J. E., 1997, J ACOUSTICAL SOC AM, V102.
   Pepiot E., 2014, SPEECH PROSODY, V7, P305, DOI DOI 10.21437/SpeechProsody.2014-48.
   R Core Team, 2017, R LANG ENV STAT COMP.
   Racz P, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00051.
   Ramscar M., 2011, P 33 ANN M COGN SCI.
   Ramscar M, 2007, COGNITIVE SCI, V31, P927, DOI 10.1080/03640210701703576.
   Ramscar M, 2013, LANGUAGE, V89, P760, DOI 10.1353/lan.2013.0068.
   Ramscar M, 2013, CHILD DEV, V84, P1308, DOI 10.1111/cdev.12044.
   Ramscar M, 2013, PSYCHOL SCI, V24, P1017, DOI 10.1177/0956797612460691.
   Ramscar M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022501.
   Ramscar M, 2010, COGNITIVE SCI, V34, P909, DOI 10.1111/j.1551-6709.2009.01092.x.
   Ramscar M, 2010, LANG COGNITIVE PROC, V25, P589, DOI 10.1080/01690960903381166.
   REBER AS, 1989, J EXP PSYCHOL GEN, V118, P219, DOI 10.1037/0096-3445.118.3.219.
   Rescorla R. A., 1972, CLASSICAL CONDITION, V2, P64, DOI DOI 10.1101/GR.110528.110.
   RESCORLA RA, 1988, AM PSYCHOL, V43, P151, DOI 10.1037/0003-066X.43.3.151.
   RESCORLA RA, 1968, J COMP PHYSIOL PSYCH, V66, P1, DOI 10.1037/h0025984.
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x.
   Schultz W, 1998, J NEUROPHYSIOL, V80, P1, DOI 10.1152/jn.1998.80.1.1.
   Schumacher R. A., 2014, P ANN M COGN SCI SOC.
   Shadmehr R, 2010, ANNU REV NEUROSCI, V33, P89, DOI 10.1146/annurev-neuro-060909-153135.
   Shafaei-Bajestan E, 2018, INTERSPEECH, P966.
   Siegel S, 1996, PSYCHON B REV, V3, P314, DOI 10.3758/BF03210755.
   Sundberg U, 1999, PHONETICA, V56, P186, DOI 10.1159/000028450.
   Terry J., 2015, ICPHS.
   Tsur R, 2006, J PRAGMATICS, V38, P905, DOI 10.1016/j.pragma.2005.12.002.
   Turnbull R, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.119.
   VANHAMME LJ, 1994, LEARN MOTIV, V25, P127, DOI 10.1006/lmot.1994.1008.
   Wanrooij K., 2015, P 18 INT C PHON SCI.
   Wanrooij K, 2015, FRONT PSYCHOL, V6, DOI {[}10.3389/fpsyg.2015.01341, 10.3389/fpg.21115.111341].
   Wanrooij K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109806.
   Werker JF, 2012, CURR DIR PSYCHOL SCI, V21, P221, DOI 10.1177/0963721412449459.
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3.
   Wilbur J., 2015, GRAMMAR PITE SAAMI.
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245.
   Yamada R. A., 1990, 1 INT C SPOK LANG PR.
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x.}},
Number-of-Cited-References = {{89}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Cognition}},
Doc-Delivery-Number = {{KQ4HS}},
Unique-ID = {{ISI:000516886300009}},
OA = {{Green Published, Other Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000510525200018,
Author = {He, Hongsen and Chen, Jingdong and Benesty, Jacob and Zhang, Wenxing and
   Yang, Tao},
Title = {{A class of multichannel sparse linear prediction algorithms for time
   delay estimation of speech sources}},
Journal = {{SIGNAL PROCESSING}},
Year = {{2020}},
Volume = {{169}},
Month = {{APR}},
Abstract = {{Time delay estimation (TDE), which is also called time difference of
   arrival estimation, is an important yet challenging problem in room
   acoustic environments where reverberation and noise coexist. The
   multichannel cross-correlation coefficient algorithm extends the
   traditional cross-correlation method from the two- to the
   multiple-channel cases and exploits the spatial information among all
   microphones to improve the robustness of TDE with respect to noise. The
   multichannel spatiotemporal prediction algorithm generalizes the
   multichannel cross-correlation coefficient algorithm by incorporating
   both the spatial and temporal information to make TDE robust to
   reverberation. This multichannel spatiotemporal prediction algorithm,
   however, is sensitive to noise. In this work, we attempt to improve the
   robustness of this algorithm by making it robust to both reverberation
   and noise. Based on the sparsity of the prediction coefficient matrix of
   speech signals, a class of multichannel sparse linear prediction
   algorithms, including the multichannel spatiotemporal sparse prediction
   and the multichannel spatiotemporal group sparse prediction, are
   developed for TDE. The multichannel cross-correlation coefficient and
   multichannel spatiotemporal prediction algorithms are unified from a TDE
   performance perspective via an F/l(1)-norm (or F/l(1,2)-norm)
   optimization model, which is solved by an alternating direction method
   of multipliers. The two new algorithms also respectively construct a set
   of time delay estimators, which make different tradeoffs between
   prewhitening and non-prewhitening by adjusting a regularization
   parameter. (C) 2019 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chen, JD (Corresponding Author), Northwestern Polytech Univ, Ctr Immers \& Intelligent Acoust, 127 Youyi West Rd, Xian 710072, Peoples R China.
   He, Hongsen; Yang, Tao, Southwest Univ Sci \& Technol, Sch Informat Engn, Robot Technol Used Special Environm Key Lab Sichu, Mianyang 621010, Sichuan, Peoples R China.
   He, Hongsen, Chinese Acad Sci, Inst Acoust, State Key Lab Acoust, Beijing 100190, Peoples R China.
   Chen, Jingdong, Northwestern Polytech Univ, Ctr Immers \& Intelligent Acoust, 127 Youyi West Rd, Xian 710072, Peoples R China.
   Benesty, Jacob, Univ Quebec, INRS EMT, 800 Gauchetiere Ouest,Suite 6900, Montreal, PQ H5A 1K6, Canada.
   Zhang, Wenxing, Univ Elect Sci \& Technol China, Sch Math Sci, Chengdu 611731, Peoples R China.}},
DOI = {{10.1016/j.sigpro.2019.107395}},
Article-Number = {{107395}},
ISSN = {{0165-1684}},
EISSN = {{1872-7557}},
Keywords = {{Acoustic source localization; Time delay estimation; Time difference of
   arrival; Prewhitening; Microphone arrays; Multichannel linear
   prediction; Spatiotemporal prediction; Sparsity; Group sparsity;
   Alternating direction method of multipliers}},
Keywords-Plus = {{SPEAKER LOCALIZATION; INTERFACE ROUGHNESS; ARRIVAL ESTIMATION;
   DIFFERENCE; NOISY}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{hongsenhe@gmail.com
   jingdongchen@ieee.org
   benesty@emt.inrs.ca
   zhangwx@uestc.edu.cn
   yangtao98@tsinghua.org.cn}},
Funding-Acknowledgement = {{Open Foundation of the State Key Laboratory of Acoustics, Chinese
   Academy of Sciences {[}SKLA201712]; National Science Foundation of China
   (NSFC)National Natural Science Foundation of China (NSFC) {[}61571376];
   Science and Technology Planning Project of Sichuan Province, China
   {[}20YYJC0605, 18YYJC1688]; National Nuclear Energy Development Project
   of China {[}18zg6103]; NSFC key programNational Natural Science
   Foundation of China (NSFC) {[}61831019]; NSFC-ISF joint research program
   {[}61761146001]; NSFC Distinguished Young Scientists Fund {[}61425005];
   NSFCNational Natural Science Foundation of China (NSFC) {[}11971003]}},
Funding-Text = {{The work of H. He was supported in part by the Open Foundation of the
   State Key Laboratory of Acoustics, Chinese Academy of Sciences (No.
   SKLA201712), in part by the National Science Foundation of China (NSFC,
   No. 61571376), in part by the Science and Technology Planning Project of
   Sichuan Province, China (Nos. 20YYJC0605, 18YYJC1688), and in part by
   the National Nuclear Energy Development Project of China (No. 18zg6103).
   The work of J. Chen was supported in part by the NSFC key program (No.
   61831019), in part by the NSFC-ISF joint research program (No.
   61761146001), and in part by the NSFC Distinguished Young Scientists
   Fund (No. 61425005). The work of W. Zhang was supported in part by the
   NSFC (No. 11971003).}},
Cited-References = {{Adalbjornsson SI, 2015, SIGNAL PROCESS, V109, P236, DOI 10.1016/j.sigpro.2014.10.014.
   Alameda-Pineda X, 2014, IEEE-ACM T AUDIO SPE, V22, P1082, DOI 10.1109/TASLP.2014.2317989.
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599.
   Athanasopoulos G, 2015, COMPUT SPEECH LANG, V34, P129, DOI 10.1016/j.csl.2015.03.009.
   Bai YC, 2014, IEEE SIGNAL PROC LET, V21, P909, DOI 10.1109/LSP.2014.2320291.
   Benesty J, 2004, IEEE T SPEECH AUDI P, V12, P509, DOI 10.1109/TSA.2004.833008.
   Benesty J, 2000, J ACOUST SOC AM, V107, P384, DOI 10.1121/1.428310.
   Benesty J, 2007, IEEE SIGNAL PROC LET, V14, P157, DOI 10.1109/LSP.2006.884038.
   Benesty J, 2008, SPRINGER TOP SIGN PR, V1, P1.
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016.
   BRANDSTEIN MS, 1997, P IEEE WORKSH APPL S.
   CARTER GC, 1981, IEEE T ACOUST SPEECH, V29, P463, DOI 10.1109/TASSP.1981.1163560.
   Champagne B, 1996, IEEE T SPEECH AUDI P, V4, P148, DOI 10.1109/89.486067.
   Chen J., 2004, P IEEE INT C AC SPEE, pIV.
   Chen JD, 2003, IEEE T SPEECH AUDI P, V11, P549, DOI 10.1109/TSA.2003.818025.
   Chen JD, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/26503.
   Clarke F., 1983, OPTIMIZATION NONSMOO.
   Claudio E.D., 2001, MICROPHONE ARRAYS SI.
   Conn A.R., 2000, TRUST REGION METHODS.
   DENG W, 2013, P SPIE WAVELETS SPAR.
   Doclo S, 2003, EURASIP J APPL SIG P, V2003, P1110, DOI 10.1155/S111086570330602X.
   Dvorkind TG, 2005, SIGNAL PROCESS, V85, P177, DOI 10.1016/j.sigpro.2004.09.014.
   Gabay D., 1976, Computers \& Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1.
   Gedalyahu K, 2010, IEEE T SIGNAL PROCES, V58, P3017, DOI 10.1109/TSP.2010.2044253.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41.
   Glowinski R., 2014, COMPUTATIONAL METHOD, P59, DOI DOI 10.1007/978-94-017-9054-3\_4.
   Hadad E, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P313, DOI 10.1109/IWAENC.2014.6954309.
   He HS, 2015, J ACOUST SOC AM, V137, P1044, DOI 10.1121/1.4906267.
   He HS, 2013, IEEE T AUDIO SPEECH, V21, P463, DOI 10.1109/TASL.2012.2223674.
   IANNIELLO JP, 1982, IEEE T ACOUST SPEECH, V30, P998, DOI 10.1109/TASSP.1982.1163992.
   Kay S. M., 1993, FUNDAMENTALS STAT SI.
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971.
   KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830.
   Kuttruff H., 2009, ROOM ACOUSTICS.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   RAMACHANDRAN RP, 1989, IEEE T ACOUST SPEECH, V37, P467, DOI 10.1109/29.17527.
   Rockafellar R. T., 1970, CONVEX ANAL.
   Sun M, 2018, IEEE T GEOSCI REMOTE, V56, P1475, DOI 10.1109/TGRS.2017.2763983.
   Sun M, 2017, SIGNAL PROCESS, V132, P272, DOI 10.1016/j.sigpro.2016.05.029.
   Talantzis F, 2005, IEEE SIGNAL PROC LET, V12, P561, DOI 10.1109/LSP.2005.849546.
   Vincent R, 2016, SIGNAL PROCESS, V118, P248, DOI 10.1016/j.sigpro.2015.07.006.
   Yu L, 2015, SIGNAL PROCESS, V111, P222, DOI 10.1016/j.sigpro.2014.12.018.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Signal Process.}},
Doc-Delivery-Number = {{KH3CX}},
Unique-ID = {{ISI:000510525200018}},
DA = {{2020-12-06}},
}

@article{ ISI:000521906300002,
Author = {Rudolph, Madhuri M. and Baur, Alexander D. J. and Haas, Matthias and
   Cash, Hannes and Miller, Kurt and Mahjoub, Samy and Hartenstein,
   Alexander and Kaufmann, David and Rotzinger, Roman and Lee, Chau Hung
   and Asbach, Patrick and Hamm, Bernd and Penzkofer, Tobias},
Title = {{Validation of the PI-RADS language: predictive values of PI-RADS lexicon
   descriptors for detection of prostate cancer}},
Journal = {{EUROPEAN RADIOLOGY}},
Year = {{2020}},
Volume = {{30}},
Number = {{8}},
Pages = {{4262-4271}},
Month = {{AUG}},
Abstract = {{Objectives To assess the discriminatory power of lexicon terms used in
   PI-RADS version 2 to describe MRI features of prostate lesions. Methods
   Four hundred fifty-four patients were included in this retrospective,
   institutional review board-approved study. Patients received
   multiparametric (mp) MRI and subsequent prostate biopsy including
   MRI/transrectal ultrasound fusion biopsy and 10-core systematic biopsy.
   PI-RADS lexicon terms describing lesion characteristics on mpMRI were
   assigned to lesions by experienced readers. Positive and negative
   predictive values (PPV, NPV) of each lexicon term were assessed using
   biopsy results as a reference standard. Results From a total of 501
   lesions, clinically significant prostate cancer (csPCa) was present in
   175 lesions (34.9\%). Terms related to findings of restricted diffusion
   showed PPVs of up to 52.0\%/43.9\% and NPV of up to 91.8\%/89.7\%
   (peripheral zone or PZ/transition zone or TZ). T2-weighted imaging
   (T2W)-related terms showed a wide range of predictive values. For PZ
   lesions, high PPVs were found for ``markedly hypointense,{''}
   ``lenticular,{''} ``lobulated,{''} and ``spiculated{''} (PPVs between
   67.2 and 56.7\%). For TZ lesions, high PPVs were found for
   ``water-drop-shaped{''} and ``erased charcoal sign{''} (78.6\% and
   61.0\%). The terms ``encapsulated,{''} ``organized chaos,{''} and
   ``linear{''} showed to be good predictors for benignity with
   distinctively low PPVs between 5.4 and 6.9\%. Most T2WI-related terms
   showed improved predictive values for TZ lesions when combined with
   DWI-related findings. Conclusions Lexicon terms with high discriminatory
   power were identified (e.g., ``markedly hypointense,{''}
   ``water-drop-shaped,{''} ``organized chaos{''}). DWI-related terms can
   be useful for excluding TZ cancer. Combining T2WI- with DWI findings in
   TZ lesions markedly improved predictive values.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Rudolph, MM (Corresponding Author), Humboldt Univ, Freie Univ Berlin, Dept Radiol, Augustenburger Pl 1, D-13353 Berlin, Germany.
   Rudolph, MM (Corresponding Author), Charite Univ Med Berlin, Berlin Inst Hlth, Augustenburger Pl 1, D-13353 Berlin, Germany.
   Rudolph, Madhuri M.; Baur, Alexander D. J.; Haas, Matthias; Mahjoub, Samy; Hartenstein, Alexander; Kaufmann, David; Rotzinger, Roman; Asbach, Patrick; Hamm, Bernd; Penzkofer, Tobias, Humboldt Univ, Freie Univ Berlin, Dept Radiol, Augustenburger Pl 1, D-13353 Berlin, Germany.
   Rudolph, Madhuri M.; Baur, Alexander D. J.; Haas, Matthias; Mahjoub, Samy; Hartenstein, Alexander; Kaufmann, David; Rotzinger, Roman; Asbach, Patrick; Hamm, Bernd; Penzkofer, Tobias, Charite Univ Med Berlin, Berlin Inst Hlth, Augustenburger Pl 1, D-13353 Berlin, Germany.
   Cash, Hannes; Miller, Kurt, Humboldt Univ, Freie Univ Berlin, Dept Urol, Charitepl 1, D-13353 Berlin, Germany.
   Cash, Hannes; Miller, Kurt, Charite Univ Med Berlin, Berlin Inst Hlth, Charitepl 1, D-13353 Berlin, Germany.
   Mahjoub, Samy, Univ Cologne, Uniklin Koln, Dept Urol, Kerpener Str 62, D-50937 Cologne, Germany.
   Lee, Chau Hung, Tan Tock Seng Hosp, Dept Radiol, Singapore, Singapore.
   Penzkofer, Tobias, BIH, Anna Louisa Karsch Str 2, D-10178 Berlin, Germany.}},
DOI = {{10.1007/s00330-020-06773-1}},
Early Access Date = {{MAR 2020}},
ISSN = {{0938-7994}},
EISSN = {{1432-1084}},
Keywords = {{Magnetic resonance imaging; Prostatic neoplasms; Predictive value of
   tests; Biopsy}},
Keywords-Plus = {{GUIDED TARGETED BIOPSY; TRANSITION-ZONE; DATA SYSTEM; DIFFERENTIATION;
   MRI; ULTRASONOGRAPHY; HYPERPLASIA; CRITERIA}},
Research-Areas = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Web-of-Science-Categories  = {{Radiology, Nuclear Medicine \& Medical Imaging}},
Author-Email = {{Madhuri.rudolph@charite.de}},
ResearcherID-Numbers = {{Penzkofer, Tobias/AAW-8839-2020
   }},
ORCID-Numbers = {{Mahjoub, Samy/0000-0001-5151-1853
   Rudolph, Madhuri Monique/0000-0002-8274-0779}},
Funding-Acknowledgement = {{Projekt DEAL}},
Funding-Text = {{Open Access funding provided by Projekt DEAL. The authors state that
   this work has not received any funding.}},
Cited-References = {{Baldisserotto M, 2016, J MAGN RESON IMAGING, V44, P1354, DOI 10.1002/jmri.25284.
   Bao J, 2017, EUR J RADIOL OPEN, V4, P123, DOI 10.1016/j.ejro.2017.08.003.
   Benndorf M, 2017, EUR J RADIOL, V93, P9, DOI 10.1016/j.ejrad.2017.05.015.
   Bossuyt PM, 2015, RADIOLOGY, V277, P826, DOI 10.1148/radiol.2015151516.
   Cash H, 2016, BJU INT, V118, P35, DOI 10.1111/bju.13327.
   Cash H, 2016, WORLD J UROL, V34, P525, DOI 10.1007/s00345-015-1671-8.
   Chesnais AL, 2013, CLIN RADIOL, V68, pE323, DOI 10.1016/j.crad.2013.01.018.
   Dickinson L, 2011, EUR UROL, V59, P477, DOI 10.1016/j.eururo.2010.12.009.
   Epstein JI, 2005, AM J SURG PATHOL, V29, P1228, DOI 10.1097/01.pas.0000173646.99337.b1.
   Faletti R, 2016, ABDOM RADIOL, V41, P926, DOI 10.1007/s00261-015-0574-x.
   Giannarini G, 2019, UROLOGY, V123, P191, DOI 10.1016/j.urology.2018.07.067.
   Girouin N, 2007, EUR RADIOL, V17, P1498, DOI 10.1007/s00330-006-0478-9.
   Greer MD, 2017, RADIOLOGY, V285, P859, DOI 10.1148/radiol.2017161316.
   Gunzel K, 2017, UROL INT, V98, P15, DOI 10.1159/000449258.
   Gunzel K, 2017, BMC UROL, V17, DOI 10.1186/s12894-016-0196-9.
   Hoeks CMA, 2013, RADIOLOGY, V266, P207, DOI 10.1148/radiol.12120281.
   Jung SI, 2013, RADIOLOGY, V269, P492, DOI 10.1148/radiol.13130029.
   Kim JH, 2008, J MAGN RESON IMAGING, V28, P1173, DOI 10.1002/jmri.21513.
   Kirkham APS, 2006, EUR UROL, V50, P1163, DOI 10.1016/j.eururo.2006.06.025.
   Lee H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199636.
   Leisenring W, 2000, BIOMETRICS, V56, P345, DOI 10.1111/j.0006-341X.2000.00345.x.
   Maxeiner A, 2018, BJU INT, V122, P211, DOI 10.1111/bju.14212.
   Maxeiner A, 2015, UROLOGY, V86, P108, DOI 10.1016/j.urology.2015.01.055.
   Muller BG, 2015, RADIOLOGY, V277, P741, DOI 10.1148/radiol.2015142818.
   Oto A, 2010, RADIOLOGY, V257, P715, DOI 10.1148/radiol.10100021.
   Pokharel SS, 2015, ABDOM IMAGING, V40, P143, DOI 10.1007/s00261-014-0199-5.
   Rosenkrantz AB, 2017, RADIOLOGY, V283, P119, DOI 10.1148/radiol.2016161124.
   Rosenkrantz AB, 2016, RADIOLOGY, V280, P793, DOI 10.1148/radiol.2016152542.
   Rouviere O, 2019, LANCET ONCOL, V20, P100, DOI 10.1016/S1470-2045(18)30569-2.
   Turkbey B, 2019, EUR UROL, V76, P340, DOI 10.1016/j.eururo.2019.02.033.
   Weinreb JC, 2016, EUR UROL, V69, P16, DOI 10.1016/j.eururo.2015.08.052.
   Weiss Brian, 2015, Rev Urol, V17, P113, DOI 10.3909/riu0670b.
   Yoshimitsu K, 2008, J MAGN RESON IMAGING, V27, P132, DOI 10.1002/jmri.21181.
   Yoshizako T, 2008, ACTA RADIOL, V49, P1207, DOI 10.1080/02841850802508959.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Eur. Radiol.}},
Doc-Delivery-Number = {{MG1GQ}},
Unique-ID = {{ISI:000521906300002}},
OA = {{Green Published, Other Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000514640000004,
Author = {Shain, Cory and Blank, Idan Asher and van Schijndel, Marten and Schuler,
   William and Fedorenko, Evelina},
Title = {{fNMI reveals language-specific predictive coding during naturalistic
   sentence comprehension}},
Journal = {{NEUROPSYCHOLOGIA}},
Year = {{2020}},
Volume = {{138}},
Month = {{FEB 17}},
Abstract = {{Much research in cognitive neuroscience supports prediction as a
   canonical computation of cognition across domains. Is such predictive
   coding implemented by feedback from higher-order domain-general
   circuits, or is it locally implemented in domain-specific circuits? What
   information sources are used to generate these predictions? This study
   addresses these two questions in the context of language processing. We
   present fMRI evidence from a naturalistic comprehension paradigm (1)
   that predictive coding in the brain's response to language is
   domain-specific, and (2) that these predictions are sensitive both to
   local word co-occurrence patterns and to hierarchical structure. Using a
   recently developed continuous-time deconvolutional regression technique
   that supports data-driven hemodynamic response function discovery from
   continuous BOLD signal fluctuations in response to naturalistic stimuli,
   we found effects of prediction measures in the language network but not
   in the domain-general multiple-demand network, which supports executive
   control processes and has been previously implicated in language
   comprehension. Moreover, within the language network, surface-level and
   structural prediction effects were separable. The predictability effects
   in the language network were substantial, with the model capturing over
   37\% of explainable variance on held-out data. These findings indicate
   that human sentence processing mechanisms generate predictions about
   upcoming words using cognitive processes that are sensitive to
   hierarchical structure and specialized for language processing, rather
   than via feedback from high-level executive control mechanisms.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Shain, C (Corresponding Author), Ohio State Univ, Columbus, OH 43210 USA.
   Shain, Cory; Schuler, William, Ohio State Univ, Columbus, OH 43210 USA.
   Blank, Idan Asher, Univ Calif Los Angeles, Los Angeles, CA 90024 USA.
   Blank, Idan Asher, MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   van Schijndel, Marten, Cornell Univ, Ithaca, NY 14853 USA.
   Schuler, William; Fedorenko, Evelina, Massachusetts Gen Hosp, Program Speech \& Hearing Biosci \& Technol, Boston, MA 02115 USA.}},
DOI = {{10.1016/j.neuropsychologia.2019.107307}},
Article-Number = {{107307}},
ISSN = {{0028-3932}},
EISSN = {{1873-3514}},
Keywords = {{Language; Predictive coding; Multiple demand network; Naturalistic;
   fMRI; Sentence processing; Syntactic structure; Surprisal}},
Keywords-Plus = {{EVENT-RELATED FMRI; FILLER-GAP DEPENDENCIES; AGE-RELATED-CHANGES;
   WORKING-MEMORY; NEURAL BASIS; BROCAS AREA; COGNITIVE CONTROL;
   BRAIN-REGIONS; HEMODYNAMIC-RESPONSE; CORTICAL REPRESENTATION}},
Research-Areas = {{Behavioral Sciences; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Behavioral Sciences; Neurosciences; Psychology, Experimental}},
Author-Email = {{shain.3@osu.edu
   iblank@psych.ucla.edu
   mv443@cornell.edu
   schuler@ling.osu.edu
   evelina9@mit.edu}},
Funding-Acknowledgement = {{NIHUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USA {[}R01-DC-016607, R01-DC-016950,
   R00-HD-057522]; National Science FoundationNational Science Foundation
   (NSF) {[}1816891]; Simons Foundation via the Simons Center for the
   Social Brain at MIT}},
Funding-Text = {{This research was supported by NIH award R00-HD-057522 (E.F.) and by
   National Science Foundation grant \#1816891 (W.S.). All views expressed
   are those of the authors and do not necessarily reflect the views of the
   National Science Foundation. E.F. was additionally supported by NIH
   awards R01-DC-016607 and R01-DC-016950 and by a grant from the Simons
   Foundation via the Simons Center for the Social Brain at MIT. The
   authors would also like to acknowledge the Athinoula A. Martinos Imaging
   Center at the McGovern Institute for Brain Research at the Massachusetts
   Institute of Technology (MIT), and the support team (especially Steven
   Shannon and Atsushi Takahashi). The authors also thank Nancy Kanwisher
   and Ted Gibson for recording the stories, and EvLab members for help
   with data collection, especially Zach Mineroff and Alex Paunov.}},
Cited-References = {{Abadi M., 2015, TENSORFLOW LARGE SCA.
   ABNEY SP, 1991, J PSYCHOLINGUIST RES, V20, P233, DOI 10.1007/BF01067217.
   Abutalebi J, 2008, ACTA PSYCHOL, V128, P466, DOI 10.1016/j.actpsy.2008.03.014.
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014.
   Ahlheim C, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00273.
   Alexander WH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21407-9.
   Alink A, 2010, J NEUROSCI, V30, P2960, DOI 10.1523/JNEUROSCI.3730-10.2010.
   Altmann GTM, 1998, TRENDS COGN SCI, V2, P146, DOI 10.1016/S1364-6613(98)01153-X.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Amalric M, 2019, NEUROIMAGE, V189, P19, DOI 10.1016/j.neuroimage.2019.01.001.
   Amunts K, 1999, J COMP NEUROL, V412, P319, DOI 10.1002/(SICI)1096-9861(19990920)412:2<319::AID-CNE10>3.0.CO;2-7.
   Aoshima S, 2004, J MEM LANG, V51, P23, DOI 10.1016/j.jml.2004.03.001.
   Baggio G, 2011, LANG COGNITIVE PROC, V26, P1338, DOI 10.1080/01690965.2010.542671.
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038.
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01.
   Baumgaertner A, 2002, NEUROIMAGE, V16, P736, DOI 10.1006/nimg.2002.1134.
   Bekinschtein TA, 2009, P NATL ACAD SCI USA, V106, P1672, DOI 10.1073/pnas.0809667106.
   Bemis DK, 2011, J NEUROSCI, V31, P2801, DOI 10.1523/JNEUROSCI.5003-10.2011.
   Bhattacharya S, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES'18), P74, DOI 10.1145/3281375.3281405.
   Bhattasali S, 2019, LANG COGN NEUROSCI, V34, P491, DOI 10.1080/23273798.2018.1518533.
   Bischoff-Grethe A, 2004, J COGNITIVE NEUROSCI, V16, P127, DOI 10.1162/089892904322755610.
   Blanco-Elorrieta E, 2017, J NEUROSCI, V37, P9022, DOI 10.1523/JNEUROSCI.0553-17.2017.
   Blank I., 2017, J NEUROSCI, P3616.
   Blank I., BIORXIV, DOI {[}10.1101/712372, DOI 10.1101/712372].
   Blank I, 2016, NEUROIMAGE, V127, P307, DOI 10.1016/j.neuroimage.2015.11.069.
   Blank I, 2014, J NEUROPHYSIOL, V112, P1105, DOI 10.1152/jn.00884.2013.
   Blank IA, 2017, COGN NEUROPSYCHOL, V34, P377, DOI 10.1080/02643294.2017.1402756.
   Blumstein SE, 2013, PERSPECT PSYCHOL SCI, V8, P44, DOI 10.1177/1745691612469021.
   Blumstein SE, 2009, LANG LINGUIST COMPAS, V3, DOI 10.1111/j.1749-818x.2009.00136.x.
   Bonhage CE, 2015, CORTEX, V68, P33, DOI 10.1016/j.cortex.2015.04.011.
   Botvinick MM, 2007, PHILOS T R SOC B, V362, P1615, DOI 10.1098/rstb.2007.2056.
   Boynton GM, 1996, J NEUROSCI, V16, P4207, DOI 10.1523/jneurosci.16-13-04207.1996.
   Braga R.M., 2019, BIORXIV.
   Braze D, 2011, CORTEX, V47, P416, DOI 10.1016/j.cortex.2009.11.005.
   Brennan J, 2012, NEW ESSAYS IN POLITICAL AND SOCIAL PHILOSOPHY, P1.
   Brennan J, 2016, LANG LINGUIST COMPAS, V10, P299, DOI 10.1111/lnc3.12198.
   Brennan JR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0207741.
   Brennan JR, 2017, COGNITIVE SCI, V41, P1515, DOI 10.1111/cogs.12445.
   Brennan JR, 2016, BRAIN LANG, V157, P81, DOI 10.1016/j.bandl.2016.04.008.
   Brian Roark, 2009, P 2009 C EMP METH NA, P324, DOI DOI 10.3115/1699510.1699553.
   Broca P., 1861, B SOC ANAT PARIS, V6, P330, DOI DOI 10.1093/ACPROF:OSO/9780195177640.003.0018.
   Brownsett SLE, 2014, BRAIN, V137, P242, DOI 10.1093/brain/awt289.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   Campbell KL, 2018, CURR OPIN BEHAV SCI, V21, P132, DOI 10.1016/j.cobeha.2018.04.008.
   Caplan D, 1999, BEHAV BRAIN SCI, V22, P77.
   Caspers S, 2008, BRAIN STRUCT FUNCT, V212, P481, DOI 10.1007/s00429-008-0195-z.
   Caspers S, 2006, NEUROIMAGE, V33, P430, DOI 10.1016/j.neuroimage.2006.06.054.
   Chao Z.C., 2018, NEURON.
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755.
   Cristescu TC, 2006, NEUROIMAGE, V33, P1178, DOI 10.1016/j.neuroimage.2006.08.017.
   D'Astolfo L, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01253.
   D'Esposito M, 2015, ANNU REV PSYCHOL, V66, P115, DOI 10.1146/annurev-psych-010814-015031.
   Dagerman KS, 2006, COGNITIVE SCI, V30, P311, DOI 10.1207/s15516709cog0000\_46.
   Dave S, 2018, NEUROPSYCHOLOGIA, V117, P135, DOI 10.1016/j.neuropsychologia.2018.05.023.
   Dax G., 1863, ACAD SCI, V61, P534.
   Dayal BS, 1996, IND ENG CHEM RES, V35, P4078, DOI 10.1021/ie960180e.
   de Bruin A, 2014, NEUROIMAGE, V90, P348, DOI 10.1016/j.neuroimage.2013.12.049.
   de Heer W.A., 2017, J NEUROSCI, P3216.
   Dehaene S, 1999, SCIENCE, V284, P970, DOI 10.1126/science.284.5416.970.
   Dehaene S, 2015, NEURON, V88, P2, DOI 10.1016/j.neuron.2015.09.019.
   Dehghani M, 2017, HUM BRAIN MAPP, V38, P6096, DOI 10.1002/hbm.23814.
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008.
   Demsar J, 2006, J MACH LEARN RES, V7, P1.
   Desai RH, 2016, J NEUROSCI, V36, P4050, DOI 10.1523/JNEUROSCI.1480-15.2016.
   Diachek E., 2019, DOMAIN GEN MULTIPLE.
   Dien J, 2008, BRAIN RES, V1229, P179, DOI 10.1016/j.brainres.2008.06.107.
   do Amaral AA, 2019, GLOB CHALL, V3, DOI 10.1002/gch2.201900001.
   Dozat T, 2016, ICLR WORKSH.
   Dronkers NF, 2004, COGNITION, V92, P145, DOI 10.1016/j.cognition.2003.11.002.
   Duffau H, 2014, BRAIN LANG, V131, P1, DOI 10.1016/j.bandl.2013.05.011.
   Duncan J, 2000, TRENDS NEUROSCI, V23, P475, DOI 10.1016/S0166-2236(00)01633-7.
   Duncan J, 2010, TRENDS COGN SCI, V14, P172, DOI 10.1016/j.tics.2010.01.004.
   Egner T, 2008, J NEUROSCI, V28, P6141, DOI 10.1523/JNEUROSCI.1262-08.2008.
   Eickhoff SB, 2011, CEREB CORTEX, V21, P1178, DOI 10.1093/cercor/bhq188.
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006.
   Federmeier KD, 2005, PSYCHOPHYSIOLOGY, V42, P133, DOI 10.1111/j.1469-8986.2005.00274.x.
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133.
   Fedorenko E, 2006, J MEM LANG, V54, P541, DOI 10.1016/j.jml.2005.12.006.
   Fedorenko E., 2018, 477851 BIORXIV.
   Fedorenko E., COGNITIVE NEUROSCIEN.
   Fedorenko E., 2011, P NATL ACAD SCI.
   Fedorenko E., BROCAS AREA IS NOT N.
   Fedorenko E., 2013, P NATL ACAD SCI.
   Fedorenko E, 2007, J MEM LANG, V56, P246, DOI 10.1016/j.jml.2006.06.007.
   Fedorenko E, 2016, P NATL ACAD SCI USA, V113, pE6256, DOI 10.1073/pnas.1612132113.
   Fedorenko E, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00335.
   Fedorenko E, 2014, TRENDS COGN SCI, V18, P120, DOI 10.1016/j.tics.2013.12.006.
   Fedorenko E, 2012, CURR BIOL, V22, P2059, DOI 10.1016/j.cub.2012.09.011.
   Fedorenko E, 2012, NEUROPSYCHOLOGIA, V50, P499, DOI 10.1016/j.neuropsychologia.2011.09.014.
   Fedorenko E, 2010, J NEUROPHYSIOL, V104, P1177, DOI 10.1152/jn.00032.2010.
   Fedorenko E, 2009, LANG LINGUIST COMPAS, V3, DOI 10.1111/j.1749-818x.2009.00143.x.
   Felser C, 2003, BRAIN LANG, V87, P345, DOI 10.1016/S0093-934X(03)00135-4.
   Ferreira F, 2018, CURR DIR PSYCHOL SCI, V27, P443, DOI 10.1177/0963721418794491.
   Fiebach CJ, 2005, HUM BRAIN MAPP, V24, P79, DOI 10.1002/hbm.20070.
   Fischl B, 2008, CEREB CORTEX, V18, P1973, DOI 10.1093/cercor/bhm225.
   Fodor J, 1983, MODULARITY MIND ESSA.
   Fossum V., 2012, P 3 WORKSH COGN MOD.
   Frank SL, 2018, LANG COGN NEUROSCI, V33, P1213, DOI 10.1080/23273798.2018.1424347.
   Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006.
   Frank SL, 2012, P ROY SOC B-BIOL SCI, V279, P4522, DOI 10.1098/rspb.2012.1741.
   Frank SL, 2011, PSYCHOL SCI, V22, P829, DOI 10.1177/0956797611409589.
   Friederici AD, 2003, CEREB CORTEX, V13, P170, DOI 10.1093/cercor/13.2.170.
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001.
   Friederici AD, 2011, BIOLINGUISTICS, V5, P87.
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011.
   Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402.
   Frost MA, 2012, NEUROIMAGE, V59, P1369, DOI 10.1016/j.neuroimage.2011.08.035.
   Futrell R, 2017, P 15 C EUR CHAPT ASS, V1, P688.
   Futrell Richard, 2018, P 11 INT C LANG RES.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Gambi C, 2018, J EXP CHILD PSYCHOL, V173, P351, DOI 10.1016/j.jecp.2018.04.012.
   Gelman A, 2014, PERSPECT PSYCHOL SCI, V9, P641, DOI 10.1177/1745691614551642.
   Geranmayeh F., 2016, NEUROLOGY.
   Geranmayeh F, 2017, BRAIN, V140, P1947, DOI 10.1093/brain/awx134.
   Geranmayeh F, 2014, BRAIN, V137, P2632, DOI 10.1093/brain/awu163.
   Gibson E, 2000, IMAGE, LANGUAGE, BRAIN, P95.
   Gibson E., 1998, 4 ARCH MECH LANG PRO.
   Glascher J, 2010, NEURON, V66, P585, DOI 10.1016/j.neuron.2010.04.016.
   Gloor P., 1997, TEMPORAL LOBE LIMBIC.
   Gold BT, 2006, J NEUROSCI, V26, P6523, DOI 10.1523/JNEUROSCI.0808-06.2006.
   Goldberg II, 2006, NEURON, V50, P329, DOI 10.1016/j.neuron.2006.03.015.
   Grant AM, 2015, BRAIN LANG, V144, P35, DOI 10.1016/j.bandl.2015.03.010.
   Grodner D, 2005, COGNITIVE SCI, V29, P261, DOI 10.1207/s15516709cog0000\_7.
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004.
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159.
   Hale J., 2015, P 6 WORKSH COGN MOD, P89.
   Hale J, 2006, COGNITIVE SCI, V30, P643, DOI 10.1207/s15516709cog0000\_64.
   Hale John T., 2014, AUTOMATON THEORIES H.
   Handwerker DA, 2004, NEUROIMAGE, V21, P1639, DOI 10.1016/j.neuroimage.2003.11.029.
   Harel N, 2002, J CEREBR BLOOD F MET, V22, P908, DOI 10.1097/00004647-200208000-00002.
   Harrison L, 2003, NEUROIMAGE, V19, P1477, DOI 10.1016/S1053-8119(03)00160-5.
   Hartwigsen G, 2018, TRENDS COGN SCI, V22, P687, DOI 10.1016/j.tics.2018.05.008.
   Hartwigsen G, 2017, NEUROIMAGE, V147, P812, DOI 10.1016/j.neuroimage.2016.08.026.
   Hasson U, 2018, COGNITION, V180, P135, DOI 10.1016/j.cognition.2018.06.018.
   Hasson U, 2012, NEUROIMAGE, V62, P1272, DOI 10.1016/j.neuroimage.2012.02.004.
   Hasson U, 2010, TRENDS COGN SCI, V14, P40, DOI 10.1016/j.tics.2009.10.011.
   Havron N, 2019, CHILD DEV, V90, P82, DOI 10.1111/cdev.13113.
   Heafield K., 2013, P 51 ANN M ASS COMP, P690.
   Hein G, 2008, J COGNITIVE NEUROSCI, V20, P2125, DOI 10.1162/jocn.2008.20148.
   Henderson JM, 2016, NEUROIMAGE, V132, P293, DOI 10.1016/j.neuroimage.2016.02.050.
   Henderson JM, 2015, NEUROIMAGE, V119, P390, DOI 10.1016/j.neuroimage.2015.06.072.
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280.
   Hervais-Adelman AG, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00234.
   Hsiao F, 2003, COGNITION, V90, P3, DOI 10.1016/S0010-0277(03)00124-0.
   Hsu NS, 2016, PSYCHOL SCI, V27, P572, DOI 10.1177/0956797615625223.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Hugdahl K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00430.
   Humphries C, 2006, J COGNITIVE NEUROSCI, V18, P665, DOI 10.1162/jocn.2006.18.4.665.
   Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637.
   James W, 1890, PRINCIPLES PSYCHOL.
   January D, 2009, J COGNITIVE NEUROSCI, V21, P2434, DOI 10.1162/jocn.2008.21179.
   JONES E G, 1970, Brain Behavior and Evolution, V93, P793, DOI 10.1093/brain/93.4.793.
   Joshi A.K., 1985, NATURAL LANGUAGE PAR, P206, DOI DOI 10.1017/CBO9780511597855.
   Juch H, 2005, NEUROIMAGE, V24, P504, DOI 10.1016/j.neuroimage.2004.08.037.
   Julian JB, 2012, NEUROIMAGE, V60, P2357, DOI 10.1016/j.neuroimage.2012.02.055.
   Kaan E, 2002, TRENDS COGN SCI, V6, P350, DOI 10.1016/S1364-6613(02)01947-2.
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa.
   Kannurpatti SS, 2004, J CEREBR BLOOD F MET, V24, P703, DOI 10.1097/01.WCB.0000121232.04853.46.
   Keller GB, 2018, NEURON, V100, P424, DOI 10.1016/j.neuron.2018.10.003.
   Kiehl KA, 2002, NEUROIMAGE, V17, P842, DOI 10.1006/nimg.2002.1244.
   Kim SY, 2016, NEUROIMAGE, V129, P25, DOI 10.1016/j.neuroimage.2015.11.068.
   Kingma Diederik P., 2014, CORR.
   Kliegl R, 2006, J EXP PSYCHOL GEN, V135, P12, DOI 10.1037/0096-3445.135.1.12.
   KLUENDER R, 1993, J COGNITIVE NEUROSCI, V5, P196, DOI 10.1162/jocn.1993.5.2.196.
   Koch K, 2008, LEARN MEMORY, V15, P728, DOI 10.1101/lm.1106408.
   Koechlin E, 2006, NEURON, V50, P963, DOI 10.1016/j.neuron.2006.05.017.
   Koelsch S., 2002, BACH SPEAKS CORTICAL.
   Kotz SA, 2009, BRAIN LANG, V109, P68, DOI 10.1016/j.bandl.2008.06.002.
   Kruggel F, 2000, MAGNET RESON MED, V44, P277, DOI 10.1002/1522-2594(200008)44:2<277::AID-MRM15>3.0.CO;2-X.
   Kruggel F, 1999, HUM BRAIN MAPP, V8, P259, DOI 10.1002/(SICI)1097-0193(1999)8:4<259::AID-HBM9>3.0.CO;2-K.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Kuperberg GR, 2003, J COGNITIVE NEUROSCI, V15, P272, DOI 10.1162/089892903321208204.
   Kuperberg GR, 2000, J COGNITIVE NEUROSCI, V12, P321, DOI 10.1162/089892900562138.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Lau EF, 2016, CEREB CORTEX, V26, P1377, DOI 10.1093/cercor/bhu219.
   LEE AT, 1995, MAGNET RESON MED, V33, P745, DOI 10.1002/mrm.1910330602.
   Lesage E, 2017, J NEUROSCI, V37, P6231, DOI 10.1523/JNEUROSCI.3203-16.2017.
   Levelt WJM., 1989, SPEAKING INTENTION A.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Levy R, 2013, J MEM LANG, V69, P461, DOI 10.1016/j.jml.2012.10.005.
   Levy R, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00229.
   Lewis RL, 2005, COGNITIVE SCI, V29, P375, DOI 10.1207/s15516709cog0000\_25.
   Lewis S, 2015, J PSYCHOLINGUIST RES, V44, P27, DOI 10.1007/s10936-014-9329-z.
   Linck JA, 2014, PSYCHON B REV, V21, P861, DOI 10.3758/s13423-013-0565-2.
   Lindquist MA, 2007, HUM BRAIN MAPP, V28, P764, DOI 10.1002/hbm.20310.
   Lindquist MA, 2009, NEUROIMAGE, V45, pS187, DOI 10.1016/j.neuroimage.2008.10.065.
   Lopopolo A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177794.
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676.
   MACDONALD MC, 1992, COGNITIVE PSYCHOL, V24, P56, DOI 10.1016/0010-0285(92)90003-K.
   Mahowald K, 2016, NEUROIMAGE, V139, P74, DOI 10.1016/j.neuroimage.2016.05.073.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556.
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   Matchin W, 2019, HUM BRAIN MAPP, V40, P663, DOI 10.1002/hbm.24403.
   Matchin W, 2017, CORTEX, V88, P106, DOI 10.1016/j.cortex.2016.12.010.
   Matchin W, 2014, BRAIN LANG, V138, P1, DOI 10.1016/j.bandl.2014.09.001.
   Mather M, 2013, PERSPECT PSYCHOL SCI, V8, P108, DOI 10.1177/1745691612469037.
   MAZOYER BM, 1993, J COGNITIVE NEUROSCI, V5, P467, DOI 10.1162/jocn.1993.5.4.467.
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI DOI 10.25080/MAJORA-7B98E3ED-003.
   McMillan CT, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00153.
   McMillan CT, 2012, NEUROPSYCHOLOGIA, V50, P674, DOI 10.1016/j.neuropsychologia.2012.01.004.
   Meier EL, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00109.
   Mesulam MM, 1998, BRAIN, V121, P1013, DOI 10.1093/brain/121.6.1013.
   Meyniel F, 2017, P NATL ACAD SCI USA, V114, pE3859, DOI 10.1073/pnas.1615773114.
   Miezin FM, 2000, NEUROIMAGE, V11, P735, DOI 10.1006/nimg.2000.0568.
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167.
   Mineroff Z, 2018, NEUROPSYCHOLOGIA, V119, P501, DOI 10.1016/j.neuropsychologia.2018.09.011.
   Mitsugi S, 2016, BILING-LANG COGN, V19, P19, DOI 10.1017/S1366728914000881.
   Mollica F., 2018, BIORXIV.
   Momma S, 2019, COGNITIVE PSYCHOL, V114, DOI 10.1016/j.cogpsych.2019.101228.
   Montague PR, 1996, J NEUROSCI, V16, P1936, DOI 10.1523/jneurosci.16-05-01936.1996.
   Monti MM, 2012, PSYCHOL SCI, V23, P914, DOI 10.1177/0956797612437427.
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114.
   NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543.
   Newman AJ, 2001, J PSYCHOLINGUIST RES, V30, P339, DOI 10.1023/A:1010499119393.
   Nguyen L., 2012, TECHNICAL PAPERS, P2125.
   Nieto-Castanon A, 2012, NEUROIMAGE, V63, P1646, DOI 10.1016/j.neuroimage.2012.06.065.
   Nieuwenhuis S, 2011, NAT NEUROSCI, V14, P1105, DOI 10.1038/nn.2886.
   Nieuwland MS, 2012, HUM BRAIN MAPP, V33, P2509, DOI 10.1002/hbm.21377.
   Novais-Santos S, 2007, NEUROIMAGE, V37, P361, DOI 10.1016/j.neuroimage.2007.03.077.
   Novick JM, 2005, COGN AFFECT BEHAV NE, V5, P263, DOI 10.3758/CABN.5.3.263.
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007.
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Pallier C, 2011, P NATL ACAD SCI USA, V108, P2522, DOI 10.1073/pnas.1018711108.
   Paunov AM, 2019, J NEUROPHYSIOL, V121, P1244, DOI 10.1152/jn.00619.2018.
   Payne BR, 2018, BRAIN RES, V1687, P117, DOI 10.1016/j.brainres.2018.02.021.
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142.
   Perani D, 2005, CURR OPIN NEUROBIOL, V15, P202, DOI 10.1016/j.conb.2005.03.007.
   PETERSEN SE, 1988, NATURE, V331, P585, DOI 10.1038/331585a0.
   Pickering MJ, 2018, PSYCHOL BULL, V144, P1002, DOI 10.1037/bul0000158.
   Pinker S., 1994, LANGUAGE INSTINCT MI.
   Pliatsikas C, 2016, BILING-LANG COGN, V19, P699, DOI 10.1017/S1366728916000249.
   Poldrack RA, 2006, TRENDS COGN SCI, V10, P59, DOI 10.1016/j.tics.2005.12.004.
   Poldrack RA, 2011, NEURON, V72, P692, DOI 10.1016/j.neuron.2011.11.001.
   POLYAK BT, 1992, SIAM J CONTROL OPTIM, V30, P838, DOI 10.1137/0330046.
   Ralph MAL, 2017, NAT REV NEUROSCI, V18, P42, DOI 10.1038/nrn.2016.150.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rasmussen NE, 2018, COGNITIVE SCI, V42, P1009, DOI 10.1111/cogs.12511.
   Rayner K, 2004, J EXP PSYCHOL HUMAN, V30, P720, DOI 10.1037/0096-1523.30.4.720.
   Resnik Philip, 1992, P 14 C COMP LING STR, P191, DOI DOI 10.3115/992066.992098.
   Richlan F, 2014, CEREB CORTEX, V24, P2647, DOI 10.1093/cercor/bht117.
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009.
   Rogalsky C, 2015, LANG COGN NEUROSCI, V30, P1326, DOI 10.1080/23273798.2015.1066831.
   Rogalsky C, 2011, J COGNITIVE NEUROSCI, V23, P1664, DOI 10.1162/jocn.2010.21530.
   Ruschemeyer SA, 2005, HUM BRAIN MAPP, V25, P266, DOI 10.1002/hbm.20098.
   Rushworth MFS, 2008, NAT NEUROSCI, V11, P389, DOI 10.1038/nn2066.
   Saad ZS, 2001, HUM BRAIN MAPP, V13, P74, DOI 10.1002/hbm.1026.
   Sakai KL, 2005, SCIENCE, V310, P815, DOI 10.1126/science.1113530.
   Saxe R, 2006, NEUROIMAGE, V30, P1088, DOI 10.1016/j.neuroimage.2005.12.062.
   Schapiro AC, 2013, NAT NEUROSCI, V16, P486, DOI 10.1038/nn.3331.
   Scheperjans F, 2008, CEREB CORTEX, V18, P2141, DOI 10.1093/cercor/bhm241.
   Schuster S, 2016, CEREB CORTEX, V26, P3889, DOI 10.1093/cercor/bhw184.
   Scott SK, 2013, HEARING RES, V303, P58, DOI 10.1016/j.heares.2013.05.001.
   Scott TL, 2017, COGN NEUROSCI-UK, V8, P167, DOI 10.1080/17588928.2016.1201466.
   Shafto MA, 2014, SCIENCE, V346, P583, DOI 10.1126/science.1254404.
   Shain C., 2019, P 2019 ANN C N AM CH.
   Shain C., 2018, P 2018 C EMP METH NA.
   Shain C., 2016, P WORKSH COMP LING L, P49.
   Shain C., 2019, CONTINUOUS TIME DECO.
   SHANNON CE, 1948, COMMUNICATION, V27, P623.
   Shmuel A, 2006, NAT NEUROSCI, V9, P569, DOI 10.1038/nn1675.
   Shmuel A, 2002, NEURON, V36, P1195, DOI 10.1016/S0896-6273(02)01061-9.
   SIMS CA, 1980, ECONOMETRICA, V48, P1, DOI 10.2307/1912017.
   Sims JA, 2016, NEUROPSYCHOLOGIA, V84, P113, DOI 10.1016/j.neuropsychologia.2015.10.019.
   Singer Y, 2018, ELIFE, V7, DOI 10.7554/eLife.31557.
   Smith AT, 2000, NEUROREPORT, V11, P271, DOI 10.1097/00001756-200002070-00010.
   Smith N.J., 2011, P 33 COGSCI C.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Sood MR, 2016, HUM BRAIN MAPP, V37, P2784, DOI 10.1002/hbm.23208.
   Speer NK, 2007, PSYCHOL SCI, V18, P449, DOI 10.1111/j.1467-9280.2007.01920.x.
   Speer NK, 2009, PSYCHOL SCI, V20, P989, DOI 10.1111/j.1467-9280.2009.02397.x.
   Sreenivasan KK, 2014, TRENDS COGN SCI, V18, P82, DOI 10.1016/j.tics.2013.12.001.
   Stanescu-Cosson R, 2000, BRAIN, V123, P2240, DOI 10.1093/brain/123.11.2240.
   Staub A, 2015, LANG LINGUIST COMPAS, V9, P311, DOI 10.1111/lnc3.12151.
   Staub A, 2013, PSYCHON B REV, V20, P1304, DOI 10.3758/s13423-013-0444-x.
   Steedman M., 2000, SYNTACTIC PROCESS.
   Stowe LA, 1998, NEUROREPORT, V9, P2995, DOI 10.1097/00001756-199809140-00014.
   Strange BA, 2005, NEURAL NETWORKS, V18, P225, DOI 10.1016/j.neunet.2004.12.004.
   Strijkers K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41376-x.
   Tahmasebi AM, 2012, HUM BRAIN MAPP, V33, P938, DOI 10.1002/hbm.21261.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Thompson-Schill SL, 2005, CURR OPIN NEUROBIOL, V15, P219, DOI 10.1016/j.conb.2005.03.006.
   Tomaiuolo F, 1999, EUR J NEUROSCI, V11, P3033, DOI 10.1046/j.1460-9568.1999.00718.x.
   Tran D., 2016, ARXIV161009787.
   Tyler LK, 2011, BRAIN, V134, P415, DOI 10.1093/brain/awq369.
   Uhrig L, 2014, J NEUROSCI, V34, P1127, DOI 10.1523/JNEUROSCI.3165-13.2014.
   Ullman M. T., 2016, NEUROBIOLOGY LANGUAG, P953, DOI {[}DOI 10.1016/B978-0-12-407794-2.00076-6, 10.1016/B978-0-12-407794-2.00076-6.].
   Vaden KI, 2013, J NEUROSCI, V33, P18979, DOI 10.1523/JNEUROSCI.1417-13.2013.
   Vagharchakian L, 2012, J NEUROSCI, V32, P9089, DOI 10.1523/JNEUROSCI.5685-11.2012.
   van Schijndel M., 2013, P HUM LANG TECHN 201.
   van Schijndel M., 2015, P NAACL HLT 2015 ASS.
   van Schijndel M, 2013, TOP COGN SCI, V5, P522, DOI 10.1111/tops.12034.
   Vandenberghe R, 2002, J COGNITIVE NEUROSCI, V14, P550, DOI 10.1162/08989290260045800.
   Vazquez-Rodriguez B, 2019, P NATL ACAD SCI USA, V116, P21219, DOI 10.1073/pnas.1903403116.
   Visser M, 2010, J COGNITIVE NEUROSCI, V22, P1083, DOI 10.1162/jocn.2009.21309.
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012.
   Wacongne C, 2011, P NATL ACAD SCI USA, V108, P20754, DOI 10.1073/pnas.1117807108.
   Wang LP, 2015, CURR BIOL, V25, P1966, DOI 10.1016/j.cub.2015.06.035.
   Wang R, 2017, J NEUROSCI, V37, P8412, DOI 10.1523/JNEUROSCI.0144-17.2017.
   Wartenburger I, 2003, NEURON, V37, P159, DOI 10.1016/S0896-6273(02)01150-9.
   Wehbe L., ACTIVITY FRONTO TEMP.
   Wehbe L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112575.
   Wernicke C, 1874, APHASISCHE SYMPTOMEN.
   Whitfield-Gabrieli S, 2012, BRAIN CONNECT, V2, P125, DOI 10.1089/brain.2012.0073.
   Whitney C, 2009, NEUROIMAGE, V47, P360, DOI 10.1016/j.neuroimage.2009.04.037.
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012.
   Willems RM, 2016, CEREB CORTEX, V26, P2506, DOI 10.1093/cercor/bhv075.
   Wilson SM, 2014, J COGNITIVE NEUROSCI, V26, P970, DOI 10.1162/jocn\_a\_00550.
   Wilson SM, 2012, BRAIN LANG, V122, P190, DOI 10.1016/j.bandl.2012.04.005.
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006.
   Wise RJS, 2001, BRAIN, V124, P83, DOI 10.1093/brain/124.1.83.
   Wlotko EW, 2012, PSYCHOPHYSIOLOGY, V49, P770, DOI 10.1111/j.1469-8986.2012.01366.x.
   Wu S., 2010, P N AM ASS COMP LING.
   Yarkoni T, 2008, NEUROIMAGE, V41, P1408, DOI 10.1016/j.neuroimage.2008.03.062.
   Yokoyama S, 2006, NEUROIMAGE, V30, P570, DOI 10.1016/j.neuroimage.2005.09.066.
   Zaccarella E, 2017, NEUROSCI BIOBEHAV R, V80, P646, DOI 10.1016/j.neubiorev.2017.06.011.
   Zarr N, 2016, NEUROIMAGE, V124, P238, DOI 10.1016/j.neuroimage.2015.08.063.}},
Number-of-Cited-References = {{318}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Neuropsychologia}},
Doc-Delivery-Number = {{KN1ZM}},
Unique-ID = {{ISI:000514640000004}},
DA = {{2020-12-06}},
}

@article{ ISI:000528666500012,
Author = {Villegas, Julian and Markov, Konstantin and Perkins, Jeremy and Lee,
   Seunghun J.},
Title = {{Prediction of Creaky Speech by Recurrent Neural Networks Using
   Psychoacoustic Roughness}},
Journal = {{IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING}},
Year = {{2020}},
Volume = {{14}},
Number = {{2}},
Pages = {{355-366}},
Month = {{FEB}},
Abstract = {{The use of a psychoacoustic roughness model as a predictor of creaky
   voice is reported. We found that the roughness temporal profile of
   vocalic segments can predict the presence of creakiness in speech. Using
   a simple bi-directional Recurrent Neural Network (rnn), we were able to
   predict the presence of creakiness in vocalic segments from only
   roughness traces with an accuracy similar to that obtained with rnns
   trained on at least 12-dimensional input data (including amplitude
   difference between the first two harmonics, residual peak prominence,
   etc.). Training rnns with the combination of roughness and
   multidimensional input data improved the performance of the predictor,
   but not significantly. Likewise, augmenting the dataset by time
   derivatives of the input features did not improve the predictor's
   performance. The proposed roughness-based predictor eases interpretation
   and comparison of creakiness among corpora and suggests that roughness
   prediction models could be successfully used for classification of
   creaky intervals in speech.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Villegas, J (Corresponding Author), Univ Aizu, Comp Arts Lab, Aizu Wakamatsu, Fukushima 9658580, Japan.
   Villegas, Julian, Univ Aizu, Comp Arts Lab, Aizu Wakamatsu, Fukushima 9658580, Japan.
   Markov, Konstantin, Univ Aizu, Human Interface Lab, Aizu Wakamatsu, Fukushima 9658580, Japan.
   Perkins, Jeremy, Univ Aizu, Ctr Language Res, Aizu Wakamatsu, Fukushima 9658580, Japan.
   Lee, Seunghun J., Int Christian Univ, Tokyo 1818585, Japan.
   Lee, Seunghun J., Univ Venda, ZA-0950 Thohoyandou, South Africa.}},
DOI = {{10.1109/JSTSP.2019.2949422}},
ISSN = {{1932-4553}},
EISSN = {{1941-0484}},
Keywords = {{Psychoacoustics; Harmonic analysis; Predictive models; Psychoacoustic
   models; Recurrent neural networks; Creakiness; Psychoacoustic Roughness;
   Recurrent Neural Networks; Phonation; Tone Classification}},
Keywords-Plus = {{VOICE QUALITY; GLOTTAL CHARACTERISTICS; AUTOMATIC DETECTION; PERCEPTION;
   FEMALE; CONSONANCE; SPEAKERS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{julian@u-aizu.ac.jp
   markov@u-aizu.ac.jp
   jperkins@u-aizu.ac.jp
   seunghun@icu.ac.jp}},
ORCID-Numbers = {{Villegas, Julian/0000-0003-1891-1753
   Markov, Konstantin/0000-0003-1838-4789
   Lee, Seunghun/0000-0001-5634-5583
   Perkins, Jeremy/0000-0002-7800-4234}},
Funding-Acknowledgement = {{JSPS KakenhiMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) {[}15K16745];
   Strategic Japanese-Swiss Science and Technology Programme of JSPS;
   Strategic Japanese-Swiss Science and Technology Programme of SNSF}},
Funding-Text = {{This work was supported in part by the JSPS Kakenhi Grant 15K16745 and
   in part by the Strategic Japanese-Swiss Science and Technology Programme
   of JSPS and SNSF. The guest editor coordinating the review of this
   manuscript and approving it for publication was Dr. Tan Lee.}},
Cited-References = {{Aichinger P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P767.
   Avelino H, 2010, J VOICE, V24, P270, DOI 10.1016/j.jvoice.2008.10.002.
   Blankenship B., 1997, THESIS.
   Blomgren M, 1998, J ACOUST SOC AM, V103, P2649, DOI 10.1121/1.422785.
   Boersma P., 2019, PRAAT DOING PHONETIC.
   Borsky M, 2017, IEEE-ACM T AUDIO SPE, V25, P2281, DOI 10.1109/TASLP.2017.2759002.
   Brockmann-Bauser M, 2018, J VOICE, V32, P162, DOI 10.1016/j.jvoice.2017.04.008.
   Catford J. C., 1964, PHONATION TYPES CLAS.
   CHILDERS DG, 1991, J ACOUST SOC AM, V90, P2394, DOI 10.1121/1.402044.
   Daniel P., 2014, ACTA ACUST UNITED AC, V83, P113.
   de Bruijn C., 2007, P PHON TEACH LEARN C.
   Degottex Gilles, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P960, DOI 10.1109/ICASSP.2014.6853739.
   Denes P. B., 1993, THE SPEECH CHAIN.
   Drugman T, 2014, COMPUT SPEECH LANG, V28, P1233, DOI 10.1016/j.csl.2014.03.002.
   Eckert H., 1994, MENSCHEN IHRE STIMME.
   Eddins DA, 2015, J ACOUST SOC AM, V138, P3820, DOI 10.1121/1.4937753.
   Edmondson J., 2006, PHONOLOGY, V23, P157, DOI DOI 10.1017/S095267570600087X.
   Esling J. H., 2003, P 15 INT C PHON SCI, V1, P1049.
   Eyben F., 2010, P 18 ACM INT C MULT, P1459, DOI DOI 10.1145/1873951.1874246.
   Fastl H, 2006, PSYCHOACOUSTICS FACT.
   Fishman YI, 2001, J NEUROPHYSIOL, V86, P2761.
   Fraile R, 2014, BIOMED SIGNAL PROCES, V14, P42, DOI 10.1016/j.bspc.2014.07.001.
   Gerratt BR, 2001, J PHONETICS, V29, P365, DOI 10.1006/jpho.2001.0149.
   Gordon M, 2001, J PHONETICS, V29, P383, DOI 10.1006/jpho.2001.0147.
   Gruber J. F., 2011, THESIS.
   Hanson HM, 2001, J PHONETICS, V29, P451, DOI 10.1006/jpho.2001.0146.
   Hanson HM, 1997, J ACOUST SOC AM, V101, P466, DOI 10.1121/1.417991.
   Hanson HM, 1999, J ACOUST SOC AM, V106, P1064, DOI 10.1121/1.427116.
   Helmholtz Hermann von, 1954, SENSATIONS TONE PHYS.
   HOGEL J, 1994, BIOMETRICAL J, V36, P411, DOI 10.1002/bimj.4710360403.
   Ishi CT, 2008, IEEE T AUDIO SPEECH, V16, P47, DOI 10.1109/TASL.2007.910791.
   Kane J, 2013, COMPUT SPEECH LANG, V27, P1028, DOI 10.1016/j.csl.2012.11.002.
   Keating P., 2015, P 18 INT C PHON SCI.
   Khan Sameer ud Dowla, 2010, UCLA WORKING PAPERS, V108, P188.
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894.
   KREIMAN J, 1993, J SPEECH HEAR RES, V36, P21, DOI 10.1044/jshr.3601.21.
   Kuang JJ, 2018, J ACOUST SOC AM, V143, pEL509, DOI 10.1121/1.5043094.
   Ladefoged P., 1971, PRELIMINARIES LINGUI.
   Laver J., 2009, CAMBRIDGE STUDIES LI.
   Lee S, 2015, J SOCIOLING, V19, P275, DOI 10.1111/josl.12123.
   LICKLIDER JCR, 1951, EXPERIENTIA, V7, P128, DOI 10.1007/BF02156143.
   Mac D.-K., 2015, P 18 INT C PHON SCI.
   Mathworks, 2019, MATLAB SOFTWARE.
   Moisik SR, 2014, J INT PHON ASSOC, V44, P21, DOI 10.1017/S0025100313000327.
   MOORE BCJ, 1983, J ACOUST SOC AM, V74, P750, DOI 10.1121/1.389861.
   Mori H., 2017, P LANG RES WORKSH, P347.
   Murton O, 2019, J ACOUST SOC AM, V145, pEL379, DOI 10.1121/1.5100911.
   Ogden R, 2004, SOUND PATTERNS INTER, P29, DOI DOI 10.1075/TSL.62.
   Owen S, 2012, MAHOUT ACTION.
   PLOMP R, 1965, J ACOUST SOC AM, V38, P548, DOI 10.1121/1.1909741.
   Pressnitzer D, 1999, J ACOUST SOC AM, V105, P2773, DOI 10.1121/1.426894.
   R Core Team, 2019, R LANG ENV STAT COMP.
   Reiter R, 2015, DTSCH ARZTEBL INT, V112, P329, DOI 10.3238/arztebl.2015.0329.
   Sapir S, 2011, EXPERT REV NEUROTHER, V11, P815, DOI {[}10.1586/ERN.11.43, 10.1586/ern.11.43].
   Schrader J. E., 2002, THESIS.
   Sethares W.A., 2005, TUNING TIMBRE SPECTR.
   Shue YL, 2010, THESIS.
   STEVENS SS, 1957, J EXP PSYCHOL, V54, P377, DOI 10.1037/h0043680.
   Stumpf C., 1898, KONSONANZ DISSONANZ, V1, P1.
   Sun XJ, 2002, INT CONF ACOUST SPEE, P333.
   TERHARDT E, 1974, ACUSTICA, V30, P201.
   Titze I. R., 1989, J ACOUST SOC AM, V86, pS26.
   Titze I. R., 1994, PRINCIPLES VOICE PRO.
   Vassilakis P. N., 2001, THESIS.
   Villegas J, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1702.
   Villegas J, 2010, J NEW MUSIC RES, V39, P75, DOI 10.1080/09298211003642480.
   Vishnubhotla S, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P949.
   von Aures W., 1985, ACUSTICA, V58, P268.
   von Bekesy G, 1928, PHYS Z, V29, P793.
   vonAures W., 1985, ACUSTICA, V59, P130.
   Wang YS, 2013, J SOUND VIB, V332, P3893, DOI 10.1016/j.jsv.2013.02.030.
   Watkins J., SOAS WORKING PAPERS, V7, P321.
   Weed E., 2019, P INSAR 2019.
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3\_1.
   Wolk L, 2012, J VOICE, V26, pE111, DOI 10.1016/j.jvoice.2011.04.007.
   ZWICKER E, 1957, J ACOUST SOC AM, V29, P548, DOI 10.1121/1.1908963.}},
Number-of-Cited-References = {{76}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE J. Sel. Top. Signal Process.}},
Doc-Delivery-Number = {{LH3DC}},
Unique-ID = {{ISI:000528666500012}},
DA = {{2020-12-06}},
}

@article{ ISI:000508702000002,
Author = {Porretta, Vincent and Buchanan, Lori and Jarvikivi, Juhani},
Title = {{When processing costs impact predictive processing: The case of
   foreign-accented speech and accent experience}},
Journal = {{ATTENTION PERCEPTION \& PSYCHOPHYSICS}},
Year = {{2020}},
Volume = {{82}},
Number = {{4}},
Pages = {{1558-1565}},
Month = {{MAY}},
Abstract = {{Listeners use linguistic information and real-world knowledge to predict
   upcoming spoken words. However, studies of predictive processing have
   focused on prediction under optimal listening conditions. We examined
   the effect of foreign-accented speech on predictive processing.
   Furthermore, we investigated whether accent-specific experience
   facilitates predictive processing. Using the visual world paradigm, we
   demonstrated that although the presence of an accent impedes predictive
   processing, it does not preclude it. We further showed that as listener
   experience increases, predictive processing for accented speech
   increases and begins to approximate the pattern seen for native speech.
   These results speak to the limitation of the processing resources that
   must be allocated, leading to a trade-off when listeners are faced with
   increased uncertainty and more effortful recognition due to a foreign
   accent.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Porretta, V (Corresponding Author), Univ Windsor, Windsor, ON, Canada.
   Porretta, Vincent; Buchanan, Lori, Univ Windsor, Windsor, ON, Canada.
   Jarvikivi, Juhani, Univ Alberta, Edmonton, AB, Canada.}},
DOI = {{10.3758/s13414-019-01946-7}},
Early Access Date = {{JAN 2020}},
ISSN = {{1943-3921}},
EISSN = {{1943-393X}},
Keywords = {{Foreign-accented speech; Prediction; Language experience; Visual world
   paradigm; Eyetracking}},
Keywords-Plus = {{RECOGNITION; WORDS}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology; Psychology, Experimental}},
Author-Email = {{porretta@uwindsor.ca}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Baayen R., 2008, ANAL LINGUISTIC DATA.
   BAAYEN RH, 2010, LINGUISTISCHE BERICH, V17, P383.
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014.
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002.
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005.
   Brodeur MB, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106953.
   Brouwer S, 2016, J PSYCHOLINGUIST RES, V45, P1151, DOI 10.1007/s10936-015-9396-9.
   Brown-Schmidt S, 2017, LANG COGN NEUROSCI, V32, P1211, DOI 10.1080/23273798.2017.1325508.
   Burchill Z, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199358.
   Burnham K., 2002, MODEL SELECTION MULT.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017.
   Henry N, 2017, LANG COGN NEUROSCI, V32, P1229, DOI 10.1080/23273798.2017.1327080.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P80, DOI 10.1080/23273798.2015.1047459.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   McQueen JM, 2007, Q J EXP PSYCHOL, V60, P661, DOI 10.1080/17470210601183890.
   Porretta V., 2019, FRONTIERS COMMUNICAT, V4, P8, DOI {[}10.3389/fcomm.2019.00008, DOI 10.3389/FCOMM.2019.00008].
   Porretta V, 2019, J EXP PSYCHOL LEARN, V45, P1832, DOI 10.1037/xlm0000674.
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006.
   Rayner K, 2011, J EXP PSYCHOL HUMAN, V37, P514, DOI 10.1037/a0020990.
   Romero-Rivas C, 2016, NEUROPSYCHOLOGIA, V85, P245, DOI 10.1016/j.neuropsychologia.2016.03.022.
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174.
   Speelman D, 2018, QUANT METH HUMAN SOC, P1, DOI 10.1007/978-3-319-69830-4.
   Szekely A, 2004, J MEM LANG, V51, P247, DOI 10.1016/j.jml.2004.03.002.
   TRUESWELL JC, 1993, J EXP PSYCHOL LEARN, V19, P528, DOI 10.1037/0278-7393.19.3.528.
   Tucker B. V., 2015, P 18 INT C PHON SCI, P1.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Verhagen V, 2018, LANG COGN, V10, P329, DOI 10.1017/langcog.2018.4.
   Wood S. N., 2017, GEN ADDITIVE MODELS.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Atten. Percept. Psychophys.}},
Doc-Delivery-Number = {{LY5OH}},
Unique-ID = {{ISI:000508702000002}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000577106400028,
Author = {Kiss, Gabor and Jenei, Attila Zoltan},
Editor = {{Herencsar, N}},
Title = {{Investigation of the Accuracy of Depression Prediction Based on Speech
   Processing}},
Booktitle = {{2020 43RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL
   PROCESSING (TSP)}},
Year = {{2020}},
Pages = {{129-132}},
Note = {{43rd International Conference on Telecommunications and Signal
   Processing (TSP), ELECTR NETWORK, JUL 07-09, 2020}},
Organization = {{Brno Univ Technol, Dept Telecommunicat; Budapest Univ Technol 7 Econ,
   Dept Telecommunicat \& Media Informa; Czech Tech Univ Prague, Dept
   Telecommunicat Engn; Isik Univ, Dept Elect \& Elect Engn; Istanbul Tech
   Univ, Elect \& Commun Engn Dept; Josip Juraj Strossmayer Univ Osijek,
   Fac Elect Engn, Comp Sci \& Informat Technol; Karadeniz Tech Univ, Dept
   Elect \& Elect Engn; Natl Taiwan Univ Sci \& Technol, Dept Elect \& Comp
   Engn; Seikei Univ, Grad Sch, Fac Sci \& Technol, Informat Networking
   Lab; Slovak Univ Technol Bratislava, Inst Multimedia Informat \& Commun
   Technologies; Escola Univ Politecnica Mataro, Tecnocampus; Technical
   University of Sofia, Faculty of Telecommunications; Univ Paris 8, UFR
   MITSIC, Lab Informatique Avancee Saint Denis; Univ Politehnica
   Bucharest, Ctr Adv Res New Mat, Prod \& Innovat Proc; Univ Ljubljana,
   Lab Telecommunicat; Univ Patras, Phys Dept; VSB Tech Univ Ostrava, Dept
   Telecommunicat; W Pomeranian Univ Technol, Fac Elect Engn; IEEE Reg 8;
   IEEE Italy Sect \& Italy Sect SP Chapter, Italy Sect VT COM Joint
   Chapter; IEEE Czechoslovakia Sect; Sci Assoc Infocommunicat; IEEE
   Czechoslovakia Sect SP CAS COM Joint Chapter}},
Abstract = {{The present study investigates the accuracy of prediction of depression
   based on speech processing. Depression is one of the most widespread
   psychiatric disorders, but early detection of depression is difficult.
   The Beck Depression Inventory II (BDI) is a self-assessment
   questionnaire and can accurately predict the severity of depression. BDI
   is most often used for early detection. There is no known objective
   biomarker for depression, but the state alters the speech of the
   individual suffering from it, providing an opportunity for speech-based
   detection. In the current study, we investigated the accuracy of
   prediction of depression severity based on speech signal processing, and
   how accurately it can predict the severity of depression compared to the
   Beck Depression Inventory.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kiss, G (Corresponding Author), Budapest Univ Technol \& Econ, Dept Telecommun \& Media Informat, Budapest, Hungary.
   Kiss, Gabor; Jenei, Attila Zoltan, Budapest Univ Technol \& Econ, Dept Telecommun \& Media Informat, Budapest, Hungary.}},
ISBN = {{978-1-7281-6376-5}},
Keywords = {{BDI; depression prediction; HAM-D; speech processing; SVR}},
Keywords-Plus = {{SUICIDE}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{kiss.gabor@tmit.bme.hu
   ja1504@hszk.bme.hu}},
Funding-Acknowledgement = {{National Research, Development and Innovation Fund of Hungary
   {[}K128568];  {[}K\_18]}},
Funding-Text = {{Project no. K128568 has been implemented with the support provided from
   the National Research, Development and Innovation Fund of Hungary,
   financed under the K\_18 funding scheme.}},
Cited-References = {{Beck AT, 1996, J PERS ASSESS, V67, P588, DOI 10.1207/s15327752jpa6703\_13.
   Boersma, 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7.
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004.
   Drucker H, 1997, ADV NEUR IN, V9, P155.
   HAMILTON M, 1960, J NEUROL NEUROSUR PS, V23, P56, DOI 10.1136/jnnp.23.1.56.
   Hawton K, 2013, J AFFECT DISORDERS, V147, P17, DOI 10.1016/j.jad.2013.01.004.
   Kiss G, 2017, INT J SPEECH TECHNOL, V20, P919, DOI 10.1007/s10772-017-9455-8.
   Liu YY, 2017, INTERSPEECH, P2680, DOI 10.21437/Interspeech.2017-280.
   MARCUS M, 2012, WHO DEP MENTAL HLTH, V1, P6, DOI DOI 10.1037/E517532013-004.
   Mathers CD, 2006, PLOS MED, V3, DOI 10.1371/journal.pmed.0030442.
   Olesen J, 2012, EUR J NEUROL, V19, P155, DOI 10.1111/j.1468-1331.2011.03590.x.
   Orozco-Arroyave JR, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P95.
   Sztaho D., 2014, WOCCI, P45.
   Tulics MG, 2017, INT CONF COGN INFO, P21, DOI 10.1109/CogInfoCom.2017.8268210.
   Vasquez-Correa JC, 2017, INTERSPEECH, P314, DOI 10.21437/Interspeech.2017-1078.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BQ1RO}},
Unique-ID = {{ISI:000577106400028}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000589171100063,
Author = {Raju, K. Venkata and Sridhar, M.},
Editor = {{Luhach, AK and Kosa, JA and Poonia, RC and Gao, XZ and Singh, D}},
Title = {{Review-Based Sentiment Prediction of Rating Using Natural Language
   Processing Sentence-Level Sentiment Analysis with Bag-of-Words Approach}},
Booktitle = {{FIRST INTERNATIONAL CONFERENCE ON SUSTAINABLE TECHNOLOGIES FOR
   COMPUTATIONAL INTELLIGENCE}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2020}},
Volume = {{1045}},
Pages = {{807-821}},
Note = {{1st International Conference on Sustainable Technologies for
   Computational Intelligence (ICTSCI), Sri Balaji Coll Engn \& Technol,
   Jaipur, INDIA, MAR 29-30, 2019}},
Organization = {{CSI Jaipur Chapter; MRK Inst Engn \& Technol; Leafra Res Pvt Ltd}},
Abstract = {{User's opinion plays a vital role in the global world of Internet as
   they are given freedom to express their feedback. A lot of hidden
   information and feeling of the user are expressed in the words that
   he/she used. Extracting this hidden information can help the service
   industry to better serve the need as per the user acceptance and to
   outfit the competition in the market. Methodology of this paper is
   intended to define the rating of the review given by the user. Method of
   bag-of-words approach taking the sentiment score and magnitude of the
   sentence using natural language processing is applied. The scale of one
   to five is considered in this experimental classification on the data
   set of hotel reviews. The results have shown that around 60\% of the
   ratings can be predicted and 40\% unpredicted with the given review. The
   Data set used in this experimental analysis is the Datafiniti's hotel
   reviews.}},
Publisher = {{SPRINGER-VERLAG SINGAPORE PTE LTD}},
Address = {{152 BEACH ROAD, \#21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Raju, KV (Corresponding Author), Acharya Nagarjuna Univ Guntur, Dept Comp Sci \& Engn, Guntur, Andhra Pradesh, India.
   Raju, K. Venkata, Acharya Nagarjuna Univ Guntur, Dept Comp Sci \& Engn, Guntur, Andhra Pradesh, India.
   Sridhar, M., RVR \& JC Coll Engn, Dept Comp Applicat, Guntur, Andhra Pradesh, India.}},
DOI = {{10.1007/978-981-15-0029-9\_63}},
ISSN = {{2194-5357}},
EISSN = {{2194-5365}},
ISBN = {{978-981-15-0029-9; 978-981-15-0028-2}},
Keywords = {{Bag-of-words; Sentimental analysis; Review; Prediction; Natural language
   processing; Sentiment prediction; Statistical methods; Opinion rating}},
Research-Areas = {{Computer Science; Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Green \& Sustainable Science
   \& Technology}},
Author-Email = {{venkatsagar05@gmail.com
   mandapati12@gmail.com}},
Cited-References = {{Ahmed E, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS AND COMPUTATIONAL INTELLIGENCE (ICBDAC), P86, DOI 10.1109/ICBDACI.2017.8070814.
   Anshuman, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P557, DOI 10.1109/CONFLUENCE.2017.7943213.
   Gang Li, 2010, Proceedings 2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering (ISKE 2010), P331, DOI 10.1109/ISKE.2010.5680859.
   Han-Xiao Shi, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P950, DOI 10.1109/ICMLC.2011.6016866.
   Kasper W., 2011, COMP LING APPL C, V231527, P45.
   Lu Y., 2009, P 18 INT C WORLD WID, P131, DOI DOI 10.1145/1526709.1526728.
   Luo WJ, 2014, IEEE DATA MINING, P380, DOI 10.1109/ICDM.2014.14.
   Venkata Raju K.D.M., 2018, J ADV RES DYN CONTRO, P663.
   Venkata Raju K.D.M., 2018, INT J PURE APPL MATH, P1456.
   Venkata Raju K.D.M., 2018, J ADV DATABASE MANAG, V5, P33.}},
Number-of-Cited-References = {{10}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BQ4DP}},
Unique-ID = {{ISI:000589171100063}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000582489400026,
Author = {Mahi, Gurjot Singh and Verma, Amandeep},
Editor = {{Sharma, N and Chakrabarti, A and Balas, VE}},
Title = {{PURAN: Word Prediction System for Punjabi Language News}},
Booktitle = {{DATA MANAGEMENT, ANALYTICS AND INNOVATION, ICDMAI 2019, VOL 1}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2020}},
Volume = {{1042}},
Pages = {{383-400}},
Note = {{International Conference on Data Management, Analytics and Innovation
   (ICDMAI), Lincoln Univ Coll, Kuala Lumpur, MALAYSIA, JAN 18-20, 2019}},
Abstract = {{This paper presents an outline of the PURAN: A state-of-the-art word
   prediction system for Punjabi language news. Word prediction systems are
   used to increase the user text composition rate while typing the text.
   Brief background of the various approaches utilized in the development
   of word prediction systems, while discussing the various factors
   affecting the development of such systems is provided. This paper also
   elaborates the word prediction system architecture in detail. The system
   performance was tested on Keystroke saving, Hit ratio, Average rank and
   Average keystrokes benchmark metrics. The paper demonstrates that the
   PURAN has achieved highest Hit ratio in Regional news genre followed by
   National news genre by making lowest average keystrokes in the said
   categories of news. The results show that system has achieved 88.38\%
   Average Hit ratio with 51.42\% Average keystroke saving for N = 10.}},
Publisher = {{SPRINGER-VERLAG SINGAPORE PTE LTD}},
Address = {{152 BEACH ROAD, \#21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Mahi, GS (Corresponding Author), Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
   Mahi, Gurjot Singh; Verma, Amandeep, Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.}},
DOI = {{10.1007/978-981-32-9949-8\_26}},
ISSN = {{2194-5357}},
EISSN = {{2194-5365}},
ISBN = {{978-981-32-9949-8; 978-981-32-9948-1}},
Keywords = {{Word completion; Word prediction; Punjabi text composition}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems}},
Author-Email = {{gurjotmahi28@gmail.com
   vaman71@gmail.com}},
Cited-References = {{{[}Anonymous], 2015, 11 ANN REPORT 2014 1.
   Arnold KC, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P603, DOI 10.1145/2984511.2984584.
   BERTENSTAM J, 1995, ASSIST TECHN RES SER, V1, P312.
   Brass P, 2008, ADVANCED DATA STRUCTURES, P1.
   Cai F, 2016, FOUND TRENDS INF RET, V10, P274, DOI 10.1561/1500000055.
   Carlberger A., 1997, P ACL WORKSH NAT LAN, P23.
   Dunlop M. D., 2000, Personal Technologies, V4, P134, DOI 10.1007/BF01324120.
   Fazly A., 2002, THESIS.
   Garay-Vitoria N., 2006, Universal Access in the Information Society, V4, P188, DOI 10.1007/s10209-005-0005-9.
   Garay-Vitoria N, 2004, LECT NOTES COMPUT SC, V3196, P400.
   Garay-Vitoria N., 2002, Text, Speech and Dialogue. 5th International Conference, TSD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2448), P397.
   Garay-Vitoria N., 1997, NATURAL LANGUAGE PRO, P29.
   Garay-Vitoria N., 2004, P 7 INT C WORK COMP, P77.
   Garay-Vitoria N., 1994, BIWIT 94 BASQ INT WO, P223.
   Ghosh S., 2011, P ACM INT C INDIAHCI, P84.
   HECKATHORNE CW, 1983, IEEE MICRO, V3, P17, DOI 10.1109/MM.1983.291116.
   Hunnicutt S., 1987, STL QPSR, V2, P15.
   Jurafsky D, 2000, SPEECH LANGUAGE PROC.
   Koester HH, 1998, AUGMENT ALTERN COMM, V14, P25.
   Lesher GW, 1998, AUGMENTATIVE ALTERNA, V14, P81, DOI DOI 10.1080/07434619812331278236.
   Longuet-Higgins H.C., 1968, P 3 ANN MACH INT WOR, P311.
   MacKenzie I.S., 2007, TEXT ENTRY SYSTEMS M, P105.
   Matiasek J., 2002, Computers Helping People with Special Needs 8th International Conference, ICCHP 2002. Proceedings (Lecture Notes in Computer Science Vol.2398), P243.
   Newell Alan F., 1992, AAC (Augmentative and Alternative Communication), V8, P304, DOI 10.1080/07434619212331276343.
   Sharma A, 2014, J MAXILLOFAC ORAL SU, V13, P1, DOI 10.1007/s12663-012-0376-4.
   Swiffin AL, 1987, AUGMENTATIVE ALTERNA, V3, P181.
   Venkatagiri H., 1994, AUGMENTATIVE ALTERNA, V10, P105, DOI DOI 10.1080/07434619312331276561.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BQ2NX}},
Unique-ID = {{ISI:000582489400026}},
DA = {{2020-12-06}},
}

@article{ ISI:000583544600001,
Author = {Yang, Jingyun and Wang, Hengjun and Guo, Kexiang},
Title = {{Natural Language Word Prediction Model Based on Multi-Window Convolution
   and Residual Network}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{188036-188043}},
Abstract = {{In this paper, we propose MCNN-ReMGU model based on multi-window
   convolution and residual-connected minimal gated unit (MGU) network for
   the natural language word prediction. First, the convolution kernels
   with different sizes are used to extract the local feature information
   of different graininess between the word sequences. Then, the extracted
   features are fed to the residual-connected MGU network. Finally, the
   prediction results are output by the SoftMax layer. Through the
   residual-connection processing of MGU network in the model, not only the
   problems of vanishing gradient and network degradation are effectively
   solved, but also the long-term dependence between word sequences is
   effectively extracted to predict the next word accurately. Meanwhile,
   the introduction of the convolution kernel in a convolutional neural
   network (CNN) enables the feature information between word sequences to
   be extracted more fully. The experimental results on the Penn Treebank
   and WikiText-2 datasets show that the proposed method has certain
   advantages in the word prediction task.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yang, JY (Corresponding Author), Zhengzhou Informat Sci \& Technol Inst, Zhengzhou 450001, Peoples R China.
   Yang, Jingyun; Wang, Hengjun; Guo, Kexiang, Zhengzhou Informat Sci \& Technol Inst, Zhengzhou 450001, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.3031200}},
ISSN = {{2169-3536}},
Keywords = {{Feature extraction; Convolution; Logic gates; Predictive models; Kernel;
   Hidden Markov models; Data mining; Deep learning; convolution operation;
   residual connection; word prediction}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{yangjy\_0611@163.com}},
Cited-References = {{BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181.
   Bjorck N., 2018, ADV NEURAL INFORM PR, P7694.
   Chen X. T., 2019, J WUHAN I TECHNOL, V41, P276.
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149.
   Chung J., 2014, CORR, DOI DOI 10.1109/IJCNN.2015.7280624.
   Collobert R., 2008, P 25 ICML, P160, DOI {[}10.1145/1390156.1390177, DOI 10.1145/1390156.1390177].
   Cooijmans T., 2016, P 5 INT C LEARN REPR, P1.
   Dai Z, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P144, DOI 10.1109/ROBIO.2018.8665330.
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978.
   Dong A, 2019, IEEE COMMUN LETT, V23, P584, DOI 10.1109/LCOMM.2019.2899603.
   Glorot X., 2010, JLMR P TRACK, V13, P249, DOI DOI 10.1177/1753193409103364..
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924.
   HAN B, 2018, ADV NEUR IN, V31.
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0\_38.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Irsoy Ozan, 2014, P 2014 C EMP METH NA, P720, DOI DOI 10.3115/V1/D14-1080.
   Jastrzebski S., 2017, P INT C LEARN REPR, P1.
   Jozefowicz R, 2015, P 32 INT C MACH LEAR, P2342, DOI DOI 10.1109/CVPR.2015.7298761.
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336.
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572.
   Liu J. X., 2019, COMPUTER RES DEV, V56, P1642.
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556.
   Melis G., 2018, P INT C LEARN REPR, P1.
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228.
   {[}宋睿 Song Rui], 2019, {[}中文信息学报, Journal of Chinese Information Processing], V33, P64.
   Stephen M., 2017, ARXIV170802182, P1.
   Wang J, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2903147.
   Wang L., 2020, J JILIN U SCI ED, V58, P95.
   {[}王伟 Wang Wei], 2019, {[}计算机应用研究, Application Research of Computers], V36, P3558.
   Wojciech Z., 2014, ARXIV14092329.
   {[}邢永康 Xing Yongkang], 2003, {[}计算机科学, Computer Science], V30, P22.
   Yang G., 2019, P 20 ANN C INT SPEEC, P1.
   {[}袁和金 Yuan Hejin], 2019, {[}中文信息学报, Journal of Chinese Information Processing], V33, P109.
   Zhou GB, 2016, INT J AUTOM COMPUT, V13, P226, DOI 10.1007/s11633-016-1006-2.
   Zilly J. G., 2016, INT C MACH LEARN, P4189.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{OI8TT}},
Unique-ID = {{ISI:000583544600001}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000543713500003,
Author = {Wung, Jason and Jukic, Ante and Malik, Sarmad and Souden, Mehrez and
   Pichevar, Ramin and Atkins, Joshua and Naik, Devang and Acero, Alex},
Title = {{Robust Multichannel Linear Prediction for Online Speech Dereverberation
   Using Weighted Householder Least Squares Lattice Adaptive Filter}},
Journal = {{IEEE TRANSACTIONS ON SIGNAL PROCESSING}},
Year = {{2020}},
Volume = {{68}},
Pages = {{3559-3574}},
Abstract = {{Speech dereverberation has been an important component of effective
   far-field voice interfaces in many applications. Algorithms based on
   multichannel linear prediction (MCLP) have been shown to be especially
   effective for blind speech dereverberation and numerous variants have
   been introduced in the literature. Most of these approaches can be
   derived from a common framework, where the MCLP problem for speech
   dereverberation is formulated as a weighted least squares problem that
   can be solved analytically. Since conventional batch MCLP-based
   dereverberation algorithms are not suitable for low-latency
   applications, a number of online variants based on the recursive least
   squares (RLS) algorithm have been proposed. However, RLS-based
   approaches often suffer from numerical instability and their use in
   online systems can further be limited due to high computational
   complexity with a large number of channels or filter taps. In this
   paper, we aim to address the issues of numerical robustness and
   computational complexity. More specifically, we derive alternative
   online weighted least squares algorithms through Householder RLS and
   Householder least squares lattice (HLSL), which are numerically stable
   and retain the fast convergence capability of the RLS algorithm.
   Furthermore, we derive an angle-normalized variant of the HLSL algorithm
   and show that it is robust to speech cancellation for a wide range of
   forgetting factors and filter taps. Finally, we support our findings
   through experimental results and demonstrate numerical and algorithmic
   robustness, long-term stability, linear complexity in filter taps, low
   memory footprint, and effectiveness in speech recognition applications.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wung, J (Corresponding Author), Apple Inc, Cupertino, CA 95014 USA.
   Wung, Jason; Jukic, Ante; Malik, Sarmad; Souden, Mehrez; Pichevar, Ramin; Atkins, Joshua; Naik, Devang; Acero, Alex, Apple Inc, Cupertino, CA 95014 USA.}},
DOI = {{10.1109/TSP.2020.2997201}},
ISSN = {{1053-587X}},
EISSN = {{1941-0476}},
Keywords = {{Signal processing algorithms; Prediction algorithms; Robustness;
   Microphones; Lattices; Computational complexity; Numerical stability;
   Multichannel linear prediction; weighted prediction error;
   dereverberation; least squares lattice; adaptive filter}},
Keywords-Plus = {{EQUALIZATION; RLS; ALGORITHMS; STABILITY}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{jwung@apple.com
   ajukic@apple.com
   sarmadaziz\_malik@apple.com
   msouden@apple.com
   rpishehvar@apple.com
   josh.atkins@apple.com
   naik.d@apple.com
   aacero@apple.com}},
ORCID-Numbers = {{Wung, Jason/0000-0002-7715-4150}},
Cited-References = {{Akino TK, 2008, IEEE T WIREL COMMUN, V7, P4248, DOI 10.1109/T-WC.2008.070497.
   Apolinario Jose Antonio, 2009, QRD RLS ADAPTIVE FIL.
   Audio Software Engineering and Siri Speech Team, 2018, APPLE MACH LEARNING, V1.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Bottomley G. E., 1989, THESIS.
   BOTTOMLEY GE, 1991, IEEE T SIGNAL PROCES, V39, P1770, DOI 10.1109/78.91147.
   Caroselli J, 2017, INTERSPEECH, P3877, DOI 10.21437/Interspeech.2017-1791.
   CIOFFI JM, 1987, IEEE T CIRCUITS SYST, V34, P821, DOI 10.1109/TCS.1987.1086209.
   CIOFFI JM, 1984, IEEE T ACOUST SPEECH, V32, P304, DOI 10.1109/TASSP.1984.1164334.
   Colman GWK, 2006, CAN CON EL COMP EN, P639.
   Delcroix M., 2014, P REVERB CHALL WORKS, V1, P1.
   Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698.
   FRIEDLANDER B, 1982, P IEEE, V70, P829, DOI 10.1109/PROC.1982.12407.
   Gesbert D, 1997, INT CONF ACOUST SPEE, P3621, DOI 10.1109/ICASSP.1997.604650.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Griffiths L. J., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing, P87.
   Griffiths L. J., 1977, IEEE INT C ACOUSTICS, V2, P683, DOI {[}DOI 10.1109/ICASSP.1977.1170162, 10.1109/ICASSP.1977.1170162].
   Haeb-Umbach R, 2019, IEEE SIGNAL PROC MAG, V36, P111, DOI 10.1109/MSP.2019.2918706.
   Han K, 2015, IEEE-ACM T AUDIO SPE, V23, P982, DOI 10.1109/TASLP.2015.2416653.
   Haykin S., 2014, ADAPTIVE FILTER THEO.
   Heymann J, 2019, INT CONF ACOUST SPEE, P6655, DOI 10.1109/ICASSP.2019.8683294.
   Heymann J, 2018, INT WORKSH ACOUSTIC, P466, DOI 10.1109/IWAENC.2018.8521255.
   Householder A. S., 2006, THEORY MATRICES NUME.
   Juki A., 2016, P AES 60 INT C LEUV, P1.
   Jukic Ante, 2015, 2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). Proceedings, P1, DOI 10.1109/WASPAA.2015.7336927.
   Jukic A, 2017, IEEE SIGNAL PROC LET, V24, P101, DOI 10.1109/LSP.2016.2640939.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita K, 2017, INTERSPEECH, P384, DOI 10.21437/Interspeech.2017-733.
   Kinoshita K, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0306-6.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Kodrasi I., 2015, THESIS.
   Lebart K, 2001, ACUSTICA, V87, P359.
   LEE DTL, 1981, IEEE T ACOUST SPEECH, V29, P627, DOI 10.1109/TASSP.1981.1163587.
   LEUNG H, 1989, IEEE T ACOUST SPEECH, V37, P760, DOI 10.1109/29.17570.
   LING F, 1984, IEEE T ACOUST SPEECH, V32, P381.
   LING FY, 1986, IEEE T ACOUST SPEECH, V34, P829.
   LING FY, 1991, IEEE T SIGNAL PROCES, V39, P1541, DOI 10.1109/78.134393.
   LIU KR, 1991, IEEE T CIRCUITS SYST, V38, P625, DOI 10.1109/31.81857.
   MCWHIRTER JG, 1993, INTEGRATION, V14, P231, DOI 10.1016/0167-9260(93)90010-A.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1673, DOI 10.1109/TASL.2010.2062590.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   NORTH RC, 1993, IEEE T SIGNAL PROCES, V41, P1809, DOI 10.1109/78.215301.
   Petkov PN, 2019, INT CONF ACOUST SPEE, P5761, DOI 10.1109/ICASSP.2019.8683542.
   PROUDLER IK, 1991, IEE PROC-F, V138, P341, DOI 10.1049/ip-f-2.1991.0045.
   Radlovic BD, 2000, IEEE T SPEECH AUDI P, V8, P311, DOI 10.1109/89.841213.
   Rontogiannis AA, 1996, SIGNAL PROCESS, V52, P35, DOI 10.1016/0165-1684(96)00060-6.
   SLOCK DTM, 1994, INT CONF ACOUST SPEE, P585.
   Tham M. T., 1988, International Conference on CONTROL 88 (Conf. Publ. No.285), P128.
   Vaidyanathan P. P., 2007, SYNTHESIS LECT SIGNA, V2, P1, DOI DOI 10.2200/S00086ED-1V01Y200712SPR003.
   VERHAEGEN MH, 1989, AUTOMATICA, V25, P437, DOI 10.1016/0005-1098(89)90013-7.
   Williamson DS, 2017, IEEE-ACM T AUDIO SPE, V25, P1492, DOI 10.1109/TASLP.2017.2696307.
   Wung J., 2019, U.S. Patent, Patent No. {[}10 403 299, 10403299].
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P436, DOI 10.1109/ASRU.2015.7404828.
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{IEEE Trans. Signal Process.}},
Doc-Delivery-Number = {{MD1CR}},
Unique-ID = {{ISI:000543713500003}},
DA = {{2020-12-06}},
}

@article{ ISI:000530835300035,
Author = {Wang, Qing and Peng, Rong-Qun and Wang, Jia-Qiang and Li, Zhi and Qu,
   Han-Bing},
Title = {{NEWLSTM: An Optimized Long Short-Term Memory Language Model for Sequence
   Prediction}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{65395-65401}},
Abstract = {{The long short-term memory (LSTM) model trained on the universal
   language modeling task overcomes the bottleneck of vanishing gradients
   in the traditional recurrent neural network (RNN) and shows excellent
   performance in processing multiple tasks generated by natural language
   processing. Although LSTM effectively alleviates the vanishing gradient
   problem in the RNN, the information will be greatly lost in the long
   distance transmission, and there are still some limitations in its
   practical use. In this paper, we propose a new model called NEWLSTM,
   which improves the LSTM model, and alleviates the defects of too many
   parameters in LSTM and the vanishing gradient. The NEWLSTM model
   directly correlates the cell state information with current information.
   The traditional LSTM \& x2019;s input gate and forget gate are
   integrated, some components are deleted, the problems of too many LSTM
   parameters and complicated calculations are solved, and the iteration
   time is effectively reduced. In this paper, a neural network model is
   used to identify the relationship between input information sequences to
   predict the language sequence. The experimental results show that the
   improved new model is simpler than traditional LSTM models and LSTM
   variants on multiple test sets. NEWLSTM has better overall stability and
   can better solve the sparse words problem.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Peng, RQ (Corresponding Author), Shandong Univ Technol, Sch Comp Sci \& Technol, Zibo 255049, Peoples R China.
   Wang, Qing; Peng, Rong-Qun, Shandong Univ Technol, Sch Comp Sci \& Technol, Zibo 255049, Peoples R China.
   Wang, Jia-Qiang; Qu, Han-Bing, Beijing Acad Sci \& Technol, Key Lab Artificial Intelligence \& Data Anal, Beijing 100094, Peoples R China.
   Li, Zhi, Univ Chinese Acad Sci, Sch Econ \& Management, Beijing 100049, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.2985418}},
ISSN = {{2169-3536}},
Keywords = {{Logic gates; Recurrent neural networks; Task analysis; Predictive
   models; Natural language processing; Context modeling; Data models; Gate
   fusion; exploding gradient; long short-term memory; recurrent neural
   network}},
Keywords-Plus = {{NEURAL-NETWORKS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{pengrq2006@126.com}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2018YFF0301000, 2018YFC0809700, 2018YFC0704800]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) {[}NSF91746207]; Beijing Postdoctoral Research FoundationChina
   Postdoctoral Science Foundation {[}ZZ-2019-76]; China Postdoctoral
   Science FoundationChina Postdoctoral Science Foundation {[}2019M660540]}},
Funding-Text = {{This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFF0301000, Grant
   2018YFC0809700, and Grant 2018YFC0704800, in part by the National
   Natural Science Foundation of China under Grant NSF91746207, in part by
   the Beijing Postdoctoral Research Foundation under Grant ZZ-2019-76, and
   in part by the China Postdoctoral Science Foundation under Grant
   2019M660540.}},
Cited-References = {{Ali F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020234.
   Bengio Y, 2001, ADV NEUR IN, V13, P932.
   Bianchi F. M., 2017, ARXIV170504378.
   Chang S., 2017, ARXIV171002224.
   Cooijmans Tim, 2016, ARXIV160309025.
   Dai Andrew, 2016, ARXIV160909106.
   de Lhoneux M., 2019, ARXIV190209781.
   Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769.
   Gers FA, 1999, IEE CONF PUBL, P850, DOI 10.1049/cp:19991218.
   Guo T., P ICML, P2494.
   Hefron RG, 2017, PATTERN RECOGN LETT, V94, P96, DOI 10.1016/j.patrec.2017.05.020.
   Hu JJ, 2019, ZOOKEYS, P1, DOI 10.3897/zookeys.873.36458.
   Jie Z., 2019, P C EMP METH NAT LAN, P1, DOI {[}10.18653/v1/D19-1399, DOI 10.18653/V1/D19-1399].
   Kent D, 2019, MIDWEST SYMP CIRCUIT, P307, DOI 10.1109/MWSCAS.2019.8885035.
   Koutnik J., 2014, P 31 INT C MACH LEAR, P1.
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528.
   Mohan AT, 2018, ARXIV180409269.
   Neil D., 2016, ADV NEURAL INFORM PR, V29, P3882.
   Pappas N., 2019, ARXIV190505513.
   Pascanu R., 2013, COMPUT SCI, V37, P1655.
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0.
   SAK H, 2014, COMPUTER SCI, P338.
   Salem F. M., 2018, ARXIV181211391.
   Smagulova K., 2020, DEEP LEARNING CLASSI, V14, P139, DOI {[}10.1007/978-3-030-14524-8\_11, DOI 10.1007/978-3-030-14524-8\_11].
   Sutskever I., 2014, ARXIV14093215.
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740.
   Takase S, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5074.
   Wen Tsung-Hsien, 2015, ARXIV150801755.
   Yao K., 2015, ARXIV150803790V1.
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco\_a\_01199.
   Zhang Y., 2019, ARXIV190302082.
   Zhao Y., 2019, P 28 INT JOINT C ART, P5450.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{LK4MO}},
Unique-ID = {{ISI:000530835300035}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000515814800001,
Author = {Dietzen, Thomas and Doclo, Simon and Moonen, Marc and van Waterschoot,
   Toon},
Title = {{Integrated Sidelobe Cancellation and Linear Prediction Kalman Filter for
   Joint Multi-Microphone Speech Dereverberation, Interfering Speech
   Cancellation, and Noise Reduction}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2020}},
Volume = {{28}},
Pages = {{740-754}},
Abstract = {{In multi-microphone speech enhancement, reverberation as well as
   additive noise and/or interfering speech are commonly suppressed by
   deconvolution and spatial filtering, e.g., using multi-channel linear
   prediction (MCLP) on the one hand and beamforming, e.g., a generalized
   sidelobe canceler (GSC), on the other hand. In this article, we consider
   several reverberant speech components, whereof some are to be
   dereverberated and others to be canceled, as well as a diffuse (e.g.,
   babble) noise component to be suppressed. In order to perform both
   deconvolution and spatial filtering, we integrate MCLP and the GSC into
   a novel architecture referred to as integrated sidelobe cancellation and
   linear prediction (ISCLP), where the sidelobe-cancellation (SC) filter
   and the linear prediction (LP) filter operate in parallel, but on
   different microphone signal frames. Within ISCLP, we estimate both
   filters jointly by means of a single Kalman filter. We further propose a
   spectral Wiener gain post-processor, which is shown to relate to the
   Kalman filter's posterior state estimate. The presented ISCLP Kalman
   filter is benchmarked against two state-of-the-art approaches, namely
   first a pair of alternating Kalman filters respectively performing
   dereverberation and noise reduction, and second an MCLP+GSC Kalman
   filter cascade. While the ISCLP Kalman filter is roughly M-2 times less
   expensive than both reference algorithms, where M denotes the number of
   microphones, it is shown to perform at least similarly as compared to
   the former, and to outperform the latter. A MATLAB implementation is
   available.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dietzen, T (Corresponding Author), Katholieke Univ Leuven, Dept Elect Engn ESAT, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, B-3001 Leuven, Belgium.
   Dietzen, Thomas; van Waterschoot, Toon, Katholieke Univ Leuven, Dept Elect Engn ESAT, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, B-3001 Leuven, Belgium.
   Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.
   Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, D-26111 Oldenburg, Germany.
   Moonen, Marc, Katholieke Univ Leuven, STADIUS, ESAT, B-3001 Leuven, Belgium.}},
DOI = {{10.1109/TASLP.2020.2966869}},
ISSN = {{2329-9290}},
EISSN = {{2329-9304}},
Keywords = {{Dereverberation; interfering speech cancellation; noise reduction;
   beamforming; multi-channel linear prediction (MCLP); Kalman filter}},
Keywords-Plus = {{REVERBERATION; ENHANCEMENT; COHERENCE; SIGNALS; DOMAIN}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{thomas.dietzen@esat.kuleuven.be
   simon.doclo@uni-oldenburg.de
   marc.moonen@esat.kuleuven.be
   toon.vanwaterschoot@esat.kuleuven.be}},
ResearcherID-Numbers = {{Moonen, Marc/E-6796-2017
   }},
ORCID-Numbers = {{Moonen, Marc/0000-0003-4461-0073
   Doclo, Simon/0000-0002-3392-2381}},
Funding-Acknowledgement = {{ESAT Laboratory of KU Leuven {[}C2-16-00449]; VLAIO OO Project
   {[}HBC.2017.0358]; EU FP7-PEOPLE Marie Curie Initial Training Network -
   European Commission {[}316969]; European Union's Horizon 2020 research
   and innovation program/ERC Consolidator Grant {[}773268]}},
Funding-Text = {{This work was supported in part by the ESAT Laboratory of KU Leuven, in
   the frame of KU Leuven internal fund C2-16-00449; VLAIO O\&O Project no.
   HBC.2017.0358; EU FP7-PEOPLE Marie Curie Initial Training Network funded
   by the European Commission under Grant Agreement no. 316969; the
   European Union's Horizon 2020 research and innovation program/ERC
   Consolidator Grant no. 773268. This paper reflects only the authors'
   views and the Union is not liable for any use that may be made of the
   contained information. The associate editor coordinating the review of
   this manuscript and approving it for publication was Dr. Andy W. H.
   Khong. (Corresponding author: Thomas Dietzen.)}},
Cited-References = {{Auditec, 1997, AUD TESTS REV.
   Avargel Y, 2007, IEEE T AUDIO SPEECH, V15, P1305, DOI 10.1109/TASL.2006.889720.
   BANG, 1992, MUSIC ARCHIMEDES.
   Barker J, 2018, INTERSPEECH, P1561, DOI 10.21437/Interspeech.2018-1768.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Braun S., 2018, IEEE-ACM T AUDIO SPE, V26, P240.
   Braun S, 2018, IEEE-ACM T AUDIO SPE, V26, P1052, DOI 10.1109/TASLP.2018.2804172.
   Braun S, 2016, IEEE SIGNAL PROC LET, V23, P1741, DOI 10.1109/LSP.2016.2616888.
   Chen Z, 2010, ARTECH HSE SIG PROC, P1.
   DALDEGAN N, 1988, SIGNAL PROCESS, V15, P43, DOI 10.1016/0165-1684(88)90027-8.
   Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698.
   Delcroix M, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0245-7.
   Dietzen T., 2019, GITHUB REPOSITORY IN.
   Dietzen T., 2017, P IEEE WORKSH APPL S.
   Dietzen T., 2016, P INT WORKSH AC SIGN, P1.
   Dietzen T, 2020, IEEE-ACM T AUDIO SPE, V28, P755, DOI 10.1109/TASLP.2020.2966891.
   Dietzen T, 2019, IEEE-ACM T AUDIO SPE, V27, P544, DOI 10.1109/TASLP.2018.2886743.
   Dietzen T, 2018, INT WORKSH ACOUSTIC, P221, DOI 10.1109/IWAENC.2018.8521250.
   Doclo S., 2010, HDB ARRAY PROCESSING, P269, DOI DOI 10.1002/9780470487068.CH9.
   Enzner G, 2006, SIGNAL PROCESS, V86, P1140, DOI 10.1016/j.sigpro.2005.09.013.
   Gannot S, 2017, IEEE-ACM T AUDIO SPE, V25, P692, DOI 10.1109/TASLP.2016.2647702.
   Habets EAP, 2008, J ACOUST SOC AM, V124, P2911, DOI 10.1121/1.2987429.
   Habets EAP, 2013, IEEE T AUDIO SPEECH, V21, P945, DOI 10.1109/TASL.2013.2239292.
   Hadad E, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P313, DOI 10.1109/IWAENC.2014.6954309.
   Haykin S., 2002, ADAPTIVE FILTER THEO.
   Heymann J, 2018, INT WORKSH ACOUSTIC, P466, DOI 10.1109/IWAENC.2018.8521255.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   ITU-T, 2001, ITU T REC P 862 INT.
   Jacobsen F, 2000, J ACOUST SOC AM, V108, P204, DOI 10.1121/1.429457.
   Jukic A, 2017, IEEE SIGNAL PROC LET, V24, P101, DOI 10.1109/LSP.2016.2640939.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kay S. M., 1993, FUNDAMENTALS STAT SI.
   Kodrasi I, 2018, IEEE-ACM T AUDIO SPE, V26, P1102, DOI 10.1109/TASLP.2018.2811184.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Lotter T, 2005, EURASIP J APPL SIG P, V2005, P1110, DOI 10.1155/ASP.2005.1110.
   Markovich S, 2009, IEEE T AUDIO SPEECH, V17, P1071, DOI 10.1109/TASL.2009.2016395.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2019, IEEE SIGNAL PROC LET, V26, P903, DOI 10.1109/LSP.2019.2911179.
   Scheuing J, 2008, SIGNALS COMMUN TECHN, P381, DOI 10.1007/978-3-540-70602-1\_11.
   Schwartz O, 2015, INT CONF ACOUST SPEE, P106, DOI 10.1109/ICASSP.2015.7177941.
   Schwartz O, 2015, IEEE-ACM T AUDIO SPE, V23, P240, DOI 10.1109/TASLP.2014.2372335.
   Simon D., 2006, OPTIMAL STATE ESTIMA.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Veaux C., 2016, CSTR VCTK CORPUS ENG.
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P436, DOI 10.1109/ASRU.2015.7404828.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2011, IEEE T AUDIO SPEECH, V19, P69, DOI 10.1109/TASL.2010.2045183.
   Yoshioka T, 2009, INT CONF ACOUST SPEE, P3733, DOI 10.1109/ICASSP.2009.4960438.}},
Number-of-Cited-References = {{49}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{KO8RE}},
Unique-ID = {{ISI:000515814800001}},
DA = {{2020-12-06}},
}

@article{ ISI:000505057100009,
Author = {Namikawa, Reiya and Unoki, Masashi},
Title = {{Non-Blind Speech Watermarking Method Based on Spread-Spectrum Using
   Linear Prediction Residue}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{2020}},
Volume = {{E103D}},
Number = {{1}},
Pages = {{63-66}},
Month = {{JAN}},
Abstract = {{We propose a method of non-blind speech watermarking based on direct
   spread spectrum (DSS) using a linear prediction scheme to solve sound
   distortion due to spread spectrum. Results of evaluation simulations
   revealed that the proposed method had much lower sound-quality
   distortion than the DSS method while having almost the same bit error
   ratios (BERs) against various attacks as the DSS method.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Unoki, M (Corresponding Author), Japan Adv Inst Sci \& Technl, Sch Informat Sci, Nomi 9231292, Japan.
   Namikawa, Reiya; Unoki, Masashi, Japan Adv Inst Sci \& Technl, Sch Informat Sci, Nomi 9231292, Japan.}},
DOI = {{10.1587/transinf.2019MUL0003}},
ISSN = {{1745-1361}},
Keywords = {{speech watermarking; spectrum spreading; linear prediction residue;
   pseudo-random noise signal}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Author-Email = {{unoki@jaist.ac.jp}},
Funding-Acknowledgement = {{I-O DATA foundation {[}17H01761]}},
Funding-Text = {{This work was supported by a Grant-in-Aid for Scientific Research (B)
   (No. 17H01761) and I-O DATA foundation.}},
Cited-References = {{Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015.
   Bregman A. S., 1990, AUDITORY SCENE ANAL.
   Cvejic N., 2007, DIGITAL AUDIO WATERM.
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005.
   Takeda K., 2010, TRI0028 ATR.
   Unoki M., 2014, P ICSV21, pg1.
   Unoki M, 2015, IEICE T INF SYST, VE98D, P38, DOI 10.1587/transinf.2014MUP0017.}},
Number-of-Cited-References = {{7}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{JZ4FM}},
Unique-ID = {{ISI:000505057100009}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000509690600005,
Author = {Zhang, Xingyu and Bellolio, M. Fernanda and Medrano-Gracia, Pau and
   Werys, Konrad and Yang, Sheng and Mahajan, Prashant},
Title = {{Use of natural language processing to improve predictive models for
   imaging utilization in children presenting to the emergency department}},
Journal = {{BMC MEDICAL INFORMATICS AND DECISION MAKING}},
Year = {{2019}},
Volume = {{19}},
Number = {{1}},
Month = {{DEC 30}},
Abstract = {{Objective: To examine the association between the medical imaging
   utilization and information related to patients' socioeconomic,
   demographic and clinical factors during the patients' ED visits; and to
   develop predictive models using these associated factors including
   natural language elements to predict the medical imaging utilization at
   pediatric ED.
   Methods: Pediatric patients' data from the 2012-2016 United States
   National Hospital Ambulatory Medical Care Survey was included to build
   the models to predict the use of imaging in children presenting to the
   ED. Multivariable logistic regression models were built with structured
   variables such as temperature, heart rate, age, and unstructured
   variables such as reason for visit, free text nursing notes and combined
   data available at triage. NLP techniques were used to extract
   information from the unstructured data.
   Results: Of the 27,665 pediatric ED visits included in the study, 8394
   (30.3\%) received medical imaging in the ED, including 6922 (25.0\%) who
   had an X-ray and 1367 (4.9\%) who had a computed tomography (CT) scan.
   In the predictive model including only structured variables, the
   c-statistic was 0.71 (95\% CI: 0.70-0.71) for any imaging use, 0.69
   (95\% CI: 0.68-0.70) for X-ray, and 0.77 (95\% CI: 0.76-0.78) for CT.
   Models including only unstructured information had c-statistics of 0.81
   (95\% CI: 0.81-0.82) for any imaging use, 0.82 (95\% CI: 0.82-0.83) for
   X-ray, and 0.85 (95\% CI: 0.83-0.86) for CT scans. When both structured
   variables and free text variables were included, the c-statistics
   reached 0.82 (95\% CI: 0.82-0.83) for any imaging use, 0.83 (95\% CI:
   0.83-0.84) for X-ray, and 0.87 (95\% CI: 0.86-0.88) for CT.
   Conclusions: Both CT and X-rays are commonly used in the pediatric ED
   with one third of the visits receiving at least one. Patients'
   socioeconomic, demographic and clinical factors presented at ED triage
   period were associated with the medical imaging utilization. Predictive
   models combining structured and unstructured variables available at
   triage performed better than models using structured or unstructured
   variables alone, suggesting the potential for use of NLP in determining
   resource utilization.}},
Publisher = {{BMC}},
Address = {{CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhang, XY (Corresponding Author), Univ Michigan, Sch Nursing, Dept Syst Populat \& Leadership, Ann Arbor, MI 48109 USA.
   Yang, S (Corresponding Author), Nanjing Med Univ, Sch Publ Hlth, Dept Biostat, Nanjing, Peoples R China.
   Zhang, Xingyu, Univ Michigan, Sch Nursing, Dept Syst Populat \& Leadership, Ann Arbor, MI 48109 USA.
   Bellolio, M. Fernanda, Mayo Clin, Dept Emergency Med, Rochester, MN USA.
   Medrano-Gracia, Pau, Univ Auckland, Dept Anat \& Med Imaging, Auckland, New Zealand.
   Werys, Konrad, Univ Oxford, Oxford Ctr Clin Magnet Resonance Res, Oxford, England.
   Yang, Sheng, Nanjing Med Univ, Sch Publ Hlth, Dept Biostat, Nanjing, Peoples R China.
   Yang, Sheng, Univ Michigan, Sch Publ Hlth, Dept Biostat, Ann Arbor, MI 48109 USA.
   Mahajan, Prashant, Univ Michigan, Sch Med, Dept Emergency Med, Ann Arbor, MI USA.}},
DOI = {{10.1186/s12911-019-1006-6}},
Article-Number = {{287}},
EISSN = {{1472-6947}},
Keywords = {{Pediatric emergency department; Natural language processing; Predictive
   model; Medical imaging utilization}},
Keywords-Plus = {{SEVERITY INDEX; TRIAGE; PATIENT; OUTCOMES; SYSTEMS; LENGTH; TESTS; CARE}},
Research-Areas = {{Medical Informatics}},
Web-of-Science-Categories  = {{Medical Informatics}},
Author-Email = {{zhangxyu@umich.edu
   yangsheng@njmu.edu.cn}},
ORCID-Numbers = {{Zhang, Xingyu/0000-0001-8108-1997}},
Funding-Acknowledgement = {{Michigan Institute for Clinical and Health Research (MICHR)
   {[}UL1TR002240]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}81703321]; NATIONAL CENTER
   FOR ADVANCING TRANSLATIONAL SCIENCESUnited States Department of Health
   \& Human ServicesNational Institutes of Health (NIH) - USANIH National
   Center for Advancing Translational Sciences (NCATS) {[}UL1TR002240,
   UL1TR002240, UL1TR002240, UL1TR002240, UL1TR002240, UL1TR002240,
   UL1TR002240, UL1TR002240, UL1TR002240, UL1TR002240, UL1TR002240] Funding
   Source: NIH RePORTER}},
Funding-Text = {{This study was supported by Michigan Institute for Clinical and Health
   Research (MICHR No. UL1TR002240). The study was also supported by
   National Natural Science Foundation of China (No. 81703321).}},
Cited-References = {{Aeimchanbanjong K, 2017, WORLD J EMERG MED, V8, P223, DOI 10.5847/wjem.j.1920-8642.2017.03.010.
   Asplin BR, 2003, ANN EMERG MED, V42, P173, DOI 10.1067/mem.2003.302.
   Baumann MR, 2005, ACAD EMERG MED, V12, P219, DOI 10.1197/j.aem.2004.09.023.
   Ben-Assuli O, 2012, J MED SYST, V36, P3795, DOI 10.1007/s10916-012-9852-0.
   Claster W, 2008, J COMPUT, V3, P1, DOI 10.4304/jcp.3.1.1-6.
   Demner-Fushman D, 2009, J BIOMED INFORM, V42, P760, DOI 10.1016/j.jbi.2009.08.007.
   Froud R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114468.
   Goto T, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2018.6937.
   Harhay M, 2013, AM J TRANSPLANT, V13, P3164, DOI 10.1111/ajt.12513.
   Hoot NR, 2008, ANN EMERG MED, V52, P126, DOI 10.1016/j.annemergmed.2008.03.014.
   Horwitz LI, 2010, ANN EMERG MED, V55, P133, DOI 10.1016/j.annemergmed.2009.07.023.
   Hryhorczuk AL, 2012, RADIOLOGY, V263, P778, DOI 10.1148/radiol.12111726.
   Janke AT, 2016, ANN EMERG MED, V67, P227, DOI 10.1016/j.annemergmed.2015.06.024.
   Kanzaria HK, 2014, AM J EMERG MED, V32, P1253, DOI 10.1016/j.ajem.2014.07.038.
   Kovacs G, 1999, ACAD EMERG MED, V6, P947, DOI 10.1111/j.1553-2712.1999.tb01246.x.
   Lee EK, 2015, INTERFACES, V45, P58, DOI 10.1287/inte.2014.0788.
   Levin S, 2018, ANN EMERG MED, V71, P565, DOI 10.1016/j.annemergmed.2017.08.005.
   Luo W, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5870.
   Macias Charles G, 2011, Pediatr Radiol, V41 Suppl 2, P498, DOI 10.1007/s00247-011-2102-7.
   Maldonado T, 2004, PEDIATRICS, V114, P356, DOI 10.1542/peds.114.2.356.
   McAdams-DeMarco MA, 2012, AM J TRANSPLANT, V12, P3283, DOI 10.1111/j.1600-6143.2012.04285.x.
   McCaig LF, 2012, ANN EMERG MED, V60, P716, DOI 10.1016/j.annemergmed.2012.07.010.
   McCallum A., 2005, ACM Queue, V3, P48, DOI 10.1145/1105664.1105679.
   McHugh M, 2012, ACAD EMERG MED, V19, P106, DOI 10.1111/j.1553-2712.2011.01240.x.
   Michalowski W, 2005, METHOD INFORM MED, V44, P14.
   Michelson KA, 2012, ACAD EMERG MED, V19, P816, DOI 10.1111/j.1553-2712.2012.01390.x.
   Natale JE, 2016, ACAD EMERG MED, V23, P584, DOI 10.1111/acem.12943.
   Patel M, 2008, TRAUMA, V10, P239, DOI 10.1177/1460408608096795.
   Payne NR, 2013, PEDIATR EMERG CARE, V29, P598, DOI 10.1097/PEC.0b013e31828e6489.
   Pencina MJ, 2015, JAMA-J AM MED ASSOC, V314, P1063, DOI 10.1001/jama.2015.11082.
   SCHNEIDER D, 1979, VITAL HLTH STAT 2, V78, P1.
   Schneider D, 1979, VITAL HLTH STAT, V2, pi.
   Schuur JD, 2013, HEALTH AFFAIR, V32, P2129, DOI 10.1377/hlthaff.2013.0730.
   Sun BC, 2013, ANN EMERG MED, V61, P605, DOI 10.1016/j.annemergmed.2012.10.026.
   Tanabe Paula, 2004, J Emerg Nurs, V30, P22, DOI 10.1016/j.jen.2003.11.004.
   Timm NL, 2008, ACAD EMERG MED, V15, P832, DOI 10.1111/j.1553-2712.2008.00224.x.
   Worster A, 2008, CAN J EMERG MED, V10, P174.
   Wuerz R, 2001, ACAD EMERG MED, V8, P61.
   Yoon Philip, 2003, CJEM, V5, P155.
   Zeng Z, 2012, J EMERG NURS, V38, P322, DOI 10.1016/j.jen.2011.03.005.
   Zhang XY, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214905.
   Zhang XY, 2017, METHOD INFORM MED, V56, P377, DOI 10.3414/ME17-01-0024.
   Zhang XY, 2015, J TRANSL MED, V13, DOI 10.1186/s12967-015-0709-4.
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0.
   Zhu W., 2010, P NESUG P HLTH CAR L, V19, P67.}},
Number-of-Cited-References = {{45}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{BMC Med. Inform. Decis. Mak.}},
Doc-Delivery-Number = {{KG1GS}},
Unique-ID = {{ISI:000509690600005}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000500609900001,
Author = {Arun Sankar, M. S. and Sathidevi, P. S.},
Title = {{Design of MELPe-Based Variable-Bit-Rate Speech Coding with Mel Scale
   Approach Using Low-Order Linear Prediction Filter and Representing
   Excitation Signal Using Glottal Closure Instants}},
Journal = {{ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING}},
Year = {{2020}},
Volume = {{45}},
Number = {{3}},
Pages = {{1785-1801}},
Month = {{MAR}},
Abstract = {{In this paper, we propose a variable-bit-rate speech codec-based on
   mixed excitation linear prediction enhanced (MELPe) with an average bit
   rate of 2 kbps and with a better representation of excitation signal.
   The order of the prediction filter in MELPe coding architecture is
   reduced from 10 to 7 without affecting the perceptual quality of the
   decoded speech by using psychoacoustic Mel scale. An efficient two-split
   vector quantization is developed with weighted Euclidean distance
   measure for Mel scale-based linear predictive coding (Mel-LPC), and it
   requires only 18 bits/frame. The instantaneous pitch or epoch that is
   vital for many speech processing applications is preserved in this codec
   by including it in the excitation signal used for reconstructing the
   voiced speech. The quantization scheme developed for glottal closure
   instants (GCIs) causes an increase in the bit requirement for voiced
   frames by 4-25 bits depending on the position of GCIs. To compensate for
   that, the Mel-LPC order for both silence and unvoiced frames has been
   brought down to 4 without compromising the perceptual quality of
   reconstructed speech. The lowered bit budget for unvoiced frame is 41
   bits/frame, and for silence, it is 31 bits/frame. Further reduction of
   10 bits for silence frame is obtained by reducing the number of
   transmitted parameters and by tuning the quantization bit requirement
   for each. For categorizing the speech frames at the entry of the
   encoder, a neural network-based voiced/unvoiced/silence classification
   algorithm using five-dimensional feature set is created. The
   experimental results show that the proposed coding scheme operates at an
   average bit rate of 2 kbps, which is less than the bit rate of MELPe
   (2.4 kbps), but with a better perceptual score. In addition to all
   these, the incorporation of Mel-LPC gives a better performance in the
   estimation of formants and GCIs.}},
Publisher = {{SPRINGER HEIDELBERG}},
Address = {{TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sankar, MSA (Corresponding Author), Natl Inst Technol Calicut, Dept Elect \& Commun Engn, Kozhikode, Kerala, India.
   Arun Sankar, M. S.; Sathidevi, P. S., Natl Inst Technol Calicut, Dept Elect \& Commun Engn, Kozhikode, Kerala, India.}},
DOI = {{10.1007/s13369-019-04273-z}},
Early Access Date = {{DEC 2019}},
ISSN = {{2193-567X}},
EISSN = {{2191-4281}},
Keywords = {{Speech coding; Vector quantization; Mel scale; GCI; Linear prediction;
   LPC; MELP}},
Keywords-Plus = {{EPOCH EXTRACTION; PARAMETERS}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{arun\_p150036ec@nitc.ac.in
   sathi@nitc.ac.in}},
Cited-References = {{ANANTHAPADMANABHA TV, 1975, IEEE T ACOUST SPEECH, V23, P562, DOI 10.1109/TASSP.1975.1162745.
   ANANTHAPADMANABHA TV, 1979, IEEE T ACOUST SPEECH, V27, P309, DOI 10.1109/TASSP.1979.1163267.
   Araujo AMD, 1998, ITS `98 PROCEEDINGS - SBT/IEEE INTERNATIONAL TELECOMMUNICATIONS SYMPOSIUM, VOLS 1 AND 2, P207, DOI 10.1109/ITS.1998.713118.
   Arun Sankar M.S., 2018, P 2 INT C VIS IM SIG.
   Atal BS, 2006, IEEE SIGNAL PROC MAG, V23, P154, DOI 10.1109/MSP.2006.1598091.
   Boersma Paul, 2018, PRAAT DOING PHONETIC.
   Bouzid M., 2010, 2010 7 INT MULT SYST, P1.
   Cannam C., 2010, P ACM MULT 2010 INT, P1467, DOI DOI 10.1145/1873951.1874248.
   Chu W. C., 2004, SPEECH CODING ALGORI.
   Deng HQ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P176.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Gibson J. D., 2005, IEEE Circuits and Systems Magazine, V5, P30, DOI 10.1109/MCAS.2005.1550167.
   Gibson J.D, 2015, SPEECH AUDIO PROCESS, P19.
   GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849.
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872.
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006.
   ITU-T, REC P 862 1 MAPP FUN.
   Kadiri SR, 2019, INT CONF ACOUST SPEE, P6500, DOI 10.1109/ICASSP.2019.8683558.
   Kaur M, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919500222.
   KRUGER E, 1988, IEEE T ACOUST SPEECH, V36, P1529, DOI 10.1109/29.90384.
   LAINE UK, 1994, INT CONF ACOUST SPEE, P349.
   Lal GJ, 2018, CIRC SYST SIGNAL PR, V37, P3245, DOI 10.1007/s00034-018-0804-x.
   Li Y, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P915, DOI 10.1109/CISP-BMEI.2016.7852841.
   Li ZH, 2010, PROCEEDINGS OF 2010 INTERNATIONAL WORKSHOP ON DIFFUSE POLLUTION-MANAGEMENT MEASURES AND CONTROL TECHNIQUE, P260.
   Ma C, 1994, IEEE T SPEECH AUDI P, V2, P258, DOI 10.1109/89.279274.
   Martin R., 1999, 1999 IEEE Workshop on Speech Coding Proceedings. Model, Coders, and Error Criteria (Cat. No.99EX351), P165, DOI 10.1109/SCFT.1999.781519.
   MCCREE AV, 1995, IEEE T SPEECH AUDI P, V3, P242, DOI 10.1109/89.397089.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   Pannu HS, 2018, CLEAN-SOIL AIR WATER, V46, DOI 10.1002/clen.201700162.
   Pannu HS, 2019, NEURAL COMPUT APPL, V31, P2195, DOI 10.1007/s00521-017-3181-7.
   PICONE JW, 1993, P IEEE, V81, P1215, DOI 10.1109/5.237532.
   Pravena D, 2017, INT J SPEECH TECHNOL, V20, P787, DOI 10.1007/s10772-017-9445-x.
   Rabiner L. R., 1978, DIGITAL PROCESSING S.
   Rao KS, 2007, IEEE SIGNAL PROC LET, V14, P762, DOI 10.1109/LSP.2007.896454.
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023.
   Shikano K, 1986, INTERNAL REPORT.
   Singh D, 2019, ARCH COMPUT METHOD E, V26, P1395, DOI 10.1007/s11831-018-9294-z.
   SPANIAS AS, 1994, P IEEE, V82, P1541, DOI 10.1109/5.326413.
   Sreenivasa Rao K., 2003, 2003 IEEE INT C AC S, pI.
   van der Merwe C. J., 1991, COMSIG 1991 Proceedings. South African Symposium on Communications and Signal Processing (Cat. No.91TH0370-7), P17, DOI 10.1109/COMSIG.1991.278216.
   Vikram CM, 2017, IEEE-ACM T AUDIO SPE, V25, P624, DOI 10.1109/TASLP.2017.2651391.
   Vuppala A.K., 2011, 2011 INT C DEV COMM, P1.
   Yegnanarayana B, 2011, SADHANA-ACAD P ENG S, V36, P651, DOI 10.1007/s12046-011-0046-0.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Arab. J. Sci. Eng.}},
Doc-Delivery-Number = {{KN7RT}},
Unique-ID = {{ISI:000500609900001}},
DA = {{2020-12-06}},
}

@article{ ISI:000509665600357,
Author = {Mellado, Elena Alvarez and Holderness, Eben and Miller, Nicholas and
   Bolton, Kirsten and Cawkwell, Philip and Pustejovsky, James and Hall,
   Mei-Hua},
Title = {{Prediction of Psychiatric Readmission Risk in Psychosis Patients With
   Natural Language Processing of Electronic Health Records}},
Journal = {{NEUROPSYCHOPHARMACOLOGY}},
Year = {{2019}},
Volume = {{44}},
Number = {{SUPPL 1, 1}},
Meeting = {{M209}},
Pages = {{187}},
Month = {{DEC}},
Note = {{58th Annual Meeting of the American-College-of-Neuropsychopharmacology
   (ACNP), Orlando, FL, DEC 08-11, 2019}},
Organization = {{Amer Coll Neuropsychopharmacol}},
Publisher = {{NATURE PUBLISHING GROUP}},
Address = {{MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND}},
Type = {{Meeting Abstract}},
Language = {{English}},
Affiliation = {{Mellado, Elena Alvarez; Holderness, Eben; Miller, Nicholas; Bolton, Kirsten; Cawkwell, Philip; Pustejovsky, James; Hall, Mei-Hua, McLean Hosp, 115 Mill St, Belmont, MA 02178 USA.}},
ISSN = {{0893-133X}},
EISSN = {{1740-634X}},
Keywords = {{Treatment Outcome Prediction; Readmission Risk; Natural Language
   Processing (NLP); Psychosis; Electronic Health Record (EHR)}},
Research-Areas = {{Neurosciences \& Neurology; Pharmacology \& Pharmacy; Psychiatry}},
Web-of-Science-Categories  = {{Neurosciences; Pharmacology \& Pharmacy; Psychiatry}},
Number-of-Cited-References = {{0}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Neuropsychopharmacology}},
Doc-Delivery-Number = {{KG0XM}},
Unique-ID = {{ISI:000509665600357}},
DA = {{2020-12-06}},
}

@article{ ISI:000496994700006,
Author = {Mantegna, Francesco and Hintz, Florian and Ostarek, Markus and Alday,
   Phillip M. and Huettig, Falk},
Title = {{Distinguishing integration and prediction accounts of ERP N400
   modulations in language processing through experimental design}},
Journal = {{NEUROPSYCHOLOGIA}},
Year = {{2019}},
Volume = {{134}},
Month = {{NOV}},
Abstract = {{Many theoretical accounts of prediction in language processing are based
   to a substantial amount on experimental evidence from
   electrophysiological studies measuring N400 target word modulations. A
   drawback of most of these studies is that lexical prediction ('top-down'
   activation) accounts cannot be distinguished conclusively from lexical
   integration ('bottom-up' activation) accounts. Here we explored whether
   it is possible to distinguish integration and prediction accounts of ERP
   N400 modulations in language processing through experimental design. By
   employing rhyming sentence completions, we kept the ease of integration
   constant across conditions that differed in word predictability only.
   This experimental design allowed us to attribute N400 target word
   effects across conditions to predictive language processing. We close by
   discussing recommendations for future electrophysiological studies on
   prediction in language.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Mantegna, F (Corresponding Author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   Mantegna, Francesco, NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   Hintz, Florian; Ostarek, Markus; Alday, Phillip M.; Huettig, Falk, Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   Huettig, Falk, Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.}},
DOI = {{10.1016/j.neuropsychologia.2010.107109}},
Article-Number = {{107109}},
ISSN = {{0028-3932}},
EISSN = {{1873-3514}},
Keywords = {{Anticipation; Prediction; Integration; ERPs; N400}},
Keywords-Plus = {{SEMANTIC INTEGRATION; BRAIN POTENTIALS; WORD RECOGNITION; UPCOMING
   WORDS; COMPREHENSION; CONTEXT; RHYME; EXPECTANCY; ACTIVATION; FREQUENCY}},
Research-Areas = {{Behavioral Sciences; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Behavioral Sciences; Neurosciences; Psychology, Experimental}},
Author-Email = {{fm1672@nyu.edu}},
Cited-References = {{Alday PM, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13451.
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005.
   Baggio G, 2011, LANG COGNITIVE PROC, V26, P1338, DOI 10.1080/01690965.2010.542671.
   Bates D, 2015, PARSIMONIOUS MIXED M.
   Bates D., 2014, LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01.
   Brilmayer I, 2019, LANG COGN NEUROSCI, V34, P411, DOI 10.1080/23273798.2018.1542501.
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5.
   Carrasco-Ortiz H, 2017, J NEUROLINGUIST, V41, P1, DOI 10.1016/j.jneuroling.2016.06.007.
   Chwilla DJ, 2005, COGNITIVE BRAIN RES, V25, P589, DOI 10.1016/j.cogbrainres.2005.08.011.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   Deacon D, 2004, PSYCHOPHYSIOLOGY, V41, P60, DOI 10.1111/1469-8986.00120.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DONNENWERTHNOLAN S, 1981, J EXP PSYCHOL-HUM L, V7, P170, DOI 10.1037/0278-7393.7.3.170.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Ferreira F, 2018, CURR DIR PSYCHOL SCI, V27, P443, DOI 10.1177/0963721418794491.
   Flecken M., 2018, LANG COGN NEUROSCI, P1.
   Frank SL, 2017, LANG COGN NEUROSCI, V32, P1192, DOI 10.1080/23273798.2017.1323109.
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159.
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004.
   HILLINGER ML, 1980, MEM COGNITION, V8, P115, DOI 10.3758/BF03213414.
   Holcomb PJ, 1999, J EXP PSYCHOL LEARN, V25, P721, DOI 10.1037/0278-7393.25.3.721.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Ito A, 2017, LANG COGN NEUROSCI, V32, P954, DOI 10.1080/23273798.2016.1242761.
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643.
   KUEHN DP, 1972, J SPEECH HEAR RES, V15, P654, DOI 10.1044/jshr.1503.654.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   KUTAS M, 1980, BIOL PSYCHOL, V11, P99, DOI 10.1016/0301-0511(80)90046-0.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Laszlo S, 2011, PSYCHOPHYSIOLOGY, V48, P176, DOI 10.1111/j.1469-8986.2010.01058.x.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1.
   Mandera P, 2017, J MEM LANG, V92, P57, DOI 10.1016/j.jml.2016.04.001.
   Marian V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043230.
   MARTIN JG, 1981, J ACOUST SOC AM, V69, P559, DOI 10.1121/1.385484.
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001.
   Nieuwland M.S., 2019, PHILOS T ROYAL SOC B.
   Nieuwland MS, 2019, NEUROSCI BIOBEHAV R, V96, P367, DOI 10.1016/j.neubiorev.2018.11.019.
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468.
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703.
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/156869.
   Otten M, 2009, BRAIN RES, V1291, P92, DOI 10.1016/j.brainres.2009.07.042.
   Pickering MJ, 2018, PSYCHOL BULL, V144, P1002, DOI 10.1037/bul0000158.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   PRAAMSTRA P, 1993, COGNITIVE BRAIN RES, V1, P73, DOI 10.1016/0926-6410(93)90013-U.
   PRAAMSTRA P, 1994, J COGNITIVE NEUROSCI, V6, P204, DOI 10.1162/jocn.1994.6.3.204.
   Rapp DN, 2002, J EXP PSYCHOL LEARN, V28, P564, DOI 10.1037//0278-7393.28.3.564.
   RUGG MD, 1987, BRAIN LANG, V32, P336, DOI 10.1016/0093-934X(87)90132-5.
   Sassenhagen J, 2016, BRAIN LANG, V162, P42, DOI 10.1016/j.bandl.2016.08.001.
   Sassenhagen J, 2014, BRAIN LANG, V137, P29, DOI 10.1016/j.bandl.2014.07.010.
   SHULMAN HG, 1978, MEM COGNITION, V6, P115, DOI 10.3758/BF03197436.
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401.
   Team RC, 2013, R LANG ENV STAT COMP.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van Casteren M, 2006, BEHAV RES METHODS, V38, P584, DOI 10.3758/BF03193889.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   VANPETTEN C, 1990, MEM COGNITION, V18, P380, DOI 10.3758/BF03197127.
   Wald A, 1973, SEQUENTIAL ANAL.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.}},
Number-of-Cited-References = {{65}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{Neuropsychologia}},
Doc-Delivery-Number = {{JN6GP}},
Unique-ID = {{ISI:000496994700006}},
DA = {{2020-12-06}},
}

@article{ ISI:000490155900025,
Author = {Alkhawaldeh, Rami S. and Khawaldeh, Saed and Pervaiz, Usama and Alawida,
   Moatsum and Alkhawaldeh, Hamzah},
Title = {{NIML: non-intrusive machine learning-based speech quality prediction on
   VoIP networks}},
Journal = {{IET COMMUNICATIONS}},
Year = {{2019}},
Volume = {{13}},
Number = {{16}},
Pages = {{2609-2616}},
Month = {{OCT 8}},
Abstract = {{Voice over Internet Protocol (VoIP) networks have recently emerged as a
   promising telecommunication medium for transmitting voice signal. One of
   the essential aspects that interests researchers is how to estimate the
   quality of transmitted voice over VoIP for several purposes such as
   design and technical issues. Two methodologies are used to evaluate the
   voice, which are subjective and objective methods. In this study, the
   authors propose a non-intrusive machine learning-based (NIML) objective
   method to estimate the quality of voice. In particular, they build a
   training set of parameters - from the network and the voice itself -
   along with the quality of voices as labels. The voice quality is
   estimated using the perceptual evaluation of speech quality (PESQ)
   method as an intrusive algorithm. Then, the authors use a set of
   classifiers to build models for estimating the quality of the
   transmitted voice from the training set. The experimental results show
   that the classifier models have a valuable performance where Random
   Forest model has superior results compared to other models of precision
   94.1\%, recall 94.2\%, and receiver operating characteristic area 99.2\%
   as evaluation metrics.}},
Publisher = {{INST ENGINEERING TECHNOLOGY-IET}},
Address = {{MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Alkhawaldeh, RS (Corresponding Author), Univ Jordan, Dept Comp Informat Syst, Aqaba 77110, Jordan.
   Alkhawaldeh, Rami S., Univ Jordan, Dept Comp Informat Syst, Aqaba 77110, Jordan.
   Khawaldeh, Saed; Pervaiz, Usama, Univ Burgundy, Erasmus Joint Master Program Med Imaging \& Appl, Dijon, France.
   Khawaldeh, Saed; Pervaiz, Usama, Univ Cassino, Erasmus Joint Master Program Med Imaging \& Applic, Cassino, Italy.
   Khawaldeh, Saed; Pervaiz, Usama, Univ Girona, Erasmus Joint Master Program Med Imaging \& Applic, Girona, Spain.
   Khawaldeh, Saed; Pervaiz, Usama, Aalto Univ, Dept Elect Engn \& Automat, Sensor Informat \& Med Technol Grp, Helsinki, Finland.
   Alawida, Moatsum, Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   Alkhawaldeh, Hamzah, Princess Sumaya Univ Technol, King Hussein Sch Comp Sci, Amman 11941, Jordan.}},
DOI = {{10.1049/iet-com.2018.5430}},
ISSN = {{1751-8628}},
EISSN = {{1751-8636}},
Keywords = {{Internet telephony; speech processing; learning (artificial
   intelligence); pattern classification; NIML; nonintrusive machine
   learning-based speech quality prediction; VoIP networks; Internet
   Protocol networks; promising telecommunication medium; voice signal;
   transmitted voice; nonintrusive machine learning-based objective method;
   training set; voice quality; speech quality method}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{r.alkhawaldeh@ju.edu.jo}},
ResearcherID-Numbers = {{Alkhawaldeh, Rami S./AAL-9097-2020}},
ORCID-Numbers = {{Alkhawaldeh, Rami S./0000-0002-2413-7074}},
Cited-References = {{Al-Akhras M, 2009, NEUROCOMPUTING, V72, P2595, DOI 10.1016/j.neucom.2008.10.019.
   {[}Anonymous], 1996, P800 ITUT.
   {[}Anonymous], 1994, P8001 ITUT.
   {[}Anonymous], 2000, G107 ITUT.
   {[}Anonymous], 2003, ITRP8621 ITUT.
   {[}Anonymous], 1999, P50 ITUT.
   {[}Anonymous], 1996, G712 ITUT.
   Barry MA, 2017, INT CONF ADV COMMUN, P275, DOI 10.23919/ICACT.2017.7890097.
   Carvalho L, 2005, IEEE SYMP COMP COMMU, P933, DOI 10.1109/ISCC.2005.23.
   Davis J, 2006, P 23 INT C MACH LEAR, DOI DOI 10.1145/1143844.1143874.
   De Rango F, 2006, INT J COMPUT SCI NET, V6, P140.
   Fernandes V., 2017, AUD ENG SOC C 2017 A.
   {*}ITU T, 1996, G7231 ITUT.
   {*}ITU T, 1996, G729 ITUT.
   {*}ITU T, 1996, P861 ITUT.
   ITU-T, 2001, P862 ITUT.
   Karapantazis S, 2009, COMPUT NETW, V53, P2050, DOI 10.1016/j.comnet.2009.03.010.
   Kekre H. B., 1977, Computers \& Electrical Engineering, V4, P133, DOI 10.1016/0045-7906(77)90022-2.
   LUSTED LB, 1971, SCIENCE, V171, P1217, DOI 10.1126/science.171.3977.1217.
   Mahdi AE, 2009, DIGIT SIGNAL PROCESS, V19, P79, DOI 10.1016/j.dsp.2007.11.006.
   MCGOWAN J, 2005, Patent No. 6931017.
   Qawaqneh Z, 2017, KNOWL-BASED SYST, V115, P5, DOI 10.1016/j.knosys.2016.10.008.
   Quackenbush S., 1988, OBJECTIVE MEASURES S.
   Raja A., 2008, GECCO 08 ATL GEORG U, P1627.
   Raja A, 2008, LECT NOTES COMPUT SC, V4971, P37, DOI 10.1007/978-3-540-78671-9\_4.
   Rix A.W., 2003, P ONL WORKSH MEAS SP, P17.
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023.
   Rix AW, 2000, INT CONF ACOUST SPEE, P1515, DOI 10.1109/ICASSP.2000.861935.
   Salama H., 2017, US Patent, Patent No. {[}9,635,087, 9635087].
   Sharan RV, 2017, INFORM SCIENCES, V396, P24, DOI 10.1016/j.ins.2017.02.013.
   Soloducha M., 2017, P INT C QUAL MULT EX, P1.
   Sun L., 2004, TECHNICAL REPORT.
   WANG SH, 1992, IEEE J SEL AREA COMM, V10, P819, DOI 10.1109/49.138987.
   Witten IH, 2011, MOR KAUF D, P1.
   Yang W., 1999, THESIS.
   Yi Gaoxiong, 2012, 2012 1st IEEE International Conference on Communications in China (ICCC 2012), P351, DOI 10.1109/ICCChina.2012.6356906.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{IET Commun.}},
Doc-Delivery-Number = {{JD7JB}},
Unique-ID = {{ISI:000490155900025}},
DA = {{2020-12-06}},
}

@article{ ISI:000489506800001,
Author = {Pinto, Serge and Tremblay, Pascale and Basirat, Anahita and Sato, Marc},
Title = {{The impact of when, what and how predictions on auditory speech
   perception}},
Journal = {{EXPERIMENTAL BRAIN RESEARCH}},
Year = {{2019}},
Volume = {{237}},
Number = {{12}},
Pages = {{3143-3153}},
Month = {{DEC}},
Abstract = {{An impressive number of theoretical proposals and neurobiological
   studies argue that perceptual processing is not strictly feedforward but
   rather operates through an interplay between bottom-up sensory and
   top-down predictive mechanisms. The present EEG study aimed to further
   determine how prior knowledge on auditory syllables may impact speech
   perception. Prior knowledge was manipulated by presenting the
   participants with visual information indicative of the syllable onset
   (when), its phonetic content (what) and/or its articulatory features
   (how). While when and what predictions consisted of unnatural visual
   cues (i.e., a visual timeline and a visuo-orthographic cue), how
   prediction consisted of the visual movements of a speaker. During
   auditory speech perception, when and what predictions both attenuated
   the amplitude of N1/P2 auditory evoked potentials. Regarding how
   prediction, not only an amplitude decrease but also a latency
   facilitation of N1/P2 auditory evoked potentials were observed during
   audiovisual compared to unimodal speech perception. However, when and
   what predictability effects were then reduced or abolished, with only
   what prediction reducing P2 amplitude but increasing latency.
   Altogether, these results demonstrate the influence of when, what and
   how visually induced predictions at an early stage on cortical auditory
   speech processing. Crucially, they indicate a preponderant predictive
   role of the speaker's articulatory gestures during audiovisual speech
   perception, likely driven by attentional load and focus.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sato, M (Corresponding Author), Aix Marseille Univ, Lab Parole \& Langage, UMR 7309, CNRS,LPL, 5 Ave Pasteur, F-13100 Aix En Provence, France.
   Pinto, Serge; Sato, Marc, Aix Marseille Univ, Lab Parole \& Langage, UMR 7309, CNRS,LPL, 5 Ave Pasteur, F-13100 Aix En Provence, France.
   Tremblay, Pascale, Univ Laval, Fac Med, Dept Readaptat, Quebec City, PQ, Canada.
   Tremblay, Pascale, Cervo Brain Res Ctr, Quebec City, PQ, Canada.
   Basirat, Anahita, Univ Lille, Sci Cognit \& Sci Affect, SCALab, CNRS,CHU Lille,UMR 9193, Lille, France.}},
DOI = {{10.1007/s00221-019-05661-5}},
Early Access Date = {{OCT 2019}},
ISSN = {{0014-4819}},
EISSN = {{1432-1106}},
Keywords = {{Auditory speech perception; Audiovisual speech perception; Predictive
   coding; Predictive timing; EEG}},
Keywords-Plus = {{ELECTROPHYSIOLOGICAL EVIDENCE; MULTISENSORY INTERACTIONS; VISUAL SPEECH;
   N1 WAVE; BRAIN; INFORMATION; TIME; INTEGRATION; KNOWLEDGE; FACILITATION}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{marc.sato@lpl-aix.fr}},
Cited-References = {{Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046.
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009.
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683.
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011.
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x.
   Boersma Paul, 2013, PRAAT DOING PHONETIC.
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Clementz BA, 2002, AUDIOL NEURO-OTOL, V7, P303, DOI 10.1159/000064444.
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009.
   Fodor Jerry, 1983, MODULARITY MIND.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Frtusova JB, 2013, PSYCHOL AGING, V28, P481, DOI 10.1037/a0031243.
   Ganesh AC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01340.
   GREGORY RL, 1980, PHILOS T ROY SOC B, V290, P181, DOI 10.1098/rstb.1980.0090.
   Heilbron M, 2018, NEUROSCIENCE, V389, P54, DOI 10.1016/j.neuroscience.2017.07.061.
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004.
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007.
   Laine M, 2007, NEUROREPORT, V18, P1697, DOI 10.1097/WNR.0b013e3282f0d118.
   Lange K, 2003, PSYCHOPHYSIOLOGY, V40, P806, DOI 10.1111/1469-8986.00081.
   Lange K, 2006, J COGNITIVE NEUROSCI, V18, P715, DOI 10.1162/jocn.2006.18.5.715.
   Lange K, 2006, EXP BRAIN RES, V173, P130, DOI 10.1007/s00221-006-0372-3.
   Lange K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00263.
   Lange K, 2009, BRAIN COGNITION, V69, P127, DOI 10.1016/j.bandc.2008.06.004.
   Massaro D. W., 1998, PERCEIVING TALKING F.
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0.
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x.
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x.
   Neisser U., 1967, COGNITIVE PSYCHOL.
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Paris T, 2017, NEUROSCIENCE, V343, P157, DOI 10.1016/j.neuroscience.2016.09.023.
   Paris T, 2016, J COGNITIVE NEUROSCI, V28, P158, DOI 10.1162/jocn\_a\_00885.
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI {[}10.1044/1092-4388(2009/07-0276), 10.1044/1092-4388].
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Roder B, 2007, RESTOR NEUROL NEUROS, V25, P311.
   Rosenblum LD, 2016, ECOL PSYCHOL, V28, P262, DOI 10.1080/10407413.2016.1230373.
   SCHAFER EWP, 1981, ELECTROEN CLIN NEURO, V52, P9, DOI 10.1016/0013-4694(81)90183-8.
   SCHERG M, 1986, ELECTROEN CLIN NEURO, V65, P344, DOI 10.1016/0168-5597(86)90014-6.
   Schwartz JL, 2014, PLOS COMPUTATIONAL B, V10, P7.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964.
   Talsma D, 2015, FRONT INTEGR NEUROSC, V19, P9.
   Treille A, 2018, NEUROPSYCHOLOGIA, V109, P126, DOI 10.1016/j.neuropsychologia.2017.12.024.
   Treille A, 2017, EXP BRAIN RES, V235, P2867, DOI 10.1007/s00221-017-5018-0.
   Treille A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00420.
   Treille A, 2014, NEUROPSYCHOLOGIA, V57, P71, DOI 10.1016/j.neuropsychologia.2014.02.004.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388.
   VONHELMHOLTZ H, 1909, TREATISE PHYSL OPTIC.
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308.
   Widmann A, 2004, PSYCHOPHYSIOLOGY, V41, P709, DOI 10.1111/j.1469-8986.2004.00208.x.
   Winneke AH, 2011, PSYCHOL AGING, V26, P427, DOI 10.1037/a0021683.
   Woods DL, 1995, EEG CL N SU, P102.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Exp. Brain Res.}},
Doc-Delivery-Number = {{JY3MM}},
Unique-ID = {{ISI:000489506800001}},
DA = {{2020-12-06}},
}

@article{ ISI:000487027200025,
Author = {Parsons, Lauren and Cordier, Reinie and Munro, Natalie and Joosten,
   Annette},
Title = {{A Play-Based, Peer-Mediated Pragmatic Language Intervention for
   School-Aged Children on the Autism Spectrum: Predicting Who Benefits
   Most}},
Journal = {{JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS}},
Year = {{2019}},
Volume = {{49}},
Number = {{10}},
Pages = {{4219-4231}},
Month = {{OCT}},
Abstract = {{This study explored characteristics of children with autism with large
   intervention effects following a peer-mediated pragmatic language
   intervention, to devise algorithms for predicting children most likely
   to benefit. Children attended a 10-week intervention with a
   typically-developing peer. Data from a pilot study and RCT formed the
   dataset for this study. The POM-2 measured intervention outcomes.
   Children completed the EVT-2, TACL-4, and Social Emotional Evaluation at
   baseline, and parents completed the CCC-2 and CCBRS. High CCC-2 Use of
   Context and CCBRS Separation Anxiety scores and comparatively lower
   EVT-2, CCC-2 Nonverbal Communication and Cohesion scores predicted
   children with large intervention effects. Results can be used by
   clinicians to predict which children within their clinics might benefit
   most from participating in this intervention.}},
Publisher = {{SPRINGER/PLENUM PUBLISHERS}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Parsons, L (Corresponding Author), Curtin Univ, Sch Occupat Therapy Social Work \& Speech Pathol, Bentley, WA 6102, Australia.
   Parsons, Lauren; Cordier, Reinie; Munro, Natalie; Joosten, Annette, Curtin Univ, Sch Occupat Therapy Social Work \& Speech Pathol, Bentley, WA 6102, Australia.
   Cordier, Reinie, Univ Oslo, Fac Educ Sci, Dept Special Needs Educ, N-0318 Blindern, Olso, Norway.
   Munro, Natalie, Univ Sydney, Fac Hlth Sci, Camperdown, NSW 2006, Australia.
   Joosten, Annette, Australian Catholic Univ, Sch Allied Hlth, Fitzroy, Vic 3065, Australia.}},
DOI = {{10.1007/s10803-019-04137-3}},
ISSN = {{0162-3257}},
EISSN = {{1573-3432}},
Keywords = {{Social communication; Intervention development; Outcome prediction;
   Discriminant function analysis}},
Keywords-Plus = {{DISORDER; COMMUNICATION; IMPAIRMENT}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Developmental}},
Author-Email = {{lauren.parsons@curtin.edu.au}},
ResearcherID-Numbers = {{Parsons, Lauren/W-9384-2019
   Cordier, Reinie/AAH-6290-2019
   Munro, Natalie/J-6163-2017
   }},
ORCID-Numbers = {{Parsons, Lauren/0000-0002-4209-7168
   Cordier, Reinie/0000-0002-9906-5300
   Munro, Natalie/0000-0002-5870-6378
   Joosten, Annette/0000-0003-4722-1081}},
Cited-References = {{Adams C., 2005, CHILD LANG TEACH THE, V21, P227, DOI DOI 10.1191/0265659005CT2900A.
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT.
   {[}Anonymous], 2000, DIAGN STAT MAN MENT.
   Antshel KM, 2011, J DEV BEHAV PEDIATR, V32, P439, DOI 10.1097/DBP.0b013e318222355d.
   Arnold JE, 2010, LANG LINGUIST COMPAS, V4, P187, DOI 10.1111/j.1749-818x.2010.00193.x.
   Bauminger N, 2003, AUTISM, V7, P81, DOI 10.1177/1362361303007001007.
   Bishop D. V. M., 2006, CHILDRENS COMMUNICAT.
   Bundy A., 2004, TEST PLAYFULNESS TOP.
   Carrow-Woolfolk E., 2014, TEST AUDITORY COMPRE.
   Cohen J., 1988, STAT POWER ANAL BEHA.
   Conners C, 2008, CONNERS COMPREHENSIV.
   Cordier R, 2018, FRONTIER PSYCHOL.
   Cordier R, 2014, RES DEV DISABIL, V35, P1588, DOI 10.1016/j.ridd.2014.03.050.
   Cordier R, 2009, AUST OCCUP THER J, V56, P332, DOI 10.1111/j.1440-1630.2009.00796.x.
   Corporation IBM, 2013, IBM SPSS STAT WIND V.
   Dunn LM, 2007, PEABODY PICTURE VICA.
   Gifford-Smith ME, 2003, J SCHOOL PSYCHOL, V41, P235, DOI 10.1016/S0022-4405(03)00048-7.
   Hale CM, 2005, AUTISM, V9, P157, DOI 10.1177/1362361305051395.
   Happe F, 1999, TRENDS COGN SCI, V3, P216, DOI 10.1016/S1364-6613(99)01318-2.
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0.
   Helland WA, 2017, RES DEV DISABIL, V70, P33, DOI 10.1016/j.ridd.2017.08.009.
   Henning B, 2016, AUST OCCUP THER J, V63, P223, DOI 10.1111/1440-1630.12285.
   Howlin P, 2011, SAGE HDB DEV DISORDE.
   Ingersoll B, 2001, J AUTISM DEV DISORD, V31, P343, DOI 10.1023/A:1010703521704.
   Jeste SS, 2014, NAT REV NEUROL, V10, P74, DOI 10.1038/nrneurol.2013.278.
   Kasari C, 2012, J AM ACAD CHILD PSY, V51, P487, DOI 10.1016/j.jaac.2012.02.019.
   Linacre J. M., 2016, WINSTEPS RASCH MEASU.
   Muller E, 2008, AUTISM, V12, P173, DOI 10.1177/1362361307086664.
   Norbury CF, 2005, J EXP CHILD PSYCHOL, V90, P142, DOI 10.1016/j.jecp.2004.11.003.
   Norbury CF, 2002, INT J LANG COMM DIS, V37, P227, DOI 10.1080/13682820210136269.
   Parsons L, 2018, INT J SPEECH LANGUAG.
   Parsons L., 2018, PEERS PRAGMATI UNPUB.
   Parsons L., 2018, RANDOMISED CON UNPUB.
   Parsons L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172242.
   Pijnacker J, 2009, J AUTISM DEV DISORD, V39, P607, DOI 10.1007/s10803-008-0661-8.
   Schwartz D, 2010, OXFORD HDB DEV PLAY.
   Semel EM, 2003, CLIN EVALUATION LANG.
   Sherer MR, 2005, J CONSULT CLIN PSYCH, V73, P525, DOI 10.1037/0022-006X.73.3.525.
   Vivanti G, 2014, FRONT PEDIATR, V2, DOI 10.3389/fped.2014.00058.
   Wiig E. H., 2008, SOCIAL EMOTIONAL EVA.
   Wilkes-Gillan S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160558.
   Williams K. T., 2007, EXPRESSIVE VOCABULAR.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{J. Autism Dev. Disord.}},
Doc-Delivery-Number = {{IZ4AR}},
Unique-ID = {{ISI:000487027200025}},
DA = {{2020-12-06}},
}

@article{ ISI:000478780200019,
Author = {Grisoni, Luigi and Mohr, Bettina and Pulvermueller, Friedemann},
Title = {{Prediction mechanisms in motor and auditory areas and their role in
   sound perception and language understanding}},
Journal = {{NEUROIMAGE}},
Year = {{2019}},
Volume = {{199}},
Pages = {{206-216}},
Month = {{OCT 1}},
Abstract = {{Is the meaning of an expected stimulus manifest in brain activity even
   before it appears? Although theories of predictive coding see
   anticipatory activity as crucial for the understanding of brain
   function, few studies have explored neurophysiologically manifest
   semantic predictions. Here, we report predictive negative-going
   potentials before the onset of action (i.e. whistle and hand clap) and
   non-action (i.e. pure tone, water drop) sounds. These prediction
   potentials (PP) indexed the meaning of action-related sounds. Dependent
   on the body-part-relationship of sound stimuli, neural sources were
   relatively more prominent in dorsal or ventral motor areas. In contrast,
   meaningless sounds (pure tones) activated predictive sources in temporal
   areas close to the auditory cortex; complex environmental sounds induced
   an anticipatory positivity broadly distributed over the scalp. We also
   found a systematic relationship between predictive activity and a
   Mismatch Negativity (MMN) like response to unexpected meaningful words
   which were presented as rare deviant stimuli amongst frequently repeated
   sounds. This deviant-elicited potential indexed semantic priming between
   action sounds and action-related words and semantic mismatch (prediction
   error). These results suggest a systematic link between
   perceptual/semantic prediction and matching mechanisms in the processing
   of sounds and words.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Pulvermuller, F (Corresponding Author), Free Univ Berlin, Brain Language Lab, Dept Philosophy \& Humanities, WE4,Habelschwerdter Allee 45, D-14195 Berlin, Germany.
   Grisoni, Luigi; Pulvermueller, Friedemann, Free Univ Berlin, Brain Language Lab, Dept Philosophy \& Humanities, WE4,Habelschwerdter Allee 45, D-14195 Berlin, Germany.
   Mohr, Bettina, Charite Univ Med Berlin, Dept Psychiat, D-12203 Berlin, Germany.
   Pulvermueller, Friedemann, Humboldt Univ, Berlin Sch Mind \& Brain, D-10099 Berlin, Germany.
   Pulvermueller, Friedemann, Einstein Ctr Neurosci, D-10117 Berlin, Germany.}},
DOI = {{10.1016/j.neuroimage.2019.05.071}},
ISSN = {{1053-8119}},
EISSN = {{1095-9572}},
Keywords = {{Grounded cognition; Mismatch negativity; Semantic processing; Prediction
   potential}},
Keywords-Plus = {{MISMATCH NEGATIVITY; MIRROR NEURONS; CORTEX; WORDS; ACTIVATION;
   ATTENTION; MMN; REPRESENTATION; INHIBITION; POTENTIALS}},
Research-Areas = {{Neurosciences \& Neurology; Radiology, Nuclear Medicine \& Medical
   Imaging}},
Web-of-Science-Categories  = {{Neurosciences; Neuroimaging; Radiology, Nuclear Medicine \& Medical
   Imaging}},
Author-Email = {{grisoniluigi@zedat.fu-berlin.de}},
ORCID-Numbers = {{pulvermuller, friedemann/0000-0003-3210-7112}},
Funding-Acknowledgement = {{Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG)}},
Funding-Text = {{We thank Verena Buscher, Dimitra Kandia, Neslihan Sener, and Shiva
   Motlagh for their help at different stages of this work. This work was
   supported by the Deutsche Forschungsgemeinschaft (Pu 97/16-1, Pu
   97/22-1). Funding to pay the Open Access publication charges for this
   article was provided by the Deutsche Forschungsgemeinschaft.}},
Cited-References = {{BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129.
   COHEN J, 1973, EDUC PSYCHOL MEAS, V33, P107, DOI 10.1177/001316447303300111.
   Cook R, 2014, BEHAV BRAIN SCI, V37, P177, DOI 10.1017/S0140525X13000903.
   DEECKE L, 1969, EXP BRAIN RES, V7, P158.
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009.
   Engel LR, 2009, NEUROIMAGE, V47, P1778, DOI 10.1016/j.neuroimage.2009.05.041.
   Escera C, 2003, EUR J NEUROSCI, V18, P2408, DOI 10.1046/j.1460-9568.2003.02937.x.
   Frangos J, 2005, NEUROREPORT, V16, P1313, DOI 10.1097/01.wnr.0000175619.23807.b7.
   Friston KJ, 2008, NEUROIMAGE, V39, P1104, DOI 10.1016/j.neuroimage.2007.09.048.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Garagnani M, 2013, BRAIN LANG, V127, P75, DOI 10.1016/j.bandl.2013.02.001.
   Garagnani M, 2011, NEUROIMAGE, V54, P170, DOI 10.1016/j.neuroimage.2010.08.031.
   Garrido MI, 2008, NEUROIMAGE, V42, P936, DOI 10.1016/j.neuroimage.2008.05.018.
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823.
   Grisoni L, 2017, J NEUROSCI, V37, P4848, DOI 10.1523/JNEUROSCI.2800-16.2017.
   Grisoni L, 2016, CEREB CORTEX, V26, P2353, DOI 10.1093/cercor/bhw026.
   Hanna J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00886.
   Hauk O, 2006, EUR J NEUROSCI, V23, P811, DOI 10.1111/j.1460-9568.2006.04586.x.
   Hauk O, 2004, NEURON, V41, P301, DOI 10.1016/S0896-6273(03)00838-9.
   Heilbron M, 2018, NEUROSCIENCE, V389, P54, DOI 10.1016/j.neuroscience.2017.07.061.
   Jaaskelainen IP, 2004, P NATL ACAD SCI USA, V101, P6809, DOI 10.1073/pnas.0303760101.
   Kappenman E.S., 2012, OXFORD HDB EVENT REL.
   Keysers C, 2003, EXP BRAIN RES, V153, P628, DOI 10.1007/s00221-003-1603-5.
   Kilner JM, 2004, NAT NEUROSCI, V7, P1299, DOI 10.1038/nn1355.
   Kohler E, 2002, SCIENCE, V297, P846, DOI 10.1126/science.1070311.
   Kornhuber HH, 2016, PFLUG ARCH EUR J PHY, V468, P1115, DOI 10.1007/s00424-016-1852-3.
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426.
   Leminen A, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00066.
   Lewis JW, 2004, CEREB CORTEX, V14, P1008, DOI 10.1093/cercor/bhh061.
   Lieder F, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003288.
   Litvak V, 2008, NEUROIMAGE, V42, P1490, DOI 10.1016/j.neuroimage.2008.06.022.
   Litvak V, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/852961.
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1.
   Manoussaki D, 2008, P NATL ACAD SCI USA, V105, P6162, DOI 10.1073/pnas.0710037105.
   May P J C, 2004, Neurol Clin Neurophysiol, V2004, P20.
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477.
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026.
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9.
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0.
   NAATANEN R, 1990, BEHAV BRAIN SCI, V13, P201, DOI 10.1017/S0140525X00078407.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Pulvermuller F, 2001, NEUROIMAGE, V14, P607, DOI 10.1006/nimg.2001.0864.
   Pulvermuller F, 2006, NEUROIMAGE, V31, P1297, DOI 10.1016/j.neuroimage.2006.01.030.
   Pulvermuller F, 2005, J COGNITIVE NEUROSCI, V17, P884, DOI 10.1162/0898929054021111.
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004.
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811.
   Pulvermuller F, 2009, BRAIN LANG, V110, P81, DOI 10.1016/j.bandl.2008.12.001.
   Rinne T, 2000, NEUROIMAGE, V12, P14, DOI 10.1006/nimg.2000.0591.
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435.
   Shtyrov Y, 2007, J COGNITIVE NEUROSCI, V19, P1633, DOI 10.1162/jocn.2007.19.10.1633.
   Shtyrov Y, 2014, P NATL ACAD SCI USA, V111, pE1918, DOI 10.1073/pnas.1323158111.
   Sussman-Fort J, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00093.
   Talavage TM, 2004, J NEUROPHYSIOL, V91, P1282, DOI 10.1152/jn.01125.2002.
   Tomasello R, 2017, NEUROPSYCHOLOGIA, V98, P111, DOI 10.1016/j.neuropsychologia.2016.07.004.
   VONHELMHOLTZ H, 1853, ANN PHYS CHEM, V89, P353, DOI DOI 10.1002/ANDP.18531650702.
   WALTER WG, 1964, NATURE, V203, P380, DOI 10.1038/203380a0.
   WARREN P, 1987, PERCEPT PSYCHOPHYS, V41, P262, DOI 10.3758/BF03208224.
   Yabe H, 1997, NEUROREPORT, V8, P1971, DOI 10.1097/00001756-199705260-00035.
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Neuroimage}},
Doc-Delivery-Number = {{IN6HY}},
Unique-ID = {{ISI:000478780200019}},
OA = {{Other Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000486395100001,
Author = {Grandchamp, Romain and Rapin, Lucile and Perrone-Bertolotti, Marcela and
   Pichat, Cedric and Haldin, Celise and Cousin, Emilie and Lachaux,
   Jean-Philippe and Dohen, Marion and Perrier, Pascal and Garnier, Maeva
   and Baciu, Monica and Loevenbruck, Helene},
Title = {{The ConDialint Model: Condensation, Dialogality, and Intentionality
   Dimensions of Inner Speech Within a Hierarchical Predictive Control
   Framework}},
Journal = {{FRONTIERS IN PSYCHOLOGY}},
Year = {{2019}},
Volume = {{10}},
Month = {{SEP 18}},
Abstract = {{Inner speech has been shown to vary in form along several dimensions.
   Along condensation, condensed inner speech forms have been described,
   that are supposed to be deprived of acoustic, phonological and even
   syntactic qualities. Expanded forms, on the other extreme, display
   articulatory and auditory properties. Along dialogality, inner speech
   can be monologal, when we engage in internal soliloquy, or dialogal,
   when we recall past conversations or imagine future dialogs involving
   our own voice as well as that of others addressing us. Along
   intentionality, it can be intentional (when we deliberately rehearse
   material in short-term memory) or it can arise unintentionally (during
   mind wandering). We introduce the ConDiallnt model, a neurocognitive
   predictive control model of inner speech that accounts for its varieties
   along these three dimensions. ConDiallnt spells out the condensation
   dimension by including inhibitory control at the conceptualization,
   formulation or articulatory planning stage. It accounts for dialogality,
   by assuming internal model adaptations and by speculating on neural
   processes underlying perspective switching. It explains the differences
   between intentional and spontaneous varieties in terms of monitoring. We
   present an fMRI study in which we probed varieties of inner speech along
   dialogality and intentionality, to examine the validity of the
   neuroanatomical correlates posited in ConDiallnt. Condensation was also
   informally tackled. Our data support the hypothesis that expanded inner
   speech recruits speech production processes down to articulatory
   planning, resulting in a predicted signal, the inner voice, with
   auditory qualities. Along dialogality, covertly using an avatar's voice
   resulted in the activation of right hemisphere homologs of the regions
   involved in internal own-voice soliloquy and in reduced cerebellar
   activation, consistent with internal model adaptation. Switching from
   first-person to third-person perspective resulted in activations in
   precuneus and parietal lobules. Along intentionality, compared with
   intentional inner speech, mind wandering with inner speech episodes was
   associated with greater bilateral inferior frontal activation and
   decreased activation in left temporal regions. This is consistent with
   the reported subjective evanescence and presumably reflects condensation
   processes. Our results provide neuroanatomical evidence compatible with
   predictive control and in favor of the assumptions made in the
   ConDiallnt model.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Loevenbruck, H (Corresponding Author), Univ Savoie Mt Blanc, Univ Grenoble Alpes, CNRS, LPNC, Grenoble, France.
   Grandchamp, Romain; Rapin, Lucile; Perrone-Bertolotti, Marcela; Pichat, Cedric; Haldin, Celise; Cousin, Emilie; Baciu, Monica; Loevenbruck, Helene, Univ Savoie Mt Blanc, Univ Grenoble Alpes, CNRS, LPNC, Grenoble, France.
   Lachaux, Jean-Philippe, CNRS, Lyon Neurosci Res Ctr, Brain Dynam \& Cognit Team, INSERM,U1028,UMR5292, Bron, France.
   Dohen, Marion; Perrier, Pascal; Garnier, Maeva, Univ Grenoble Alpes, CNRS, Grenoble INP, GIPSA Lab, Grenoble, France.}},
DOI = {{10.3389/fpsyg.2019.02019}},
Article-Number = {{2019}},
ISSN = {{1664-1078}},
Keywords = {{inner speech; auditory verbal imagery; mind wandering; condensation;
   dialogality; intentionality; fMRI; predictive control}},
Keywords-Plus = {{AUDITORY VERBAL HALLUCINATIONS; TOP-DOWN ACTIVATION; COROLLARY
   DISCHARGE; SENTENCE PRODUCTION; LANGUAGE PRODUCTION; COGNITIVE
   FUNCTIONS; FUNCTIONAL-ANATOMY; PREFRONTAL CORTEX; BRAIN MECHANISMS;
   LEXICAL BIAS}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{Helene.Loevenbruck@univ-grenoble-alpes.fr}},
ResearcherID-Numbers = {{Baciu, Monica/AAE-4011-2020
   Perrier, Pascal/AAQ-2687-2020}},
ORCID-Numbers = {{Baciu, Monica/0000-0002-6842-1317
   Perrier, Pascal/0000-0003-2192-4176}},
Funding-Acknowledgement = {{ANR project INNERSPEECHFrench National Research Agency (ANR)
   {[}ANR-13-BSH2-0003-01]; French program ``Investissement d'Avenir{''} by
   the ``Agence Nationale pour la Recherche{''}French National Research
   Agency (ANR) {[}ANR-11-INBS-0006]}},
Funding-Text = {{This research was supported by the ANR project INNERSPEECH (Grant Number
   ANR-13-BSH2-0003-01; http://lpnc.univ-grenoble-alpes.fr/InnerSpeech).The
   IRMaGe MRI/Neurophysiology facility was partly funded by the French
   program ``Investissement d'Avenir{''} run by the `` Agence Nationale
   pour la Recherche{''} (Grant `` Infrastructure d'avenir en Biologie
   Sante{''} - ANR-11-INBS-0006).}},
Cited-References = {{Agnew ZK, 2013, NEUROIMAGE, V73, P191, DOI 10.1016/j.neuroimage.2012.08.020.
   Alderson-Day B, 2018, CONSCIOUS COGN, V65, P48, DOI 10.1016/j.concog.2018.07.001.
   Alderson-Day B, 2016, SOC COGN AFFECT NEUR, V11, P110, DOI 10.1093/scan/nsv094.
   Alderson-Day B, 2015, PSYCHOL BULL, V141, P931, DOI 10.1037/bul0000021.
   Aleman A, 2008, HALLUCINATIONS SCI I.
   Baciu MV, 1999, NMR BIOMED, V12, P293, DOI 10.1002/(SICI)1099-1492(199908)12:5<293::AID-NBM573>3.0.CO;2-6.
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014.
   Bain Alexander, 1855, SENSES INTELLECT.
   Baldo JV, 2005, BRAIN LANG, V92, P240, DOI 10.1016/j.bandl.2004.06.103.
   Basho S, 2007, NEUROPSYCHOLOGIA, V45, P1697, DOI 10.1016/j.neuropsychologia.2007.01.007.
   Baum SR, 1999, APHASIOLOGY, V13, P581, DOI 10.1080/026870399401957.
   Beldo JV, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01523.
   Bergounioux G, 2001, LANGUE FRANCAISE, P106.
   Bergounioux G., 2004, MOYEN PARLER.
   BLACKMER ER, 1991, COGNITION, V39, P173, DOI 10.1016/0010-0277(91)90052-6.
   Blakemore SJ, 2002, TRENDS COGN SCI, V6, P237, DOI 10.1016/S1364-6613(02)01907-1.
   Blank SC, 2002, BRAIN, V125, P1829, DOI 10.1093/brain/awf191.
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292.
   Bock K., 1987, Natural Language Generation: New Results in Artificial Intelligence, Psychology and Linguistics. Proceedings of the NATO Advanced Research Workshop, P351.
   Bookheimer SY, 1995, HUM BRAIN MAPP, V3, P93, DOI 10.1002/hbm.460030206.
   BRES Jacques, 2005, DIALOGISME POLYPHONI, P47.
   Browman CP, 1989, PHONOLOGY, V6, P201, DOI DOI 10.1017/S0952675700001019.
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011.
   Buckner RL, 2011, J NEUROPHYSIOL, V106, P2322, DOI 10.1152/jn.00339.2011.
   Caplan D, 1998, BRAIN LANG, V63, P184, DOI 10.1006/brln.1998.1930.
   Caplan D, 2000, HUM BRAIN MAPP, V9, P65.
   Carruthers P, 2002, BEHAV BRAIN SCI, V25, P657, DOI 10.1017/S0140525X02000122.
   Clark A, 2002, BEHAV BRAIN SCI, V25, P681, DOI 10.1017/S0140525X02290123.
   Clowes R, 2007, J CONSCIOUSNESS STUD, V14, P59.
   CONRAD B, 1979, ARCH PSYCHIAT NERVEN, V226, P251, DOI 10.1007/BF00342238.
   Conway MA, 2005, J MEM LANG, V53, P594, DOI 10.1016/j.jml.2005.08.005.
   Corley M, 2011, J EXP PSYCHOL LEARN, V37, P162, DOI 10.1037/a0021321.
   De Smet HJ, 2013, BRAIN LANG, V127, P334, DOI 10.1016/j.bandl.2012.11.001.
   Decety J, 2006, BRAIN RES, V1079, P4, DOI 10.1016/j.brainres.2005.12.115.
   Decety J., 2005, OTHER MINDS HUMANS B, P143.
   Dell GS, 2015, BLACKW HBK LINGUIST, P404.
   Dell GS, 2013, BEHAV BRAIN SCI, V36, P351, DOI 10.1017/S0140525X12002531.
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283.
   DELL GS, 1992, EXPT SLIPS HUMAN ERR, P237, DOI DOI 10.1007/978-1-4899-1164-3\_10.
   Dennett D., 1991, CONSCIOUSNESS EXPLAI.
   Diedrichsen J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133402.
   Duffau H, 2014, BRAIN LANG, V131, P1, DOI 10.1016/j.bandl.2013.05.011.
   Egger V., 1881, PAROLE INTERIEURE ES.
   Emerson MJ, 2003, J MEM LANG, V48, P148, DOI 10.1016/S0749-596X(02)00511-9.
   FEINBERG I, 1978, SCHIZOPHRENIA BULL, V4, P636, DOI 10.1093/schbul/4.4.636.
   Fernyhough C, 2004, NEW IDEAS PSYCHOL, V22, P49, DOI 10.1016/j.newideapsych.2004.09.001.
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112.
   Ford JM, 2004, J PSYCHIATR RES, V38, P37, DOI 10.1016/S0022-3956(03)00095-5.
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011.
   Friedrich J, 2001, LANG FR, V132, P57, DOI {[}10.3406/lfr.2001.6315, DOI 10.3406/LFR.2001.6315].
   Friston KJ, 2005, NEUROIMAGE, V25, P661, DOI 10.1016/j.neuroimage.2005.01.013.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Frith C.D., 1992, COGNITIVE NEUROPSYCH.
   Frith CD, 1995, HUM BRAIN MAPP, V3, P153, DOI 10.1002/hbm.460030209.
   Frith CD, 2000, BRAIN RES REV, V31, P357, DOI 10.1016/S0165-0173(99)00052-1.
   Gallagher S, 2004, PSYCHOPATHOLOGY, V37, P8, DOI 10.1159/000077014.
   Gernsbacher MA, 2003, ANNU REV PSYCHOL, V54, P91, DOI 10.1146/annurev.psych.54.101601.145128.
   Geva S, 2011, BRAIN, V134, P3071, DOI 10.1093/brain/awr232.
   Gregory D, 2017, J CONSCIOUSNESS STUD, V24, P111.
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001.
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006.
   Haller S, 2005, NEUROPSYCHOLOGIA, V43, P807, DOI 10.1016/j.neuropsychologia.2004.09.007.
   Hardy J, 2006, PSYCHOL SPORT EXERC, V7, P81, DOI 10.1016/j.psychsport.2005.04.002.
   Haruno M, 2003, INT CONGR SER, V1250, P575, DOI 10.1016/S0531-5131(03)00190-0.
   Henson R, 2005, TECHNICAL REPORT.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001.
   Hoffman RE, 2011, BIOL PSYCHIAT, V69, P407, DOI 10.1016/j.biopsych.2010.09.050.
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082.
   Huang J, 2002, HUM BRAIN MAPP, V15, P39, DOI 10.1002/hbm.1060.
   Huettig F, 2010, LANG COGNITIVE PROC, V25, P347, DOI 10.1080/01690960903046926.
   Hurlburt R. T., 2011, INVESTIGATING PRISTI.
   Hurlburt RT, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147932.
   Hurlburt RT, 2013, CONSCIOUS COGN, V22, P1477, DOI 10.1016/j.concog.2013.10.003.
   Imamizu H, 2009, PSYCHOL RES-PSYCH FO, V73, P527, DOI 10.1007/s00426-009-0235-1.
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001.
   Indefrey P, 2001, P NATL ACAD SCI USA, V98, P5933, DOI 10.1073/pnas.101118098.
   Indefrey P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00255.
   Jackendoff R, 2011, LANGUAGE, V87, P586.
   Jacobson E, 1931, AM J PHYSIOL, V97, P200.
   Jeannerod M, 2001, NEUROIMAGE, V14, pS103, DOI 10.1006/nimg.2001.0832.
   Jones SR, 2007, CONSCIOUS COGN, V16, P391, DOI 10.1016/j.concog.2005.12.003.
   Jones SR, 2007, CLIN PSYCHOL REV, V27, P140, DOI 10.1016/j.cpr.2006.10.001.
   Kell CA, 2017, HUM BRAIN MAPP, V38, P493, DOI 10.1002/hbm.23398.
   KEMPEN G, 1987, COGNITIVE SCI, V11, P201.
   Knobloch C., 1984, SPRACHPSYCHOLOGIE BE.
   KORBA RJ, 1990, PERCEPT MOTOR SKILL, V71, P1043, DOI 10.2466/pms.1990.71.3.1043.
   Langland-Hassan P, 2018, INNER SPEECH NEW VOI.
   Langland-Hassan P, 2017, ACTA PSYCHOL, V181, P62, DOI 10.1016/j.actpsy.2017.10.004.
   Laroi F, 2007, HARVARD REV PSYCHIAT, V15, P109, DOI 10.1080/10673220701401993.
   Laurent L, 2016, J COGN PSYCHOL, V28, P585, DOI 10.1080/20445911.2016.1164173.
   Laver J., 1980, ERRORS LINGUISTIC PE, P287.
   LEVELT WJM, 1983, COGNITION, V14, P41, DOI 10.1016/0010-0277(83)90026-4.
   Levelt WJM., 1989, SPEAKING INTENTION A.
   Linden DEJ, 2011, CEREB CORTEX, V21, P330, DOI 10.1093/cercor/bhq097.
   Livesay J, 1996, PERCEPT MOTOR SKILL, V83, P1355, DOI 10.2466/pms.1996.83.3f.1355.
   Loevenbruck H, 2005, J NEUROLINGUIST, V18, P237, DOI 10.1016/j.jneuroling.2004.12.002.
   Loevenbruck H., 2018, INNER SPEECH NEW VOI, P131.
   Loevenbruck H., 1996, THESIS.
   Loevenbruck H., 2018, LANGAGE INTERIEUR ES, V18.
   Loewenstein J, 2005, COGNITIVE PSYCHOL, V50, P315, DOI 10.1016/j.cogpsych.2004.09.004.
   MacKay D.G., 1992, AUDITORY IMAGERY, P121.
   MacSweeney M, 2008, TRENDS COGN SCI, V12, P432, DOI 10.1016/j.tics.2008.07.010.
   Maingueneau D, 2016, TERMES CLES ANAL DIS.
   Manfra L, 2016, EARLY CHILD RES Q, V37, P94, DOI 10.1016/j.ecresq.2016.04.004.
   Marien P, 2014, CEREBELLUM, V13, P386, DOI 10.1007/s12311-013-0540-5.
   Martinez-Manrique F, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00232.
   Martinez-Manrique F, 2010, J CONSCIOUSNESS STUD, V17, P141.
   Marvel CL, 2012, BRAIN LANG, V120, P42, DOI 10.1016/j.bandl.2011.08.005.
   Max LW, 1937, J COMP PSYCHOL, V24, P301, DOI 10.1037/h0057481.
   McCarthy-Jones S, 2011, CONSCIOUS COGN, V20, P1586, DOI 10.1016/j.concog.2011.08.005.
   MCGUIGAN FJ, 1989, PAVLOVIAN J BIOL SCI, V24, P19.
   McGuire PK, 1996, PSYCHOL MED, V26, P29, DOI 10.1017/S0033291700033699.
   McGuire PK, 1997, NEUROREPORT, V8, P695, DOI 10.1097/00001756-199702100-00023.
   MEACHAM JA, 1979, DEV SELF REGULATION, P237.
   Merleau-Ponty M, 1948, CAUSERIES.
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4.
   Miall RC, 2003, NEUROREPORT, V14, P2135, DOI 10.1097/00001756-200312020-00001.
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167.
   Morin Alain, 2012, Open Neuroimag J, V6, P78, DOI 10.2174/1874440001206010078.
   Morin A, 2011, PROCD SOC BEHV, V30, DOI 10.1016/j.sbspro.2011.10.331.
   Murdoch BE, 2010, CORTEX, V46, P858, DOI 10.1016/j.cortex.2009.07.018.
   Nalborczyk L, 2017, BIOL PSYCHOL, V127, P53, DOI 10.1016/j.biopsycho.2017.04.013.
   Netsell R, 2016, PERCEPT MOTOR SKILL, V123, P383, DOI 10.1177/0031512516664992.
   New B, 2001, ANN PSYCHOL, V101, P447.
   Newton AM, 2007, PSYCHOL SCI, V18, P574, DOI 10.1111/j.1467-9280.2007.01942.x.
   Nooteboom SG, 2005, SPEECH COMMUN, V47, P43, DOI 10.1016/j.specom.2005.02.003.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Oppenheim GM, 2008, COGNITION, V106, P528, DOI 10.1016/j.cognition.2007.02.006.
   Oppenheim GM, 2010, MEM COGNITION, V38, P1147, DOI 10.3758/MC.38.8.1147.
   Pacherie E, 2008, COGNITION, V107, P179, DOI 10.1016/j.cognition.2007.09.003.
   Palmer ED, 2001, NEUROIMAGE, V14, P182, DOI 10.1006/nimg.2001.0779.
   Partovi S, 2012, ACAD RADIOL, V19, P518, DOI 10.1016/j.acra.2011.12.017.
   Patri JF, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005942.
   Paulhan F, 1886, REV PHILOS, V21, P26.
   Pavlenko A, 2014, BILINGUAL MIND WHAT.
   Peirce CS, 1934, COLLECTED PAPERS CS, V5.
   Perkell J, 1997, SPEECH COMMUN, V22, P227, DOI 10.1016/S0167-6393(97)00026-5.
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011.
   Perrier P, 1996, J PHONETICS, V24, P53, DOI 10.1006/jpho.1996.0005.
   Perrone-Bertolotti M, 2014, BEHAV BRAIN RES, V261, P220, DOI 10.1016/j.bbr.2013.12.034.
   Perrone-Bertolotti M, 2012, J NEUROSCI, V32, P17554, DOI 10.1523/JNEUROSCI.2982-12.2012.
   Pichon S, 2013, J NEUROSCI, V33, P1640, DOI 10.1523/JNEUROSCI.3530-12.2013.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Postma A, 1996, LANG SPEECH, V39, P375, DOI 10.1177/002383099603900403.
   Postma A, 2000, COGNITION, V77, P97, DOI 10.1016/S0010-0277(00)00090-1.
   Rapin L, 2016, TRAITE NEUROLINGUIST, P347.
   Rapin L, 2013, J SPEECH LANG HEAR R, V56, pS1882, DOI 10.1044/1092-4388(2013/12-0210).
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331.
   REISBERG D, 1989, Q J EXP PSYCHOL-A, V41, P619, DOI 10.1080/14640748908402385.
   Ricoeur P, 1990, SOI MEME COMME AUTRE.
   Ridderinkhof KR, 2004, BRAIN COGNITION, V56, P129, DOI 10.1016/j.bandc.2004.09.016.
   Rosen HJ, 2000, BRAIN COGNITION, V42, P201, DOI 10.1006/brcg.1999.1100.
   ROULET E, 1984, J PRAGMATICS, V8, P31, DOI 10.1016/0378-2166(84)90061-4.
   Roulet E, 2006, FRENCH ENGLISH GLOSS.
   Ruby P, 2001, NAT NEUROSCI, V4, P546.
   Saint-Paul G, 1892, ESSAIS LANGAGE INTER.
   Saltzman E. L., 1989, ECOL PSYCHOL, V1, P333, DOI {[}10.1207/s15326969eco0104\_2, DOI 10.1207/S15326969EC00104\_].
   Sato M, 2004, NEUROIMAGE, V23, P1143, DOI 10.1016/j.neuroimage.2004.07.055.
   Scott M, 2013, J ACOUST SOC AM, V133, pEL286, DOI 10.1121/1.4794932.
   SHEEHAN PW, 1967, J CLIN PSYCHOL, V23, P386, DOI 10.1002/1097-4679(196707)23:3<386::AID-JCLP2270230328>3.0.CO;2-S.
   Shergill SS, 2000, AM J PSYCHIAT, V157, P1691, DOI 10.1176/appi.ajp.157.10.1691.
   Shergill SS, 2001, PSYCHOL MED, V31, P241, DOI 10.1017/S003329170100335X.
   Smadja S, 2018, EPISTEMOCRITIQUE, V18.
   Smallwood J, 2012, BRAIN RES, V1428, P60, DOI 10.1016/j.brainres.2011.03.072.
   SMITH JD, 1995, NEUROPSYCHOLOGIA, V33, P1433, DOI 10.1016/0028-3932(95)00074-D.
   Sokolov A., 1972, INNER SPEECH THOUGHT.
   Sokolov AA, 2017, TRENDS COGN SCI, V21, P313, DOI 10.1016/j.tics.2017.02.005.
   Sommer IEC, 2008, BRAIN, V131, P3169, DOI 10.1093/brain/awn251.
   Stricker S., 1885, LANGAGE MUSIQUE TRAD.
   Swiney L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00675.
   TAINE H, 1870, INTELLIGENCE.
   Tan X, 2012, FRONT HUM NEUROSCI, V6, DOI {[}10.3389/fnhum.2012.00305, 10.3389/fnhum.2012.00314].
   Tian X, 2016, CORTEX, V77, P1, DOI 10.1016/j.cortex.2016.01.002.
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn\_a\_00381.
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166.
   Tremblay P, 2016, BRAIN LANG, V162, P60, DOI 10.1016/j.bandl.2016.08.004.
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710.
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978.
   Venkatraman V, 2009, J NEUROSCI, V29, P13158, DOI 10.1523/JNEUROSCI.2708-09.2009.
   Vercueil L, 2013, EPILEPSY BEHAV, V27, P307, DOI 10.1016/j.yebeh.2013.02.007.
   Vicente A, 2016, PHILOS EXPLOR, V19, P173, DOI 10.1080/13869795.2016.1176234.
   Vygotsky L., 1934, THOUGHT LANGUAGE.
   WARREN RM, 1961, BRIT J PSYCHOL, V52, P249, DOI 10.1111/j.2044-8295.1961.tb00787.x.
   Wiley N, 2006, J THEOR SOC BEHAV, V36, P319, DOI 10.1111/j.1468-5914.2006.00309.x.
   Wiley Norbert, 2006, INT J DIALOGICAL SCI, V1, P5.
   Wiley Norbert, 2014, INT J DIALOGICAL SCI, V8, P1.
   Wilkinson S, 2017, CONSCIOUSNESS SEARCH, P285.
   Yao B, 2012, NEUROIMAGE, V60, P1832, DOI 10.1016/j.neuroimage.2012.01.111.}},
Number-of-Cited-References = {{189}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Front. Psychol.}},
Doc-Delivery-Number = {{IY4XA}},
Unique-ID = {{ISI:000486395100001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000489065400006,
Author = {Chang, Young-Soo and Hong, Sung Hwa and Kim, Eun Yeon and Choi, Ji Eun
   and Chung, Won-Ho and Cho, Yang-Sun and Moon, Il Joon},
Title = {{Benefit and predictive factors for speech perception outcomes in
   pediatric bilateral cochlear implant recipients}},
Journal = {{BRAZILIAN JOURNAL OF OTORHINOLARYNGOLOGY}},
Year = {{2019}},
Volume = {{85}},
Number = {{5}},
Pages = {{571-577}},
Month = {{SEP-OCT}},
Abstract = {{Introduction: Despite recent advancement in the prediction of cochlear
   implant outcome, the benefit of bilateral procedures compared to bimodal
   stimulation and how we predict speech perception outcomes of sequential
   bilateral cochlear implant based on bimodal auditory performance in
   children remain unclear.
   Objectives: This investigation was performed: (1) to determine the
   benefit of sequential bilateral cochlear implant and (2) to identify the
   associated factors for the outcome of sequential bilateral cochlear
   implant.
   Methods: Observational and retrospective study. We retrospectively
   analyzed 29 patients with sequential cochlear implant following
   bimodal-fitting condition. Audiological evaluations were performed; the
   categories of auditory performance scores, speech perception with
   monosyllable and disyllables words, and the Korean version of Ling.
   Audiological evaluations were performed before sequential cochlear
   implant with the bimodal fitting condition (CI1 + HA) and one year after
   the sequential cochlear implant with bilateral cochlear implant
   condition (CI1 + CI2). The good performance group (GP) was defined as
   follows; 90\% or higher in monosyllable and bisyllable tests with
   auditory-only condition or 20\% or higher improvement of the scores with
   CI1 + CI2. Age at first implantation, inter-implant interval, categories
   of auditory performance score, and various comorbidities were analyzed
   by logistic regression analysis.
   Results: Compared to the CI1 + HA, CI1 + CI2 provided significant
   benefit in categories of auditory performance, speech perception, and
   Korean version of Ling results. Preoperative categories of auditory
   performance scores were the only associated factor for being GP (odds
   ratio = 4.38, 95\% confidence interval - 95\% = 1.07-17.93, p = 0.04).
   Conclusions: The children with limited language development in bimodal
   condition should be considered as the sequential bilateral cochlear
   implant and preoperative categories of auditory performance score could
   be used as the predictor in speech perception after sequential cochlear
   implant. (C) 2018 Associacao Brasileira de Otorrinolaringologia e
   Cirurgia Cervico-Facial. Published by Elsevier Editora Ltda.}},
Publisher = {{ASSOC BRASILEIRA OTORRINOLARINGOLOGIA \& CIRURGIA CERVICOFACIAL}},
Address = {{AV INDIANOPOLOS 740, MOEMA, SAO PAULO, SP 04062-001, BRAZIL}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Moon, I (Corresponding Author), Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Otorhinolaryngol Head \& Neck Surg, Seoul, South Korea.
   Chang, Young-Soo; Chung, Won-Ho; Cho, Yang-Sun; Moon, Il Joon, Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Otorhinolaryngol Head \& Neck Surg, Seoul, South Korea.
   Hong, Sung Hwa, Sungkyunkwan Univ, Sch Med, Samsung Changwon Hosp, Dept Otorhinolaryngol Head \& Neck Surg, Seoul, South Korea.
   Kim, Eun Yeon, Myongji Univ, Grad Sch, Dept Speech \& Language Pathol, Seoul, South Korea.
   Choi, Ji Eun, Dankook Univ Hosp, Dept Otorhinolaryngol Head \& Neck Surg, Cheonan, South Korea.}},
DOI = {{10.1016/j.bjorl.2018.04.009}},
ISSN = {{1808-8694}},
EISSN = {{1808-8686}},
Keywords = {{Bilateral cochlear implant; Pediatric; Predictive factors; Speech
   perception}},
Keywords-Plus = {{RECOGNITION}},
Research-Areas = {{Otorhinolaryngology}},
Web-of-Science-Categories  = {{Otorhinolaryngology}},
Author-Email = {{moonij@skku.edu}},
ORCID-Numbers = {{MOON, IL JOON/0000-0002-3613-0734}},
Cited-References = {{Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220.
   Basura GJ, 2009, LARYNGOSCOPE, V119, P2395, DOI 10.1002/lary.20751.
   Blamey PJ, 2015, EAR HEARING, V36, P408, DOI 10.1097/AUD.0000000000000150.
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022).
   Firszt JB, 2008, J REHABIL RES DEV, V45, P749, DOI 10.1682/JRRD.2007.08.0120.
   Friedmann DR, 2015, LARYNGOSCOPE, V125, P1952, DOI 10.1002/lary.25293.
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318.
   Gordon KA, 2009, OTOL NEUROTOL, V30, P319, DOI 10.1097/MAO.0b013e31819a8f4c.
   Landsberger DM, 2009, HEARING RES, V254, P34, DOI 10.1016/j.heares.2009.04.007.
   Litovsky RY, 2006, INT J AUDIOL, V45, pS78, DOI 10.1080/14992020600782956.
   Moon IJ, 2012, EUR ARCH OTO-RHINO-L, V269, P739, DOI 10.1007/s00405-011-1699-3.
   Moon IJ, 2011, INT J PEDIATR OTORHI, V75, P495, DOI 10.1016/j.ijporl.2011.01.003.
   Schafer EC, 2011, INT J AUDIOL, V50, P871, DOI 10.3109/14992027.2011.622300.
   Uhler K, 2016, OTOL NEUROTOL, V37, pE70, DOI 10.1097/MAO.0000000000000911.
   Valente M, 2006, J AM ACAD AUDIOL, V17, P6, DOI 10.3766/jaaa.17.1.2.
   van Hoesel RJM, 2003, J ACOUST SOC AM, V113, P1617, DOI 10.1121/1.1539520.
   van Schoonhoven J, 2013, OTOL NEUROTOL, V34, P190, DOI 10.1097/MAO.0b013e318278506d.
   Wolfe J, 2007, OTOL NEUROTOL, V28, P589, DOI 10.1097/MAO.0b013e318067bd24.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Braz. J. Otorhinolaryngol.}},
Doc-Delivery-Number = {{JC1VI}},
Unique-ID = {{ISI:000489065400006}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000486015700018,
Author = {Mousavi, Leila and Razzazi, Farbod and Haghbin, Afrooz},
Title = {{Blind speech dereverberation using sparse decomposition and
   multi-channel linear prediction}},
Journal = {{INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY}},
Year = {{2019}},
Volume = {{22}},
Number = {{3}},
Pages = {{729-738}},
Month = {{SEP}},
Abstract = {{In this study, a blind speech dereverberation method in a noiseless
   single input multiple output acoustic channel is proposed. The method is
   based on multichannel linear prediction (MCLP) in STFT domain assuming
   sparsity in both residual speech and channel coefficients. The proposed
   speech dereverberation algorithm assumes that both the residual speech
   signal and the linear prediction coefficients is sparse. The
   optimization was performed by convex optimization using ADMM and CVX.
   The proposed model was compared with state of the art methods with l(p)
   norm optimization criteria. Simulations were evaluated in different room
   models with various reverberation times, numbers of microphones and
   parameter adjustments. The results show that the performance of the
   proposed method is superior in terms of speech dereverberation
   assessment criteria.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Razzazi, F (Corresponding Author), Islamic Azad Univ, Dept Elect \& Comp Engn, Sci \& Res Branch, Tehran, Iran.
   Mousavi, Leila; Razzazi, Farbod; Haghbin, Afrooz, Islamic Azad Univ, Dept Elect \& Comp Engn, Sci \& Res Branch, Tehran, Iran.}},
DOI = {{10.1007/s10772-019-09620-x}},
ISSN = {{1381-2416}},
EISSN = {{1572-8110}},
Keywords = {{Multichannel sparse linear prediction (MSLP); Residual sparse signal;
   Speech dereverberation; Speech enhancement; Convex optimization; Mixed
   Gaussian distribution}},
Keywords-Plus = {{ALGORITHMS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{lemoosavi@gmail.com
   razzazi@srbiau.ac.ir
   ahaghbin@gmail.com}},
ResearcherID-Numbers = {{Haghbin, Afrooz/AAO-3414-2020}},
ORCID-Numbers = {{Haghbin, Afrooz/0000-0003-1551-0348}},
Cited-References = {{Babacan SD, 2012, LECT NOTES COMPUT SC, V7577, P341, DOI 10.1007/978-3-642-33783-3\_25.
   Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x.
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498.
   Giacobello Daniele, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2524.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086.
   Jensen T.L., 2016, P EUR SIGN PROC C EU, P1.
   Jensen TL, 2016, SPEECH COMMUN, V76, P143, DOI 10.1016/j.specom.2015.09.013.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Jukic A, 2014, 2014 4TH JOINT WORKSHOP ON HANDS-FREE SPEECH COMMUNICATION AND MICROPHONE ARRAYS (HSCMA), P23, DOI 10.1109/HSCMA.2014.6843244.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Moshirynia M., 2014, REVERB WORKSH, P1.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Novey M, 2010, IEEE T SIGNAL PROCES, V58, P1427, DOI 10.1109/TSP.2009.2036049.
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003.
   Schmid D, 2014, IEEE-ACM T AUDIO SPE, V22, P1320, DOI 10.1109/TASLP.2014.2329732.
   Schwartz B., 2013, P EUR SIGN PROC C EU, P1.
   Wipf David, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P40, DOI 10.1007/978-3-642-40395-8\_4.
   Wipf D, 2010, IEEE J-STSP, V4, P317, DOI 10.1109/JSTSP.2010.2042413.
   Yoshioka T, 2010, THESIS.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Int. J. Speech Technol.}},
Doc-Delivery-Number = {{IX9NI}},
Unique-ID = {{ISI:000486015700018}},
DA = {{2020-12-06}},
}

@article{ ISI:000478671500002,
Author = {Pandarova, Irina and Schmidt, Torben and Hartig, Johannes and Boubekki,
   Ahcene and Jones, Roger Dale and Brefeld, Ulf},
Title = {{Predicting the Difficulty of Exercise Items for Dynamic Difficulty
   Adaptation in Adaptive Language Tutoring}},
Journal = {{INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION}},
Year = {{2019}},
Volume = {{29}},
Number = {{3}},
Pages = {{342-367}},
Month = {{AUG}},
Abstract = {{Advances in computer technology and artificial intelligence create
   opportunities for developing adaptive language learning technologies
   which are sensitive to individual learner characteristics. This paper
   focuses on one form of adaptivity in which the difficulty of learning
   content is dynamically adjusted to the learner's evolving language
   ability. A pilot study is presented which aims to advance the
   (semi-)automatic difficulty scoring of grammar exercise items to be used
   in dynamic difficulty adaptation in an intelligent language tutoring
   system for practicing English tenses. In it, methods from item response
   theory and machine learning are combined with linguistic item analysis
   in order to calibrate the difficulty of an initial exercise pool of cued
   gap-filling items (CGFIs) and isolate CGFI features predictive of item
   difficulty. Multiple item features at the gap, context and CGFI levels
   are tested and relevant predictors are identified at all three levels.
   Our pilot regression models reach encouraging prediction accuracy levels
   which could, pending additional validation, enable the dynamic selection
   of newly generated items ranging from moderately easy to moderately
   difficult. The paper highlights further applications of the proposed
   methodology in the area of adapting language tutoring, item design and
   second language acquisition, and sketches out issues for future
   research.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Pandarova, I (Corresponding Author), Leuphana Univ Luneburg, Univ Allee 1, D-21335 Luneburg, Germany.
   Pandarova, Irina; Schmidt, Torben; Boubekki, Ahcene; Jones, Roger Dale; Brefeld, Ulf, Leuphana Univ Luneburg, Univ Allee 1, D-21335 Luneburg, Germany.
   Hartig, Johannes, Leibniz Inst Res \& Informat Educ DIPF, Rostocker Str 6, D-60323 Frankfurt, Germany.
   Jones, Roger Dale, Tech Univ Carolo Wilhelmina Braunschweig, Univ Pl 2, D-38106 Braunschweig, Germany.}},
DOI = {{10.1007/s40593-019-00180-4}},
ISSN = {{1560-4292}},
EISSN = {{1560-4306}},
Keywords = {{Adaptivity; Intelligent language tutoring systems; Item difficulty
   prediction; Item response theory; Machine learning; Second language
   acquisition}},
Keywords-Plus = {{ITEM DIFFICULTY; LEARNING-SYSTEM; MENTAL EFFORT; ENGLISH; ACQUISITION;
   PERFORMANCE; INSTRUCTION; MOTIVATION; SELECTION; RATINGS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications}},
Author-Email = {{pandarova@leuphana.de
   torben.schmidt@leuphana.de
   hartig@dipf.de
   ahcene.boubeldci@leuphana.de
   r.jones@tu-braunschweig.de
   brefeld@leuphana.de}},
ORCID-Numbers = {{Pandarova, Irina/0000-0003-1209-8511}},
Funding-Acknowledgement = {{Fund for Scientific Research (Kleinforschungsprojekt) at Leuphana
   University Luneburg {[}73100024]}},
Funding-Text = {{We wish to acknowledge the financial support offered for this project by
   the Fund for Scientific Research (Kleinforschungsprojekt) at Leuphana
   University Luneburg (73100024). Thanks to JanaLuise Bimkiewicz, Svenja
   Buck, Kim Greife and Mareike Vahlenkamp for their support during data
   collection. Thanks also to Beatrice Brodesser for her support in the
   formatting of this article. Last but not least, we are grateful to the
   three anonymous reviewers for their competent and constructive comments
   and suggestions. All remaining errors are our own.}},
Cited-References = {{Amaral LA, 2011, RECALL, V23, P4, DOI 10.1017/S0958344010000261.
   Attali Yigal, 2018, Artificial Intelligence in Education. 19th International Conference, AIED 2018. Proceedings: LNAI 10947, P17, DOI 10.1007/978-3-319-93843-1\_2.
   AXELSSON MW, 2001, ICAME J, V25, P5.
   Bailey N. H, 1987, THESIS.
   Bardovi-Harlig K, 2000, TENSE ASPECT LANGUAG.
   Beinborn L., 2014, T ASS COMPUTATIONAL, V2, P517, DOI DOI 10.1162/tacl\_a\_00200.
   Beinborn Lisa Marina, 2016, THESIS.
   BEJAR II, 2003, J TECHNOLOGY LEARNIN, V2.
   Bengs D, 2018, J COMPUTERIZED ADAPT, V6, P15.
   Brusilovsky P., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P3, DOI 10.1007/978-3-540-72079-9\_1.
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5.
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977.
   Camp G, 2001, COMPUT HUM BEHAV, V17, P575, DOI 10.1016/S0747-5632(01)00028-0.
   Chen CM, 2008, EDUC TECHNOL SOC, V11, P153.
   Chen CM, 2008, COMPUT EDUC, V51, P624, DOI 10.1016/j.compedu.2007.06.011.
   Collins L, 2009, MOD LANG J, V93, P336, DOI 10.1111/j.1540-4781.2009.00894.x.
   Csikszentmihalyi M., 1991, FLOW PSYCHOL OPTIMAL.
   Davydova J., 2011, TOP ENGL LINGUIST, V77.
   Deci E. L., 1985, INTRINSIC MOTIVATION.
   Declerck R, 2006, TOP ENGL LINGUIST, V60, P1, DOI 10.1515/9783110199888.
   DeKeyser RM, 2005, LANG LEARN, V55, P1, DOI 10.1111/j.0023-8333.2005.00294.x.
   ECKMAN FR, 1977, LANG LEARN, V27, P315, DOI 10.1111/j.1467-1770.1977.tb00124.x.
   Eggen JHM, 2012, PSYCHOMETRICS PRACTI, P11.
   Ellis R, 2012, LANGUAGE TEACHING RE.
   Embretson S E, 2000, ITEM RESPONSE THEORY.
   Embretson SE, 1998, PSYCHOL METHODS, V3, P380, DOI 10.1037/1082-989X.3.3.380.
   Embretson SE, 1999, PSYCHOMETRIKA, V64, P407, DOI 10.1007/BF02294564.
   Embretson SE, 2005, COGNITION INTELLIGEN, P251.
   FREEDLE R, 1993, LANG TEST, V10, P133, DOI DOI 10.1177/026553229301000203.
   Fritts BE, 2010, SOC PSYCHOL EDUC, V13, P441, DOI 10.1007/s11218-010-9113-3.
   Gierl M. J., 2012, AUTOMATIC ITEM GENER.
   Gorin JS, 2006, APPL PSYCH MEAS, V30, P394, DOI 10.1177/0146621606288554.
   Gotz S, 2015, LEARNER CORPORA LANG, P191.
   Haegeman L, 2006, LINGUA, V116, P1651, DOI 10.1016/j.lingua.2005.03.014.
   Halstijn J., 1994, AILA REV, V11, P97.
   Hartig J, 2012, EDUC PSYCHOL MEAS, V72, P665, DOI 10.1177/0013164411430707.
   Heift T, 2016, INT J ARTIF INTELL E, V26, P489, DOI 10.1007/s40593-015-0061-0.
   Heilman M., 2010, PERS ARTIF INTEL ED, V20, P73, DOI DOI 10.3233/JAI-2010-0003.
   Hoffmann Sebastian, 2008, CORPUS LINGUISTICS B.
   Impara JC, 1998, J EDUC MEAS, V35, P69, DOI 10.1111/j.1745-3984.1998.tb00528.x.
   Izura C, 2011, J MEM LANG, V64, P32, DOI 10.1016/j.jml.2010.09.002.
   Kalyuga S, 2005, ETR\&D-EDUC TECH RES, V53, P83, DOI 10.1007/BF02504800.
   Kammerer S, 2012, INPUT PROCESS PRODUC, P284.
   Kerr P, 2016, ELT J, V70, P88, DOI 10.1093/elt/ccv055.
   Krashen S., 1985, INPUT HYPOTHESIS ISS.
   Kuperman V, 2012, BEHAV RES METHODS, V44, P978, DOI 10.3758/s13428-012-0210-4.
   Kyle K., 2016, THESIS.
   Kyle K, 2015, TESOL QUART, V49, P757, DOI 10.1002/tesq.194.
   Linacre J.M., 1994, RASCH MEASUREMENT T, V7, P328.
   Ling GM, 2017, APPL PSYCH MEAS, V41, P495, DOI 10.1177/0146621617707556.
   Lu XF, 2010, INT J CORPUS LINGUIS, V15, P474, DOI 10.1075/ijcl.15.4.02lu.
   Martin AJ, 2018, J EDUC PSYCHOL, V110, P27, DOI 10.1037/edu0000205.
   McDonald SA, 2001, LANG SPEECH, V44, P295, DOI 10.1177/00238309010440030101.
   Mitrovic A, 2004, LECT NOTES COMPUT SC, V3137, P185.
   Moeyaert M, 2016, SYSTEMS, V4, DOI 10.3390/systems4010014.
   Niedersachsisches Kultusministerium (Hrsg, 2015, KERN GYMN SCHULJ 5 1.
   Niedersachsisches Kultusministerium (Hrsg. ), 2015, KERNC INT GES SCHULJ.
   Norris JM, 2000, LANG LEARN, V50, P417, DOI 10.1111/0023-8333.00136.
   Orvis KA, 2008, COMPUT HUM BEHAV, V24, P2415, DOI 10.1016/j.chb.2008.02.016.
   Purpura J., 2004, ASSESSING GRAMMAR.
   Reckase M. D., 2010, PSYCHOL TEST ASSESSM, V52, P127.
   Rice K, 2007, CAMBRIDGE HANDBOOK OF PHONOLOGY, P79.
   Rogatcheva SI, 2012, INPUT PROCESS PRODUC, P258.
   Salden RJCM, 2004, INSTR SCI, V32, P153, DOI 10.1023/B:TRUC.0000021814.03996.ff.
   Sandberg J, 2014, COMPUT EDUC, V76, P119, DOI 10.1016/j.compedu.2014.03.006.
   Schmidt R., 1995, ATTENTION AWARENESS, V9, P1.
   Scott M, 2011, WORDSMITH TOOLS VERS.
   Shute VJ, 2007, FRONT ARTIF INTEL AP, V158, P230.
   SHUTE VJ, 2012, ADAPTIVE TECHNOLOGIE, V7, P27, DOI DOI 10.1017/CB09781139049580.004.
   Slavuj V, 2016, COMPUT ASSIST LANG L, V30, P64.
   Spada N, 2010, LANG LEARN, V60, P263, DOI 10.1111/j.1467-9922.2010.00562.x.
   Sung TW, 2017, ELECTRON LIBR, V35, P358, DOI 10.1108/EL-11-2015-0221.
   Svetashova Y, 2015, THESIS.
   Timms MJ, 2007, FRONT ARTIF INTEL AP, V158, P213.
   TSUTAKAWA RK, 1990, PSYCHOMETRIKA, V55, P371, DOI 10.1007/BF02295293.
   Vajjala S., 2012, P 7 WORKSH BUILD ED, P163.
   VanderLinden WJ, 2010, STAT SOC BEHAV SC, P1.
   Vygotsky L, 1978, MIND SOC DEV HIGHER.
   Wauters K, 2010, J COMPUT ASSIST LEAR, V26, P549, DOI 10.1111/j.1365-2729.2010.00368.x.
   Wauters K, 2012, COMPUT EDUC, V58, P1183, DOI 10.1016/j.compedu.2011.11.020.
   Weekes BS, 2006, READ WRIT, V19, P133, DOI 10.1007/s11145-005-2032-6.
   White L, 1989, UNIVERSAL GRAMMAR 2.
   WHITELY SE, 1983, PSYCHOL BULL, V93, P179, DOI 10.1037/0033-2909.93.1.179.
   Wilson M., 2004, CONSTRUCTING MEASURE.
   Wu TT, 2011, EDUC TECHNOL SOC, V14, P164.
   Yuksel BF, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5372, DOI 10.1145/2858036.2858388.
   Zapata-Rivera D, 2007, FRONT ARTIF INTEL AP, V158, P323.}},
Number-of-Cited-References = {{87}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Int. J. Artif. Intell. Educ.}},
Doc-Delivery-Number = {{IN4UH}},
Unique-ID = {{ISI:000478671500002}},
DA = {{2020-12-06}},
}

@article{ ISI:000467568600004,
Author = {Cauchi, Benjamin and Siedenburg, Kai and Santos, Joao E. and Falk, Tiago
   H. and Doclo, Simon and Goetze, Stefan},
Title = {{Non-Intrusive Speech Quality Prediction Using Modulation Energies and
   LSTM-Network}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2019}},
Volume = {{27}},
Number = {{7}},
Pages = {{1151-1163}},
Month = {{JUL}},
Abstract = {{Many signal processing algorithms have been proposed to improve the
   quality of speech recorded in the presence of noise and reverberation.
   Perceptual measures, i.e., listening tests, are usually considered the
   most reliable way to evaluate the quality of speech processed by such
   algorithms but are costly and time-consuming. Consequently, speech
   enhancement algorithms are often evaluated using signal-based measures,
   which can be either intrusive or non-intrusive. As the computation of
   intrusive measures requires a reference signal, only non-intrusive
   measures can be used in applications for which the clean speech signal
   is not available. However, many existing non-intrusive measures
   correlate poorly with the perceived speech quality, particularly when
   applied over a wide range of algorithms or acoustic conditions. In this
   paper, we propose a novel non-intrusive measure of the quality of
   processed speech that combines modulation energy features and a
   recurrent neural network using long short-term memory cells. We
   collected a dataset of perceptually evaluated signals representing
   several acoustic conditions and algorithms and used this dataset to
   train and evaluate the proposed measure. Results show that the proposed
   measure yields higher correlation with perceptual speech quality than
   that of benchmark intrusive and non-intrusive measures when considering
   various categories of algorithms. Although the proposed measure is
   sensitive to mismatch between training and testing, results show that it
   is a useful approach to evaluate specific algorithms over a wide range
   of acoustic conditions and may, thus, become particularly useful for
   real-time selection of speech enhancement algorithm settings.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cauchi, B (Corresponding Author), OFFIS Inst Informat Technol, D-26121 Oldenburg, Germany.
   Cauchi, Benjamin; Goetze, Stefan, Fraunhofer Inst Digital Media Technol, D-98693 Ilmenau, Germany.
   Cauchi, Benjamin, OFFIS Inst Informat Technol, D-26121 Oldenburg, Germany.
   Siedenburg, Kai; Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust \& Cluster Excellence Heari, D-26129 Oldenburg, Germany.
   Santos, Joao E.; Falk, Tiago H., Univ Quebec, INRS, EMT, Montreal, PQ H5A 1K6, Canada.
   Goetze, Stefan, Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, D-26129 Oldenburg, Germany.}},
DOI = {{10.1109/TASLP.2019.2912123}},
ISSN = {{2329-9290}},
Keywords = {{Speech quality; non-intrusive prediction; modulation energy;
   LSTM-network}},
Keywords-Plus = {{INTELLIGIBILITY PREDICTION; ENHANCEMENT; ROBUST; MODEL}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{benjamin.cauchi@offis.de
   kai.siedenburg@uni-oldenburg.de
   jfsantos@emt.inrs.ca
   falk@emt.inrs.ca
   simon.doclo@uni-oldenburg.de
   s.goetze@idmt.fraunhofer.de}},
ORCID-Numbers = {{Cauchi, Benjamin/0000-0003-0338-492X
   Siedenburg, Kai/0000-0002-7360-4249
   Doclo, Simon/0000-0002-3392-2381
   Goetze, Stefan/0000-0003-1044-7343
   Santos, Joao Felipe/0000-0003-3934-3943}},
Funding-Acknowledgement = {{project Audio-PSS - Bundesministerium fur Bildung und Forschung (BMBF)
   {[}02K16C201, 13GW0209B]; EU Seventh Framework Programme project DREAMS
   {[}ITN-GA-2012-316969]; Deutsche Forschungsgemeinschaft (DFG,
   German-Research Foundation)German Research Foundation (DFG)
   {[}390895286-EXC 2177/1]; project THERESIAH - Bundesministerium fur
   Bildung und Forschung (BMBF) {[}02K16C201, 13GW0209B]}},
Funding-Text = {{This work was supported in part by the projects Audio-PSS
   (www.audiopss.de) and THERESIAH, funded by the Bundesministerium fur
   Bildung und Forschung (BMBF) under Grants 02K16C201 and 13GW0209B, in
   part by the EU Seventh Framework Programme project DREAMS under Grant
   ITN-GA-2012-316969, and in part by the Deutsche Forschungsgemeinschaft
   (DFG, German-Research Foundation)-Project ID 390895286-EXC 2177/1.}},
Cited-References = {{Andersen AH, 2017, INT CONF ACOUST SPEE, P5085, DOI 10.1109/ICASSP.2017.7953125.
   {[}Anonymous], 2001, PERC OBJ LIST QUAL A.
   {[}Anonymous], 1997, S351997R2007 ANSI.
   {[}Anonymous], 2011, P863 ITUT.
   {[}Anonymous], 2009, 12REV1WP212 ITUT.
   {[}Anonymous], 2003, P835 ITUT.
   {[}Anonymous], 2003, BS15343 ITUT.
   Benesty J, 2008, SPRINGER TOP SIGN PR, V1, P1.
   Bitzer J, 2001, SPEECH COMMUN, V34, P3, DOI 10.1016/S0167-6393(00)00042-X.
   Breithaupt C, 2008, INT CONF ACOUST SPEE, P4037, DOI 10.1109/ICASSP.2008.4518540.
   Breithaupt C, 2008, INT CONF ACOUST SPEE, P4897, DOI 10.1109/ICASSP.2008.4518755.
   Cauchi B., 2016, P ITG C SPEECH COMM, P180.
   Cauchi B, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0242-x.
   Chollet Francois, 2015, KERAS.
   COX H, 1987, IEEE T ACOUST SPEECH, V35, P1365, DOI 10.1109/TASSP.1987.1165054.
   Doclo S, 2015, IEEE SIGNAL PROC MAG, V32, P18, DOI 10.1109/MSP.2014.2366780.
   Doire CSJ, 2017, J ACOUST SOC AM, V141, P2501, DOI 10.1121/1.4979580.
   Doire CSJ, 2017, IEEE-ACM T AUDIO SPE, V25, P572, DOI 10.1109/TASLP.2016.2641904.
   Eaton J., 2015, P IEEE WORKSH APPL S, P1.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Flipsen P, 2006, CLIN LINGUIST PHONET, V20, P303, DOI 10.1080/02699200400024863.
   Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   General Performance Objectives Applicable to All Modern International Circuits and National Extension Circuits, 1980, GEN PERF OBJ APPL AL.
   Gerkmann T, 2012, IEEE T AUDIO SPEECH, V20, P1383, DOI 10.1109/TASL.2011.2180896.
   Goetze S, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P233, DOI 10.1109/IWAENC.2014.6954293.
   Gradshteyn IS, 1994, TABLE INTEGRALS SERI.
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947.
   Huber R, 2006, IEEE T AUDIO SPEECH, V14, P1902, DOI 10.1109/TASL.2006.883259.
   Jukic A, 2017, IEEE SIGNAL PROC LET, V24, P101, DOI 10.1109/LSP.2016.2640939.
   Karbasi M, 2016, INTERSPEECH, P625, DOI 10.21437/Interspeech.2016-155.
   Kim DS, 2007, BELL LABS TECH J, V12, P221, DOI 10.1002/bltj.20228.
   Kingma DP, 2014, ADAM METHOD STOCHAST.
   Kinoshita K., 2015, SUMMARY REVERB CHALL.
   Kinoshita K., 2015, EURASIP J ADV SIG PR, V2016, P1.
   Lebart K, 2001, ACUSTICA, V87, P359.
   Malfait L, 2006, IEEE T AUDIO SPEECH, V14, P1924, DOI 10.1109/TASL.2006.883177.
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Objective Measurement of Active Speech Level, 1993, OBJ MEAS ACT SPEECH.
   Pascanu R, 2013, INT C MACH LEARN, P1310, DOI DOI 10.1109/72.279181.
   ROBINSON T, 1995, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1995.479278.
   Santore JC, 2016, PRINCIPLES AND PRACTICE OF TONAL COUNTERPOINT, P1.
   Santos JF, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P55, DOI 10.1109/IWAENC.2014.6953337.
   Santos JF, 2014, IEEE-ACM T AUDIO SPE, V22, P2197, DOI 10.1109/TASLP.2014.2363788.
   Sharma D, 2016, SPEECH COMMUN, V80, P84, DOI 10.1016/j.specom.2016.03.005.
   Spille C, 2018, COMPUT SPEECH LANG, V48, P51, DOI 10.1016/j.csl.2017.10.004.
   Sprinthall R. C., 2013, BASIC STAT ANAL.
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Taghia J, 2014, IEEE-ACM T AUDIO SPE, V22, P6, DOI 10.1109/TASL.2013.2281574.
   Vincent E., 2018, AUD SOURC SEP SPEECH.
   2010, IEEE T INSTRUM MEAS, V59, P978, DOI DOI 10.1109/TIM.2009.2024697.
   1984, IEEE T ACOUST SPEECH, V32, P1109.}},
Number-of-Cited-References = {{56}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{HX7EY}},
Unique-ID = {{ISI:000467568600004}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000475470500005,
Author = {Zhang, Yumei and Guo, Xiangying and Wu, Xia and Shi, Suzhen and Wu,
   Xiaojun},
Title = {{RPSOVF Prediction Model for Speech Signal Series Based on UPSO}},
Journal = {{INTERNATIONAL JOURNAL OF BIFURCATION AND CHAOS}},
Year = {{2019}},
Volume = {{29}},
Number = {{6}},
Month = {{JUN}},
Abstract = {{In this paper, we propose a nonlinear prediction model of speech signal
   series with an explicit structure. In order to overcome some intrinsic
   shortcomings, such as traps at the local minimum, improper selection of
   parameters, and slow convergence rate, which are always caused by
   improper parameters generated by, typically, the low performance of
   least mean square (LMS) in updating kernel coefficients of the Volterra
   model, a uniform searching particle swarm optimization (UPSO) algorithm
   to optimize the kernel coefficients of the Volterra model is proposed.
   The second-order Volterra filter (SOVF) speech prediction model based on
   UPSO is established by using English phonemes, words, and phrases. In
   order to reduce the complexity of the model, given a user-designed
   tolerance of errors, we extract the reduced parameter of SOVF (RPSOVF)
   for acceleration. The experimental results show that in the tasks of
   single-frame and multiframe speech signals, both UPSO-SOVF and
   UPSO-RPSOVF are better than LMS-SOVF and PSO-SOVF in terms of root mean
   square error (RMSE) and mean absolute deviation (MAD). UPSO-SOVF and
   UPSO-RPSOVF can better reflect trends and regularity of speech signals,
   which can fully meet the requirements of speech signal prediction. The
   proposed model presents a nonlinear analysis and valuable model
   structure for speech signal series, and can be further employed in
   speech signal reconstruction or compression coding.}},
Publisher = {{WORLD SCIENTIFIC PUBL CO PTE LTD}},
Address = {{5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.
   Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.
   Zhang, Yumei; Wu, Xiaojun, Shaanxi Normal Univ, Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.
   Zhang, Yumei; Wu, Xia; Shi, Suzhen; Wu, Xiaojun, Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.
   Guo, Xiangying, Beijing Univ Technol, Dept Mech Engn, Beijing 100124, Peoples R China.}},
DOI = {{10.1142/S0218127419500755}},
Article-Number = {{1950075}},
ISSN = {{0218-1274}},
EISSN = {{1793-6551}},
Keywords = {{Speech signal; chaos; Volterra prediction model; UPSO algorithm}},
Keywords-Plus = {{PRACTICAL METHOD; PARAMETERS}},
Research-Areas = {{Mathematics; Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences}},
Author-Email = {{wythe@snnu.edu.cn}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2017YFB1402102]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}11872036, 11772178,
   61701291]; Shaanxi Science and Technology Plan Project
   {[}2019ZDLSF07-01, 2019GY-217]}},
Funding-Text = {{This work was partially supported by the National Key Research and
   Development Program of China (Grant No. 2017YFB1402102), the National
   Natural Science Foundation of China (Grant Nos. 11872036, 11772178 and
   61701291) and Shaanxi Science and Technology Plan Project (Grant Nos.
   2019ZDLSF07-01 and 2019GY-217). The authors thank the referees for their
   valuable suggestions and comments.}},
Cited-References = {{Abarbanel HDI, 2001, PHYS LETT A, V281, P368, DOI 10.1016/S0375-9601(01)00128-1.
   Bazaraa M. S., 2013, NONLINEAR PROGRAMMIN.
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8.
   Chang WD, 2012, DIGIT SIGNAL PROCESS, V22, P1056, DOI 10.1016/j.dsp.2012.07.005.
   Chao Weng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5532, DOI 10.1109/ICASSP.2014.6854661.
   Chouikhi N, 2017, APPL SOFT COMPUT, V55, P211, DOI 10.1016/j.asoc.2017.01.049.
   Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344.
   Guerin A, 2003, IEEE T SPEECH AUDI P, V11, P672, DOI 10.1109/TSA.2003.818077.
   Kocal OH, 2008, IEEE T INF FOREN SEC, V3, P651, DOI 10.1109/TIFS.2008.2004289.
   Kokkinos I, 2005, IEEE T SPEECH AUDI P, V13, P1098, DOI 10.1109/TSA.2005.852982.
   Matthew K.L., 2012, INT J ADV RES ARTIF, V1, P39.
   Ogorzalek M, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL IV, PROCEEDINGS, P564.
   Rivas JG, 2013, WOODH PUB SER ELECT, P62, DOI 10.1533/9780857096494.1.62.
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P.
   Sigrist Z, 2012, SIGNAL PROCESS, V92, P1010, DOI 10.1016/j.sigpro.2011.10.013.
   Stavrakoudis DG, 2007, IEEE T SYST MAN CY B, V37, P1305, DOI 10.1109/TSMCB.2007.900516.
   Sun JF, 2007, SIGNAL PROCESS, V87, P2431, DOI 10.1016/j.sigpro.2007.03.020.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.
   Wei Rui-xuan, 2005, Acta Electronica Sinica, V33, P656.
   Wu Xiao-jun, 2011, Acta Electronica Sinica, V39, P1261.
   Yuhui Shi, 1998, Evolutionary Programming VII. 7th International Conference, EP98. Proceedings, P591, DOI 10.1007/BFb0040810.
   Zhang JS, 2005, CHINESE PHYS, V14, P49, DOI 10.1088/1009-1963/14/1/011.
   Zhang YM, 2015, ACTA PHYS SIN-CH ED, V64, DOI 10.7498/aps.64.200507.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Int. J. Bifurcation Chaos}},
Doc-Delivery-Number = {{II8VJ}},
Unique-ID = {{ISI:000475470500005}},
DA = {{2020-12-06}},
}

@article{ ISI:000472684400001,
Author = {Parchami, Mandi and Amindavar, Hamidreza and Zhu, Wei-Ping},
Title = {{Speech reverberation suppression for time-varying environments using
   weighted prediction error method with time-varying autoregressive model}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2019}},
Volume = {{109}},
Pages = {{1-14}},
Month = {{MAY}},
Abstract = {{In this paper, a novel approach for the task of speech reverberation
   suppression in non-stationary (changing) acoustic environments is
   proposed. The suggested approach is based on the popular weighted
   prediction error (WPE) method, yet, instead of considering fixed
   reverberation prediction weights, our method takes into account the more
   generic time-varying autoregressive (TV-AR) model which allows dynamic
   estimation and updating for the prediction weights over time. We use an
   initial estimate of the prediction weights in order to optimally select
   the TV-AR model order and also to calculate the TV-AR coefficients.
   Next, by properly interpolating the calculated coefficients, we obtain
   the ultimate estimate of reverberation prediction weights. Performance
   evaluation of the proposed approach is shown not only for fixed acoustic
   rooms but also for environments where the source and/or sensors are
   moving. Our experiments reveal further reverberation suppression as well
   as higher quality in the enhanced speech samples in comparison with
   recent literature within the context of speech dereverberation.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Parchami, M (Corresponding Author), Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   Parchami, Mandi; Amindavar, Hamidreza, Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   Zhu, Wei-Ping, Concordia Univ, Dept Elect \& Comp Engn, Montreal, PQ, Canada.}},
DOI = {{10.1016/j.specom.2019.03.002}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Dereverberation; Speech enhancement; Time-varying autoregressive model;
   Weighted prediction error}},
Keywords-Plus = {{DEREVERBERATION; ENHANCEMENT; NOISE}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{mparchami@aut.ac.ir
   hamidami@aut.ac.ir
   weiping@ece.concordia.ca}},
Cited-References = {{Abramovich YI, 2007, IEEE T SIGNAL PROCES, V55, P2861, DOI 10.1109/TSP.2007.893966.
   {[}Anonymous], 2001, REC P 862 REC P 862.
   {[}Anonymous], 1993, REC P 56 REC P 56 OB.
   Attias H, 2001, ADV NEUR IN, V13, P758.
   Bao XL, 2013, SPEECH COMMUN, V55, P932, DOI 10.1016/j.specom.2013.04.003.
   Brookes M, 2009, VOICEBOX SPEECH PROC.
   CLAUSEN M, 1991, THEOR COMPUT SCI, V84, P151, DOI 10.1016/0304-3975(91)90157-W.
   Eldar Y. C., 2012, COMPRESSED SENSING T.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Furuya K, 2007, IEEE T AUDIO SPEECH, V15, P1579, DOI 10.1109/TASL.2007.898456.
   Gannot S, 2001, IEEE T SIGNAL PROCES, V49, P1614, DOI 10.1109/78.934132.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Habets E. E., 2007, SINGLE MULTIMICROPHO.
   HALL MG, 1983, SIGNAL PROCESS, V5, P267, DOI 10.1016/0165-1684(83)90074-9.
   Hsiao T, 2008, IEEE T SIGNAL PROCES, V56, P3497, DOI 10.1109/TSP.2008.919393.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Huang YTA, 2005, IEEE T SPEECH AUDI P, V13, P882, DOI 10.1109/TSA.2005.851941.
   HUFFEL SV, 1991, FRONTIERS APPL MATH.
   I. CVX Research, 2012, CVX MATL SOFTW DISC.
   Jukic Ante, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5172, DOI 10.1109/ICASSP.2014.6854589.
   Jukic A, 2017, IEEE SIGNAL PROC LET, V24, P101, DOI 10.1109/LSP.2016.2640939.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Kinoshita T, 2013, 2013 9TH INTERNATIONAL WORKSHOP ON ELECTROMAGNETIC COMPATIBILITY OF INTEGRATED CIRCUITS (EMC COMPO 2013), P1, DOI 10.1109/EMCCompo.2013.6735162.
   Kodrasi I, 2016, IEEE-ACM T AUDIO SPE, V24, P680, DOI 10.1109/TASLP.2016.2518804.
   Lehmann E. A., IMAGE SOURCE METHOD.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Parchami M, 2017, SPEECH COMMUN, V92, P100, DOI 10.1016/j.specom.2017.06.005.
   Parchami M, 2017, SPEECH COMMUN, V87, P49, DOI 10.1016/j.specom.2017.01.004.
   Peng J, 2014, J COMPUT PHYS, V267, P92, DOI 10.1016/j.jcp.2014.02.024.
   Rabiner L. R., 2010, THEORY APPL DIGITAL.
   Rauhut H, 2012, J APPROX THEORY, V164, P517, DOI 10.1016/j.jat.2012.01.008.
   Rudoy D, 2011, IEEE T AUDIO SPEECH, V19, P977, DOI 10.1109/TASL.2010.2073704.
   Sahinler S., 2007, J APPL QUANTITATIVE, V2, P188.
   Schwarz B., REVDYN SPEECH DATABA.
   Sodsri C., 2003, THESIS.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.
   Vermaak J, 2002, IEEE T SPEECH AUDI P, V10, P173, DOI 10.1109/TSA.2002.1001982.
   Warsitz E, 2007, IEEE T AUDIO SPEECH, V15, P1529, DOI 10.1109/TASL.2007.898454.
   Wiesel A, 2013, IEEE T SIGNAL PROCES, V61, P2791, DOI 10.1109/TSP.2013.2256900.
   Yang JM, 2014, IEEE-ACM T AUDIO SPE, V22, P608, DOI 10.1109/TASLP.2013.2294578.
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029.
   Yoshioka T, 2009, IEEE T AUDIO SPEECH, V17, P231, DOI 10.1109/TASL.2008.2008042.}},
Number-of-Cited-References = {{46}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{13}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{IE9HB}},
Unique-ID = {{ISI:000472684400001}},
DA = {{2020-12-06}},
}

@article{ ISI:000466381800031,
Author = {Liu, Xiaokang and Tian, Hui and Huang, Yongfeng and Lu, Jing},
Title = {{A novel steganographic method for
   algebraic-code-excited-linear-prediction speech streams based on
   fractional pitch delay search}},
Journal = {{MULTIMEDIA TOOLS AND APPLICATIONS}},
Year = {{2019}},
Volume = {{78}},
Number = {{7}},
Pages = {{8447-8461}},
Month = {{APR}},
Abstract = {{Although a large number of steganography algorithms based on
   algebraic-code-excited-linear-prediction have been proposed, their
   performance, such as embedding capacity, embedding transparency and
   capability for resisting detection, can be further enhanced. Therefore,
   we are motivated to present a new steganographic scheme based on pitch
   delay search, which can achieve better performance by embedding secret
   information into the fractional pitch delay parameters while keeping the
   integer pitch delay parameters unchanged. Specifically, we treat all
   fractional pitch delays as replaceable cover bits to achieve maximum
   embedding capacity. Further, the steganographic process is encrypted and
   guided by m sequences for flexibility and security. The proposed method
   is evaluated with a large number of adaptive multi-rate speech samples
   and compared with the existing works. Experimental results show that the
   proposed method can provide larger embedding capacity than the existing
   works while achieving excellent embedding transparency. Moreover, we
   evaluate the performance of the proposed method for resisting the
   state-of-the-art steganalysis methods. The experimental results
   demonstrate that the proposed method is highly secure, since the
   state-of-the-art steganalysis methods cannot detect it efficiently.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tian, H (Corresponding Author), Natl Huaqiao Univ, Coll Comp Sci \& Technol, Xiamen 361021, Peoples R China.
   Liu, Xiaokang; Tian, Hui, Natl Huaqiao Univ, Coll Comp Sci \& Technol, Xiamen 361021, Peoples R China.
   Huang, Yongfeng, Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   Lu, Jing, Natl Huaqiao Univ, Dept Informat Syst \& Management, Xiamen 361021, Peoples R China.}},
DOI = {{10.1007/s11042-018-6867-7}},
ISSN = {{1380-7501}},
EISSN = {{1573-7721}},
Keywords = {{Speech steganography; Algebraic code-excited linear prediction; Pitch
   period prediction}},
Keywords-Plus = {{VOICE}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic}},
Author-Email = {{htian@hqu.edu.cn}},
ResearcherID-Numbers = {{Tian, Hui/AAG-4048-2019}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}U1536115, U1405254]; Natural Science
   Foundation of Fujian Province of ChinaNatural Science Foundation of
   Fujian Province {[}2018J01093]; Program for New Century Excellent
   Talents in Fujian Province UniversityProgram for New Century Excellent
   Talents in University (NCET) {[}MJK2016-23]; Program for Outstanding
   Youth Scientific and Technological Talents in Fujian Province University
   {[}MJK2015-54]; Promotion Program for Young and Middle-aged Teacher in
   Science \& Technology Research of Huaqiao University {[}ZQN-PY115];
   Program for Science \& Technology Innovation Teams and Leading Talents
   of Huaqiao University {[}2014KJTD13]; Opening Project of Shanghai Key
   Laboratory of Integrated Administration Technologies for Information
   Security {[}AGK201710]}},
Funding-Text = {{This work was supported in part by National Natural Science Foundation
   of China under Grant Nos. U1536115 and U1405254, Natural Science
   Foundation of Fujian Province of China under Grant No. 2018J01093,
   Program for New Century Excellent Talents in Fujian Province University
   under Grant No. MJK2016-23, Program for Outstanding Youth Scientific and
   Technological Talents in Fujian Province University under Grant No.
   MJK2015-54, Promotion Program for Young and Middle-aged Teacher in
   Science \& Technology Research of Huaqiao University under Grant No.
   ZQN-PY115, Program for Science \& Technology Innovation Teams and
   Leading Talents of Huaqiao University under Grant No.2014KJTD13, Opening
   Project of Shanghai Key Laboratory of Integrated Administration
   Technologies for Information Security under Grant No. AGK201710.}},
Cited-References = {{Ali A. H., 2018, MULTIMED TOOLS APPL, V6, P1.
   Aoki N, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P534, DOI 10.1109/IIHMSP.2010.136.
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4.
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4.
   Chang PC, 2002, CONF REC ASILOMAR C, P1199.
   Dittmann J, 2005, STEGANOGRAPHY STEGAN, P607.
   Erchi Xu, 2011, Proceedings of the 2011 14th International Conference on Network-Based Information Systems (NBiS 2011), P612, DOI 10.1109/NBiS.2011.103.
   Huang YF, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1512, DOI 10.1109/IIH-MSP.2008.174.
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599.
   Kumar P. B., 2018, MAT SCI TECHNOL, P1.
   LIN C, 2006, MAN, V3, P2380, DOI DOI 10.1109/ICSMC.2006.385219.
   Liu LH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P406, DOI 10.1109/IIH-MSP.2008.297.
   Liu P, 2017, MULTIMED TOOLS APPL, V76, P2837, DOI 10.1007/s11042-016-3257-x.
   Miao R, 2011, P 46 IEEE INT C COMM, P1, DOI DOI 10.1109/ICC.2011.5962657.
   Mrak M, 2008, ENCY MULTIMEDIA, P771.
   Qin J, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P462, DOI 10.1109/3PGCIC.2015.65.
   RAMACHANDRAN RP, 1989, IEEE T ACOUST SPEECH, V37, P467, DOI 10.1109/29.17527.
   Ren YZ, 2018, MULTIMED TOOLS APPL, V77, P12095, DOI 10.1007/s11042-017-4860-1.
   Ren YZ, 2017, IEEE T INF FOREN SEC, V12, P1345, DOI 10.1109/TIFS.2016.2636087.
   Samphaiboon N, 2011, MULTIMED TOOLS APPL, V52, P569, DOI 10.1007/s11042-009-0432-3.
   Su YM, 2006, 2006 IMACS: Multiconference on Computational Engineering in Systems Applications, Vols 1 and 2, P11.
   Tian H, 2015, SIGNAL PROCESS, V117, P33, DOI 10.1016/j.sigpro.2015.05.001.
   Tian H, 2014, MULTIMEDIA SYST, V20, P143, DOI 10.1007/s00530-013-0302-8.
   Tian H, 2011, COMPUT COMMUN, V34, P2236, DOI 10.1016/j.comcom.2011.07.003.
   Tian H, 2009, ISCAS: 2009 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-5, P2922, DOI 10.1109/ISCAS.2009.5118414.
   Wang CY, 2007, IEEE INT SYM MULTIM, P255, DOI 10.1109/ISM.2007.33.
   Wang FH, 2007, J NETW COMPUT APPL, V30, P4, DOI 10.1016/j.jnca.2005.08.002.
   XIAO B, 2008, IEEE GLOB TEL C GLOB, P1, DOI DOI 10.1109/GLOCOM.2008.ECP.375.
   Xu T., 2009, P INT C WIR COMM SIG, P1, DOI DOI 10.1109/WCSP.2009.5371745.
   Yan S, 2015, APPL RES COMPUT.
   Yan SF, 2015, MULTIMED TOOLS APPL, V74, P11763, DOI 10.1007/s11042-014-2265-y.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Multimed. Tools Appl.}},
Doc-Delivery-Number = {{HW0OW}},
Unique-ID = {{ISI:000466381800031}},
DA = {{2020-12-06}},
}

@article{ ISI:000462210400010,
Author = {Zhou, Peng and Zhan, Likan and Ma, Huimin},
Title = {{Predictive Language Processing in Preschool Children with Autism
   Spectrum Disorder: An Eye-Tracking Study}},
Journal = {{JOURNAL OF PSYCHOLINGUISTIC RESEARCH}},
Year = {{2019}},
Volume = {{48}},
Number = {{2}},
Pages = {{431-452}},
Month = {{APR}},
Abstract = {{Sentence comprehension relies on the abilities to rapidly integrate
   different types of linguistic and non-linguistic information. The
   present study investigated whether Mandarin-speaking preschool children
   with autism spectrum disorder (ASD) are able to use verb information
   predictively to anticipate the upcoming linguistic input during
   real-time sentence comprehension. 26 five-year-olds with ASD, 25
   typically developing (TD) five-year-olds and 24 TD four-year-olds were
   tested using the visual world eye-tracking paradigm. The results showed
   that the 5-year-olds with ASD, like their TD peers, exhibited verb-based
   anticipatory eye movements during real-time sentence comprehension. No
   difference was observed between the ASD and TD groups in the time course
   of their eye gaze patterns, indicating that Mandarin-speaking preschool
   children with ASD are able to use verb information as effectively and
   rapidly as TD peers to predict the upcoming linguistic input.}},
Publisher = {{SPRINGER/PLENUM PUBLISHERS}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhou, P (Corresponding Author), Tsinghua Univ, Child Cognit Lab, Dept Foreign Languages \& Literatures, Beijing 100084, Peoples R China.
   Zhan, LK (Corresponding Author), Beijing Language \& Culture Univ, Inst Speech Pathol \& Brain Sci, Beijing 100083, Peoples R China.
   Zhou, Peng; Ma, Huimin, Tsinghua Univ, Child Cognit Lab, Dept Foreign Languages \& Literatures, Beijing 100084, Peoples R China.
   Zhan, Likan, Beijing Language \& Culture Univ, Inst Speech Pathol \& Brain Sci, Beijing 100083, Peoples R China.}},
DOI = {{10.1007/s10936-018-9612-5}},
ISSN = {{0090-6905}},
EISSN = {{1573-6555}},
Keywords = {{Predictive language processing; Anticipatory eye movements; Visual world
   paradigm; Autism spectrum disorder; Child sentence comprehension}},
Keywords-Plus = {{YOUNG-CHILDREN; SENTENCE COMPREHENSION; VISUAL-ATTENTION;
   INDIVIDUAL-DIFFERENCES; GRAMMATICAL ASPECT; SPOKEN LANGUAGE; IMPAIRMENT;
   ADOLESCENTS; INFORMATION; TODDLERS}},
Research-Areas = {{Linguistics; Psychology}},
Web-of-Science-Categories  = {{Linguistics; Psychology, Experimental}},
Author-Email = {{zhoupeng1892@mail.tsinghua.edu.cn
   zhanlikan@hotmail.com}},
ResearcherID-Numbers = {{Zhan, Likan/B-5684-2019
   Zhou, Peng/C-8845-2018}},
ORCID-Numbers = {{Zhan, Likan/0000-0002-9275-3557
   Zhou, Peng/0000-0002-0818-2545}},
Funding-Acknowledgement = {{National Social Science Foundation of China {[}16BYY076]}},
Funding-Text = {{This work was supported by the National Social Science Foundation of
   China {[}16BYY076] to Peng Zhou. The authors would like to thank the
   children, the parents and the teachers at the Enqi Autism Platform and
   at the Taolifangyuan Kindergarten, Beijing, China, for their assistance
   and support in running the study. The authors are also grateful to the
   reviewer for the thoughtful comments and suggestions.}},
Cited-References = {{Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT.
   American Psychiatric Association, 2000, DIAGN STAT MAN MENT.
   Andreu L, 2013, APPL PSYCHOLINGUIST, V34, P5, DOI 10.1017/S0142716411000592.
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005.
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001.
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002.
   Bates D., 2015, ARXIV150604967STATME.
   Bates D., 2013, IME4 LINEAR MIXED EF.
   Bavin EL, 2016, INT J LANG COMM DIS, V51, P137, DOI 10.1111/1460-6984.12191.
   Bavin EL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00171.
   Boucher J, 2012, J CHILD PSYCHOL PSYC, V53, P219, DOI 10.1111/j.1469-7610.2011.02508.x.
   Brock J, 2008, COGNITION, V108, P896, DOI 10.1016/j.cognition.2008.06.007.
   Chita-Tegmark M, 2015, J AUTISM DEV DISORD, V45, P3327, DOI 10.1007/s10803-015-2495-5.
   Choi Y, 2010, J EXP CHILD PSYCHOL, V106, P41, DOI 10.1016/j.jecp.2010.01.003.
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X.
   DiCriscio AS, 2016, J AUTISM DEV DISORD, V46, P2797, DOI 10.1007/s10803-016-2804-7.
   Diehl JJ, 2015, DEV PSYCHOPATHOL, V27, P867, DOI 10.1017/S0954579414000741.
   Eigsti IM, 2007, J AUTISM DEV DISORD, V37, P1007, DOI 10.1007/s10803-006-0239-2.
   Eigsti IM, 2011, RES AUTISM SPECT DIS, V5, P681, DOI 10.1016/j.rasd.2010.09.001.
   Falck-Ytter T, 2013, J NEURODEV DISORD, V5, DOI 10.1186/1866-1955-5-28.
   Fernald A, 2008, DEVELOPMENTAL PSYCHOLINGUISTICS: ON-LINE METHODS IN CHILDREN'S LANGUAGE PROCESSING, P97.
   Frischen A, 2007, PSYCHOL BULL, V133, P694, DOI 10.1037/0033-2909.133.4.694.
   Garraffa M, 2018, AUTISM DEV LANGUAGE, V3, DOI 10.1177/2396941518779939.
   Gliga T, 2015, CURR BIOL, V25, P1727, DOI 10.1016/j.cub.2015.05.011.
   Guillon Q, 2014, NEUROSCI BIOBEHAV R, V42, P279, DOI 10.1016/j.neubiorev.2014.03.013.
   Happe F, 2006, BRAIN COGNITION, V61, P25, DOI 10.1016/j.bandc.2006.03.004.
   Howlin P, 2003, J AUTISM DEV DISORD, V33, P3, DOI 10.1023/A:1022270118899.
   Huang YT, 2013, J MEM LANG, V69, P589, DOI 10.1016/j.jml.2013.08.002.
   Hudry K, 2010, INT J LANG COMM DIS, V45, P681, DOI 10.3109/13682820903461493.
   Jones W, 2013, NATURE, V504, P427, DOI 10.1038/nature12715.
   Kaldy Z, 2016, J AUTISM DEV DISORD, V46, P1513, DOI 10.1007/s10803-013-1957-x.
   Kaldy Z, 2011, DEVELOPMENTAL SCI, V14, P980, DOI 10.1111/j.1467-7687.2011.01053.x.
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kasari C, 2013, AUTISM RES, V6, P479, DOI 10.1002/aur.1334.
   Kjelgaard MM, 2001, LANG COGNITIVE PROC, V16, P287, DOI 10.1080/01690960042000058.
   Koning C, 2001, AUTISM, V5, P23, DOI 10.1177/1362361301005001003.
   Kover ST, 2014, AM J SPEECH-LANG PAT, V23, P385, DOI 10.1044/2014\_AJSLP-13-0073.
   Lew-Williams C, 2007, PSYCHOL SCI, V18, P193, DOI 10.1111/j.1467-9280.2007.01871.x.
   Li Y. Q., 2014, WECHSLER PRESCHOOL P.
   Lord C., 1999, AUTISM DIAGNOSTIC OB.
   Luyster RJ, 2008, J AUTISM DEV DISORD, V38, P1426, DOI 10.1007/s10803-007-0510-1.
   Naigles L. R., 2015, CAMBRIDGE HDB CHILD, P637.
   Naigles LR, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1438.
   Naigles LR, 2012, JOVE-J VIS EXP, DOI 10.3791/4331.
   Naigles LR, 2011, AUTISM RES, V4, P422, DOI 10.1002/aur.223.
   Naigles LR, 2017, INNOVATIVE INVESTIGA, P49, DOI DOI 10.1037/15964-000.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Norbury C. F., 2017, INNOVATIVE INVESTIGA, P13, DOI {[}10.1037/15964-002, DOI 10.1037/15964-002].
   Omaki A, 2010, THESIS.
   Perovic A, 2013, APPL PSYCHOLINGUIST, V34, P813, DOI 10.1017/S0142716412000033.
   R Development Core Team, 2017, R LANG ENV STAT COMP.
   Rapin I, 2003, BRAIN DEV-JPN, V25, P166, DOI 10.1016/S0387-7604(02)00191-2.
   Riches NG, 2012, INT J SPEECH-LANG PA, V14, P307, DOI 10.3109/17549507.2012.679313.
   Robins DL, 2014, PEDIATRICS, V133, P37, DOI 10.1542/peds.2013-1813.
   RUTTER M, 1992, SPECIFIC SPEECH AND LANGUAGE DISORDERS IN CHILDREN : CORRELATES, CHARACTERISTICS AND OUTCOMES, P63.
   Sasson NJ, 2008, AUTISM RES, V1, P31, DOI 10.1002/aur.4.
   Sekerina IA, 2012, FIRST LANG, V32, P63, DOI 10.1177/0142723711403981.
   Skwerer DP, 2016, AUTISM, V20, P591, DOI 10.1177/1362361315600146.
   Smith V, 2007, J SPEECH LANG HEAR R, V50, P149, DOI 10.1044/1092-4388(2007/013).
   Su YE, 2018, J AUTISM DEV DISORDE.
   Swensen LD, 2007, CHILD DEV, V78, P542, DOI 10.1111/j.1467-8624.2007.01022.x.
   Tager-Flusberg H, 2000, METHODS FOR STUDYING LANGUAGE PRODUCTION, P313.
   Tager-Flusberg H., 2005, HDB AUTISM PERVASIVE, V1, P335, DOI DOI 10.1002/9780470939345.CH12.
   Tager-Flusberg H, 2016, J SPEECH LANG HEAR R, V59, P143, DOI 10.1044/2015\_JSLHR-L-15-0146.
   Tager-Flusberg H, 2013, AUTISM RES, V6, P468, DOI 10.1002/aur.1329.
   TAGERFLUSBERG H, 1981, APPL PSYCHOLINGUIST, V2, P5, DOI 10.1017/S014271640000062X.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Tek S, 2014, J AUTISM DEV DISORD, V44, P75, DOI 10.1007/s10803-013-1853-4.
   Tovar AT, 2015, J SPEECH LANG HEAR R, V58, P301, DOI 10.1044/2014\_JSLHR-L-13-0257.
   Trueswell JC, 1999, COGNITION, V73, P89, DOI 10.1016/S0010-0277(99)00032-3.
   van Heugten M, 2009, DEVELOPMENTAL SCI, V12, P419, DOI 10.1111/j.1467-7687.2008.00788.x.
   Venker CE, 2013, AUTISM RES, V6, P417, DOI 10.1002/aur.1304.
   Wittke K, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00532.
   Zhan LK, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00061.
   Zhan LK, 2015, J COGN PSYCHOL, V27, P367, DOI 10.1080/20445911.2015.1016527.
   Zhou P, 2018, J PSYCHOLINGUIST RES, V47, P241, DOI 10.1007/s10936-017-9530-y.
   Zhou P, 2014, COGNITION, V133, P262, DOI 10.1016/j.cognition.2014.06.018.}},
Number-of-Cited-References = {{80}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{24}},
Journal-ISO = {{J. Psycholinguist. Res.}},
Doc-Delivery-Number = {{HQ2DQ}},
Unique-ID = {{ISI:000462210400010}},
DA = {{2020-12-06}},
}

@article{ ISI:000459644500022,
Author = {Huettig, Falk and Guerra, Ernesto},
Title = {{Effects of speech rate, preview time of visual context, and participant
   instructions reveal strong limits on prediction in language processing}},
Journal = {{BRAIN RESEARCH}},
Year = {{2019}},
Volume = {{1706}},
Pages = {{196-208}},
Month = {{MAR 1}},
Abstract = {{There is a consensus among language researchers that people can predict
   upcoming language. But do people always predict when comprehending
   language? Notions that ``brains ... are essentially prediction
   machines{''} certainly suggest so. In three eye-tracking experiments we
   tested this view. Participants listened to simple Dutch sentences (look
   at the displayed bicycle') while viewing four objects (a target, e.g. a
   bicycle, and three unrelated distractors). We used the identical visual
   stimuli and the same spoken sentences but varied speech rates, preview
   time, and participant instructions. Target nouns were preceded by
   definite gender-marked determiners, which allowed participants to
   predict the target object because only the targets but not the
   distractors agreed in gender with the determiner. In Experiment 1,
   participants had four seconds preview and sentences were presented
   either in a slow or a normal speech rate. Participants predicted the
   targets as soon as they heard the determiner in both conditions.
   Experiment 2 was identical except that participants were given only a
   one second preview. Participants predicted the targets only in the slow
   speech condition. Experiment 3 was identical to Experiment 2 except that
   participants were explicitly told to predict. This led only to a small
   prediction effect in the normal speech condition. Thus, a normal speech
   rate only afforded prediction if participants had an extensive preview.
   Even the explicit instruction to predict the target resulted in only a
   small anticipation effect with a normal speech rate and a short preview.
   These findings are problematic for theoretical proposals that assume
   that prediction pervades cognition.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Huettig, F (Corresponding Author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   Huettig, Falk, Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   Guerra, Ernesto, Univ Chile, Ctr Adv Res Educ CIAE, Santiago, Chile.}},
DOI = {{10.1016/j.brainres.2018.11.013}},
ISSN = {{0006-8993}},
EISSN = {{1872-6240}},
Keywords = {{Prediction; Language processing; Eye-tracking}},
Keywords-Plus = {{DISCOURSE CONTEXT; UPCOMING WORDS; EYE-MOVEMENTS; COMPREHENSION;
   INFORMATION; INTEGRATION; RECOGNITION; INFERENCE; PICTURES; OBJECTS}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{falk.huettig@mpi.nl}},
ResearcherID-Numbers = {{, CIAE/R-5423-2017
   Guerra, Ernesto/S-9086-2019
   }},
ORCID-Numbers = {{Guerra, Ernesto/0000-0001-7403-5271}},
Cited-References = {{Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arai M, 2013, LANG COGNITIVE PROC, V28, P525, DOI 10.1080/01690965.2012.658072.
   Boland JE, 1995, J MEM LANG, V34, P774, DOI 10.1006/jmla.1995.1034.
   Boylan C, 2014, BRAIN LANG, V137, P40, DOI 10.1016/j.bandl.2014.07.009.
   Brouwer S, 2013, APPL PSYCHOLINGUIST, V34, P519, DOI 10.1017/S0142716411000853.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Cousineau D, 2014, BEHAV RES METHODS, V46, P1149, DOI 10.3758/s13428-013-0441-z.
   Cumming G, 2005, AM PSYCHOL, V60, P170, DOI 10.1037/0003-066X.60.2.170.
   Cumming G, 2014, PSYCHOL SCI, V25, P7, DOI 10.1177/0956797613504966.
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074.
   de Lange FP, 2018, TRENDS COGN SCI, V22, P764, DOI 10.1016/j.tics.2018.06.002.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Dikker S, 2013, BRAIN LANG, V127, P55, DOI 10.1016/j.bandl.2012.08.004.
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751.
   Drake E, 2015, MEM COGNITION, V43, P1136, DOI 10.3758/s13421-015-0530-6.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Ferreira F., 2018, CURR DIRECT PSYCHOL.
   Frisson S, 2017, J MEM LANG, V95, P200, DOI 10.1016/j.jml.2017.04.007.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Fruchter J, 2015, J COGNITIVE NEUROSCI, V27, P1912, DOI 10.1162/jocn\_a\_00822.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Hsu J, 1996, MULTIPLE COMP THEORY.
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Ito A, 2017, LANG COGN NEUROSCI, V32, P954, DOI 10.1080/23273798.2016.1242761.
   Kaiser E, 2004, COGNITION, V94, P113, DOI 10.1016/j.cognition.2004.01.002.
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362.
   Kochari A, 2018, LANG COGNIT NEUROSCI.
   Kochari AR, 2018, BEHAV BRAIN SCI, V41, DOI 10.1017/S0140525X18000730.
   Kuhn Th.S, 1970, STRUCTURE SCI REVOLU.
   Kukona A, 2011, COGNITION, V119, P23, DOI 10.1016/j.cognition.2010.12.002.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Lesage E, 2012, CURR BIOL, V22, pR794, DOI 10.1016/j.cub.2012.07.006.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Lowder MW, 2016, J EXP PSYCHOL LEARN, V42, P1400, DOI 10.1037/xlm0000256.
   Luke SG, 2016, COGNITIVE PSYCHOL, V88, P22, DOI 10.1016/j.cogpsych.2016.06.002.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   MATIN E, 1993, PERCEPT PSYCHOPHYS, V53, P372, DOI 10.3758/BF03206780.
   McQueen JM, 2014, ATTEN PERCEPT PSYCHO, V76, P190, DOI 10.3758/s13414-013-0560-8.
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468.
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703.
   Otten M, 2009, BRAIN RES, V1291, P92, DOI 10.1016/j.brainres.2009.07.042.
   Pickering MJ, 2018, PSYCHOL BULL, V144, P1002, DOI 10.1037/bul0000158.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Popper K. R., 1959, LOGIC SCI DISCOVERY.
   Salverda AP, 2011, J EXP PSYCHOL HUMAN, V37, P1122, DOI 10.1037/a0023101.
   Salverda AP, 2011, ACTA PSYCHOL, V137, P172, DOI 10.1016/j.actpsy.2010.09.010.
   SASLOW MG, 1967, J OPT SOC AM, V57, P1030, DOI 10.1364/JOSA.57.001030.
   Severens E, 2005, ACTA PSYCHOL, V119, P159, DOI 10.1016/j.actpsy.2005.01.002.
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425.
   Staub A, 2015, LANG LINGUIST COMPAS, V9, P311, DOI 10.1111/lnc3.12151.
   van Assen MALM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084896.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Willems RM, 2016, CEREB CORTEX, V26, P2506, DOI 10.1093/cercor/bhv075.
   Zwaan RA, 2018, BEHAV BRAIN SCI, V41, DOI 10.1017/S0140525X17001972.}},
Number-of-Cited-References = {{64}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{Brain Res.}},
Doc-Delivery-Number = {{HM7FZ}},
Unique-ID = {{ISI:000459644500022}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000455190700003,
Author = {Dietzen, Thomas and Spriet, Ann and Tirry, Wouter and Doclo, Simon and
   Moonen, Marc and van Waterschoot, Toon},
Title = {{Comparative Analysis of Generalized Sidelobe Cancellation and
   Multi-Channel Linear Prediction for Speech Dereverberation and Noise
   Reduction}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2019}},
Volume = {{27}},
Number = {{3}},
Pages = {{544-558}},
Month = {{MAR}},
Abstract = {{For blind speech dereverberation, two frameworks are commonly used: on
   the one hand, the multi-channel linear prediction (MCLP) framework, and
   on the other hand, data-dependent beamforming, e.g., the generalized
   sidelobe canceler (GSC) framework. The MCLP framework is designed to
   perform deconvolution and hence has gained increased prominence in blind
   speech dereverberation. The GSC framework is commonly used for noise
   reduction, but may be applied for dereverberation as well. In previous
   work, we have shown that for the noiseless case, MCLP and the GSC yield
   in theory mathematically equivalent results in terms of dereverberation.
   In this paper, we assume additional coherent as well as incoherent-noise
   components and formally analyze and compare both frameworks in terms of
   dereverberation and noise reduction performance. Both the theoretical
   analysis and time domain simulation results demonstrate that unlike the
   GSC, MCLP expectably shows limited performance in terms of noise
   reduction, while both perform equally well in terms of dereverberation,
   provided that the GSC blocking matrix achieves complete blocking of the
   early reverberant-speech component and sufficiently many microphones are
   available. In case of incomplete blocking, however, the GSC performs
   inferior to MCLP in terms of dereverberation, as shown in short-time
   Fourier transform domain simulations.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dietzen, T (Corresponding Author), NXP Semicond Belgium NV, B-3001 Leuven, Belgium.
   Dietzen, T (Corresponding Author), Katholieke Univ Leuven, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, Dept Elect Engn ESAT, B-3001 Leuven, Belgium.
   Dietzen, Thomas; Spriet, Ann; Tirry, Wouter, NXP Semicond Belgium NV, B-3001 Leuven, Belgium.
   Dietzen, Thomas; Moonen, Marc; van Waterschoot, Toon, Katholieke Univ Leuven, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, Dept Elect Engn ESAT, B-3001 Leuven, Belgium.
   Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.
   Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearine4A11, D-26111 Oldenburg, Germany.}},
DOI = {{10.1109/TASLP.2018.2886743}},
ISSN = {{2329-9290}},
Keywords = {{Multi-channel linear prediction; data-dependent beamforming;
   dereverberation; noise reduction}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{thomas.dietzen@esat.kuleuven.be
   ann.spriet@nxp.com
   wouter.tirry@nxp.com
   simon.doclo@uni-oldenburg.de
   marc.moonen@esat.kuleuven.be
   toon.vanwaterschoot@esat.kuleuven.be}},
ResearcherID-Numbers = {{Moonen, Marc/E-6796-2017
   }},
ORCID-Numbers = {{Moonen, Marc/0000-0003-4461-0073
   Doclo, Simon/0000-0002-3392-2381}},
Funding-Acknowledgement = {{KU LeuvenKU Leuven {[}C2-16-00449, VES/16/032, VES/19/004, IMP/14/037];
   IWT OO Project {[}150611]; VLAIO TETRA Project {[}HBC.2016.0085]; OO
   Project {[}HBC.2017.0358]; European CommissionEuropean
   CommissionEuropean Commission Joint Research Centre {[}316969]; European
   Research Council under the European Union's Horizon 2020 research and
   innovation program / ERC Consolidator Grant: SONORA {[}773268]}},
Funding-Text = {{This work was carried out at the ESAT Laboratory of KU Leuven, in the
   frame of KU Leuven internal funds C2-16-00449 ``Distributed Digital
   Signal Processing for Ad-HocWireless Local Area Audio Networking,{''}
   VES/16/032, VES/19/004, and Impulse Fund IMP/14/037; IWT O\&O Project
   150611 ``Proof-of-concept of a Rationed Architecture for Vehicle
   Entertainment and NVH Next-generation Acoustics (RAVENNA){''}; VLAIO
   TETRA Project HBC.2016.0085 ``m-sense: innovative use of sensors in
   mobile platforms{''} and O\&O Project HBC.2017.0358 ``SPOTT-Tomorrow's
   Scalable and PersOnalised advertising Technnology, Today{''}; and EU
   FP7-PEOPLE Marie Curie Initial Training Network ``Dereverberation and
   Reverberation of Audio, Music, and Speech (DREAMS),{''} funded by the
   European Commission under Grant 316969. The research leading to these
   results has received funding from the European Research Council under
   the European Union's Horizon 2020 research and innovation program / ERC
   Consolidator Grant: SONORA (773268).}},
Cited-References = {{Avargel Y, 2007, IEEE T AUDIO SPEECH, V15, P1305, DOI 10.1109/TASL.2006.889720.
   Bang, 1992, MUS ARCH.
   Barker J, 2018, INTERSPEECH, P1561, DOI 10.21437/Interspeech.2018-1768.
   Benesty J, 2007, IEEE T AUDIO SPEECH, V15, P1053, DOI 10.1109/TASL.2006.885251.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Braun S., 2018, IEEE-ACM T AUDIO SPE, V26, P240.
   Braun S, 2016, IEEE SIGNAL PROC LET, V23, P1741, DOI 10.1109/LSP.2016.2616888.
   De Sena E, 2015, IEEE-ACM T AUDIO SPE, V23, P774, DOI 10.1109/TASLP.2015.2405476.
   Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698.
   Delcroix M, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0245-7.
   Dietzen T, 2015, EUR SIGNAL PR CONF, P2461, DOI 10.1109/EUSIPCO.2015.7362827.
   Dietzen T., 2018, AUDIO EXAMPLES IEEE.
   Dietzen T., 2016, P INT WORKSH AC SIGN, P1.
   Dietzen T, 2018, INT WORKSH ACOUSTIC, P221, DOI 10.1109/IWAENC.2018.8521250.
   Dietzen T, 2017, IEEE WORK APPL SIG, P284, DOI 10.1109/WASPAA.2017.8170040.
   Gannot S, 2017, IEEE-ACM T AUDIO SPE, V25, P692, DOI 10.1109/TASLP.2016.2647702.
   GRIFFITHS LJ, 1982, IEEE T ANTENN PROPAG, V30, P27, DOI 10.1109/TAP.1982.1142739.
   Habets EAP, 2010, IEEE T AUDIO SPEECH, V18, P158, DOI 10.1109/TASL.2009.2024731.
   Hikichi T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/34013.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Jukic A, 2017, IEEE SIGNAL PROC LET, V24, P101, DOI 10.1109/LSP.2016.2640939.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kodrasi I, 2017, 2017 HANDS-FREE SPEECH COMMUNICATIONS AND MICROPHONE ARRAYS (HSCMA 2017), P116, DOI 10.1109/HSCMA.2017.7895573.
   Kodrasi I, 2016, IEEE-ACM T AUDIO SPE, V24, P680, DOI 10.1109/TASLP.2016.2518804.
   Lim F., 2013, P EUR SIGN PROC C, P1.
   Lim F, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P119, DOI 10.1109/IWAENC.2014.6953350.
   Markovich S, 2009, IEEE T AUDIO SPEECH, V17, P1071, DOI 10.1109/TASL.2009.2016395.
   Meyer C, 2000, MATRIX ANAL APPL LIN.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Schwartz O, 2015, INT CONF ACOUST SPEE, P106, DOI 10.1109/ICASSP.2015.7177941.
   Schwartz O, 2015, IEEE-ACM T AUDIO SPE, V23, P240, DOI 10.1109/TASLP.2014.2372335.
   Thomas MRP, 2012, INT CONF ACOUST SPEE, P521, DOI 10.1109/ICASSP.2012.6287931.
   Triki M., 2005, P 2005 INT WORKSH AC, P173.
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P436, DOI 10.1109/ASRU.2015.7404828.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2011, IEEE T AUDIO SPEECH, V19, P69, DOI 10.1109/TASL.2010.2045183.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{HG7RE}},
Unique-ID = {{ISI:000455190700003}},
DA = {{2020-12-06}},
}

@article{ ISI:000452027000006,
Author = {Kochari, Arnold R. and Flecken, Monique},
Title = {{Lexical prediction in language comprehension: a replication study of
   grammatical gender effects in Dutch}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2019}},
Volume = {{34}},
Number = {{2}},
Pages = {{239-253}},
Month = {{FEB 7}},
Abstract = {{An important question in predictive language processing is the extent to
   which prediction effects can reliably be measured on pre-nominal
   material (e.g. articles before nouns). Here, we present a large sample
   (N = 58) close replication of a study by Otten and van Berkum (2009).
   They report ERP modulations in relation to the predictability of nouns
   in sentences, measured on gender-marked Dutch articles. We used nearly
   identical materials, procedures, and data analysis steps. We fail to
   replicate the original effect, but do observe a pattern consistent with
   the original data. Methodological differences between our replication
   and the original study that could potentially have contributed to the
   diverging results are discussed. In addition, we discuss the suitability
   of Dutch gender-marked determiners as a test-case for future studies of
   pre-activation of lexical items.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Flecken, M (Corresponding Author), Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, Nijmegen, Netherlands.
   Flecken, M (Corresponding Author), Max Planck Inst Psycholinguist, Neurobiol Language Dept, Nijmegen, Netherlands.
   Kochari, Arnold R., Univ Amsterdam, Inst Log Language \& Computat, Amsterdam, Netherlands.
   Kochari, Arnold R.; Flecken, Monique, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, Nijmegen, Netherlands.
   Flecken, Monique, Max Planck Inst Psycholinguist, Neurobiol Language Dept, Nijmegen, Netherlands.}},
DOI = {{10.1080/23273798.2018.1524500}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Language comprehension; lexical prediction; grammatical gender; ERP;
   Dutch}},
Keywords-Plus = {{BRAIN POTENTIALS; SENTENCE COMPREHENSION; WORD RECOGNITION; EVENT
   KNOWLEDGE; UPCOMING WORDS; ACTIVATION; ERP; INFORMATION; INTEGRATION;
   EXPECTANCY}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{monique.flecken@mpi.nl}},
ORCID-Numbers = {{Kochari, Arnold R./0000-0003-1373-5121}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Brothers T, 2017, J MEM LANG, V93, P203, DOI 10.1016/j.jml.2016.10.002.
   Chow W.-Y., 2018, 31 ANN CUN SENT PROC.
   Dambacher M, 2012, NEUROPSYCHOLOGIA, V50, P1852, DOI 10.1016/j.neuropsychologia.2012.04.011.
   Delaney-Busch N., 2017, P 39 ANN C COGN SCI.
   DeLong K. A., 2017, NIEUWLAND.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Dussias PE, 2013, STUD SECOND LANG ACQ, V35, P353, DOI 10.1017/S0272263112000915.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Ito A, 2017, LANG COGN NEUROSCI, V32, P954, DOI 10.1080/23273798.2016.1242761.
   Ito A, 2017, LANG COGN NEUROSCI, V32, P974, DOI 10.1080/23273798.2017.1323112.
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572.
   Kim A, 2012, J COGNITIVE NEUROSCI, V24, P1104, DOI 10.1162/jocn\_a\_00148.
   Kochari A., 2015, THESIS.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Kurumada C, 2014, COGNITION, V133, P335, DOI 10.1016/j.cognition.2014.05.017.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004.
   Lau EF, 2016, CEREB CORTEX, V26, P1377, DOI 10.1093/cercor/bhu219.
   Lau EF, 2013, J COGNITIVE NEUROSCI, V25, P484, DOI 10.1162/jocn\_a\_00328.
   Luck SJ, 2017, PSYCHOPHYSIOLOGY, V54, P146, DOI 10.1111/psyp.12639.
   Metusalem R, 2012, J MEM LANG, V66, P545, DOI 10.1016/j.jml.2012.01.001.
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468.
   Nieuwland MS, 2015, J COGNITIVE NEUROSCI, V27, P2215, DOI 10.1162/jocn\_a\_00856.
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/156869.
   Otten M., 2008, THESIS.
   Otten M, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-89.
   Otten M, 2009, BRAIN RES, V1291, P92, DOI 10.1016/j.brainres.2009.07.042.
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463.
   R Development Core Team, 2016, R LANG ENV STAT COMP, DOI {[}10.1038/sj.hdy.6800737, DOI 10.1038/SJ.HDY.6800737, 10.1038/sj.hdy.6800737.].
   Rommers J., 2018, RES METHODS PSYCHOLI, P247.
   Schlueter Z., 2018, 31 ANN CUN SENT PROC.
   Shetter W. Z., 1959, J ENGLISH GERMANIC P, V58, P75, DOI 10.2307/27707226.
   Simonsohn U, 2015, PSYCHOL SCI, V26, P559, DOI 10.1177/0956797614567341.
   Szewczyk J. M., 2018, 31 AN CUN SENT PROC.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Verhagen J, 2014, J EXP PSYCHOL GEN, V143, P1457, DOI 10.1037/a0036731.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8.
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0.
   Wlotko EW, 2015, CORTEX, V68, P20, DOI 10.1016/j.cortex.2015.03.014.
   Yan S., 2017, BIORXIV, DOI {[}10.1101/143750, DOI 10.1101/143750].}},
Number-of-Cited-References = {{51}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{HC8BS}},
Unique-ID = {{ISI:000452027000006}},
OA = {{Green Published, Green Accepted, Other Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000455849400011,
Author = {Klimovich-Gray, Anastasia and Tyler, Lorraine K. and Randall, Billi and
   Kocagoncu, Ece and Devereux, Barry and Marslen-Wilson, William D.},
Title = {{Balancing Prediction and Sensory Input in Speech Comprehension: The
   Spatiotemporal Dynamics of Word Recognition in Context}},
Journal = {{JOURNAL OF NEUROSCIENCE}},
Year = {{2019}},
Volume = {{39}},
Number = {{3}},
Pages = {{519-527}},
Month = {{JAN 16}},
Abstract = {{Spoken word recognition in context is remarkably fast and accurate, with
   recognition times of similar to 200 ms, typically well before the end of
   the word. The neurocomputational mechanisms underlying these contextual
   effects are still poorly understood. This study combines
   source-localized electroencephalographic and magnetoencephalographic
   (EMEG) measures of real-time brain activity with multivariate
   representational similarity analysis to determine directly the timing
   and computational content of the processes evoked as spoken words are
   heard in context, and to evaluate the respective roles of bottom-up and
   predictive processing mechanisms in the integration of sensory and
   contextual constraints. Male and female human participants heard simple
   (modifier-noun) English phrases that varied in the degree of semantic
   constraint that the modifier (W1) exerted on the noun (W2), as in pairs,
   such as ``yellow banana.{''} We used gating tasks to generate estimates
   of the probabilistic predictions generated by these constraints as well
   as measures of their interaction with the bottom-up perceptual input for
   W2. Representation similarity analysis models of these measures were
   tested against electroencephalographic and magnetoencephalographic brain
   data across a bilateral fronto-temporo-parietal language network.
   Consistent with probabilistic predictive processing accounts, we found
   early activation of semantic constraints in frontal cortex (LBA45) as W1
   was heard. The effects of these constraints (at 100 ms after W2 onset in
   left middle temporal gyrus and at 140 ms in left Heschl's gyrus) were
   only detectable, however, after the initial phonemes of W2 had been
   heard. Within an overall predictive processing framework, bottom-up
   sensory inputs are still required to achieve early and robust spoken
   word recognition in context.}},
Publisher = {{SOC NEUROSCIENCE}},
Address = {{11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tyler, LK (Corresponding Author), Univ Cambridge, Ctr Speech Language \& Brain, Dept Psychol, Downing St, Cambridge CB2 3EB, England.
   Klimovich-Gray, Anastasia; Tyler, Lorraine K.; Randall, Billi; Kocagoncu, Ece; Devereux, Barry; Marslen-Wilson, William D., Univ Cambridge, Ctr Speech Language \& Brain, Dept Psychol, Downing St, Cambridge CB2 3EB, England.}},
DOI = {{10.1523/JNEUROSCI.3573-17.2018}},
ISSN = {{0270-6474}},
Keywords = {{language; prediction; RSA; speech; time-course; word recognition}},
Keywords-Plus = {{COGNITIVE CONTROL; LANGUAGE; MEG; ORGANIZATION; COMPETITION; PERCEPTION;
   MODEL}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{lktyler@csl.psychol.cam.ac.uk}},
ORCID-Numbers = {{Tyler, Lorraine/0000-0002-9943-118X
   Kocagoncu, Ece/0000-0002-6292-7472
   Klimovich-Gray, Anastasia/0000-0002-6292-6381}},
Funding-Acknowledgement = {{European Research Council Advanced Investigator Grant under the European
   Community's Horizon 2020 Research and Innovation Programme (2014-2020
   ERC Grant) {[}669820]; Isaac Newton Trust Research Grant 2017
   {[}15.40(k)]}},
Funding-Text = {{This work was supported by a European Research Council Advanced
   Investigator Grant to L.K.T. under the European Community's Horizon 2020
   Research and Innovation Programme (2014-2020 ERC Grant Agreement
   669820), and Isaac Newton Trust Research Grant 2017 Grant 15.40(k) to
   L.K.T.}},
Cited-References = {{Baroni M, 2010, COMPUT LINGUIST, V36, P673, DOI 10.1162/coli\_a\_00016.
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512.
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1.
   Delaney- Busch N, 2017, 39 ANN C COGN SCI SO.
   Devereux BJ, 2014, BEHAV RES METHODS, V46, P1119, DOI 10.3758/s13428-013-0420-4.
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021.
   Friston KJ, 2015, CORTEX, V68, P129, DOI 10.1016/j.cortex.2015.03.025.
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646.
   Gaskell MG, 2002, COGNITIVE PSYCHOL, V45, P220.
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267.
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386.
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Kocagoncu E, 2017, J NEUROSCI, V37, P1312, DOI 10.1523/JNEUROSCI.2858-16.2016.
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Li Su, 2012, 2012 2nd International Workshop on Pattern Recognition in NeuroImaging (PRNI), P97, DOI 10.1109/PRNI.2012.26.
   Lin FH, 2006, NEUROIMAGE, V31, P160, DOI 10.1016/j.neuroimage.2005.11.054.
   Luke SG, 2016, COGNITIVE PSYCHOL, V88, P22, DOI 10.1016/j.cogpsych.2016.06.002.
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024.
   MARSLENWILSON W, 1975, NATURE, V257, P784, DOI 10.1038/257784a0.
   MARSLENWILSON WD, 1975, SCIENCE, V189, P226, DOI 10.1126/science.189.4198.226.
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9.
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366.
   Musz E, 2017, BRAIN LANG, V165, P21, DOI 10.1016/j.bandl.2016.11.002.
   Nili H, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003553.
   Novick JM, 2005, COGN AFFECT BEHAV NE, V5, P263, DOI 10.3758/CABN.5.3.263.
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1.
   Sereno SC, 2003, PSYCHOL SCI, V14, P328, DOI 10.1111/1467-9280.14471.
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113.
   Taulu S, 2005, IEEE T SIGNAL PROCES, V53, P3359, DOI 10.1109/TSP.2005.853302.
   TYLER LK, 1983, PERCEPT PSYCHOPHYS, V34, P409, DOI 10.3758/BF03203056.
   Tyler LK, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00271.
   Uppenkamp S, 2006, NEUROIMAGE, V31, P1284, DOI 10.1016/j.neuroimage.2006.01.004.
   Warrier C, 2009, J NEUROSCI, V29, P61, DOI 10.1523/JNEUROSCI.3489-08.2009.
   WILSON WM, 1973, NATURE, V244, P522, DOI 10.1038/244522a0.
   Wingfield C, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005617.
   Zhuang J, 2014, CEREB CORTEX, V24, P908, DOI 10.1093/cercor/bhs366.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{J. Neurosci.}},
Doc-Delivery-Number = {{HH6NX}},
Unique-ID = {{ISI:000455849400011}},
OA = {{Bronze, Green Published}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000564759600020,
Author = {Shijaku, Rexhep and Canhasi, Ercan},
Editor = {{Silhavy, R and Silhavy, P and Prokopova, Z}},
Title = {{Model-Based Prediction of the Size, the Language and the Quality of the
   Web Domains}},
Booktitle = {{INTELLIGENT SYSTEMS APPLICATIONS IN SOFTWARE ENGINEERING, VOL 1}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2019}},
Volume = {{1046}},
Pages = {{209-225}},
Note = {{3rd Conference on Computational Methods in Systems and Software
   (CoMeSySo), ELECTR NETWORK, OCT, 2019}},
Organization = {{OpenPublish eu s r o; W Pomeranian Univ Technol, Fac Elect Engn}},
Abstract = {{This article investigates possibilities for developing a model, which
   without completely downloading domains, is able to predict: (1) the size
   of domains, (2) the domains main language (as Albanian or not), (3) the
   multilingual domains, where at least one of the languages is Albanian,
   and (4) the quality of a domain. Proposed model excludes domains which
   are not written in Albanian from a given set of domains and ranks
   exclusively Albanian domains by their importance. Consequently,
   presented model offers higher flexibility and efficiency to a search
   engine which tends to index the Albanian web.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Canhasi, E (Corresponding Author), Gjirafa Inc, Rr Ahmet Krasniqi, Veranda C2-7, Prishtine, Kosovo.
   Canhasi, E (Corresponding Author), Univ Prizren, Rruga \& Shkronjave 1, Prizren 20000, Kosovo.
   Canhasi, Ercan, Gjirafa Inc, Rr Ahmet Krasniqi, Veranda C2-7, Prishtine, Kosovo.
   Shijaku, Rexhep; Canhasi, Ercan, Univ Prizren, Rruga \& Shkronjave 1, Prizren 20000, Kosovo.}},
DOI = {{10.1007/978-3-030-30329-7\_20}},
ISSN = {{2194-5357}},
EISSN = {{2194-5365}},
ISBN = {{978-3-030-30329-7; 978-3-030-30328-0}},
Keywords = {{Language specific web crawling; Multi-lingual domain detection; Domain
   quality estimation; Domain size prediction}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods}},
Author-Email = {{rexhepshijaku@gmail.com
   ercan@gjriafa.com}},
Funding-Acknowledgement = {{Gjirafa, Inc.}},
Funding-Text = {{This work was completely supported by the Gjirafa, Inc. We also thanks
   Univesity of Prizren for allowing us to use their infrastructure.}},
Cited-References = {{Baykan E., 2008, WEB PAGE LANGUAGE ID.
   Bendersky M., 2011, QUALITY BIASED RANKI.
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X.
   Brin S., 1995, COPY DETECTION MECH.
   Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7.
   Cavnar W.B., 1994, N GRAM BASED TEXT CA.
   Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3.
   Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380, DOI DOI 10.1145/509907.509965.
   De Bra P., 1994, WWW C.
   Ingle N., 1980, LANGUAGE IDENTIFICAT.
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140.
   Manku G.S., 2007, DETECTING NEAR DUPLI.
   Najork M.A., 2007, P 16 ACM C INF KNOWL, P157, DOI DOI 10.1145/1321440.1321465.
   Somboonviwat K., SIMULATION STUDY LAN.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP8EW}},
Unique-ID = {{ISI:000564759600020}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000553441500046,
Author = {Si, Dong and Cheng, Sunny Chieh and Xing, Ruiwen and Liu, Chang and Wu,
   Hoi Yan},
Book-Group-Author = {{IEEE}},
Title = {{Scaling up Prediction of Psychosis by Natural Language Processing}},
Booktitle = {{2019 IEEE 31ST INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI 2019)}},
Series = {{Proceedings-International Conference on Tools With Artificial
   Intelligence}},
Year = {{2019}},
Pages = {{339-347}},
Note = {{31st IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI), Portland, OR, NOV 04-06, 2019}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{Mental health professionals currently diagnose and treat mental
   disorders, such as schizophrenia, mainly by analyzing the language and
   speech of their patients, a method that maybe improved with the usage of
   artificial intelligence. This study aims to use machine learning to
   distinguish between the speech of patients who suffer from mental
   disorders which cause psychosis from that of healthy individuals to
   improve early detection of schizophrenia. We analyzed forty interview
   transcripts from patients who have been diagnosed with first episode
   psychosis. Word embeddings and convolutional neural network were
   utilized for the classification of patients from healthy individuals.
   The preliminary test results achieved a prediction rate of 99\%, which
   indicated that our speech classifier was able to discriminate speech in
   patients from healthy individuals' daily conversations. This suggested
   that machine learning models can learn and train upon features of
   natural languages to predict whether or not an individual is beginning
   to show the first signs of early psychosis based on their speech. This
   line of inquiry will contribute to the improved identification of
   individuals at risk for psychiatric symptoms and lead to the development
   of targeted therapies.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Si, D (Corresponding Author), Univ Washington, Comp \& Software Syst, Bothell, WA 98011 USA.
   Si, Dong; Xing, Ruiwen; Liu, Chang; Wu, Hoi Yan, Univ Washington, Comp \& Software Syst, Bothell, WA 98011 USA.
   Cheng, Sunny Chieh, Univ Washington, Nursing \& Healthcare Leadership, Tacoma, WA USA.}},
DOI = {{10.1109/ICTAI.2019.00055}},
ISSN = {{1082-3409}},
ISBN = {{978-1-7281-3798-8}},
Keywords = {{Machine learning; Natural language processing; Text classification;
   Prediction of psychosis; Schizophrenia; Word embeddings; Convolutional
   neural networks}},
Keywords-Plus = {{HIGH-RISK; SCHIZOPHRENIA; PREVALENCE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{dongsi@uw.edu
   ccsunny@uw.edu
   ruiwen@uw.edu
   chang15@uw.edu
   hoiyanwu@uw.edu}},
Funding-Acknowledgement = {{Graduate Research Award of Computing and Software Systems division;
   University of Washington BothellUniversity of Washington {[}74-0525];
   NVIDIA Corporation (Santa Clara, CA, USA)}},
Funding-Text = {{This research was funded by the Graduate Research Award of Computing and
   Software Systems division and the startup fund 74-0525 of the University
   of Washington Bothell.; We gratefully acknowledge the support of NVIDIA
   Corporation (Santa Clara, CA, USA) with the donation of the GPU used for
   this research.}},
Cited-References = {{Bedi G, 2015, NPJ SCHIZOPHR, V1, DOI 10.1038/npjschz.2015.30.
   Bird S, 2009, NATURAL LANGUAGE PRO, P134, DOI {[}10.1007/3-540-09456-9, DOI 10.1007/3-540-09456-9].
   Brownlee J., 2016, GRID SEARCH HYPERPAR.
   Chen T, 2013, LANG RESOUR EVAL, V47, P299, DOI 10.1007/s10579-012-9197-9.
   Cheng SC, 2019, EARLY INTERV PSYCHIA, V13, P574, DOI 10.1111/eip.12525.
   Clark S, 2015, J NEURAL TRANSM, V122, P155, DOI 10.1007/s00702-014-1325-9.
   Du YH, 2018, NEUROIMAGE-CLIN, V17, P335, DOI 10.1016/j.nicl.2017.10.018.
   Firth J. R., 1957, SYNOPSIS LINGUISTIC.
   Francois C., 2018, KERAS GITHUB REPOSIT.
   Fxsjy, 2018, JIEBA.
   Goldberg Y., 2015, PRIMER NEURAL NETWOR.
   Goldberg Y, 2017, SYNTH LECT HUM LANG, V10, P1, DOI DOI 10.2200/S00762ED1V01Y201703HLT037.
   Grave E., 2018, FACEBOOKRESEARCH FAS.
   Grave E, 2018, LEARNING WORD VECTOR, V1.
   Hampton B, 2009, J APPL SOC PSYCHOL, V39, P449, DOI 10.1111/j.1559-1816.2008.00446.x.
   Hilbert M, 2011, SCIENCE, V332, P60, DOI 10.1126/science.1200970.
   Malla A, 2014, SOC PSYCH PSYCH EPID, V49, P1711, DOI 10.1007/s00127-014-0893-1.
   McGrath J, 2008, EPIDEMIOL REV, V30, P67, DOI 10.1093/epirev/mxn001.
   National Institute of Mental Health, 2016, SCHIZ FACT SHEET.
   Nikhil N., 2018, CONVOLUTIONAL NEURAL.
   Padula MC, 2017, NEUROIMAGE-CLIN, V16, P142, DOI 10.1016/j.nicl.2017.07.023.
   Poulin C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085733.
   Rezaii N, 2019, NPJ SCHIZOPHR, V5, DOI 10.1038/s41537-019-0077-9.
   Rong X., 2014, WORD2VEC PARAMETER L.
   Sasaki Y., 2017, LANGUAGE RESOURCES E.
   Socher R., 2013, P 51 ANN M ASS COMP, P455.
   Socher R., 2013, EMNLP, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791.
   Van Rijsbergen CJ, 1979, INFORM RETRIEVAL.
   Vos T, 2015, LANCET, V386, P743, DOI 10.1016/S0140-6736(15)60692-4.
   WHO, 2018, SCHIZ FACT SHEET.
   Yung AR, 2010, SCHIZOPHR RES, V120, P1, DOI 10.1016/j.schres.2010.03.014.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP4NY}},
Unique-ID = {{ISI:000553441500046}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000539883100090,
Author = {Weiner, Jochen and Frankenberg, Claudia and Schroeder, Johannes and
   Schultz, Tanja},
Book-Group-Author = {{IEEE}},
Title = {{SPEECH REVEALS FUTURE RISK OF DEVELOPING DEMENTIA: PREDICTIVE DEMENTIA
   SCREENING FROM BIOGRAPHIC INTERVIEWS}},
Booktitle = {{2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU
   2019)}},
Year = {{2019}},
Pages = {{674-681}},
Note = {{IEEE Automatic Speech Recognition and Understanding Workshop (ASRU),
   Guadeloupe, FRANCE, DEC 15-18, 2019}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Signal Proc Soc}},
Abstract = {{Alzheimer's disease is a progressive incurable condition for which the
   success of any symptomatic therapy depends crucially on the starting
   time. Ideally it starts before the disease has caused any cognitive
   impairments. Our work aims at developing speech-based dementia screening
   methods that detect dementia as early as possible. Here, we aim to
   predict the outbreak even before clinical screening tests can diagnose
   the disease. Using the longitudinal ILSE study, we automatically extract
   features from biographic interviews and predict the development of
   dementia 5 and 12 years into the future. Our prediction system achieves
   results of 73.3\% and 75.7\% unweighted average recall (UAR),
   respectively, which clearly outperform a prediction based on prior
   diagnoses or disease prevalence. Thus, the automated analysis of spoken
   interviews offers a highly effective prediction procedure that allows
   for easy-to-use, cost-effective casual testing.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Weiner, J (Corresponding Author), Univ Bremen, Cognit Syst Lab, Bremen, Germany.
   Weiner, Jochen; Schultz, Tanja, Univ Bremen, Cognit Syst Lab, Bremen, Germany.
   Frankenberg, Claudia; Schroeder, Johannes, Heidelberg Univ, Sect Geriatr Psychiat, Heidelberg, Germany.}},
ISBN = {{978-1-7281-0306-8}},
Keywords = {{dementia screening; predictive screening; ILSE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Funding-Acknowledgement = {{German research foundationGerman Research Foundation (DFG) {[}DFG SCHR
   471/5-1, SCHU 2452/11-1]}},
Funding-Text = {{The present study was supported by the German research foundation (DFG
   SCHR 471/5-1 and SCHU 2452/11-1).}},
Cited-References = {{Anne Schiller, 1999, GUIDELINES TAGGING D.
   APPELL J, 1982, BRAIN LANG, V17, P73, DOI 10.1016/0093-934X(82)90006-2.
   Brunet E, 1978, VOCABULAIRE J GIRAUD.
   Bucks RS, 2000, APHASIOLOGY, V14, P71, DOI 10.1080/026870300401603.
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307.
   Deutsche Gesellschaft fur Psychiatrie und Psychotherapie Psychosomatik und Nervenheilkunde (DGPPN)/Deutsche Gesellschaft fur Neurologie (DGN), 2016, S3 LEITLINIE DEMENZE.
   Espinoza-Cuadros F, 2014, LECT NOTES ARTIF INT, V8854, P219, DOI 10.1007/978-3-319-13623-3\_23.
   Gosztolya G, 2019, COMPUT SPEECH LANG, V53, P181, DOI 10.1016/j.csl.2018.07.007.
   Honore A., 1979, ASS LIT LINGUISTIC C, V7, P172.
   Khodabakhsh A, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0052-y.
   Martin P., 2000, ASPEKTE ENTWICKLUNG, P17.
   Mirheidari B, 2019, COMPUT SPEECH LANG, V53, P65, DOI 10.1016/j.csl.2018.07.006.
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825.
   Pennebaker James W., 2001, ERLBAUM.
   Prince M, 2015, WORLD ALZHEIMER REPO.
   Prud'hommeaux ET, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3028.
   Sadeghian R, 2017, INTERSPEECH, P2705, DOI 10.21437/Interspeech.2017-1712.
   Sattler Christine, 2017, INTERDISCIPLINARY LO, P1213.
   Schmid Helmut, 1995, P ACL SIGDAT WORKSH, P47, DOI {[}10.1007/978-94-017-2390-9\_2, DOI 10.1007/978-94-017-2390-9\_2].
   Schuller B, 2016, INTERSPEECH, P2001, DOI 10.21437/Interspeech.2016-129.
   Shum SH, 2013, IEEE T AUDIO SPEECH, V21, P2015, DOI 10.1109/TASL.2013.2264673.
   Toth L, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2694.
   Tweedie FJ, 1998, COMPUT HUMANITIES, V32, P323, DOI 10.1023/A:1001749303137.
   Wankerl Sebastian, 2016, 12 ITG C SPEECH COMM, P254.
   Weiner J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P718.
   Weiner J, 2017, INTERSPEECH, P3117, DOI 10.21437/Interspeech.2017-112.
   Weiner J, 2018, LECT NOTES ARTIF INT, V11096, P747, DOI 10.1007/978-3-319-99579-3\_76.
   Weiner Jochen, 2018, 13 ITG C SPEECH COMM.
   Weiner Jochen, 2016, INTERSPEECH 2016.
   Westpfahl S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1493.
   Wolf M, 2008, DIAGNOSTICA, V54, P85, DOI 10.1026/0012-1924.54.2.85.
   World Health Organization, 2012, DEM PUBL HLTH PRIOR.
   Zhou LK, 2016, INTERSPEECH, P1948, DOI 10.21437/Interspeech.2016-1228.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP1KJ}},
Unique-ID = {{ISI:000539883100090}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000491352900508,
Author = {Song, Jingyu and Chen, Bo and Li, Xueliang and Yang, Yi and Liu, Chang
   and Li, Haifeng},
Editor = {{Xu, B}},
Title = {{The software fault prediction model based on the AltaRica language}},
Booktitle = {{PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING,
   ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019)}},
Year = {{2019}},
Pages = {{2549-2552}},
Note = {{IEEE 3rd Information Technology, Networking, Electronic and Automation
   Control Conference (ITNEC), Chengdu, PEOPLES R CHINA, MAR 15-17, 2019}},
Organization = {{IEEE Beijing Sect; Global Union Acad Sci \& Technol; Chongqing Global
   Union Acad Sci \& Technol; Chengdu Global Union Acad Sci \& Technol;
   Chongqing Geeks Educ Technol Co Ltd; IEEE}},
Abstract = {{Many existing software fault prediction methods are difficult to
   identify and predict various complex faults such as the abnormal
   interface data, the concurrency conflict between functions, and the
   invalid state transition. To solve this problem, a new software fault
   prediction model based on AltaRica language is proposed in this paper
   based on the AltaRica language and the Line Temporal Logic (LTL) with
   the operation characters of the airborne support system. The
   experimental results show that this new model can improve the
   effectiveness and applicability of the fault prediction methods which
   can describe the operation characters of the airborne support system
   software accurately and identify the complex faults adequately.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Song, JY (Corresponding Author), China State Shipbldg Corp, Syst Engn Res Inst, Beijing, Peoples R China.
   Song, Jingyu; Chen, Bo; Li, Xueliang; Yang, Yi, China State Shipbldg Corp, Syst Engn Res Inst, Beijing, Peoples R China.
   Liu, Chang; Li, Haifeng, Beihang Univ, Inst Reliabil Engn, Beijing, Peoples R China.}},
ISBN = {{978-1-5386-6243-4}},
Keywords = {{fault prediction; AltaRica; software safety; requirement model; Line
   Temporal Logic}},
Research-Areas = {{Automation \& Control Systems; Computer Science; Engineering}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Hardware \&
   Architecture; Engineering, Electrical \& Electronic}},
Author-Email = {{songjingyu2018@163.com}},
Cited-References = {{Bieber P, 2004, WORLD COMP C.
   Chen Xiang, 2016, Journal of Software, V27, P1, DOI 10.13328/j.cnki.jos.004923.
   {[}刘雪 Liu Xue], 2015, {[}计算机工程与科学, Computer Engineering and Science], V37, P1498.
   Prosvirnova T., 2013, INSIGHT, V16, P24.
   Shi Jiaojie, 2015, COMPUTER TECHNOLOGY, V25, P7.
   Wu Z., 2017, J AIRCRAFT, P1, DOI DOI 10.1016/J.JALLCOM.2017.01.156.}},
Number-of-Cited-References = {{6}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BO0JR}},
Unique-ID = {{ISI:000491352900508}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000482554000128,
Author = {Ooster, Jasper and Meyer, Bernd T.},
Book-Group-Author = {{IEEE}},
Title = {{IMPROVING DEEP MODELS OF SPEECH QUALITY PREDICTION THROUGH VOICE
   ACTIVITY DETECTION AND ENTROPY-BASED MEASURES}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2019}},
Pages = {{636-640}},
Note = {{44th IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Brighton, ENGLAND, MAY 12-17, 2019}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{This paper explores Deep machine listening for Estimating Speech Quality
   (DESQ), which predicts the perceived speech quality based on phoneme
   posterior probabilities obtained from a deep neural network. The
   degradation of phonemes is quantified with the entropybased Gini measure
   that is compared to the mean temporal distance (MTD) proposed earlier.
   Since long speech pauses might have a large effect on the speech
   quality, we investigate if a voice activity detection (VAD) has a
   beneficial or detrimental effect on the predictive power of our model.
   The evaluation is performed by correlating the model output and mean
   opinion scores (MOS) of normal-hearing listeners who rated signals
   degraded by typical VoIP artifacts. While the Gini-based measure and MTD
   result in very similar predictions (with a lower computational cost for
   the Gini-measure), the VAD increases performance from r = 0.87 to r =
   0.91 which is higher than three competing baselines (ITU-P. 563,
   ANIQUE+, and SRM-Rnorm).}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ooster, J (Corresponding Author), Carl Von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   Ooster, Jasper, Carl Von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   Carl Von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-8131-1}},
Keywords = {{subjective speech quality prediction; non-intrusive; deep neural
   network; voice activity detection; automatic speech recognition}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Funding-Acknowledgement = {{DFG (Cluster of Excellence 1077/1 Hearing4all)German Research Foundation
   (DFG); DFGGerman Research Foundation (DFG) {[}CRC TRR 31]}},
Funding-Text = {{This research was supported by the DFG (Cluster of Excellence 1077/1
   Hearing4all; URL: http://hearing4all.eu and the CRC TRR 31, Transfer
   Project T01).}},
Cited-References = {{Breiman Leo, 1984, CLASSIFICATION REGRE.
   European Telecommunications Standards Institute, 2008, 2023961 ETSI EG.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Harte N, 2015, INT WORK QUAL MULTIM.
   Hermansky H, 2013, INT CONF ACOUST SPEE, P7423, DOI 10.1109/ICASSP.2013.6639105.
   Hirsch H.G., 2000, ASR2000 AUT SPEECH R.
   Huber R, 2018, J AUDIO ENG SOC, V66, P759, DOI 10.17743/jaes.2018.0041.
   Huber R, 2018, HEARING RES, V359, P40, DOI 10.1016/j.heares.2017.12.014.
   ITU-T, 2011, REC P 862 PERC EV SP.
   ITU-T, 1996, REC P 800 METH SUBJ.
   ITU-T, 2011, REC P 341 TRANSM CHA, P30.
   ITU-T, 2004, REC P 563 SINGL END.
   ITU-T, 2011, REC P 863 PERC OBJ L.
   Kim DS, 2007, BELL LABS TECH J, V12, P221, DOI 10.1002/bltj.20228.
   Mallidi H, 2016, INT CONF ACOUST SPEE, P5680, DOI 10.1109/ICASSP.2016.7472765.
   Meyerl BT, 2016, IEEE W SP LANG TECH, P50, DOI 10.1109/SLT.2016.7846244.
   Moller S, 2011, IEEE SIGNAL PROC MAG, V28, P18, DOI 10.1109/MSP.2011.942469.
   Ooster J, 2018, INTERSPEECH, P976.
   Santos Joo F., 2014, INT WORKSH AC SIGN E.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BN4NP}},
Unique-ID = {{ISI:000482554000128}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000482554006187,
Author = {Zhang, Zixing and Wu, Bingwen and Schuller, Bjoern},
Book-Group-Author = {{IEEE}},
Title = {{ATTENTION-AUGMENTED END-TO-END MULTI-TASK LEARNING FOR EMOTION
   PREDICTION FROM SPEECH}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2019}},
Pages = {{6705-6709}},
Note = {{44th IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Brighton, ENGLAND, MAY 12-17, 2019}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Despite the increasing research interest in end-to-end learning systems
   for speech emotion recognition, conventional systems either suffer from
   the overfitting due in part to the limited training data, or do not
   explicitly consider the different contributions of automatically learnt
   representations for a specific task. In this contribution, we propose a
   novel end-to-end framework which is enhanced by learning other auxiliary
   tasks and an attention mechanism. That is, we jointly train an
   end-to-end network with several different but related emotion prediction
   tasks, i.e., arousal, valence, and dominance predictions, to extract
   more robust representations shared among various tasks than traditional
   systems with the hope that it is able to relieve the overfitting
   problem. Meanwhile, an attention layer is implemented on top of the
   layers for each task, with the aim to capture the contribution
   distribution of different segment parts for each individual task. To
   evaluate the effectiveness of the proposed system, we conducted a set of
   experiments on the widely used database IEMOCAP. The empirical results
   show that the proposed systems significantly outperform corresponding
   baseline systems.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, ZX (Corresponding Author), Imperial Coll London, Grp Language Audio \& Mus, London, England.
   Zhang, ZX (Corresponding Author), AudEERING GmbH, Gilching, Germany.
   Zhang, Zixing; Schuller, Bjoern, Imperial Coll London, Grp Language Audio \& Mus, London, England.
   Zhang, Zixing; Schuller, Bjoern, AudEERING GmbH, Gilching, Germany.
   Wu, Bingwen, Imperial Coll London, Dept Comp, London, England.
   Schuller, Bjoern, Univ Augsburg, ZD B Chair Embedded Intelligence Hlth Care \& Well, Augsburg, Germany.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-8131-1}},
Keywords = {{Speech emotion prediction; end-to-end; attention mechanism; multi-task
   learning}},
Keywords-Plus = {{MODEL}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{zixing.zhang@imperial.ac.uk
   bingwen.wu17@imperial.ac.uk}},
ORCID-Numbers = {{Schuller, Bjorn/0000-0002-6478-8699}},
Funding-Acknowledgement = {{TransAtlantic Platform ``Digging into Data{''} collaboration grant
   (ACLEW: Analysing Child Language Experiences Around The World); UK's
   Economic \& Social Research Council {[}HJ-253479]}},
Funding-Text = {{Both authors contributed equally to this work. This work was supported
   by the TransAtlantic Platform ``Digging into Data{''} collaboration
   grant (ACLEW: Analysing Child Language Experiences Around The World),
   with the support of the UK's Economic \& Social Research Council through
   the research Grant No. HJ-253479.}},
Cited-References = {{Amodei Dario, 2016, INT C MACH LEARN, P173, DOI DOI 10.1007/978-3-030-14596-5\_12.
   Bahdanau Dzmitry, 2015, P ICLR.
   Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663.
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6.
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246.
   Eyben F., 2015, REAL TIME SPEECH MUS.
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417.
   Eyben F, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133372.
   Graves A., 2014, P 31 INT C MACH LEAR, P1764, DOI DOI 10.1145/1143844.1143891.
   Han J, 2018, INTERSPEECH, P3082, DOI 10.21437/Interspeech.2018-996.
   Han J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P890, DOI 10.1145/3123266.3123383.
   Han K, 2014, INTERSPEECH, P223.
   Heigold G, 2016, INT CONF ACOUST SPEE, P5115, DOI 10.1109/ICASSP.2016.7472652.
   Huang J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6837, DOI 10.1109/ICASSP.2018.8461963.
   Li PC, 2018, INTERSPEECH, P3087, DOI 10.21437/Interspeech.2018-1242.
   Metallinou A, 2012, IEEE T AFFECT COMPUT, V3, P184, DOI 10.1109/T-AFFC.2011.40.
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790.
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552.
   Parthasarathy S, 2017, INTERSPEECH, P1103, DOI 10.21437/Interspeech.2017-1494.
   Ruder S., 2017, ARXIV170605098.
   Sarma M, 2018, INTERSPEECH, P3097, DOI 10.21437/Interspeech.2018-1353.
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669.
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438.
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452.
   Xia R, 2017, IEEE T AFFECT COMPUT, V8, P3, DOI 10.1109/TAFFC.2015.2512598.
   Zhang B., 2017, IEEE T AFFECTIVE COM.
   Zhang Z., 2017, ARXIV170708729.
   Zhang Z., 2018, IEEE T MULTIMEDIA.
   Zhang Z., 2014, ADV NEURAL INFORM PR, P2204, DOI DOI 10.1017/S037346330300239X.
   Zhang ZX, 2018, INTERSPEECH, P142.
   Zhao ZP, 2018, INTERSPEECH, P272, DOI 10.21437/Interspeech.2018-1477.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BN4NP}},
Unique-ID = {{ISI:000482554006187}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000482554007023,
Author = {Cui, Zihao and Bao, Changchun},
Book-Group-Author = {{IEEE}},
Title = {{LINEAR PREDICTION-BASED PART-DEFINED AUTO-ENCODER USED FOR SPEECH
   ENHANCEMENT}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2019}},
Pages = {{6880-6884}},
Note = {{44th IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Brighton, ENGLAND, MAY 12-17, 2019}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{This paper proposes a linear prediction-based part-defined auto-encoder
   (PAE) network to enhance speech signal. The PAE is a defined decoder or
   a defined encoder network, based on efficient learning algorithm or
   classical model. In this paper, the PAE utilizes AR-Wiener filter as
   decoder part, and the AR-Wiener filter is modified as a linear
   prediction (LP) model by incorporating the modified factor from residual
   signal. The parameters of line spectral frequency (LSF) of speech and
   noise and the Wiener filtering mask are utilized for training targets.
   Finally, the proposed the LP-based PAE is compared with the baseline
   method, namely the Wiener filtering mask-based DNN. The PESQ and STOI
   results of the LP-based PAE are better than baseline method at lower
   signal noise ratio (SNR) levels.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Cui, ZH (Corresponding Author), Beijing Univ Technol, Fac Informat Technol, Speech \& Audio Signal Proc Lab, Beijing 100124, Peoples R China.
   Cui, Zihao; Bao, Changchun, Beijing Univ Technol, Fac Informat Technol, Speech \& Audio Signal Proc Lab, Beijing 100124, Peoples R China.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-8131-1}},
Keywords = {{Part-defined auto-encoder; speech enhancement; DNN; linear prediction;
   residual signal}},
Keywords-Plus = {{NOISE}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{cuizihao@emails.bjut.edu.cn
   baochch@bjut.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61831019, 61471014]}},
Funding-Text = {{This work was supported by the National Natural Science Foundation of
   China (Grant No. 61831019 and No. 61471014). The authors are also
   grateful to the thorough reviewers.}},
Cited-References = {{BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550.
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453.
   Garofolo J.S., 1993, NASA STI RECON TECHN, V93.
   Glorot X., 2011, P 14 INT C ART INT S, P315, DOI DOI 10.1177/1753193410395357.
   Goodfellow Ian J., 2013, ARXIV13024389.
   He K., DEEP RESIDUAL LEARNI, P770.
   Kang G. S., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8), P244.
   Kingma D. P., 2015, 14126980 ARXIV, V3, P1, DOI DOI 10.1145/1830483.1830503.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI DOI 10.1145/3065386.
   Kuropatwinski M, 2001, INT CONF ACOUST SPEE, P669, DOI 10.1109/ICASSP.2001.940920.
   Li Z, 1999, IEEE T SPEECH AUDI P, V7, P91, DOI 10.1109/89.736335.
   Liou CY, 2014, NEUROCOMPUTING, V139, P84, DOI 10.1016/j.neucom.2013.09.055.
   Loizou PC, 2013, SPEECH ENHANCEMENT T.
   Lu XG, 2013, INTERSPEECH, P436.
   Mohammadiha N, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P45, DOI 10.1109/ASPAA.2011.6082303.
   Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038.
   Nie S, 2018, IEEE-ACM T AUDIO SPE, V26, P2043, DOI 10.1109/TASLP.2018.2851151.
   Pascual S, 2017, ARXIV170309452.
   Reddy CKA, 2017, IEEE SIGNAL PROC LET, V24, P1601, DOI 10.1109/LSP.2017.2750979.
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935.
   Weng J. J., 1993, {[}1993] Proceedings Fourth International Conference on Computer Vision, P121, DOI 10.1109/ICCV.1993.378228.
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452.
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240.
   Yang Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2901, DOI 10.1109/ICASSP.2018.8462563.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BN4NP}},
Unique-ID = {{ISI:000482554007023}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000482554007054,
Author = {Lu, Chunhui and Zhang, Pengyuan and Yan, Yonghong},
Book-Group-Author = {{IEEE}},
Title = {{SELF-ATTENTION BASED PROSODIC BOUNDARY PREDICTION FOR CHINESE SPEECH
   SYNTHESIS}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2019}},
Pages = {{7035-7039}},
Note = {{44th IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Brighton, ENGLAND, MAY 12-17, 2019}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Predicting prosodic boundaries from input text plays an important role
   in Chinese text-to-speech (TTS) system, which directly influences the
   naturalness and intelligibility of synthesized speech. In this paper, we
   propose to combine self-attention with multitask learning for prosodic
   boundary prediction. Self-attention is used to capture the dependency
   between two arbitrary characters in the input sentence, while multitask
   learning models the relationships between prosodic boundaries and
   lexicon words by setting word segmentation as an auxiliary task. The
   proposed method can generate prosodic boundary labels directly from
   Chinese characters and achieve the whole process end-to-end.
   Experimental results show the effectiveness of our proposed model and
   prove that the performance can be further improved by pretraining the
   model with extra word segmentation data.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, PY (Corresponding Author), Inst Acoust, Key Lab Speech Acoust \& Content Understanding, Beijing, Peoples R China.
   Zhang, PY (Corresponding Author), Univ Chinese Acad Sci, Beijing, Peoples R China.
   Lu, Chunhui; Zhang, Pengyuan; Yan, Yonghong, Inst Acoust, Key Lab Speech Acoust \& Content Understanding, Beijing, Peoples R China.
   Lu, Chunhui; Zhang, Pengyuan; Yan, Yonghong, Univ Chinese Acad Sci, Beijing, Peoples R China.
   Yan, Yonghong, Chinese Acad Sci, Xinjiang Key Lab Minor Speech \& Language Informat, Xinjiang Tech Inst Phys \& Chem, Beijing, Peoples R China.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-8131-1}},
Keywords = {{prosodic boundary prediction; self-attention; multitask learning; speech
   synthesis}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}11590773, 11590770]; Pre-research Project
   for Equipment of General Information System {[}JZX2017-0994/Y306]}},
Funding-Text = {{This work is partially supported by the National Natural Science
   Foundation of China (Nos. 11590773, 11590770), the Pre-research Project
   for Equipment of General Information System (No. JZX2017-0994/Y306).}},
Cited-References = {{Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265.
   Ba J. Lei, 2016, ARXIV160706450.
   CHU M, 2001, COMPUT LINGUIST, V6, P61.
   Ding C, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P98, DOI 10.1109/ASRU.2015.7404780.
   Emerson T., 2005, 4 SIGHAN WORKSH CHIN.
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944.
   Huang YC, 2017, INTERSPEECH, P779, DOI 10.21437/Interspeech.2017-949.
   Kingma D.P., 2015, P ICLR.
   Levow G., 2008, P IJCNLP, P217.
   Li Jianfeng, 2004, INT 2004 JEJ ISL KOR, P729.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   {[}聂鑫 Nie Xin], 2003, {[}中文信息学报, Journal of Chinese Information Processing], V17, P39.
   Rendel A, 2016, INT CONF ACOUST SPEE, P5655, DOI 10.1109/ICASSP.2016.7472760.
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929.
   Strubell E, 2018, P EMNLP.
   Tan Z., 2018, P AAAI.
   Vaswani A., 2017, ADV NEURAL INFORM PR, P5998, DOI DOI 10.1017/S0140525X16001837.
   Vinod N., 2010, ICML, P807, DOI DOI 10.0RG/PAPERS/432.PDF.
   Wang M., 1991, HLT 91, P378.
   Yao Qian, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P135, DOI 10.1109/ISCSLP.2010.5684835.
   Zheng YB, 2018, INTERSPEECH, P47.
   Zheng YB, 2016, INTERSPEECH, P3201, DOI 10.21437/Interspeech.2016-1060.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BN4NP}},
Unique-ID = {{ISI:000482554007054}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000482554007098,
Author = {Serai, Prashant and Wang, Peidong and Fosler-Lussier, Eric},
Book-Group-Author = {{IEEE}},
Title = {{IMPROVING SPEECH RECOGNITION ERROR PREDICTION FOR MODERN AND
   OFF-THE-SHELF SPEECH RECOGNIZERS}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2019}},
Pages = {{7255-7259}},
Note = {{44th IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Brighton, ENGLAND, MAY 12-17, 2019}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Modeling the errors of a speech recognizer can help simulate errorful
   recognized speech data from plain text, which has proven useful for
   tasks like discriminative language modeling, improving robustness of NLP
   systems, where limited or even no audio data is available at train time.
   Previous work typically considered replicating behavior of GMM-HMM based
   systems, but the behavior of more modern posterior-based neural network
   acoustic models is not the same and requires adjustments to the error
   prediction model. In this work, we extend a prior phonetic confusion
   based model for predicting speech recognition errors in two ways: first,
   we introduce a sampling-based paradigm that better simulates the
   behavior of a posterior-based acoustic model. Second, we investigate
   replacing the confusion matrix with a sequence-to-sequence model in
   order to introduce context dependency into the prediction. We evaluate
   the error predictors in two ways: first by predicting the errors made by
   a Switchboard ASR system on unseen data (Fisher), and then using that
   same predictor to estimate the behavior of an unrelated cloud-based ASR
   system on a novel task. Sampling greatly improves predictive accuracy
   within a 100-guess paradigm, while the sequence model performs similarly
   to the confusion matrix.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Serai, P (Corresponding Author), Ohio State Univ, Dept Comp Sci \& Engn, Columbus, OH 43210 USA.
   Serai, Prashant; Wang, Peidong; Fosler-Lussier, Eric, Ohio State Univ, Dept Comp Sci \& Engn, Columbus, OH 43210 USA.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-8131-1}},
Keywords = {{Speech Recognition; Error Prediction; Low Resource; Sequence to Sequence
   Neural Networks; Simulated ASR Errors}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
ORCID-Numbers = {{Fosler-Lussier, Eric/0000-0001-8004-5169}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}1618336]; NVIDIA Corporation}},
Funding-Text = {{This material is based upon work supported by the National Science
   Foundation under Grant No. 1618336. We gratefully acknowledge the
   support of NVIDIA Corporation with the donation of the Quadro P6000 GPU
   used for this research. Additional computing resources provided by the
   Ohio Supercomputer Center {[}21]. We thank Adam Stiff for sharing the
   paired text and speech recognized data from the Virtual Patient project
   for our experiments.}},
Cited-References = {{Anguita J, 2005, IEEE SIGNAL PROC LET, V12, P585, DOI 10.1109/LSP.2005.851256.
   Bahdanau D., 2014, ARXIV14090473.
   Cantab Research, 2015, CANT TEDL LANG MOD L.
   Cieri C., 2004, L REC, P69.
   Fosler-Lussier E, 2005, SPEECH COMMUN, V46, P153, DOI 10.1016/j.specom.2005.03.003.
   Jin Lifeng, 2017, P 12 WORKSH INN US N, P11, DOI DOI 10.18653/V1/W17-4715.PDF.
   Jyothi P, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1049.
   Jyothi Preethi, 2009, 10 ANN C INT SPEECH.
   Kurata G, 2011, INT CONF ACOUST SPEE, P5576.
   Li Xiang, 2018, ARXIV181100728.
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790.
   Mohri M., 2002, 7 INT C SPOK LANG PR.
   Rousseau A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3935.
   Ruiz N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2247.
   Sagae K, 2012, INT CONF ACOUST SPEE, P5001, DOI 10.1109/ICASSP.2012.6289043.
   Stiff Adam, 2019 IEEE INT UNPUB.
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.1007/S10107-014-0839-0.
   Tan QF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2442.
   Tsvetkov Y, 2014, P EACL, P616.
   Vesely K, 2013, INTERSPEECH, P2344.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BN4NP}},
Unique-ID = {{ISI:000482554007098}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000482554007101,
Author = {Yi, Jiangyan and Tao, Jianhua},
Book-Group-Author = {{IEEE}},
Title = {{SELF-ATTENTION BASED MODEL FOR PUNCTUATION PREDICTION USING WORD AND
   SPEECH EMBEDDINGS}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2019}},
Pages = {{7270-7274}},
Note = {{44th IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Brighton, ENGLAND, MAY 12-17, 2019}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{This paper proposes to use self-attention based model to predict
   punctuation marks for word sequences. The model is trained using word
   and speech embedding features which are obtained from the
   pre-trainedWord2Vec and Speech2Vec, respectively. Thus, the model can
   use any kind of textual data and speech data. Experiments are conducted
   on English IWSLT2011 datasets. The results show that the self-attention
   based model trained using word and speech embedding features outperforms
   the previous state-of-the-art single model by up to 7.8\% absolute
   overall F-1-score. The results also show that it obtains performance
   improvement by up to 4.7\% absolute overall F-1-score against the
   previous best ensemble model.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Yi, JY (Corresponding Author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   Yi, Jiangyan; Tao, Jianhua, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   Tao, Jianhua, Chinese Acad Sci, CAS Ctr Excellence Brain Sci \& Intelligence Techn, Beijing, Peoples R China.
   Tao, Jianhua, Univ Chinese Acad Sci, Beijing, Peoples R China.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-8131-1}},
Keywords = {{Self-attention; transfer learning; word embedding; speech embedding;
   punctuation prediction}},
Keywords-Plus = {{RECOGNITION; SYSTEM}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{jiangyan.yi@nlpr.ia.ac.cn
   jhtao@nlpr.ia.ac.cn}},
Funding-Acknowledgement = {{National Key Research \& Development Plan of China {[}2017YFC0820602];
   National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) {[}61425017, 61831022, 61773379,
   61771472]; Inria-CAS Joint Research Project {[}173211KYSB20170061]}},
Funding-Text = {{This work is supported by the National Key Research \& Development Plan
   of China (No. 2017YFC0820602) and the National Natural Science
   Foundation of China (NSFC) (No. 61425017, No. 61831022, No. 61773379,
   No. 61771472), and Inria-CAS Joint Research Project (No.
   173211KYSB20170061)}},
Cited-References = {{Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265.
   BEEFERMAN D, 1998, ACOUST SPEECH SIG PR, P689.
   Bell P., 2015, AUTOMATIC SPEECH REC.
   Che XY, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P654.
   Che XY, 2016, INTERSPEECH, P2528, DOI 10.21437/Interspeech.2016-257.
   Cho E., 2012, SEGMENTATION PUNCTUA, P252.
   Christensen D, 2006, CHANGING EUROPEAN FARMING SYSTEMS FOR A BETTER FUTURE: NEW VISIONS FOR RURAL AREAS, P35.
   Chung YA, 2018, INTERSPEECH, P811, DOI 10.21437/Interspeech.2018-2341.
   Driesen J., 2014, AUTOMATED PRODUCTION, P2146.
   Gravano A, 2009, INT CONF ACOUST SPEE, P4741, DOI 10.1109/ICASSP.2009.4960690.
   Hasan M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P349.
   Kim JH, 2003, SPEECH COMMUN, V41, P563, DOI 10.1016/S0167-6393(03)00049-9.
   Kingma D. P., 2015, ICLR.
   Klejch O, 2017, INT CONF ACOUST SPEE, P5700, DOI 10.1109/ICASSP.2017.7953248.
   Klejch O, 2016, IEEE W SP LANG TECH, P433, DOI 10.1109/SLT.2016.7846300.
   Kol J., 2012, INTERSPEECH, P1376.
   Liu Y, 2006, IEEE T AUDIO SPEECH, V14, P1526, DOI 10.1109/TASL.2006.878255.
   Lu Wei, 2010, P 2010 C EMP METH NA, P177.
   Mikolov T., 2013, COMPUTER SCI.
   Peitz Stephan, 2011, IWSLT, P238.
   Tilk O, 2016, INTERSPEECH, P3047, DOI 10.21437/Interspeech.2016-1517.
   Tilk O, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P683.
   Ueffing N, 2013, INTERSPEECH, P3096.
   Vaswani A, 2017, NIPS.
   Yi JY, 2017, INTERSPEECH, P2779, DOI 10.21437/Interspeech.2017-1079.
   Zelasko P, 2018, INTERSPEECH, P2633, DOI 10.21437/Interspeech.2018-1096.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BN4NP}},
Unique-ID = {{ISI:000482554007101}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000465405500005,
Author = {Yun, Hyungbin and Sim, Ghudae and Seok, Junhee},
Book-Group-Author = {{IEEE}},
Title = {{Stock Prices Prediction using the Title of Newspaper Articles with
   Korean Natural Language Processing}},
Booktitle = {{2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN
   INFORMATION AND COMMUNICATION (ICAIIC 2019)}},
Year = {{2019}},
Pages = {{19-21}},
Note = {{1st International Conference on Artificial Intelligence in Information
   and Communication (ICAIIC), Okinawa, JAPAN, FEB 11-13, 2019}},
Organization = {{IEEE; IEEE Commun Soc; Korean Inst Commmun \& Informat Sci; ICICE Commun
   Soc; Elect \& Telecommunicat Res Inst; Korea Elect Technol Inst; Inst
   Informat \& Commun Technol Planning \& Evaluat; Samsung Elect; LG Elect;
   KT; SK Telecom; LG U+; Sensors; Multi Screen Serv Forum; Soc Safety Syst
   Forum; Kookmin Univ, Internet Energy Res Ctr; Kyungpook Natl Univ, Ctr
   ICT \& Automot Convergence; Kookmin Univ, LED Convergence Res Ctr;
   Kookmin Univ, Telemat Res Ctr; Kookmin Univ, Hybrid Device Based
   Circadian ICT Res Ctr}},
Abstract = {{Non-quantitative data have a significant impact on the financial market
   as well as quantitative data. In this paper, we propose CNN model of
   stock price prediction using Korean natural language processing. In the
   case of Korean natural language processing research was not actively
   performed compared to English language. We converted Korean sentences
   into nouns and vectorized them using skip-grams to extract the
   characteristics of the words. Then, the vectorized word sentence was
   used as input data of the CNN model to predict the stock price after 5
   days of trading day. Most models have more than 50\% prediction accuracy
   for stock price up and down. The highest accuracy of the model was about
   53\%. Since the result is not considerable but meaningful, it shows the
   possibility of developing the stock price prediction model through
   Korean natural language processing in the future.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Seok, J (Corresponding Author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
   Yun, Hyungbin; Sim, Ghudae; Seok, Junhee, Korea Univ, Sch Elect Engn, Seoul, South Korea.}},
ISBN = {{978-1-5386-7822-0}},
Keywords = {{artificial neural network; Korean natural language processing;
   skip-gram; convolution neural network; stock price prediction}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Telecommunications}},
Author-Email = {{hb\_yun@korea.ac.kr
   ghudaesim@korea.ac.kr
   jseok14@korea.ac.kr}},
Funding-Acknowledgement = {{National Research Foundation of KoreaNational Research Foundation of
   Korea {[}NRF-2017R1C1B2002850]; Korea University {[}K1822271]; Mirae
   Asset Global Investment}},
Funding-Text = {{This work was supported by the National Research Foundation of Korea
   grant (NRF-2017R1C1B2002850) and Korea University grant (K1822271) as
   well as a grant from Mirae Asset Global Investment. Correspondence
   should be addressed to jseok14@korea.ac.kr.}},
Cited-References = {{Adebiyi Ayodele Ariyo, 2014, J APPL MATH, V2014.
   Altay E., 2005, J FINANCIAL MANAGEME, V18, P18.
   Cao LJ, 2003, IEEE T NEURAL NETWOR, V14, P1506, DOI 10.1109/TNN.2003.820556.
   Ding X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2327.
   Freitas FD, 2009, NEUROCOMPUTING, V72, P2155, DOI 10.1016/j.neucom.2008.08.019.
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647.
   Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Kumar M., 2006, FORECASTING STOCK IN.
   Mikolov Tomas, 2013, ARXIV13013781.
   Nelson DMQ, 2017, IEEE IJCNN, P1419, DOI 10.1109/IJCNN.2017.7966019.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BM5QM}},
Unique-ID = {{ISI:000465405500005}},
DA = {{2020-12-06}},
}

@article{ ISI:000468224300005,
Author = {Popukaylo, Vladimir},
Title = {{Predicting the occurrence of strokes using the language R}},
Journal = {{COMPUTER SCIENCE JOURNAL OF MOLDOVA}},
Year = {{2019}},
Volume = {{27}},
Number = {{1}},
Pages = {{73-84}},
Abstract = {{Probability of stroke is analyzed based on data from Stroke.md system.
   Selection of features that significantly affect target variable was
   made. To solve the problem, classification algorithms are used: support
   vector machines, logistic regression, decision trees, random forest and
   others; comparison of the resulting mathematical models; preprocessing
   and building models produced in R-language.}},
Publisher = {{INST MATHEMATICS \& COMPUTER SCIENCE ACAD}},
Address = {{ACADEMIEI 5, CHISINAU, KISHINEV, 2028, MOLDOVA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Popukaylo, V (Corresponding Author), TG Shevchenko Transnistrian State Univ, Vladimir Andrunakievich Inst Math \& Comp Sci, Str Vosstania 2a,Cab 311B, Tiraspol, Moldova.
   Popukaylo, Vladimir, TG Shevchenko Transnistrian State Univ, Vladimir Andrunakievich Inst Math \& Comp Sci, Str Vosstania 2a,Cab 311B, Tiraspol, Moldova.}},
ISSN = {{1561-4042}},
Keywords = {{mathematical modeling; stroke prediction; data analysis; Stroke.md}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{vsp.science@gmail.com}},
ResearcherID-Numbers = {{Popukaylo, Vladimir/L-7533-2016}},
ORCID-Numbers = {{Popukaylo, Vladimir/0000-0001-7742-7959}},
Funding-Acknowledgement = {{National Agency of Research and Development (NARD) {[}17.000418.80.07A]}},
Funding-Text = {{This work was supported by National Agency of Research and Development
   (NARD) project Ref. Nr. 17.000418.80.07A}},
Cited-References = {{Cojocaru S., 2018, P MFOI 2018, P51.
   Groppa S, 2017, J NEUROL SCI, V381, P411, DOI 10.1016/j.jns.2017.08.3373.
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05.
   RC Team, 2019, R LANG DEF.
   Zamsa E., 2015, 2015 E HLTH BIOENG C, P1.}},
Number-of-Cited-References = {{5}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Comput. Sci. J. Mold.}},
Doc-Delivery-Number = {{HY6FE}},
Unique-ID = {{ISI:000468224300005}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000466215600001,
Author = {Zhang, Yumei and Rong, Yuying and Yan, Chengling and Liu, Jiangshan and
   Wu, Xiaojun},
Title = {{Kernel Estimation of Volterra Using an Adaptive Artificial Bee Colony
   Optimization and Its Application to Speech Signal Multi-Step Prediction}},
Journal = {{IEEE ACCESS}},
Year = {{2019}},
Volume = {{7}},
Pages = {{49048-49058}},
Abstract = {{In order to solve parameters selection problem when applying recursive
   least square (RLS), least mean square (LMS) or normalized LMS (NLMS)
   algorithms to estimate kernels of second-order Volterra filter (SOVF), a
   novel adaptive gbest-guide artificial bee colony (AGABC) optimization
   algorithm is used to derive kernels of Volterra, that is a type of the
   AGABC-SOVF prediction model with an explicit configuration for speech
   signal is proposed. The AGABC algorithm modifies the solution search
   equation of ABC algorithm and combines the best solution with
   neighborhood information at present iteration, which not only ensures
   the exploration of the global optimization algorithm but also improves
   the exploitation. The AGABC-SOVF model is performed to predict speech
   signal series of the given English phonemes, sentences, and chaotic time
   series. Simulation results based on benchmark function show that AGABC
   algorithm performs faster convergence in achieving higher quality
   solutions than original ABC and other improved ABC algorithms.
   Prediction results of applying the AGABC-SOVF model to multi-step
   predictions for Lorenz time series reveal its stability and convergence
   properties. For the measured multi-frame speech signals, prediction
   accuracy and length of multi-step prediction using the AGABC-SOVF model
   are better than that of the ABC-SOVF model. The AGABC-SOVF model can
   better predict chaotic time series and the real measured speech signal
   series.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Shaanxi, Peoples R China.
   Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.
   Zhang, Yumei; Wu, Xiaojun, Shaanxi Normal Univ, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Shaanxi, Peoples R China.
   Zhang, Yumei; Rong, Yuying; Liu, Jiangshan; Wu, Xiaojun, Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.
   Yan, Chengling, Shandong Univ, Sch Environm Sci, Qingdao 266000, Shandong, Peoples R China.}},
DOI = {{10.1109/ACCESS.2018.2880280}},
ISSN = {{2169-3536}},
Keywords = {{Speech signal; kernel estimation; Volterra model; ABC algorithm;
   multi-step prediction}},
Keywords-Plus = {{ALGORITHM; SYSTEM}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{xjwu@snnu.edu.cn}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2017YFB1402102]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}11872036, 11502133,
   11772178, 11372167]; 111 ProjectMinistry of Education, China - 111
   Project {[}B18032]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   {[}GK201703082, GK201801004]}},
Funding-Text = {{This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB1402102, in part by the
   National Natural Science Foundation of China under Grant 11872036, Grant
   11502133, Grant 11772178, and Grant 11372167, in part by the 111 Project
   under Grant B18032, and in part by the Fundamental Research Funds for
   the Central Universities under Grant GK201703082 and Grant GK201801004.}},
Cited-References = {{Aghdam MH, 2009, EXPERT SYST APPL, V36, P6843, DOI 10.1016/j.eswa.2008.08.022.
   Bansal Jagdish Chand, 2013, International Journal of Advanced Intelligence Paradigms, V5, P123.
   Batista ELO, 2012, SIGNAL PROCESS, V92, P2381, DOI 10.1016/j.sigpro.2012.02.011.
   Birkelund Y, 2003, INT J OFFSHORE POLAR, V13, P12.
   BOYD S, 1985, IEEE T CIRCUITS SYST, V32, P1150, DOI 10.1109/TCS.1985.1085649.
   Cheng CH, 2001, IEEE T SIGNAL PROCES, V49, P147, DOI 10.1109/78.890357.
   Eberhart R. C., 2001, SWARM INTELLIGENCE.
   Fahad S. A. M., 2012, SYST C SYSCON 2012 I, P1, DOI DOI 10.1109/SYSCON.2012.6189539.
   Gao WF, 2012, J COMPUT APPL MATH, V236, P2741, DOI 10.1016/j.cam.2012.01.013.
   Guerin A, 2003, IEEE T SPEECH AUDI P, V11, P672, DOI 10.1109/TSA.2003.818077.
   Huang C. -M., IEEE ACCESS.
   Imanian N, 2014, ENG APPL ARTIF INTEL, V36, P148, DOI 10.1016/j.engappai.2014.07.012.
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x.
   Kohli AK, 2013, CIRC SYST SIGNAL PR, V32, P223, DOI 10.1007/s00034-012-9445-7.
   Liu JS, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P211, DOI 10.1109/CIS.2017.00053.
   Luo J, 2013, APPL MATH COMPUT, V219, P10253, DOI 10.1016/j.amc.2013.04.001.
   Mathews V., 2000, POLYNOMIAL SIGNAL PR.
   Patel SK, 2017, IEEE J EM SEL TOP P, V5, P559, DOI 10.1109/JESTPE.2016.2633481.
   Sabry-Rizk M, 2000, PROC SPIE, V4116, P322, DOI 10.1117/12.406510.
   Sigrist Z, 2012, SIGNAL PROCESS, V92, P1010, DOI 10.1016/j.sigpro.2011.10.013.
   Wei Jian, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P3900, DOI 10.1109/ICIEA.2009.5138938.
   Xinling Wen, 2013, INDONESIAN J ELECT E, V11, P2277.
   Yang HH, 2018, IEEE ACCESS, V6, P42264, DOI 10.1109/ACCESS.2018.2855703.
   Zhang H, 2016, J CHINA ACAD ELECT I, V11, P1.
   Zhu GP, 2010, APPL MATH COMPUT, V217, P3166, DOI 10.1016/j.amc.2010.08.049.
   1999, IEEE T SIGNAL PROCES, V47, P579.
   2008, EXPERT SYST APPL, V34, P1905, DOI DOI 10.1016/J.ESWA.2007.02.002.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{HV8FC}},
Unique-ID = {{ISI:000466215600001}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000460647500017,
Author = {Bhuyan, M. P. and Sarma, S. K.},
Title = {{An N-gram based model for predicting of word-formation in Assamese
   language}},
Journal = {{JOURNAL OF INFORMATION \& OPTIMIZATION SCIENCES}},
Year = {{2019}},
Volume = {{40}},
Number = {{2, SI}},
Pages = {{427-440}},
Abstract = {{Word prediction is a technique which try to suggest the word by
   observing the previous input letters or words in any text editor. At
   present there is no such software or tool in Assamese which can predict
   the future word(s) of a sentence. This method helps the people who are
   not very much expert in typing and this research aims to reduce the gap
   between the people who are very much expert in typing with the people
   who are differently abled or the people who are not the daily users of
   the computer system. To predict the words, N-gram based models like
   unigram, bigram, trigram and quadrigram are used in this work. After
   doing two different level of experiments and testing maximum keystrokes
   saving (KS) 74.04\% and 48.28\% are found for preconfigured data-set and
   user-input data respectively. The results indicate a significant level
   of improvement towards sentence completion with the help of prediction
   method in Assamese language.}},
Publisher = {{ANALYTIC PUBL CO}},
Address = {{F-23 MODEL TOWN, DELHI 110 009, INDIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bhuyan, MP (Corresponding Author), Gauhati Univ, Dept Informat Technol, Gauhati 781014, Assam, India.
   Bhuyan, M. P.; Sarma, S. K., Gauhati Univ, Dept Informat Technol, Gauhati 781014, Assam, India.}},
DOI = {{10.1080/02522667.2019.1580883}},
ISSN = {{0252-2667}},
EISSN = {{2169-0103}},
Keywords = {{n-gram; Prediction-system; Keystrokes saving (KS); Keystrokes Until
   Completion (KUC); Backoff model}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Author-Email = {{mpratim250@gmail.com
   sks001@gmail.com}},
Cited-References = {{Abbas Q., 2014, INT J INTELL SYST, V7, P94, DOI {[}10.5815/ijisa.2015.01.09, DOI 10.5815/IJISA.2015.01.09].
   Aliprandi C., 1981, J MOL BIOL, V147, P195, DOI {[}10.1016/0022-2836(81)90087-5, DOI 10.1016/0022-2836(81)90087-5].
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084.
   Bickel Steffen, 2005, P C EMP METH NAT LAN.
   Cavalieri DC, 2016, IEEE-ACM T AUDIO SPE, V24, P1481, DOI 10.1109/TASLP.2016.2547743.
   Ghayoomi M, 2009, IEEE SYS MAN CYBERN, P5083, DOI 10.1109/ICSMC.2009.5346027.
   Ghayoomi Masood, 1970, POS BASED WORD PREDI, P138, DOI {[}10.1007/978-3- 540-85287-2\_14, DOI 10.1007/978-3-540-85287-2\_14].
   Goswami G. C., 1982, STRUCTURE ASSAMESE.
   Goulart Henrique X., 2018, CORR.
   Habib Md Tarek, 2018, International Journal of Intelligent Systems and Applications, V10, P47, DOI 10.5815/ijisa.2018.02.05.
   Haque M., 2015, INT J FUNDATION COMP, V5.
   Saharia N, 2012, P 2 WORKSH ADV TEXT, P79.
   Saharia N, 2011, LANGUAGE INDIA, V11.
   Troiano L, 2017, SOFT COMPUT, V21, P1583, DOI 10.1007/s00500-015-1870-7.
   Wiegand Karl, 2012, P 3 WORKSH SPEECH LA, P28.
   Yu Seunghak, 2018, COLING 2018, P128.
   Zagler W.L., 2003, ASSIST TECHNOL, V11, P964.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{J. Inform. Optim. Science}},
Doc-Delivery-Number = {{HO1EF}},
Unique-ID = {{ISI:000460647500017}},
DA = {{2020-12-06}},
}

@article{ ISI:000453259200002,
Author = {Friend, Margaret and Smolak, Erin and Patrucco-Nanchen, Tamara and
   Poulin-Dubois, Diane and Zesiger, Pascal},
Title = {{Language Status at Age 3: Group and Individual Prediction From
   Vocabulary Comprehension in the Second Year}},
Journal = {{DEVELOPMENTAL PSYCHOLOGY}},
Year = {{2019}},
Volume = {{55}},
Number = {{1}},
Pages = {{9-22}},
Month = {{JAN}},
Abstract = {{The present research extends recent work on the prediction of preschool
   language skills by exploring prediction from decontextualized vocabulary
   comprehension. Vocabulary comprehension was a stronger predictor than
   parent-reported production, yielding a quadrupling of variance accounted
   for relative to prior studies. Parallel studies (Studies 1 and 2) are
   reported for two linguistically and geographically distinct samples. In
   both samples, decontextualized vocabulary comprehension late in the
   second year provided the best balance between model fit and parsimony in
   predicting language skills at age three. In Study 3, vocabulary
   comprehension prospectively identified children with low language status
   2 years earlier than other prospective studies but with similar
   sensitivity and specificity. The present paper provides evidence on
   three questions of practical and theoretical significance: the relation
   between decontextualized vocabulary prior to 30 months of age and
   language outcomes, how prediction from decontextualized vocabulary
   compares with parent-reported vocabulary, and finally how early stable
   predictions to language outcomes can be made.}},
Publisher = {{AMER PSYCHOLOGICAL ASSOC}},
Address = {{750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Friend, M (Corresponding Author), San Diego State Univ, Dept Psychol, 6505 Alvarado Rd,Suite 101, San Diego, CA 92120 USA.
   Friend, Margaret, San Diego State Univ, Dept Psychol, 6505 Alvarado Rd,Suite 101, San Diego, CA 92120 USA.
   Smolak, Erin, San Diego State Univ, Joint Doctoral Program Language \& Communicat Diso, San Diego, CA 92182 USA.
   Smolak, Erin, Univ Calif San Diego, San Diego, CA 92103 USA.
   Patrucco-Nanchen, Tamara; Zesiger, Pascal, Univ Geneva, Psychol \& Sci Educ, Geneva, Switzerland.
   Poulin-Dubois, Diane, Concordia Univ, Dept Psychol, Montreal, PQ, Canada.}},
DOI = {{10.1037/dev0000617}},
ISSN = {{0012-1649}},
EISSN = {{1939-0599}},
Keywords = {{comprehension; Cross-Language; practical significance; prediction}},
Keywords-Plus = {{SENTENCE REPETITION; LEXICAL DEVELOPMENT; LATE-TALKING; MEAN LENGTH;
   CHILDREN; VALIDITY; SKILLS; DELAY; KNOWLEDGE; OUTCOMES}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Developmental}},
Author-Email = {{mfriend@sdsu.edu}},
ORCID-Numbers = {{Friend, Margaret/0000-0002-5477-041X
   Smolak, Erin/0000-0002-4477-7327}},
Funding-Acknowledgement = {{NICHDUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health \& Human Development (NICHD) {[}R01HD468058];
   NIDCDUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness \&
   Other Communication Disorders (NIDCD) {[}T32DC00736]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health \& Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness \& Other Communication Disorders (NIDCD)
   {[}T32DC007361, T32DC007361, T32DC007361] Funding Source: NIH RePORTER}},
Funding-Text = {{We gratefully acknowledge Laura Alaria, Kristi Hendrickson, and Danielle
   Rosen for assistance in data collection and coding and all of our
   participant families. This research was supported by NICHD R01HD468058
   and NIDCD T32DC00736 and does not necessarily represent the views of the
   National Institutes of Health.}},
Cited-References = {{American Speech and Hearing Association, 2017, SPOK LANG DIS.
   Armon-Lotem S, 2016, INT J LANG COMM DIS, V51, P715, DOI 10.1111/1460-6984.12242.
   Bion RAH, 2013, COGNITION, V126, P39, DOI 10.1016/j.cognition.2012.08.008.
   Bleses D, 2008, J CHILD LANG, V35, P619, DOI 10.1017/S0305000908008714.
   Bleses D, 2016, APPL PSYCHOLINGUIST, V37, P1461, DOI 10.1017/S0142716416000060.
   Bornstein MH, 2017, CHILD DEV PERSPECT, V11, P113, DOI 10.1111/cdep.12221.
   Bornstein MH, 2016, DEV PSYCHOL, V52, P704, DOI 10.1037/dev0000111.
   Conti-Ramsden G, 2001, J CHILD PSYCHOL PSYC, V42, P741, DOI 10.1111/1469-7610.00770.
   Dale PS, 2003, J SPEECH LANG HEAR R, V46, P544, DOI 10.1044/1092-4388(2003/044).
   Dapretto M, 2000, CHILD DEV, V71, P635, DOI 10.1111/1467-8624.00172.
   DeAnda S, 2016, J SPEECH LANG HEAR R, V59, P1346, DOI 10.1044/2016\_JSLHR-L-15-0234.
   Dethorne LS, 2005, CLIN LINGUIST PHONET, V19, P635, DOI 10.1080/02699200410001716165.
   Devescovi A, 2007, INT J LANG COMM DIS, V42, P187, DOI 10.1080/13682820601030686.
   Dickinson DK, 2010, EDUC RESEARCHER, V39, P305, DOI 10.3102/0013189X10370204.
   Duff FJ, 2015, J CHILD PSYCHOL PSYC, V56, P848, DOI 10.1111/jcpp.12378.
   Dunn L., 1993, ECHELLE VOCABULAIRE.
   Dunn L. M., 1997, PPVT III PEABODY PIC.
   Eriksson M, 2010, RES DEV DISABIL, V31, P943, DOI 10.1016/j.ridd.2010.04.019.
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146.
   Fenson L., 2007, MACARTHUR BATES COMM.
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1.
   Fernald A, 2012, CHILD DEV, V83, P203, DOI 10.1111/j.1467-8624.2011.01692.x.
   Frank MC, 2017, J CHILD LANG, V44, P677, DOI 10.1017/S0305000916000209.
   Friend M, 2003, BEHAV RES METH INS C, V35, P302, DOI 10.3758/BF03202556.
   Friend M., 2011, ENFANCE, V2011, P329, DOI {[}DOI 10.4074/S0013754511003041, 10.4074/S0013754511003053].
   Friend M, 2008, J CHILD LANG, V35, P77, DOI 10.1017/S0305000907008264.
   Friend M, 2018, DEV PSYCHOL, V54, P1317, DOI 10.1037/dev0000514.
   Friend M, 2012, DEV PSYCHOL, V48, P136, DOI 10.1037/a0025511.
   Frisk V, 2009, INFANT YOUNG CHILD, V22, P290, DOI 10.1097/IYC.0b013e3181bc4db6.
   Gershkoff-Stowe L, 2013, J EXP CHILD PSYCHOL, V114, P489, DOI 10.1016/j.jecp.2012.11.005.
   Ghassabian A, 2014, ACTA PAEDIATR, V103, P70, DOI 10.1111/apa.12449.
   Heilmann J, 2005, AM J SPEECH-LANG PAT, V14, P40, DOI 10.1044/1058-0360(2005/006).
   Hendrickson K, 2017, J EXP CHILD PSYCHOL, V158, P95, DOI 10.1016/j.jecp.2017.01.003.
   Hendrickson K, 2015, DEVELOPMENTAL SCI, V18, P723, DOI 10.1111/desc.12250.
   Henrichs J, 2011, J SPEECH LANG HEAR R, V54, P854, DOI 10.1044/1092-4388(2010/09-0255).
   Hewitt LE, 2005, J COMMUN DISORD, V38, P197, DOI 10.1016/j.jcomdis.2004.10.002.
   Hilbe J. M., 2011, NEGATIVE BINOMIAL RE.
   HIRSHPASEK K, 1996, LANG SPEECH \& COMMUN, P105.
   Hoff E, 2013, DEV PSYCHOL, V49, P4, DOI 10.1037/a0027238.
   Kemp N, 2017, APPL PSYCHOLINGUIST, V38, P289, DOI 10.1017/S0142716416000199.
   Kern S., 2010, INVENTAIRE FRANCAIS.
   Kern S., 2007, FIRST LANG, V27, P227, DOI DOI 10.1177/0142723706075789.
   Kern S., 2003, GLOSSA, V85, P48.
   Klee T, 2000, J SPEECH LANG HEAR R, V43, P821, DOI 10.1044/jslhr.4304.821.
   Klee T, 1998, J SPEECH LANG HEAR R, V41, P627, DOI 10.1044/jslhr.4103.627.
   Klem M, 2015, DEVELOPMENTAL SCI, V18, P146, DOI 10.1111/desc.12202.
   Law J, 2000, DEV MED CHILD NEUROL, V42, P190, DOI 10.1017/S0012162200000335.
   Law J, 2008, CHILD ADOL MENT H-UK, V13, P198, DOI 10.1111/j.1475-3588.2008.00503.x.
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x.
   Mayor J, 2010, PSYCHOL REV, V117, P1, DOI 10.1037/a0018130.
   McIntyre LL, 2017, J PEDIATR-US, V181, P189, DOI 10.1016/j.jpeds.2016.10.035.
   McKean C, 2016, INT J EARLY CHILD, V48, P329, DOI DOI 10.1007/S13158-016-0174-0.
   McKean C, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-1684.
   Miller J. F, 2012, SYSTEMATIC ANAL LANG.
   MILLER JF, 1981, J SPEECH HEAR RES, V24, P154, DOI 10.1044/jshr.2402.154.
   Morgan PL, 2015, CHILD DEV, V86, P1351, DOI 10.1111/cdev.12398.
   Oakhill JV, 2012, SCI STUD READ, V16, P91, DOI 10.1080/10888438.2010.529219.
   Posada D, 2004, SYST BIOL, V53, P793, DOI 10.1080/10635150490522304.
   R Core Team, 2016, R LANG ENV STAT COMP.
   Reilly S, 2010, PEDIATRICS, V126, pE1530, DOI 10.1542/peds.2010-0254.
   REZNICK JS, 1992, DEV PSYCHOL, V28, P406, DOI 10.1037/0012-1649.28.3.406.
   Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77.
   Samuelson LK, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1421.
   Schmitt N, 2014, LANG LEARN, V64, P913, DOI 10.1111/lang.12077.
   Silva M, 2015, J EDUC PSYCHOL, V107, P321, DOI 10.1037/a0037769.
   Smith LB, 2013, LANG LEARN DEV, V9, P25, DOI 10.1080/15475441.2012.707104.
   Stott CM, 2002, INT J LANG COMM DIS, V37, P133, DOI 10.1080/13682820110116785.
   Thordardottir ET, 2005, INT J LANG COMM DIS, V40, P243, DOI 10.1080/13682820410001729655.
   Vlach HA, 2017, J MEM LANG, V93, P217, DOI 10.1016/j.jml.2016.10.001.
   Vlach HA, 2013, COGNITION, V127, P375, DOI 10.1016/j.cognition.2013.02.015.
   Vlach HA, 2011, J EXP CHILD PSYCHOL, V108, P394, DOI 10.1016/j.jecp.2010.09.011.
   Wallace IF, 2015, PEDIATRICS, V136, pE448, DOI 10.1542/peds.2014-3889.
   Westerlund M, 2006, J SPEECH LANG HEAR R, V49, P237, DOI 10.1044/1092-4388(2006/020).
   Wetherby AM, 2003, INFANT YOUNG CHILD, V16, P161, DOI 10.1097/00001163-200304000-00008.
   YOUDEN WJ, 1950, CANCER, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3.
   Yu C, 2012, PSYCHOL REV, V119, P21, DOI 10.1037/a0026182.
   Yurovsky D, 2013, DEVELOPMENTAL SCI, V16, P959, DOI 10.1111/desc.12036.}},
Number-of-Cited-References = {{77}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Dev. Psychol.}},
Doc-Delivery-Number = {{HE3MC}},
Unique-ID = {{ISI:000453259200002}},
OA = {{Bronze, Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000453096500008,
Author = {Ferreira, Fernanda and Chantavarin, Suphasiree},
Title = {{Integration and Prediction in Language Processing: A Synthesis of Old
   and New}},
Journal = {{CURRENT DIRECTIONS IN PSYCHOLOGICAL SCIENCE}},
Year = {{2018}},
Volume = {{27}},
Number = {{6}},
Pages = {{443-448}},
Month = {{DEC}},
Abstract = {{Current theories of language processing emphasize prediction as a
   mechanism to facilitate comprehension, which contrasts with the state of
   the field a few decades ago, when prediction was rarely mentioned. We
   argue that the field of psycholinguistics would benefit from revisiting
   these earlier theories of comprehension that attempted to explain
   integration and the processes underlying the formation of rich
   representations of linguistic input and that emphasized informational
   newness over redundancy. We suggest further that integration and
   anticipation may be complementary mechanisms that operate on elaborated,
   coherent discourse representations, supporting enhanced comprehension
   and memory. In addition, the traditional emphasis on language as a tool
   for communication implies that much linguistic content will be
   nonredundant; moreover, the purpose of anticipation is probably not to
   permit the prediction of exact lexical or syntactic forms but instead to
   induce a state of preparedness that allows the comprehender to be
   receptive to new information, thus facilitating its processing.}},
Publisher = {{SAGE PUBLICATIONS INC}},
Address = {{2455 TELLER RD, THOUSAND OAKS, CA 91320 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ferreira, F (Corresponding Author), Univ Calif Davis, Dept Psychol, 1 Shields Ave, Davis, CA 95616 USA.
   Ferreira, Fernanda; Chantavarin, Suphasiree, Univ Calif Davis, Dept Psychol, 1 Shields Ave, Davis, CA 95616 USA.}},
DOI = {{10.1177/0963721418794491}},
ISSN = {{0963-7214}},
EISSN = {{1467-8721}},
Keywords = {{language processing; inferences; prediction; integration}},
Keywords-Plus = {{LEXICAL PREDICTION; COMPREHENSION; PREDICTABILITY; INFORMATION;
   INFERENCES; DISCOURSE; SEARCH; WORDS; BRAIN}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{fferreira@ucdavis.edu}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}BCS-1650888]; National Institutes of HealthUnited States Department
   of Health \& Human ServicesNational Institutes of Health (NIH) - USA
   {[}5R56AG053346]; NATIONAL INSTITUTE ON AGINGUnited States Department of
   Health \& Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Aging (NIA) {[}R56AG053346, R56AG053346] Funding
   Source: NIH RePORTER}},
Funding-Text = {{This research was supported by National Science Foundation Grant
   BCS-1650888 (to F. Ferreira) and National Institutes of Health Grant
   5R56AG053346 (to F. Ferreira, John M. Henderson, and Tamara Swaab).}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Bansal S, 2018, ANN NY ACAD SCI, V1426, P199, DOI 10.1111/nyas.13686.
   Brothers T, 2017, J MEM LANG, V93, P203, DOI 10.1016/j.jml.2016.10.002.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P233, DOI 10.1017/S0140525X12002440.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DUFFY SA, 1989, J EXP PSYCHOL LEARN, V15, P791, DOI 10.1037/0278-7393.15.5.791.
   Ferreira F, 2016, PSYCHOL LEARN MOTIV, V65, P217, DOI 10.1016/bs.plm.2016.04.002.
   FOERTSCH J, 1994, DISCOURSE PROCESS, V18, P271, DOI 10.1080/01638539409544896.
   GERNSBACHER MA, 1991, PSYCHOL LEARN MOTIV, V27, P217, DOI 10.1016/S0079-7421(08)60125-5.
   GRAESSER AC, 1994, PSYCHOL REV, V101, P371, DOI 10.1037/0033-295X.101.3.371.
   Griffiths TL, 2010, TRENDS COGN SCI, V14, P357, DOI 10.1016/j.tics.2010.05.004.
   Hale J, 2016, LANG LINGUIST COMPAS, V10, P397, DOI 10.1111/lnc3.12196.
   HAVILAND SE, 1974, J VERB LEARN VERB BE, V13, P512, DOI 10.1016/S0022-5371(74)80003-4.
   Henderson JM, 2016, NEUROIMAGE, V132, P293, DOI 10.1016/j.neuroimage.2016.02.050.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   KINTSCH W, 1988, PSYCHOL REV, V95, P163, DOI 10.1037/0033-295X.95.2.163.
   KINTSCH W, 1978, PSYCHOL REV, V85, P363, DOI 10.1037/0033-295X.85.5.363.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Long DL, 2005, DISCOURSE PROCESS, V39, P279, DOI 10.1080/0163853X.2005.9651684.
   Lowder MW, 2016, J EXP PSYCHOL LEARN, V42, P1400, DOI 10.1037/xlm0000256.
   Luke SG, 2016, COGNITIVE PSYCHOL, V88, P22, DOI 10.1016/j.cogpsych.2016.06.002.
   Lupyan G, 2015, CURR DIR PSYCHOL SCI, V24, P279, DOI 10.1177/0963721415570732.
   MCKOON G, 1992, PSYCHOL REV, V99, P440, DOI 10.1037/0033-295X.99.3.440.
   Minsky M, 1975, PSYCHOL COMPUTER VIS, P211.
   MURRAY JD, 1993, J MEM LANG, V32, P464, DOI 10.1006/jmla.1993.1025.
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468.
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169.
   Rayner K, 2004, J EXP PSYCHOL HUMAN, V30, P720, DOI 10.1037/0096-1523.30.4.720.
   SINGER M, 1983, J VERB LEARN VERB BE, V22, P437, DOI 10.1016/S0022-5371(83)90282-7.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Staub A, 2015, LANG LINGUIST COMPAS, V9, P311, DOI 10.1111/lnc3.12151.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{Curr. Dir. Psychol.}},
Doc-Delivery-Number = {{HE2HE}},
Unique-ID = {{ISI:000453096500008}},
OA = {{Green Accepted, Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000445713300008,
Author = {Yan, Wei and Zhang, Jiashu and Zhang, Sheng and Wen, Pengwei},
Title = {{A novel pipelined neural IIR adaptive filter for speech prediction}},
Journal = {{APPLIED ACOUSTICS}},
Year = {{2018}},
Volume = {{141}},
Pages = {{64-70}},
Month = {{DEC 1}},
Abstract = {{The paper presents a pipelined neural IIR filter (PNIIR) for nonlinear
   speech prediction. It inherits the usual pipelined two layers
   architecture: the nonlinear modular cascaded subsections and linear
   combiner subsection, and the nonlinear and linear weights of each module
   are updated using an real-time learning algorithms. The PNIIR filter
   units the good tracking performance of the neural IIR network and the
   low computation load of the pipelined architecture. The performance
   analysis and complexity analysis are illustrated in this paper. The
   experimental study for speech prediction is also carried out to testify
   the efficiency of the proposed nonlinear filter.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhang, JS (Corresponding Author), Southwest Jiaotong Univ, Sichuan Prov Key Lab Signal \& Informat Proc, Chengdu 610031, Sichuan, Peoples R China.
   Yan, Wei; Zhang, Jiashu; Zhang, Sheng; Wen, Pengwei, Southwest Jiaotong Univ, Sichuan Prov Key Lab Signal \& Informat Proc, Chengdu 610031, Sichuan, Peoples R China.}},
DOI = {{10.1016/j.apacoust.2018.06.007}},
ISSN = {{0003-682X}},
EISSN = {{1872-910X}},
Keywords = {{Nonlinear speech prediction; Neural IIR filter; Pipelined architecture}},
Keywords-Plus = {{VOLTERRA FILTER; ALGORITHM}},
Research-Areas = {{Acoustics}},
Web-of-Science-Categories  = {{Acoustics}},
Author-Email = {{weiyan.vy@my.swjtu.edu.cn
   jszhang@home.swjtu.edu.cn
   zhangsheng@my.swjtu.edu.cn}},
ResearcherID-Numbers = {{Zhang, Sheng/AAE-3571-2019}},
Funding-Acknowledgement = {{National Science foundation of P. R. ChinaNational Natural Science
   Foundation of China (NSFC) {[}61671392]}},
Funding-Text = {{This work was partially supported by National Science foundation of P.
   R. China (Grant: 61671392).}},
Cited-References = {{Al-Jumeily D., 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9226, P654, DOI 10.1007/978-3-319-22186-1\_65.
   Bibby C, 2013, APPL ACOUST, V74, P585, DOI 10.1016/j.apacoust.2012.10.005.
   Birgmeier, 1996, EUR SIGN PROC C, P10.
   DAVILA CE, 1987, IEEE T ACOUST SPEECH, V35, P1259, DOI 10.1109/TASSP.1987.1165293.
   Despotovic V, 2012, IEEE T AUDIO SPEECH, V20, P1069, DOI 10.1109/TASL.2011.2169788.
   Faundez M, 1997, LECT NOTES COMPUT SC, V1240, P1154.
   Galbrun L, 2014, APPL ACOUST, V81, P1, DOI 10.1016/j.apacoust.2014.02.001.
   Harada T, P 2001 IEEE INT S IS, P785.
   HAYKIN S, 1995, IEEE T SIGNAL PROCES, V43, P526, DOI 10.1109/78.348134.
   Haykin S., 1994, NEURAL NETWORKS COMP.
   Keranen J, 2013, APPL ACOUST, V74, P1315, DOI 10.1016/j.apacoust.2013.05.011.
   Kiselman BA, 2005, IEEE T SPEECH AUDI P, V13, P1093, DOI 10.1109/TSA.2005.853007.
   Kobus A, 2013, ADV INTELL SYST, V226, P887, DOI 10.1007/978-3-319-00969-8\_87.
   Mandic DP, 2000, ELECTRON LETT, V36, P845, DOI 10.1049/el:20000631.
   Mandic DP, 2000, NEURAL PROCESS LETT, V11, P1, DOI 10.1023/A:1009686825582.
   Mandic DP, 2001, ADAPT LEARN SYST SIG.
   Orcik L, 2017, WIRELESS PERS COMMUN, V96, P5375, DOI 10.1007/s11277-016-3746-2.
   Pang YJ, 2016, DIGIT SIGNAL PROCESS, V56, P67, DOI 10.1016/j.dsp.2016.03.004.
   Patil Hemant A, INTERSPEECH, P25.
   PICHE SW, 1994, IEEE T NEURAL NETWOR, V5, P198, DOI 10.1109/72.279185.
   Rabiner Lawrence, 1993, FUNDAMENTALS SPEECH, V1, P353.
   Wang AH, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1353, DOI 10.1109/ICMLC.2002.1167426.
   Zhai LY, 2014, IEICE ELECTRON EXPR, V11, DOI 10.1587/elex.11.20131030.
   Zhang JS, 2014, DIGIT SIGNAL PROCESS, V26, P71, DOI 10.1016/j.dsp.2013.10.003.
   Zhang JS, 2010, DIGIT SIGNAL PROCESS, V20, P23, DOI 10.1016/j.dsp.2009.06.006.
   Zhang S, 2016, SIGNAL PROCESS, V129, P195, DOI 10.1016/j.sigpro.2016.06.007.
   Zhang S, 2014, IEEE T CIRCUITS-II, V61, P536, DOI 10.1109/TCSII.2014.2327376.
   Zhao HQ, 2010, IEEE T SYST MAN CY B, V40, P162, DOI 10.1109/TSMCB.2009.2024313.
   Zhao HQ, 2009, IEEE T SIGNAL PROCES, V57, P237, DOI 10.1109/TSP.2008.2007105.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Appl. Acoust.}},
Doc-Delivery-Number = {{GU9YN}},
Unique-ID = {{ISI:000445713300008}},
DA = {{2020-12-06}},
}

@article{ ISI:000460600700010,
Author = {Jang, Giup and Lee, Taekeon and Hwang, Soyoun and Park, Chihyun and Ahn,
   Jaegyoon and Seo, Sukyung and Hwang, Youhyeon and Yoon, Youngmi},
Title = {{PISTON: Predicting drug indications and side effects using topic
   modeling and natural language processing}},
Journal = {{JOURNAL OF BIOMEDICAL INFORMATICS}},
Year = {{2018}},
Volume = {{87}},
Pages = {{96-107}},
Month = {{NOV}},
Abstract = {{The process of discovering novel drugs to treat diseases requires a long
   time and high cost. It is important to understand side effects of drugs
   as well as their therapeutic effects, because these can seriously damage
   the patients due to unexpected actions of the derived candidate drugs.
   In order to overcome these limitations, computational methods for
   predicting the therapeutic effects and side effects have been proposed.
   In particular, text mining is a widely used technique in the field of
   systems biology, because it can discover hidden relationships between
   drugs, genes and diseases from a large amount of literature data.
   Compared with in vivo/in vitro experiments, text mining derives
   meaningful results with less time and cost.
   In this study, we propose an algorithm for predicting novel
   drug-phenotype associations and drug-side effect associations using
   topic modeling and natural language processing (NLP). We extract
   sentences in which drugs and genes co-occur from the abstracts of the
   literature and identify words that describe the relationship between
   them using NLP. Considering the characteristics of the identified words,
   we determine if the drug has an up regulation effect or a
   down-regulation effect on the gene. Based on genes that affect drugs and
   their regulatory relationships, we group the frequently occurring genes
   and regulatory relationships into topics, and build a drug topic
   probability matrix by calculating the score that the drug will have a
   topic using topic modeling. Using the matrix, a classifier is
   constructed for predicting the novel indications and side effects of
   drugs considering the characteristics of known drug-phenotype
   associations or drug-side effect associations.
   The proposed method predicts both indications and side effects with a
   single algorithm, and it can exclude drugs with serious side effects or
   side effects that patients do not want to experience from among the
   candidate drugs provided for the treatment of the phenotype.
   Furthermore, lists of novel candidate drugs for phenotypes and side
   effects can be continuously updated with our algorithm every time a
   document is added. More than a thousand documents are produced per day,
   and it is possible for our algorithm to efficiently derive candidate
   drugs because it requires less cost than the existing drug repositioning
   methods. The resource of PISTON is available at
   databio.gachon.ac.kr/tools/PISTON.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yoon, Y (Corresponding Author), Gachon Univ, Dept Comp Engn, Seongnam, South Korea.
   Jang, Giup; Hwang, Soyoun, Gachon Univ, Dept IT Convergence Engn, Seongnam, South Korea.
   Lee, Taekeon; Seo, Sukyung; Yoon, Youngmi, Gachon Univ, Dept Comp Engn, Seongnam, South Korea.
   Park, Chihyun, Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
   Ahn, Jaegyoon, Incheon Univ, Dept Comp Sci \& Engn, Incheon, South Korea.
   Hwang, Youhyeon, Univ Southern Calif, Dept Comp Sci, Los Angeles, CA USA.}},
DOI = {{10.1016/j.jbi.2018.09.015}},
ISSN = {{1532-0464}},
EISSN = {{1532-0480}},
Keywords = {{Text mining; Drug repositioning; Side effect prediction; Bioinformatics;
   Systems biology}},
Keywords-Plus = {{PHARMACOGENOMICS KNOWLEDGE; DISCOVERY; TEXT}},
Research-Areas = {{Computer Science; Medical Informatics}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Medical Informatics}},
Author-Email = {{ymyoon@gachon.ac.kr}},
ORCID-Numbers = {{Park, Chihyun/0000-0003-4995-2312}},
Funding-Acknowledgement = {{National Research Foundation of Korea (NRF) - Korea government (Ministry
   of Science, ICT \& Future Planning) {[}NRF-2018R1A2B6006223]}},
Funding-Text = {{This research was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (Ministry of Science, ICT \&
   Future Planning) (NRF-2018R1A2B6006223).}},
Cited-References = {{Adams CP, 2006, HEALTH AFFAIR, V25, P420, DOI 10.1377/hlthaff.25.2.420.
   Allen James F., 2003, NATURAL LANGUAGE PRO, P1218.
   Bisgin H, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-S10-S11.
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826.
   Booth B, 2004, NAT REV DRUG DISCOV, V3, P451, DOI 10.1038/nrd1384.
   Canese Kathi, 2013, BIBLIOGRAPHIC DATABA.
   Chong CR, 2007, NATURE, V448, P645, DOI 10.1038/448645a.
   Chopra Abhimanyu, 2013, INT J TECHNOLOGY ENH, V1, P131.
   Coulet A, 2010, J BIOMED INFORM, V43, P1009, DOI 10.1016/j.jbi.2010.08.005.
   Davis AP, 2015, NUCLEIC ACIDS RES, V43, pD914, DOI 10.1093/nar/gku935.
   Dillon M., 1983, INTRO MODERN INFORM, P402.
   DiMasi JA, 2001, CLIN PHARMACOL THER, V69, P286, DOI 10.1067/mcp.2001.115132.
   Dudley JT, 2011, BRIEF BIOINFORM, V12, P303, DOI 10.1093/bib/bbr013.
   Dumontier M, 2009, BRIEF BIOINFORM, V10, P153, DOI 10.1093/bib/bbn056.
   Edwards IR, 2000, LANCET, V356, P1255, DOI 10.1016/S0140-6736(00)02799-9.
   Fleuren WWM, 2015, METHODS, V74, P97, DOI 10.1016/j.ymeth.2015.01.015.
   Giacomini KM, 2007, NATURE, V446, P975, DOI 10.1038/446975a.
   Gottlieb A, 2011, MOL SYST BIOL, V7, DOI 10.1038/msb.2011.26.
   Grun B, 2011, J STAT SOFTW, V40, P1.
   Hwang Y, 2017, MOL BIOSYST, V13, P1788, DOI 10.1039/c7mb00059f.
   Jang D, 2016, J BIOMED INFORM, V59, P248, DOI 10.1016/j.jbi.2015.12.003.
   Jang G, 2017, MOL BIOSYST, V13, P1399, DOI 10.1039/c7mb00020k.
   Kanehisa M, 2017, NUCLEIC ACIDS RES, V45, pD353, DOI 10.1093/nar/gkw1092.
   kim HyuMin, 2016, P 31 ANN ACM S APPL.
   Klein D., 2003, P 41 ANN M ASS COMP.
   Kuhn M, 2016, NUCLEIC ACIDS RES, V44, pD1075, DOI 10.1093/nar/gkv1075.
   Li J, 2016, BRIEF BIOINFORM, V17, P2, DOI 10.1093/bib/bbv020.
   Lipscomb CE, 2000, B MED LIBR ASSOC, V88, P265.
   Mandloi S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10021.
   Patchala Jagadeesh, 2015, AMIA Jt Summits Transl Sci Proc, V2015, P222.
   Percha B, 2012, BIOCOMPUT-PAC SYM, P410.
   Perna R. E., 2003, MEDICINE, V31, P20.
   Persidis A., 2011, DRUG DISCOV, V12, P9.
   Rodriguez G., 2007, LECT NOTES GEN LINEA, P2010.
   Rodriguez -Ortiz Maria E., 2012, J AM SOC NEPHROL.
   SLEIGH SH, 2010, PHARM MED, V24, P151.
   Tan A. H., 1999, P PAKDD 1999 WORKSH, V8.
   Tonkens Ross, 2005, Physician Exec, V31, P48.
   Whirl-Carrillo M, 2012, CLIN PHARMACOL THER, V92, P414, DOI 10.1038/clpt.2012.96.
   {*}WHO, 1999, GUID ATC CLASS DDD A.
   Wishart DS, 2006, NUCLEIC ACIDS RES, V34, pD668, DOI 10.1093/nar/gkj067.
   Xu R, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-181.
   Yeleswarapu S, 2014, BMC MED INFORM DECIS, V14, DOI 10.1186/1472-6947-14-13.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{J. Biomed. Inform.}},
Doc-Delivery-Number = {{HO0NP}},
Unique-ID = {{ISI:000460600700010}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000451790000016,
Author = {Li Jingjing and Zhang Qijin and Zhang Yumei and Wu Xiaojun and Wang
   Xiaoming and Su Yuping},
Title = {{Hidden Phase Space Reconstruction: A Novel Chaotic Time Series
   Prediction Method for Speech Signals}},
Journal = {{CHINESE JOURNAL OF ELECTRONICS}},
Year = {{2018}},
Volume = {{27}},
Number = {{6}},
Pages = {{1221-1228}},
Month = {{NOV}},
Abstract = {{Speech signals are nonlinear chaotic time series. This paper proposes a
   novel speech signal nonlinear prediction model with the hidden phase
   space reconstruction method. The parameters, embedding dimension m, time
   delay tau and model structure are solved simultaneously, breaking the
   restriction of phase space, which needs to be reconstructed before
   modeling for the existing prediction method. Subsequently, an explicit
   speech signal prediction model is generated. Meanwhile, the introduction
   of the frame length parameter k effectively extends the prediction
   length. Experimental results show that the values of m and tau solved by
   the proposed method are consistent with the values addressed by the Cao
   method and mutual information method, respectively. In addition, the
   optimal value of k is further discussed. The prediction results obtained
   using the proposed model are more accurate than those of linear
   prediction coding, the radial basis function neural network model and
   the long short-term memory network.}},
Publisher = {{TECHNOLOGY EXCHANGE LIMITED HONG KONG}},
Address = {{BLDG\#13, PUHUINANLI, SOUTH YUYUANTAN RD, HAIDIAN DIST, BEIJING, 00000,
   PEOPLES R CHINA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.
   Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.
   Li Jingjing; Zhang Yumei; Wu Xiaojun, Shaanxi Normal Univ, Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.
   Zhang Qijin; Zhang Yumei; Wu Xiaojun; Wang Xiaoming; Su Yuping, Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.}},
DOI = {{10.1049/cje.2018.09.010}},
ISSN = {{1022-4653}},
EISSN = {{2075-5597}},
Keywords = {{Speech signal; Hidden phase space reconstruction; Chaotic time series
   prediction; Frame length parameter}},
Keywords-Plus = {{ECHO STATE NETWORK; MODEL}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{jingj1101@snnu.edu.cn
   513164238@qq.com
   zym0910@snnu.edu.cn
   xjwu@snnu.edu.cn
   wangxm@snnu.edu.cn
   ypsu@snnu.edu.cn}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2017YFB1402100]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}11772178, 11502133,
   61701291]; 111 ProjectMinistry of Education, China - 111 Project
   {[}B16031]; Fundamental Research Fund for the Central Universities
   {[}2017CBY008]; China Postdoctoral Science FoundationChina Postdoctoral
   Science Foundation {[}2017M613053]; Shaanxi Science \& Technology
   Co-ordination \& Innovation Project {[}2015KTZDGY06-05-01]}},
Funding-Text = {{This work is supported by the National Key Research and Development
   Program of China (No.2017YFB1402100), the National Natural Science
   Foundation of China (No.11772178, No.11502133, No.61701291), the 111
   Project (No.B16031), the Fundamental Research Fund for the Central
   Universities (No.2017CBY008), the China Postdoctoral Science Foundation
   funded project (No.2017M613053), and the Shaanxi Science \& Technology
   Co-ordination \& Innovation Project (No.2015KTZDGY06-05-01).}},
Cited-References = {{Bianchi FM, 2015, NEURAL NETWORKS, V71, P204, DOI 10.1016/j.neunet.2015.08.010.
   Chao Weng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5532, DOI 10.1109/ICASSP.2014.6854661.
   Chouikhi N, 2017, APPL SOFT COMPUT, V55, P211, DOI 10.1016/j.asoc.2017.01.049.
   Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344.
   Fay MP, 2010, STAT SURV, V4, P1, DOI 10.1214/09-SS051.
   {[}韩红桂 Han Honggui], 2018, {[}电子学报, Acta Electronica Sinica], V46, P315.
   Jiang JJ, 2006, J VOICE, V20, P2, DOI 10.1016/j.jvoice.2005.01.001.
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968.
   Kocal OH, 2008, IEEE T INF FOREN SEC, V3, P651, DOI 10.1109/TIFS.2008.2004289.
   Lee YS, 2011, KNOWL-BASED SYST, V24, P66, DOI 10.1016/j.knosys.2010.07.006.
   Matthew K.L., 2012, INT J ADV RES ARTIF, V1, P39.
   Ogorzalek M., 2002, IEEE INT S CIRC SYST, V4, pIV.
   Pradeepkumar D, 2017, APPL SOFT COMPUT, V58, P35, DOI 10.1016/j.asoc.2017.04.014.
   Stavrakoudis DG, 2007, IEEE T SYST MAN CY B, V37, P1305, DOI 10.1109/TSMCB.2007.900516.
   Sun JF, 2007, SIGNAL PROCESS, V87, P2431, DOI 10.1016/j.sigpro.2007.03.020.
   Wu Xiao-jun, 2011, Acta Electronica Sinica, V39, P1261.
   Wu XJ, 2013, APPL SOFT COMPUT, V13, P3314, DOI 10.1016/j.asoc.2013.02.008.
   {[}吴晓军 Wu Xiaojun], 2012, {[}电子学报, Acta Electronica Sinica], V40, P1115.
   Xie X. F., 2005, DISSIPATIVE PARTICLE, P1456.
   Yang L, 2016, APPL SOFT COMPUT, V38, P754, DOI 10.1016/j.asoc.2015.10.003.
   Zhang Y. M., 2015, ACTA PHYS SINICA, V64, P117.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{22}},
Journal-ISO = {{Chin. J. Electron.}},
Doc-Delivery-Number = {{HC4QT}},
Unique-ID = {{ISI:000451790000016}},
DA = {{2020-12-06}},
}

@article{ ISI:000448145900001,
Author = {Biau, Emmanuel and Kotz, Sonja A.},
Title = {{Lower Beta: A Central Coordinator of Temporal Prediction in Multimodal
   Speech}},
Journal = {{FRONTIERS IN HUMAN NEUROSCIENCE}},
Year = {{2018}},
Volume = {{12}},
Month = {{OCT 24}},
Abstract = {{How the brain decomposes and integrates information in multimodal speech
   perception is linked to oscillatory dynamics. However, how speech takes
   advantage of redundancy between different sensory modalities, and how
   this translates into specific oscillatory patterns remains unclear. We
   address the role of lower beta activity (similar to 20 Hz), generally
   associated with motor functions, as an amodal central coordinator that
   receives bottom-up delta-theta copies from specific sensory areas and
   generate top-down temporal predictions for auditory entrainment.
   Dissociating temporal prediction from entrainment may explain how and
   why visual input benefits speech processing rather than adding cognitive
   load in multimodal speech perception. On the one hand, body movements
   convey prosodic and syllabic features at delta and theta rates (i.e.,
   1-3 Hz and 4-7 Hz). On the other hand, the natural precedence of visual
   input before auditory onsets may prepare the brain to anticipate and
   facilitate the integration of auditory delta-theta copies of the
   prosodic-syllabic structure. Here, we identify three fundamental
   criteria based on recent evidence and hypotheses, which support the
   notion that lower motor beta frequency may play a central and generic
   role in temporal prediction during speech perception. First, beta
   activity must respond to rhythmic stimulation across modalities. Second,
   beta power must respond to biological motion and speech-related
   movements conveying temporal information in multimodal speech
   processing. Third, temporal prediction may recruit a communication loop
   between motor and primary auditory cortices (PACs) via delta-to-beta
   cross-frequency coupling. We discuss evidence related to each criterion
   and extend these concepts to a beta-motivated framework of multimodal
   speech processing.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Biau, E (Corresponding Author), Univ Maastricht, Fac Psychol \& Neurosci, Dept Neuropsychol \& Psychopharmacol, Basic \& Appl Neuro Dynam Lab, Maastricht, Netherlands.
   Biau, Emmanuel; Kotz, Sonja A., Univ Maastricht, Fac Psychol \& Neurosci, Dept Neuropsychol \& Psychopharmacol, Basic \& Appl Neuro Dynam Lab, Maastricht, Netherlands.
   Kotz, Sonja A., Max Planck Inst Human Cognit \& Brain Sci, Dept Neuropsychol, Leipzig, Germany.}},
DOI = {{10.3389/fnhum.2018.00434}},
Article-Number = {{434}},
ISSN = {{1662-5161}},
Keywords = {{temporal predictions; beta oscillations; multimodal speech perception;
   prosody; biological motion}},
Keywords-Plus = {{HUMAN AUDITORY-CORTEX; AUDIOVISUAL SPEECH; NEURONAL OSCILLATIONS;
   BIOLOGICAL MOTION; BAND OSCILLATIONS; VISUAL SPEECH; CORTICAL
   OSCILLATIONS; NEURAL OSCILLATIONS; PREMOTOR CORTEX; HAND GESTURES}},
Research-Areas = {{Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Neurosciences; Psychology}},
Author-Email = {{emmanuel.biau@maastrichtuniversity.nl}},
Funding-Acknowledgement = {{European Union's Horizon 2020 research and innovation program, under the
   Marie SkElEodowska-Curie Actions grant {[}707727]}},
Funding-Text = {{This research was supported by a postdoctoral fellowship from the
   European Union's Horizon 2020 research and innovation program, under the
   Marie SkElEodowska-Curie Actions grant agreement (No. 707727).}},
Cited-References = {{Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008.
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998.
   Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103.
   Arnal LH, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00225.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009.
   Avanzini P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037534.
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011.
   Baker SN, 2007, CURR OPIN NEUROBIOL, V17, P649, DOI 10.1016/j.conb.2008.01.007.
   Bartolo R, 2015, J NEUROSCI, V35, P4635, DOI 10.1523/JNEUROSCI.4570-14.2015.
   Bartolo R, 2014, J NEUROSCI, V34, P3910, DOI 10.1523/JNEUROSCI.2679-13.2014.
   Biau E, 2018, LANG LEARN, V68, P102, DOI 10.1111/lang.12257.
   Biau E, 2016, NEUROIMAGE, V132, P129, DOI 10.1016/j.neuroimage.2016.02.018.
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018.
   Biau E, 2013, BRAIN LANG, V124, P143, DOI 10.1016/j.bandl.2012.10.008.
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442.
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006.
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3.
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155.
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436.
   Cirelli LK, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00742.
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015.
   Di Nota PM, 2017, BMC NEUROSCI, V18, DOI 10.1186/s12868-017-0349-0.
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186.
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027.
   Drijvers L, 2018, HUM BRAIN MAPP, V39, P2075, DOI 10.1002/hbm.23987.
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015.
   Etchell AC, 2016, NEUROIMAGE, V125, P953, DOI 10.1016/j.neuroimage.2015.10.086.
   Etchell AC, 2015, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.01036.
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694.
   Fujioka T, 2015, J NEUROSCI, V35, P15187, DOI 10.1523/JNEUROSCI.2397-15.2015.
   Fujioka T, 2012, J NEUROSCI, V32, P1791, DOI 10.1523/JNEUROSCI.4107-11.2012.
   Fujioka T, 2009, ANN NY ACAD SCI, V1169, P89, DOI 10.1111/j.1749-6632.2009.04779.x.
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063.
   Grahn JA, 2009, J NEUROSCI, V29, P7540, DOI 10.1523/JNEUROSCI.2018-08.2009.
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Hosaka R, 2016, CEREB CORTEX, V26, P3442, DOI 10.1093/cercor/bhv163.
   Jack A, 2017, HUM BRAIN MAPP, V38, P1914, DOI 10.1002/hbm.23493.
   Jansma H, 2014, NEUROSCIENCE, V256, P230, DOI 10.1016/j.neuroscience.2013.10.047.
   Jenkinson N, 2011, TRENDS NEUROSCI, V34, P611, DOI 10.1016/j.tins.2011.09.003.
   Jessen S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036070.
   Keil J, 2012, CEREB CORTEX, V22, P221, DOI 10.1093/cercor/bhr125.
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473.
   Keitel C, 2017, NEUROIMAGE, V146, P58, DOI 10.1016/j.neuroimage.2016.11.043.
   Kilavik BE, 2013, EXP NEUROL, V245, P15, DOI 10.1016/j.expneurol.2012.09.014.
   Kilner JM, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004925.
   Kilner JM, 2003, NEUROIMAGE, V18, P67, DOI 10.1006/nimg.2002.1322.
   Kilner JM, 2000, J NEUROSCI, V20, P8838.
   Kosem A, 2014, NEUROIMAGE, V92, P274, DOI 10.1016/j.neuroimage.2014.02.010.
   Kosem A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040936.
   Konoike N, 2012, NEUROIMAGE, V63, P328, DOI 10.1016/j.neuroimage.2012.07.002.
   Kononowicz TW, 2015, NEUROPSYCHOLOGIA, V75, P381, DOI 10.1016/j.neuropsychologia.2015.06.014.
   Kotz SA, 2015, ANN NY ACAD SCI, V1337, P62, DOI 10.1111/nyas.12657.
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005.
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005.
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735.
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004.
   Macaluso E, 2004, NEUROIMAGE, V21, P725, DOI 10.1016/j.neuroimage.2003.09.049.
   Mai GT, 2016, NEUROIMAGE, V133, P516, DOI 10.1016/j.neuroimage.2016.02.064.
   MAURITZ KH, 1986, EXP BRAIN RES, V61, P229.
   Meirovitch Y, 2015, J NEUROSCI, V35, P1627, DOI 10.1523/JNEUROSCI.5371-13.2015.
   Merchant H, 2013, ANNU REV NEUROSCI, V36, P313, DOI 10.1146/annurev-neuro-062012-170349.
   Mersov AM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00443.
   Meyer M, 2004, BRAIN LANG, V89, P277, DOI 10.1016/S0093-934X(03)00350-X.
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114.
   Morillon B, 2016, J NEUROSCI, V36, P2342, DOI 10.1523/JNEUROSCI.0836-15.2016.
   Morillon B, 2015, CURR OPIN NEUROBIOL, V31, P230, DOI 10.1016/j.conb.2014.12.005.
   Morillon B, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6255.
   Morin O, 2008, NEUROPHYSIOL CLIN, V38, P189, DOI 10.1016/j.neucli.2008.02.005.
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x.
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024.
   Nelson A, 2013, J NEUROSCI, V33, P14342, DOI 10.1523/JNEUROSCI.2275-13.2013.
   Nourski KV, 2009, J NEUROSCI, V29, P15564, DOI 10.1523/JNEUROSCI.3065-09.2009.
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521.
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049.
   Pavlova MA, 2017, CEREB CORTEX, V27, P5318, DOI 10.1093/cercor/bhx151.
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006.
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320.
   Peuskens H, 2005, EUR J NEUROSCI, V21, P2864, DOI 10.1111/j.1460-9568.2005.04106.x.
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI {[}10.1044/1092-4388(2009/07-0276), 10.1044/1092-4388].
   Press C, 2011, J NEUROSCI, V31, P2792, DOI 10.1523/JNEUROSCI.1595-10.2011.
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230.
   Romero YR, 2015, J NEUROPHYSIOL, V113, P2342, DOI 10.1152/jn.00783.2014.
   Saleh M, 2010, NEURON, V65, P461, DOI 10.1016/j.neuron.2010.02.001.
   Schepers IM, 2013, NEUROIMAGE, V70, P101, DOI 10.1016/j.neuroimage.2012.11.066.
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002.
   Schroeder CE, 2009, BRAIN TOPOGR, V22, P24, DOI 10.1007/s10548-009-0080-y.
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012.
   Schwartze M, 2016, BRAIN LANG, V161, P28, DOI 10.1016/j.bandl.2015.08.005.
   Skipper JI, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0297.
   Sokolov AA, 2012, NEUROIMAGE, V59, P2824, DOI 10.1016/j.neuroimage.2011.08.039.
   Spitzer B, 2012, J NEUROSCI, V32, P3287, DOI 10.1523/JNEUROSCI.5280-11.2012.
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964.
   van Ede F, 2011, J NEUROSCI, V31, P2016, DOI 10.1523/JNEUROSCI.5630-10.2011.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.
   Venezia JH, 2016, NEUROIMAGE, V126, P196, DOI 10.1016/j.neuroimage.2015.11.038.
   von Stein A, 1999, CEREB CORTEX, V9, P137, DOI 10.1093/cercor/9.2.137.
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308.
   Wagner P, 2014, SPEECH COMMUN, V57, P209, DOI 10.1016/j.specom.2013.09.008.
   Zoefel B, 2016, NEUROIMAGE, V124, P16, DOI 10.1016/j.neuroimage.2015.08.054.}},
Number-of-Cited-References = {{101}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Front. Hum. Neurosci.}},
Doc-Delivery-Number = {{GX9SJ}},
Unique-ID = {{ISI:000448145900001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000445854400007,
Author = {Johari, Karim and den Ouden, Dirk-Bart and Behroozmand, Roozbeh},
Title = {{Effects of aging on temporal predictive mechanisms of speech and hand
   motor reaction time}},
Journal = {{AGING CLINICAL AND EXPERIMENTAL RESEARCH}},
Year = {{2018}},
Volume = {{30}},
Number = {{10}},
Pages = {{1195-1202}},
Month = {{OCT}},
Abstract = {{Evidence from previous studies has suggested that movement execution in
   younger adults is accelerated in response to temporally predictable vs.
   unpredictable sensory stimuli. This effect indicates that external
   temporal information can modulate motor behavior; however, how aging can
   influence temporal predictive mechanisms in motor system has yet to be
   understood. The objective of the present study was to investigate aging
   effects on the initiation and inhibition of speech and hand movement
   reaction times in response to temporally predictable and unpredictable
   sensory stimuli. Fifteen younger (mean age 22.6) and fifteen older (mean
   age 63.8) adults performed a randomized speech vowel vocalization or
   button press initiation and inhibition tasks in two counterbalanced
   blocks in response to temporally predictable and unpredictable visual
   cue stimuli. Results showed that motor reaction time was accelerated in
   both younger and older adults for predictable vs. unpredictable stimuli
   during initiation and inhibition of speech and hand movement. However,
   older adults were significantly slower than younger adults in motor
   execution of speech and hand movement when stimulus timing was
   unpredictable. Moreover, we found that overall, motor inhibition of
   speech and hand was executed faster than their initiation. Our findings
   suggest that older adults can compensate age-related decline in motor
   reaction times by incorporating external temporal information and
   execute faster movement in response to predictable stimuli, whereas
   unpredictable temporal information cannot counteract aging effects
   efficiently and lead to less accurate motor timing predictive codes for
   speech production and hand movement.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Behroozmand, R (Corresponding Author), Univ South Carolina, Speech Neurosci Lab, Dept Commun Sci \& Disorders, 915 Greene St, Columbia, SC 29208 USA.
   Johari, Karim; Behroozmand, Roozbeh, Univ South Carolina, Speech Neurosci Lab, Dept Commun Sci \& Disorders, 915 Greene St, Columbia, SC 29208 USA.
   den Ouden, Dirk-Bart, Univ South Carolina, Neurolinguist Lab, Dept Commun Sci \& Disorders, 915 Greene St, Columbia, SC 29208 USA.}},
DOI = {{10.1007/s40520-018-0902-4}},
ISSN = {{1594-0667}},
EISSN = {{1720-8319}},
Keywords = {{Aging; Speech production; Hand movement; Motor reaction time; Temporal
   predictive code}},
Keywords-Plus = {{TASK COMPLEXITY; OBJECT MANIPULATION; MOVEMENT; FMRI; UNCERTAINTY;
   FOREPERIOD; DURATION; STOP; STIMULATION; PROBABILITY}},
Research-Areas = {{Geriatrics \& Gerontology}},
Web-of-Science-Categories  = {{Geriatrics \& Gerontology}},
Author-Email = {{r-behroozmand@sc.edu}},
ResearcherID-Numbers = {{Johari, Karim/C-7552-2013
   Johari, Karim/N-5396-2019}},
ORCID-Numbers = {{Johari, Karim/0000-0002-0295-7397}},
Funding-Acknowledgement = {{NIH/NIDCDUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness \&
   Other Communication Disorders (NIDCD) {[}K01-DC015831-01A1]; University
   of South Carolina; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness \& Other Communication Disorders (NIDCD) {[}K01DC015831,
   K01DC015831, K01DC015831, K01DC015831] Funding Source: NIH RePORTER}},
Funding-Text = {{The authors wish to thank Drs. Chris Rorden and Allen Montgomery for
   their feedback on this manuscript. This research was supported by a
   Grant from the NIH/NIDCD, Grant number: K01-DC015831-01A1 (PI:
   Behroozmand), and by the Graduate Scholar Award for Aging Research
   received by Karim Johari from the University of South Carolina.}},
Cited-References = {{Balci Fuat, 2009, P161, DOI 10.1007/978-1-59745-422-3\_8.
   Behroozmand R, 2016, BRAIN RES, V1636, P1, DOI 10.1016/j.brainres.2016.01.040.
   Berchicci M, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00101.
   BERTELSON P, 1960, NATURE, V187, P531, DOI 10.1038/187531a0.
   BEVAN W, 1965, PERCEPT MOTOR SKILL, V20, P969, DOI 10.2466/pms.1965.20.3.969.
   Binkofski F, 1999, EUR J NEUROSCI, V11, P3276, DOI 10.1046/j.1460-9568.1999.00753.x.
   Binkofski F, 1999, EXP BRAIN RES, V128, P210, DOI 10.1007/s002210050838.
   Block RA, 1998, PSYCHOL AGING, V13, P584, DOI 10.1037/0882-7974.13.4.584.
   Chauvin JJ, 2016, PSYCHOL AGING, V31, P442, DOI 10.1037/pag0000105.
   Corballis MC, 2003, BEHAV BRAIN SCI, V26, P199, DOI 10.1017/S0140525X03000062.
   Coull JT, 2016, NEUROIMAGE, V141, P40, DOI 10.1016/j.neuroimage.2016.07.036.
   Craik FIM, 1999, PERCEPT PSYCHOPHYS, V61, P549, DOI 10.3758/BF03211972.
   DRAZIN DH, 1961, J EXP PSYCHOL, V62, P43, DOI 10.1037/h0046860.
   Espinosa-Fernandez L, 2003, ACTA PSYCHOL, V112, P221, DOI 10.1016/S0001-6918(02)00093-8.
   FOZARD JL, 1994, J GERONTOL, V49, pP179, DOI 10.1093/geronj/49.4.P179.
   Gajewski PD, 2013, INT J PSYCHOPHYSIOL, V87, P273, DOI 10.1016/j.ijpsycho.2012.08.007.
   Gentilucci M, 2008, Q J EXP PSYCHOL, V61, P944, DOI 10.1080/17470210701625683.
   Gentilucci M, 2009, NEUROPSYCHOLOGIA, V47, P3190, DOI 10.1016/j.neuropsychologia.2009.07.020.
   Johari K, 2017, EXP BRAIN RES, V235, P1439, DOI 10.1007/s00221-017-4900-0.
   Johari K, 2017, HUM MOVEMENT SCI, V54, P41, DOI 10.1016/j.humov.2017.03.005.
   JORDAN TC, 1977, BRIT J PSYCHOL, V68, P189, DOI 10.1111/j.2044-8295.1977.tb01575.x.
   KARLIN L, 1959, J EXP PSYCHOL, V58, P185, DOI 10.1037/h0049152.
   KLEMMER ET, 1956, J EXP PSYCHOL, V51, P179, DOI 10.1037/h0042317.
   Koppe G, 2014, NEUROIMAGE, V101, P236, DOI 10.1016/j.neuroimage.2014.07.008.
   Levin O, 2014, NEUROSCI BIOBEHAV R, V43, P100, DOI 10.1016/j.neubiorev.2014.04.001.
   Li CSR, 2005, EXP BRAIN RES, V167, P305, DOI 10.1007/s00221-005-0110-2.
   LOGAN GD, 1986, J EXP PSYCHOL HUMAN, V12, P549, DOI 10.1037/0096-1523.12.4.549.
   Ma H, 2004, AM J OCCUP THER, V58, P150, DOI 10.5014/ajot.58.2.150.
   Mattes S, 1997, PERCEPT PSYCHOPHYS, V59, P1089, DOI 10.3758/BF03205523.
   Munoz DP, 1998, EXP BRAIN RES, V121, P391, DOI 10.1007/s002210050473.
   NIEMI P, 1981, PSYCHOL BULL, V89, P133, DOI 10.1037/0033-2909.89.1.133.
   Pachella RG, 1973, 45 U MICH ANN ARB HU.
   Ramautar JR, 2004, BRAIN COGNITION, V56, P234, DOI 10.1016/j.bandc.2004.07.002.
   Schubotz RI, 2000, NEUROIMAGE, V11, P1, DOI 10.1006/nimg.1999.0514.
   Singleton W, 1955, OLD AGE MODERN WORLD, P221.
   Thickbroom GW, 2000, BRAIN RES, V874, P233, DOI 10.1016/S0006-8993(00)02588-9.
   Vallesi A, 2009, NEUROPSYCHOLOGIA, V47, P2876, DOI 10.1016/j.neuropsychologia.2009.06.013.
   Vallesi A, 2009, J COGNITIVE NEUROSCI, V21, P1116, DOI 10.1162/jocn.2009.21098.
   Wolpert DM, 1997, TRENDS COGN SCI, V1, P209, DOI 10.1016/S1364-6613(97)01070-X.
   Wolpert DM, 2001, CURR BIOL, V11, pR729, DOI 10.1016/S0960-9822(01)00432-8.
   Yan JH, 1998, EXP AGING RES, V24, P155.
   Zanto TP, 2011, J NEUROSCI, V31, P12461, DOI 10.1523/JNEUROSCI.1149-11.2011.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Aging Clin. Exp. Res.}},
Doc-Delivery-Number = {{GV1QH}},
Unique-ID = {{ISI:000445854400007}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000445089400002,
Author = {Pickering, Martin J. and Gambi, Chiara},
Title = {{Predicting While Comprehending Language: A Theory and Review}},
Journal = {{PSYCHOLOGICAL BULLETIN}},
Year = {{2018}},
Volume = {{144}},
Number = {{10}},
Pages = {{1002-1044}},
Month = {{OCT}},
Abstract = {{Researchers agree that comprehenders regularly predict upcoming
   language, but they do not always agree on what prediction is (and how to
   differentiate it from integration) or what constitutes evidence for it.
   After defining prediction, we show that it occurs at all linguistic
   levels from semantics to form, and then propose a theory of which
   mechanisms comprehenders use to predict. We argue that they most
   effectively predict using their production system (i.e.,
   prediction-by-production): They covertly imitate the linguistic form of
   the speaker's utterance and construct a representation of the underlying
   communicative intention. Comprehenders can then run this intention
   through their own production system to prepare the predicted utterance.
   But doing so takes time and resources, and comprehenders vary in the
   extent of preparation, with many groups of comprehenders (non-native
   speakers, illiterates, children, and older adults) using it less than
   typical native young adults. We thus argue that prediction-by-production
   is an optional mechanism, which is augmented by mechanisms based on
   association. Support for our proposal comes from many areas of research
   (electrophysiological, eye-tracking, and behavioral studies of reading,
   spoken language processing in the context of visual environments, speech
   processing, and dialogue).}},
Publisher = {{AMER PSYCHOLOGICAL ASSOC}},
Address = {{750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Pickering, MJ (Corresponding Author), Univ Edinburgh, Dept Psychol, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.
   Pickering, Martin J.; Gambi, Chiara, Univ Edinburgh, Dept Psychol, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.
   Gambi, Chiara, Cardiff Univ, Sch Psychol, Cardiff, S Glam, Wales.}},
DOI = {{10.1037/bul0000158}},
ISSN = {{0033-2909}},
EISSN = {{1939-1455}},
Keywords = {{dialogue; language comprehension; language production; prediction}},
Keywords-Plus = {{SPOKEN-WORD RECOGNITION; SPREADING-ACTIVATION THEORY; EVENT KNOWLEDGE
   ACTIVATION; THEMATIC ROLE-ASSIGNMENT; EYE-MOVEMENT CONTROL; SENTENCE
   COMPREHENSION; TIME-COURSE; LEXICAL ACCESS; VISUAL-WORLD; PHONOLOGICAL
   TYPICALITY}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology; Psychology, Multidisciplinary}},
Author-Email = {{martin.pickering@ed.ac.uk}},
ORCID-Numbers = {{Pickering, Martin/0000-0002-2005-049X}},
Cited-References = {{Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014.
   Adank P, 2010, PSYCHOL SCI, V21, P1903, DOI 10.1177/0956797610389192.
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558.
   ALLPORT DA, 1981, PHILOS T ROY SOC B, V295, P397, DOI 10.1098/rstb.1981.0148.
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004.
   Altmann GTM, 2009, COGNITION, V111, P55, DOI 10.1016/j.cognition.2008.12.005.
   Altmann GTM, 2004, COGNITION, V93, pB79, DOI 10.1016/j.cognition.2004.02.005.
   Altmann GTM, 1999, J MEM LANG, V41, P124, DOI 10.1006/jmla.1999.2640.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Amsel BD, 2015, J MEM LANG, V82, P118, DOI 10.1016/j.jml.2015.03.009.
   Andrews M, 2009, PSYCHOL REV, V116, P463, DOI 10.1037/a0016261.
   Arai M, 2007, COGNITIVE PSYCHOL, V54, P218, DOI 10.1016/j.cogpsych.2006.07.001.
   Arai M, 2015, J EXP PSYCHOL LEARN, V41, P482, DOI 10.1037/a0038389.
   Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914.
   BALOTA DA, 1985, COGNITIVE PSYCHOL, V17, P364, DOI 10.1016/0010-0285(85)90013-1.
   Barr DJ, 2008, COGNITION, V109, P18, DOI 10.1016/j.cognition.2008.07.005.
   Bendixen A, 2014, CORTEX, V53, P9, DOI 10.1016/j.cortex.2014.01.001.
   BENTIN S, 1985, ELECTROEN CLIN NEURO, V60, P343, DOI 10.1016/0013-4694(85)90008-2.
   Bever T., 1970, COGNITION DEV LANGUA, P279, DOI DOI 10.1093/ACPROF:OSO/9780199677139.003.0001.
   BIERWISCH M, 1992, COGNITION, V42, P23, DOI 10.1016/0010-0277(92)90039-K.
   Bobb SC, 2016, J EXP CHILD PSYCHOL, V151, P51, DOI 10.1016/j.jecp.2015.11.002.
   BOCK JK, 1986, J EXP PSYCHOL LEARN, V12, P575, DOI 10.1037/0278-7393.12.4.575.
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6.
   Bock K., 1994, HDB PSYCHOLINGUISTIC, P945.
   Bogels S, 2015, J PHONETICS, V52, P46, DOI 10.1016/j.wocn.2015.04.004.
   Bogels S, 2015, SCI REP-UK, V5, DOI 10.1038/srep12881.
   Boiteau TW, 2014, J EXP PSYCHOL GEN, V143, P295, DOI 10.1037/a0031858.
   Boland JE, 1995, J MEM LANG, V34, P774, DOI 10.1006/jmla.1995.1034.
   Boland JE, 2005, COGNITION, V95, P237, DOI 10.1016/j.cognition.2004.01.008.
   Borovsky A, 2017, LANG COGN NEUROSCI, V32, P190, DOI 10.1080/23273798.2016.1238494.
   Borovsky A, 2014, J MEM LANG, V73, P1, DOI 10.1016/j.jml.2014.02.001.
   Borovsky A, 2014, DEV PSYCHOL, V50, P1600, DOI 10.1037/a0035591.
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005.
   Borsky S, 1998, J ACOUST SOC AM, V103, P2670, DOI 10.1121/1.422787.
   Bosker HR, 2014, J MEM LANG, V75, P104, DOI 10.1016/j.jml.2014.05.004.
   Boylan C, 2014, BRAIN LANG, V137, P40, DOI 10.1016/j.bandl.2014.07.009.
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103.
   Brothers T, 2017, J MEM LANG, V93, P203, DOI 10.1016/j.jml.2016.10.002.
   Brothers T, 2015, COGNITION, V136, P135, DOI 10.1016/j.cognition.2014.10.017.
   Brown-Schmidt S, 2009, J MEM LANG, V61, P171, DOI 10.1016/j.jml.2009.04.003.
   Caramazza A, 2001, J EXP PSYCHOL LEARN, V27, P1430, DOI 10.1037//0278-7393.27.6.1430.
   Carminati MN, 2008, J EXP PSYCHOL LEARN, V34, P1098, DOI 10.1037/a0012795.
   Carreiras M, 2014, TRENDS COGN SCI, V18, P90, DOI 10.1016/j.tics.2013.11.005.
   Chambers CG, 2008, COGNITION, V108, P26, DOI 10.1016/j.cognition.2007.12.009.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Chen E, 2005, J MEM LANG, V52, P144, DOI 10.1016/j.jml.2004.10.001.
   Chow WY, 2016, LANG COGN NEUROSCI, V31, P577, DOI 10.1080/23273798.2015.1066832.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Clark Herbert H., 1996, USING LANGUAGE, DOI {[}10.1017/CBO9780511620539, DOI 10.1017/CBO9780511620539].
   CLARK HH, 1972, COGNITIVE PSYCHOL, V3, P472, DOI 10.1016/0010-0285(72)90019-9.
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009.
   D'Ausilio A, 2011, NEUROPSYCHOLOGIA, V49, P3670, DOI 10.1016/j.neuropsychologia.2011.09.022.
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074.
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750.
   Dale R, 2012, ADV COGN PSYCHOL, V8, P196, DOI {[}10.2478/v10053-008-0115-z, 10.5709/acp-0115-z].
   Davis MH, 2011, J COGNITIVE NEUROSCI, V23, P3914, DOI {[}10.1097/JOM.0b013e31820805d5, 10.1162/jocn\_a\_00084].
   De Ruiter JP, 2006, LANGUAGE, V82, P515, DOI 10.1353/lan.2006.0130.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DeLong KA, 2012, BRAIN LANG, V121, P226, DOI 10.1016/j.bandl.2012.02.006.
   Dikker S, 2014, J NEUROSCI, V34, P6267, DOI 10.1523/JNEUROSCI.3796-13.2014.
   Dikker S, 2013, BRAIN LANG, V127, P55, DOI 10.1016/j.bandl.2012.08.004.
   Dikker S, 2011, BRAIN LANG, V118, P23, DOI 10.1016/j.bandl.2011.02.006.
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751.
   Dikker S, 2009, COGNITION, V110, P293, DOI 10.1016/j.cognition.2008.09.008.
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743.
   DOSHER BA, 1989, J EXP PSYCHOL GEN, V118, P191, DOI 10.1037/0096-3445.118.2.191.
   Drake E, 2015, MEM COGNITION, V43, P1136, DOI 10.3758/s13421-015-0530-6.
   Drieghe D, 2005, J EXP PSYCHOL HUMAN, V31, P954, DOI 10.1037/0096-1523.31.5.954.
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031.
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6.
   ELMAN JL, 1988, J MEM LANG, V27, P143, DOI 10.1016/0749-596X(88)90071-X.
   Engbert R, 2005, PSYCHOL REV, V112, P777, DOI 10.1037/0033-295X.112.4.777.
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x.
   Farmer TA, 2006, P NATL ACAD SCI USA, V103, P12203, DOI 10.1073/pnas.0602173103.
   Farmer TA, 2015, J EXP PSYCHOL HUMAN, V41, P958, DOI 10.1037/xhp0000054.
   Farmer TA, 2011, J EXP PSYCHOL LEARN, V37, P1318, DOI 10.1037/a0023063.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133.
   FERREIRA F, 1991, J MEM LANG, V30, P210, DOI 10.1016/0749-596X(91)90004-4.
   Ferreira VS, 1996, J MEM LANG, V35, P724, DOI 10.1006/jmla.1996.0038.
   Forster K. I., 1979, SENTENCE PROCESSING, P27.
   Foucart A, 2016, BILING-LANG COGN, V19, P213, DOI 10.1017/S1366728915000486.
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756.
   Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006.
   FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1.
   FRAZIER L, 1987, ATTENTION PERFORM, P559.
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001.
   Frisson S, 2017, J MEM LANG, V95, P200, DOI 10.1016/j.jml.2017.04.007.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Fruchter J, 2015, J COGNITIVE NEUROSCI, V27, P1912, DOI 10.1162/jocn\_a\_00822.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Gambi C., 2017, HDB PSYCHOLINGUISTIC, P157, DOI {[}10.1002/9781118829516.ch7, DOI 10.1002/9781118829516.CH7].
   Gambi C, 2016, COGNITION, V157, P340, DOI 10.1016/j.cognition.2016.10.003.
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110.
   GARROD S, 1987, COGNITION, V27, P181, DOI 10.1016/0010-0277(87)90018-7.
   Garrod S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00751.
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1.
   GIBSON E, 1993, LANG COGNITIVE PROC, V8, P147, DOI 10.1080/01690969308406952.
   Gibson E, 2013, P NATL ACAD SCI USA, V110, P8051, DOI 10.1073/pnas.1216438110.
   Goldrick M., 2014, OXFORD HDB LANGUAGE, DOI {[}10.1093/oxfordhb/9780199735471.001.0001, DOI 10.1093/OXFORDHB/9780199735471.001.0001].
   Gomez RL, 2000, TRENDS COGN SCI, V4, P178, DOI 10.1016/S1364-6613(00)01467-4.
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476.
   Gow D. W., 2007, LAB PHONOLOGY, V9, P173.
   Gow DW, 2015, J MEM LANG, V82, P41, DOI 10.1016/j.jml.2015.03.004.
   Grisoni L, 2017, J NEUROSCI, V37, P4848, DOI 10.1523/JNEUROSCI.2800-16.2017.
   Groppe DM, 2010, BRAIN RES, V1361, P54, DOI 10.1016/j.brainres.2010.09.003.
   Guediche S, 2015, CEREB CORTEX, V25, P1867, DOI 10.1093/cercor/bht428.
   Guediche S, 2013, J COGNITIVE NEUROSCI, V25, P706, DOI 10.1162/jocn\_a\_00351.
   Hale J., 2001, P 2 M NO AM CHAPT AS.
   Hanna JE, 2003, J MEM LANG, V49, P43, DOI 10.1016/S0749-596X(03)00022-6.
   Heinks-Maldonado TH, 2006, NEUROREPORT, V17, P1375, DOI 10.1097/01.wnr.0000233102.43526.e9.
   Heldner M, 2010, J PHONETICS, V38, P555, DOI 10.1016/j.wocn.2010.08.002.
   Heller D, 2015, LANG SPEECH, V58, P190, DOI 10.1177/0023830914528107.
   Herrmann B, 2009, NEUROIMAGE, V48, P590, DOI 10.1016/j.neuroimage.2009.06.082.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Hintz F, 2017, J EXP PSYCHOL LEARN, V43, P1352, DOI 10.1037/xlm0000388.
   Hintz F, 2016, Q J EXP PSYCHOL, V69, P1056, DOI 10.1080/17470218.2015.1131309.
   Hintz F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130766.
   Hirose Y, 2015, COGNITION, V136, P350, DOI 10.1016/j.cognition.2014.11.033.
   Hohenstein S, 2014, J EXP PSYCHOL LEARN, V40, P166, DOI 10.1037/a0033670.
   Hosemann J, 2013, NEUROPSYCHOLOGIA, V51, P2224, DOI 10.1016/j.neuropsychologia.2013.07.013.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Huettig F, 2015, DYSLEXIA, V21, P97, DOI 10.1002/dys.1497.
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001.
   Indefrey P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00255.
   INHOFF AW, 1986, PERCEPT PSYCHOPHYS, V40, P431, DOI 10.3758/BF03208203.
   Ito A, 2017, LANG COGN NEUROSCI, V32, P954, DOI 10.1080/23273798.2016.1242761.
   Ito A, 2018, BILING-LANG COGN, V21, P251, DOI 10.1017/S1366728917000050.
   Ito A, 2018, J MEM LANG, V98, P1, DOI 10.1016/j.jml.2017.09.002.
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007.
   Ito M, 2008, NAT REV NEUROSCI, V9, P304, DOI 10.1038/nrn2332.
   JESCHENIAK JD, 1994, J EXP PSYCHOL LEARN, V20, P824, DOI 10.1037/0278-7393.20.4.824.
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329.
   Kaiser E, 2004, COGNITION, V94, P113, DOI 10.1016/j.cognition.2004.01.002.
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kempen G, 2014, NEUROINFORMATICS, V12, P111, DOI 10.1007/s12021-013-9191-4.
   Keysar B, 1998, CURR DIR PSYCHOL SCI, V7, P46, DOI 10.1111/1467-8721.ep13175613.
   Keysar B, 2003, COGNITION, V89, P25, DOI 10.1016/S0010-0277(03)00064-7.
   Keysar B, 2000, PSYCHOL SCI, V11, P32, DOI 10.1111/1467-9280.00211.
   Kim A, 2012, J COGNITIVE NEUROSCI, V24, P1104, DOI 10.1162/jocn\_a\_00148.
   Kim AE, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00045.
   Kim CS, 2015, COGNITION, V139, P28, DOI 10.1016/j.cognition.2015.02.009.
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5.
   Kleinman D, 2015, COGNITIVE PSYCHOL, V79, P68, DOI 10.1016/j.cogpsych.2015.04.001.
   Knoeferle P, 2005, COGNITION, V95, P95, DOI 10.1016/j.cognition.2004.03.002.
   Knoeferle P, 2007, J MEM LANG, V57, P519, DOI 10.1016/j.jml.2007.01.003.
   Knoeferle P, 2006, COGNITIVE SCI, V30, P481, DOI 10.1207/s15516709cog0000\_65.
   Kretzschtnar F, 2015, J EXP PSYCHOL LEARN, V41, P1648, DOI 10.1037/xlm0000128.
   Kukona A, 2014, J EXP PSYCHOL LEARN, V40, P326, DOI 10.1037/a0034903.
   Kukona A, 2011, COGNITION, V119, P23, DOI 10.1016/j.cognition.2010.12.002.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Kurumada C, 2014, COGNITION, V133, P335, DOI 10.1016/j.cognition.2014.05.017.
   KUTAS M, 1988, BRAIN, V111, P553, DOI 10.1093/brain/111.3.553.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kwon N, 2017, COGNITION, V166, P433, DOI 10.1016/j.cognition.2017.06.010.
   Lammertink I, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00495.
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004.
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003.
   Lau EF, 2013, J COGNITIVE NEUROSCI, V25, P484, DOI 10.1162/jocn\_a\_00328.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619.
   Lerner G.H., 2002, LANGUAGE TURN SEQUEN, P225.
   Lesage E, 2012, CURR BIOL, V22, pR794, DOI 10.1016/j.cub.2012.07.006.
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1.
   Levelt WJM., 1989, SPEAKING INTENTION A.
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Linzen T, 2016, COGNITIVE SCI, V40, P1382, DOI 10.1111/cogs.12274.
   Lowder MW, 2016, J EXP PSYCHOL LEARN, V42, P1400, DOI 10.1037/xlm0000256.
   Luke SG, 2016, COGNITIVE PSYCHOL, V88, P22, DOI 10.1016/j.cogpsych.2016.06.002.
   Lukyanenko C, 2016, COGNITION, V146, P349, DOI 10.1016/j.cognition.2015.10.012.
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676.
   Mack JE, 2013, J NEUROLINGUIST, V26, P619, DOI 10.1016/j.jneuroling.2013.04.002.
   Maess B, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00591.
   Magnuson JS, 2003, COGNITIVE SCI, V27, P285, DOI 10.1016/S0364-0213(03)00004-1.
   Magyari L, 2014, J COGNITIVE NEUROSCI, V26, P2530, DOI 10.1162/jocn\_a\_00673.
   Magyari L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00376.
   Mahr T, 2015, COGNITION, V142, P345, DOI 10.1016/j.cognition.2015.05.009.
   Mani N, 2016, Q J EXP PSYCHOL, V69, P2189, DOI 10.1080/17470218.2015.1111395.
   Mani N, 2014, J EXP CHILD PSYCHOL, V126, P264, DOI 10.1016/j.jecp.2014.05.004.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   MANN VA, 1981, J ACOUST SOC AM, V69, P548, DOI 10.1121/1.385483.
   Marr D., 1982, VISION COMPUTATIONAL.
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9.
   Martin CD, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19499-4.
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   Mattys SL, 2005, PSYCHOL SCI, V16, P958, DOI 10.1111/j.1467-9280.2005.01644.x.
   Mattys SL, 2001, COGNITION, V78, P91, DOI 10.1016/S0010-0277(00)00109-8.
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006.
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007.
   McNamara T., 2005, SEMANTIC PRIMING PER, DOI {[}DOI 10.4324/9780203338001, 10.4324/9780203338001].
   McQueen JM, 2006, TRENDS COGN SCI, V10, P533, DOI 10.1016/j.tics.2006.10.004.
   McQueen JM, 2016, LANG COGN NEUROSCI, V31, P860, DOI 10.1080/23273798.2016.1154975.
   McQueen JM, 2009, J MEM LANG, V61, P1, DOI 10.1016/j.jml.2009.03.002.
   McQueen JM, 2003, SPEECH COMMUN, V41, P257, DOI 10.1016/S0167-6393(02)00108-5.
   McRae K, 2005, MEM COGNITION, V33, P1174, DOI 10.3758/BF03193221.
   Melancon A, 2015, J CHILD LANG, V42, P1379, DOI 10.1017/S0305000914000804.
   Menenti L, 2011, PSYCHOL SCI, V22, P1173, DOI 10.1177/0956797611418347.
   Metusalem R, 2012, J MEM LANG, V66, P545, DOI 10.1016/j.jml.2012.01.001.
   Meyer AS, 1996, J MEM LANG, V35, P477, DOI 10.1006/jmla.1996.0026.
   MEYER DE, 1971, J EXP PSYCHOL, V90, P227, DOI 10.1037/h0031564.
   Miall RC, 2016, NEUROPSYCHOLOGIA, V86, P103, DOI 10.1016/j.neuropsychologia.2016.04.022.
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491.
   Mintz TH, 2003, COGNITION, V90, P91, DOI 10.1016/S0010-0277(03)00140-9.
   Mishra RK, 2012, J EYE MOVEMENT RES, V5.
   Misyak J. B., 2007, P 29 ANN COGN SCI SO.
   Misyak JB, 2010, TOP COGN SCI, V2, P138, DOI 10.1111/j.1756-8765.2009.01072.x.
   Mitsugi S, 2016, BILING-LANG COGN, V19, P19, DOI 10.1017/S1366728914000881.
   Moberget T, 2016, ANN NY ACAD SCI, V1369, P154, DOI 10.1111/nyas.13094.
   Moberget T, 2014, J NEUROSCI, V34, P2871, DOI 10.1523/JNEUROSCI.2264-13.2014.
   Nakatani K, 2010, COGNITIVE SCI, V34, P94, DOI 10.1111/j.1551-6709.2009.01067.x.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Neely JH, 2001, SCI CON SER, P69, DOI 10.1037/10394-005.
   NEVILLE HJ, 1986, J MEM LANG, V25, P75, DOI 10.1016/0749-596X(86)90022-7.
   Newman RL, 2004, COGNITIVE BRAIN RES, V21, P94, DOI 10.1016/j.cogbrainres.2004.05.006.
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2.
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468.
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013.
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9.
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241.
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357.
   Nuttall HE, 2016, NEUROIMAGE, V128, P218, DOI 10.1016/j.neuroimage.2015.12.038.
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128.
   Otten M, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-89.
   Otten M, 2009, BRAIN RES, V1291, P92, DOI 10.1016/j.brainres.2009.07.042.
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463.
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049.
   Perea M, 1997, COGNITION, V62, P223, DOI 10.1016/S0010-0277(96)00782-2.
   Peterson RR, 1998, J EXP PSYCHOL LEARN, V24, P539, DOI 10.1037/0278-7393.24.3.539.
   PICKERING M, 1991, LANG COGNITIVE PROC, V6, P229, DOI 10.1080/01690969108406944.
   Pickering MJ, 2008, PSYCHOL BULL, V134, P427, DOI 10.1037/0033-2909.134.3.427.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169.
   Pickering MJ, 2001, J EXP PSYCHOL LEARN, V27, P1401, DOI 10.1037//0278-7393.27.6.1401.
   Pitt MA, 1998, J MEM LANG, V39, P347, DOI 10.1006/jmla.1998.2571.
   Pozzan L, 2015, COGNITIVE PSYCHOL, V80, P73, DOI 10.1016/j.cogpsych.2015.03.004.
   PRAAMSTRA P, 1993, COGNITIVE BRAIN RES, V1, P73, DOI 10.1016/0926-6410(93)90013-U.
   Pulvermuller F, 2005, J COGNITIVE NEUROSCI, V17, P884, DOI 10.1162/0898929054021111.
   Quene H, 2008, J ACOUST SOC AM, V123, P1104, DOI 10.1121/1.2821762.
   Rabagliati H, 2016, LANG COGN NEUROSCI, V31, P94, DOI 10.1080/23273798.2015.1077979.
   RATCLIFF R, 1988, PSYCHOL REV, V95, P385, DOI 10.1037/0033-295X.95.3.385.
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372.
   Rayner K, 1996, PSYCHON B REV, V3, P504, DOI 10.3758/BF03214555.
   Rayner K, 2004, J EXP PSYCHOL HUMAN, V30, P720, DOI 10.1037/0096-1523.30.4.720.
   RAYNER K, 1983, J EXP PSYCHOL HUMAN, V9, P912, DOI 10.1037/0096-1523.9.6.912.
   Rayner K, 2011, J EXP PSYCHOL HUMAN, V37, P514, DOI 10.1037/a0020990.
   Reichle ED, 1998, PSYCHOL REV, V105, P125, DOI 10.1037/0033-295X.105.1.125.
   REPP BH, 1992, PERCEPT PSYCHOPHYS, V51, P14, DOI 10.3758/BF03205070.
   Roark B., 2009, P 2009 C EMP METH NA, V1.
   Roelofs A, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00307.
   Roland D, 2012, COGNITION, V122, P267, DOI 10.1016/j.cognition.2011.11.011.
   Romero-Rivas C, 2016, NEUROPSYCHOLOGIA, V85, P245, DOI 10.1016/j.neuropsychologia.2016.03.022.
   Rommers J, 2015, ATTEN PERCEPT PSYCHO, V77, P720, DOI 10.3758/s13414-015-0873-x.
   Rommers J, 2013, NEUROPSYCHOLOGIA, V51, P437, DOI 10.1016/j.neuropsychologia.2012.12.002.
   Rothermich K, 2012, NEUROPSYCHOLOGIA, V50, P232, DOI 10.1016/j.neuropsychologia.2011.10.025.
   RUGG MD, 1985, PSYCHOPHYSIOLOGY, V22, P642, DOI 10.1111/j.1469-8986.1985.tb01661.x.
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243.
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243.
   Saffran JR, 2001, COGNITION, V81, P149, DOI 10.1016/S0010-0277(01)00132-9.
   Salverda AP, 2014, J MEM LANG, V71, P145, DOI 10.1016/j.jml.2013.11.002.
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474.
   Samuel AG, 2003, J MEM LANG, V48, P416, DOI 10.1016/S0749-596X(02)00514-4.
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364.
   Sauppe S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00095.
   Schank Roger C., 1977, SCRIPTS GOALS PLANS.
   Schotter ER, 2015, J MEM LANG, V83, P118, DOI 10.1016/j.jml.2015.04.005.
   SCHWANENFLUGEL PJ, 1985, J MEM LANG, V24, P232, DOI 10.1016/0749-596X(85)90026-9.
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603.
   Sedivy JC, 1999, COGNITION, V71, P109, DOI 10.1016/S0010-0277(99)00025-6.
   Segaert K, 2012, CEREB CORTEX, V22, P1662, DOI 10.1093/cercor/bhr249.
   Sereno SC, 2003, TRENDS COGN SCI, V7, P489, DOI 10.1016/j.tics.2003.09.010.
   Shahin AJ, 2009, NEUROIMAGE, V44, P1133, DOI 10.1016/j.neuroimage.2008.09.045.
   Silbert LJ, 2014, P NATL ACAD SCI USA, V111, pE4687, DOI 10.1073/pnas.1323812111.
   Sivonen P, 2006, BRAIN RES, V1121, P177, DOI 10.1016/j.brainres.2006.08.123.
   Sivonen P, 2006, NEUROSCI LETT, V408, P220, DOI 10.1016/j.neulet.2006.09.001.
   Sjerps MJ, 2015, COGNITION, V136, P304, DOI 10.1016/j.cognition.2014.10.008.
   Skipper JI, 2006, ACTION TO LANGUAGE VIA THE MIRROR NEURON SYSTEM, P250, DOI 10.1017/CBO9780511541599.009.
   SLOWIACZEK LM, 1987, J EXP PSYCHOL LEARN, V13, P64, DOI 10.1037/0278-7393.13.1.64.
   Smith M, 2004, J EXP PSYCHOL LEARN, V30, P675, DOI 10.1037/0278-7393.30.3.675.
   Smith M, 1999, COGNITION, V73, P205, DOI 10.1016/S0010-0277(99)00053-0.
   Smith N. J., 2011, 33 ANN M COGN SCI SO.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Soderstrom P, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00512.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   STANOVICH KE, 1979, MEM COGNITION, V7, P77, DOI 10.3758/BF03197588.
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425.
   Staub A, 2015, LANG LINGUIST COMPAS, V9, P311, DOI 10.1111/lnc3.12151.
   Staub A, 2015, J MEM LANG, V82, P1, DOI 10.1016/j.jml.2015.02.004.
   Staub A, 2011, PSYCHON B REV, V18, P371, DOI 10.3758/s13423-010-0046-9.
   Staub A, 2010, J EXP PSYCHOL HUMAN, V36, P1280, DOI 10.1037/a0016896.
   Staub A, 2009, J EXP PSYCHOL LEARN, V35, P806, DOI 10.1037/a0015123.
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107.
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106.
   Strijkers K, 2016, LANG COGN NEUROSCI, V31, P484, DOI 10.1080/23273798.2015.1120878.
   SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401.
   Thiessen ED, 2011, CHILD DEV, V82, P462, DOI 10.1111/j.1467-8624.2010.01522.x.
   Thornhill DE, 2012, INT J PSYCHOPHYSIOL, V83, P382, DOI 10.1016/j.ijpsycho.2011.12.007.
   Thothathiri M, 2008, J MEM LANG, V58, P188, DOI 10.1016/j.jml.2007.06.012.
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424.
   Traxler MJ, 1996, J MEM LANG, V35, P454, DOI 10.1006/jmla.1996.0025.
   Traxler MJ, 2000, J EXP PSYCHOL LEARN, V26, P1266, DOI 10.1037//0278-7393.26.5.1266.
   TRUESWELL JC, 1994, J MEM LANG, V33, P285, DOI 10.1006/jmla.1994.1014.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054.
   van Berkum JJA, 2013, THEOR LINGUIST, V39, P75, DOI 10.1515/tl-2013-0004.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Vigliocco G, 1997, PSYCHOL SCI, V8, P314, DOI 10.1111/j.1467-9280.1997.tb00444.x.
   Vissers CTWM, 2006, BRAIN RES, V1106, P150, DOI 10.1016/j.brainres.2006.05.012.
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392.
   Warren T, 2016, J NEUROLINGUIST, V39, P38, DOI 10.1016/j.jneuroling.2016.01.001.
   Weber A, 2006, COGNITION, V99, pB63, DOI 10.1016/j.cognition.2005.07.001.
   White SJ, 2008, J EXP PSYCHOL HUMAN, V34, P205, DOI 10.1037/0096-1523.34.1.205.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Willems RM, 2016, CEREB CORTEX, V26, P2506, DOI 10.1093/cercor/bhv075.
   Wilson M, 2005, PSYCHON B REV, V12, P957, DOI 10.3758/BF03206432.
   WILSON WM, 1973, NATURE, V244, P522, DOI 10.1038/244522a0.
   Wlotko EW, 2015, CORTEX, V68, P20, DOI 10.1016/j.cortex.2015.03.014.
   Wlotko EW, 2012, PSYCHOL AGING, V27, P975, DOI 10.1037/a0029206.
   Wlotko EW, 2012, NEUROIMAGE, V62, P356, DOI 10.1016/j.neuroimage.2012.04.054.
   Wlotko EW, 2012, PSYCHOPHYSIOLOGY, V49, P770, DOI 10.1111/j.1469-8986.2012.01366.x.
   Wolpert DM, 1997, TRENDS COGN SCI, V1, P209, DOI 10.1016/S1364-6613(97)01070-X.
   WRIGHT B, 1984, MEM COGNITION, V12, P31, DOI 10.3758/BF03196995.
   Yan S., 2017, BIORXIV, DOI {[}10.1101/143750, DOI 10.1101/143750].
   Yoshida M, 2013, LANG COGNITIVE PROC, V28, P272, DOI 10.1080/01690965.2011.622905.}},
Number-of-Cited-References = {{338}},
Times-Cited = {{34}},
Usage-Count-Last-180-days = {{16}},
Usage-Count-Since-2013 = {{106}},
Journal-ISO = {{Psychol. Bull.}},
Doc-Delivery-Number = {{GU2HG}},
Unique-ID = {{ISI:000445089400002}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000438718300017,
Author = {Andersen, Asger Heidemann and de Haan, Jan Mark and Tan, Zheng-Hua and
   Jensen, Jesper},
Title = {{Nonintrusive Speech Intelligibility Prediction Using Convolutional
   Neural Networks}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2018}},
Volume = {{26}},
Number = {{10}},
Pages = {{1925-1939}},
Month = {{OCT}},
Abstract = {{Speech Intelligibility Prediction (SIP) algorithms are becoming popular
   tools within the development and operation of speech processing devices
   and algorithms. However, many SIP algorithms require knowledge of the
   underlying clean speech; a signal that is often not available in
   real-world applications. This has led to increased interest in
   nonintrusive SIP algorithms, which do not require clean speech to make
   predictions. In this paper, we investigate the use of Convolutional
   Neural Networks (CNNs) for nonintrusive SIP. To do so, we utilize a CNN
   architecture that shows similarities to existing SIP algorithms, in
   terms of computational structure, and which allows for easy and
   meaningful visualization and interpretation of trained weights. We
   evaluate this architecture using a large dataset obtained by combining
   datasets from the literature. The proposed method shows high prediction
   performance when compared with four existing intrusive and nonintrusive
   SIP algorithms. This demonstrates the potential of deep learning for
   speech intelligibility prediction.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Andersen, AH (Corresponding Author), Oticon AS, DK-2765 Smorum, Denmark.
   Andersen, Asger Heidemann; de Haan, Jan Mark; Jensen, Jesper, Oticon AS, DK-2765 Smorum, Denmark.
   Tan, Zheng-Hua; Jensen, Jesper, Aalborg Univ, DK-9220 Aalborg, Denmark.}},
DOI = {{10.1109/TASLP.2018.2847459}},
ISSN = {{2329-9290}},
Keywords = {{Nonintrusive speech intelligibility prediction; convolutional neural
   networks}},
Keywords-Plus = {{EQUALIZATION-CANCELLATION MODEL; FREQUENCY-IMPORTANCE; RECEPTION
   THRESHOLD; ADDITIVE NOISE; NORMAL-HEARING; SENTENCE TEST; INDEX;
   RECOGNITION; PERCEPTION; QUALITY}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{aand@oticon.com
   janh@oticon.com
   zt@es.aau.dk
   jesj@oticon.com}},
ResearcherID-Numbers = {{Tan, Zheng-Hua/B-6889-2015
   }},
ORCID-Numbers = {{Tan, Zheng-Hua/0000-0001-6856-8928
   Jensen, Jesper/0000-0003-1478-622X}},
Funding-Acknowledgement = {{Oticon Foundation; Danish Innovation Foundation}},
Funding-Text = {{The work was supported in part by the Oticon Foundation and in part the
   Danish Innovation Foundation.}},
Cited-References = {{Alghamdi A., 2017, P IEEE CAN C EL COMP, P386.
   Allen JB, 2005, AUDITORY SIGNAL PROCESSINGP: PHYSIOLOGY, PSYCHOACOUSTICS, AND MODELS, P314.
   American national standard institute, 1997, METH CALC SPEECH INT.
   Andersen AH, 2017, INT CONF ACOUST SPEE, P5085, DOI 10.1109/ICASSP.2017.7953125.
   Andersen AH, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2563.
   Andersen AH, 2016, IEEE-ACM T AUDIO SPE, V24, P1908, DOI 10.1109/TASLP.2016.2588002.
   Andersson A., 2016, P 2016 IEEE EN CONV, P1.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575.
   Chabot-Leclerc A, 2016, J ACOUST SOC AM, V140, P192, DOI 10.1121/1.4954254.
   Chen F, 2013, BIOMED SIGNAL PROCES, V8, P311, DOI 10.1016/j.bspc.2012.11.007.
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600.
   Cosentino S, 2014, J ACOUST SOC AM, V135, P796, DOI 10.1121/1.4861239.
   Dugas C., 2001, P 13 INT C NEUR INF, P1369.
   Elhilali M, 2003, SPEECH COMMUN, V41, P331, DOI 10.1016/S0167-6393(02)00134-6.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   Falk TH, 2013, INT CONF ACOUST SPEE, P7820, DOI 10.1109/ICASSP.2013.6639186.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Fletcher H, 1929, BELL SYST TECH J, V8, P806, DOI 10.1002/j.1538-7305.1929.tb01246.x.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goodfellow Ian, 2017, DEEP LEARNING.
   Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893.
   Hendriks RC, 2015, IEEE-ACM T AUDIO SPE, V23, P851, DOI 10.1109/TASLP.2015.2409780.
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597.
   Hirsh IJ, 1952, J SPEECH HEAR DISORD, V17, P321, DOI 10.1044/jshd.1703.321.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   Houben R, 2014, INT J AUDIOL, V53, P760, DOI 10.3109/14992027.2014.920111.
   HOUTGAST T, 1971, ACUSTICA, V25, P355.
   Jelfs S, 2011, HEARING RES, V275, P96, DOI 10.1016/j.heares.2010.12.005.
   Jensen J, 2016, IEEE-ACM T AUDIO SPE, V24, P2009, DOI 10.1109/TASLP.2016.2585878.
   Jensen J, 2014, IEEE-ACM T AUDIO SPE, V22, P430, DOI 10.1109/TASLP.2013.2295914.
   Jia XP, 2016, INT CONF SIGN PROCES, P541, DOI 10.1109/ICSP.2016.7877892.
   Jones E., 2001, SCIPY OPEN SOURCE SC.
   Jorgensen S, 2015, ACTA ACUST UNITED AC, V101, P1016, DOI 10.3813/AAA.918896.
   Jorgensen S, 2013, J ACOUST SOC AM, V134, P436, DOI 10.1121/1.4807563.
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502.
   Karbasi M, 2016, INT CONF ACOUST SPEE, P624, DOI 10.1109/ICASSP.2016.7471750.
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002.
   Kates JM, 2013, J ACOUST SOC AM, V134, pEL459, DOI 10.1121/1.4826148.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673.
   Kleijn WB, 2015, IEEE SIGNAL PROC LET, V22, P303, DOI 10.1109/LSP.2014.2351784.
   Kolbaek M, 2017, IEEE-ACM T AUDIO SPE, V25, P153, DOI 10.1109/TASLP.2016.2628641.
   Lavandier M, 2010, J ACOUST SOC AM, V127, P387, DOI 10.1121/1.3268612.
   Lightbum L, 2016, INT CONF ACOUST SPEE, P5365, DOI 10.1109/ICASSP.2016.7472702.
   LIGHTBURN L, 2015, P IEEE INT C AC SPEE, P5078.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Loizou PC, 2011, J ACOUST SOC AM, V130, P986, DOI 10.1121/1.3605668.
   Mahdavian M., 2013, 10 INT C EL ENG COMP, P1.
   Mandel MI, 2016, J ACOUST SOC AM, V140, P2542, DOI 10.1121/1.4964102.
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491.
   Rhebergen KS, 2006, J ACOUST SOC AM, V120, P3988, DOI 10.1121/1.2358008.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   Santos JF, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P55, DOI 10.1109/IWAENC.2014.6953337.
   Santos JF, 2014, IEEE-ACM T AUDIO SPE, V22, P2197, DOI 10.1109/TASLP.2014.2363788.
   Schadler MR, 2015, INT J AUDIOL, V54, P100, DOI 10.3109/14992027.2015.1061708.
   Sharma D, 2016, SPEECH COMMUN, V80, P84, DOI 10.1016/j.specom.2016.03.005.
   Sharma D, 2010, EUR SIGNAL PR CONF, P1899.
   Smeds K, 2014, J ACOUST SOC AM, V136, P1363, DOI 10.1121/1.4892766.
   Sorensen C, 2017, INT CONF ACOUST SPEE, P386, DOI 10.1109/ICASSP.2017.7952183.
   Sorensen C, 2016, EUR SIGNAL PR CONF, P1358, DOI 10.1109/EUSIPCO.2016.7760470.
   Spille C, 2018, COMPUT SPEECH LANG, V48, P51, DOI 10.1016/j.csl.2017.10.004.
   Stadler S., 2007, P INT 2007, P398.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STUDEBAKER GA, 1991, J SPEECH HEAR RES, V34, P427, DOI 10.1044/jshr.3402.427.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Taghia J, 2014, IEEE-ACM T AUDIO SPE, V22, P6, DOI 10.1109/TASL.2013.2281574.
   The Theano Development Team, 2016, ARXIV160502688 THEAN.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.
   vomHovel H., 1984, THESIS.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.
   Wan R, 2014, J ACOUST SOC AM, V136, P768, DOI 10.1121/1.4884767.
   Wan R, 2010, J ACOUST SOC AM, V128, P3678, DOI 10.1121/1.3502458.}},
Number-of-Cited-References = {{73}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{GN1BN}},
Unique-ID = {{ISI:000438718300017}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000438375200005,
Author = {Blank, Helen and Spangenberg, Marlene and Davis, Matthew H.},
Title = {{Neural Prediction Errors Distinguish Perception and Misperception of
   Speech}},
Journal = {{JOURNAL OF NEUROSCIENCE}},
Year = {{2018}},
Volume = {{38}},
Number = {{27}},
Pages = {{6076-6089}},
Month = {{JUL 4}},
Abstract = {{Humans use prior expectations to improve perception, especially of
   sensory signals that are degraded or ambiguous. However, if sensory
   input deviates from prior expectations, then correct perception depends
   on adjusting or rejecting prior expectations. Failure to adjust or
   reject the prior leads to perceptual illusions, especially if there is
   partial overlap (and thus partial mismatch) between expectations and
   input. With speech, ``slips of the ear{''} occur when expectations lead
   to misperception. For instance, an entomologist might be more
   susceptible to hear ``The ants are my friends{''} for ``The answer, my
   friend{''} (in the Bob Dylan song Blowing in the Wind). Here, we
   contrast two mechanisms by which prior expectations may lead to
   misperception of degraded speech. First, clear representations of the
   common sounds in the prior and input (i.e., expected sounds) may lead to
   incorrect confirmation of the prior. Second, insufficient
   representations of sounds that deviate between prior and input (i.e.,
   prediction errors) could lead to deception. We used crossmodal
   predictions from written words that partially match degraded speech to
   compare neural responses when male and female human listeners were
   deceived into accepting the prior or correctly reject it. Combined
   behavioral and multivariate representational similarity analysis of fMRI
   data show that veridical perception of degraded speech is signaled by
   representations of prediction error in the left superior temporal
   sulcus. Instead of using top-down processes to support perception of
   expected sensory input, our findings suggest that the strength of neural
   prediction error representations distinguishes correct perception and
   misperception.}},
Publisher = {{SOC NEUROSCIENCE}},
Address = {{11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Blank, H (Corresponding Author), Univ Med Ctr Hamburg, Dept Syst Neurosci, Eppendorf Martinistr 52, D-20248 Hamburg, Germany.
   Blank, Helen; Spangenberg, Marlene; Davis, Matthew H., Univ Cambridge, Med Res Council, Cognit \& Brain Sci Unit, Cambridge CB2 7E, England.
   Blank, Helen, Univ Med Ctr Hamburg, Dept Syst Neurosci, Eppendorf Martinistr 52, D-20248 Hamburg, Germany.
   Spangenberg, Marlene, Univ Oxford, Dept Expt Psychol, Oxford OX1 3PH, England.}},
DOI = {{10.1523/JNEUROSCI.3258-17.2018}},
ISSN = {{0270-6474}},
EISSN = {{1529-2401}},
Keywords = {{fMRI; misperception; predictive coding; prior expectations;
   representational similarity analysis; speech perception}},
Keywords-Plus = {{PRIOR KNOWLEDGE; HEARING-LOSS; RECOGNITION; REPRESENTATIONS;
   ORGANIZATION; INFORMATION; CORTEX; OSCILLATIONS; REPETITION; BRAIN}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{hblank@uke.de}},
ORCID-Numbers = {{Spangenberg, Marlene/0000-0002-2549-3476
   , Helen/0000-0002-5824-0811
   Davis, Matt/0000-0003-2239-0778}},
Funding-Acknowledgement = {{UK Medical Research CouncilMedical Research Council UK (MRC)
   {[}RG91365/SUAG/008]; European Union Horizon 2020 Programme (Marie Curie
   Fellowship)European Union (EU) {[}703635]}},
Funding-Text = {{This work was supported by the UK Medical Research Council (Grant
   RG91365/SUAG/008 to M.H.D.) and the European Union Horizon 2020
   Programme (Marie Curie Fellowship 703635 to H.B.). We thank Yaara Erez,
   Jenni Rodd, Ediz Sohoglu, and Arnold Ziesche for valuable comments on a
   previous version of this manuscript and Helen Lloyd and Steve Eldridge
   for assistance in radiography.}},
Cited-References = {{Aitchison L, 2017, CURR OPIN NEUROBIOL, V46, P219, DOI 10.1016/j.conb.2017.08.010.
   Alderson-Day B, 2017, BRAIN, V140, P2475, DOI 10.1093/brain/awx206.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Billig AJ, 2013, CURR BIOL, V23, P1585, DOI 10.1016/j.cub.2013.06.042.
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577.
   Blank H, 2013, NEUROIMAGE, V65, P109, DOI 10.1016/j.neuroimage.2012.09.047.
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333.
   Bond Z., 1999, SLIPS EAR ERRORS PER.
   Bond ZS, 2005, BLACKW HBK LINGUIST, P290, DOI 10.1002/9780470757024.ch12.
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3.
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7.
   Cusack R, 2015, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00090.
   Dalton DS, 2003, GERONTOLOGIST, V43, P661, DOI 10.1093/geront/43.5.661.
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021.
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111.
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136.
   Fletcher PC, 2009, NAT REV NEUROSCI, V10, P48, DOI 10.1038/nrn2536.
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063.
   Gregory R.L., 1997, EYE BRAIN PSYCHOL SE.
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006.
   Henson RNA, 2003, PROG NEUROBIOL, V70, P53, DOI 10.1016/S0301-0082(03)00086-8.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011.
   Kok P, 2012, NEURON, V75, P265, DOI 10.1016/j.neuron.2012.04.034.
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   Misaki M, 2010, NEUROIMAGE, V53, P103, DOI 10.1016/j.neuroimage.2010.05.051.
   Moore DR, 2009, NAT NEUROSCI, V12, P686, DOI 10.1038/nn.2326.
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477.
   Murray SO, 2004, NEURAL NETWORKS, V17, P695, DOI 10.1016/j.neunet.2004.03.010.
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011.
   Nili H, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003553.
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091.
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rogersa CS, 2015, J ACOUST SOC AM, V138, pEL26, DOI 10.1121/1.4922363.
   Roth TN, 2011, EUR ARCH OTO-RHINO-L, V268, P1101, DOI 10.1007/s00405-011-1597-8.
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1.
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303.
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113.
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Summerfield C, 2008, NAT NEUROSCI, V11, P1004, DOI 10.1038/nn.2163.
   Teufel C, 2015, P NATL ACAD SCI USA, V112, P13401, DOI 10.1073/pnas.1503916112.
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978.
   Zoefel B, 2017, LANG COGN NEUROSCI, V32, P910, DOI 10.1080/23273798.2016.1247970.}},
Number-of-Cited-References = {{48}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{J. Neurosci.}},
Doc-Delivery-Number = {{GM7NL}},
Unique-ID = {{ISI:000438375200005}},
OA = {{Green Published, Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000438890800012,
Author = {Noppeney, Uta and Lee, Hwee Ling},
Title = {{Causal inference and temporal predictions in audiovisual perception of
   speech and music}},
Journal = {{ANNALS OF THE NEW YORK ACADEMY OF SCIENCES}},
Year = {{2018}},
Volume = {{1423}},
Number = {{1, SI}},
Pages = {{102-116}},
Month = {{JUL}},
Note = {{6th International Conference on Neurosciences and Music, Mariani Fdn
   Paediat Neurol, Boston, MA, JUN 15-18, 2017}},
Abstract = {{To form a coherent percept of the environment, the brain must integrate
   sensory signals emanating from a common source but segregate those from
   different sources. Temporal regularities are prominent cues for
   multisensory integration, particularly for speech and music perception.
   In line with models of predictive coding, we suggest that the brain
   adapts an internal model to the statistical regularities in its
   environment. This internal model enables cross-sensory and sensorimotor
   temporal predictions as a mechanism to arbitrate between integration and
   segregation of signals from different senses.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Lee, HL (Corresponding Author), German Ctr Neurodegenerat Dis DZNE, Sigmund Freud Str 27, D-53127 Bonn, Germany.
   Noppeney, Uta, Univ Birmingham, Computat Neurosci \& Cognit Robot Ctr, Birmingham, W Midlands, England.
   Lee, Hwee Ling, German Ctr Neurodegenerat Dis DZNE, Sigmund Freud Str 27, D-53127 Bonn, Germany.}},
DOI = {{10.1111/nyas.13615}},
ISSN = {{0077-8923}},
EISSN = {{1749-6632}},
Keywords = {{audiovisual; speech; music; prediction error; Bayesian causal inference}},
Keywords-Plus = {{VISUAL-SPEECH; MULTISENSORY INTEGRATION; BRAIN; INFORMATION; EXPERTISE;
   SYNCHRONY; RECALIBRATION; RECOGNITION; TEXTURE; REPRESENTATION}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{hwee-ling.lee@dzne.de}},
ORCID-Numbers = {{Noppeney, Uta/0000-0002-7697-2290}},
Funding-Acknowledgement = {{ERCEuropean Research Council (ERC)}},
Funding-Text = {{This research was funded by the ERC (multsens). We thank Samuel Jones
   for comments on a previous version of this manuscript.}},
Cited-References = {{Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Baart M, 2010, NEUROSCI LETT, V471, P100, DOI 10.1016/j.neulet.2010.01.019.
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038.
   Bastos AM, 2015, NEURON, V85, P390, DOI 10.1016/j.neuron.2014.12.018.
   BERTELSON P, 1981, PERCEPT PSYCHOPHYS, V29, P578, DOI 10.3758/BF03207374.
   Bishop L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01123.
   Blank H, 2013, NEUROIMAGE, V65, P109, DOI 10.1016/j.neuroimage.2012.09.047.
   Bonath B, 2014, NEUROIMAGE, V98, P425, DOI 10.1016/j.neuroimage.2014.04.077.
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436.
   Chen JL, 2008, CEREB CORTEX, V18, P2844, DOI 10.1093/cercor/bhn042.
   Denison RN, 2013, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00619.
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719.
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a.
   Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300.
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Ganesh AC, 2016, ADV EXP MED BIOL, V894, P399, DOI 10.1007/978-3-319-25474-6\_42.
   Gau R, 2016, NEUROIMAGE, V124, P876, DOI 10.1016/j.neuroimage.2015.09.045.
   Grahn JA, 2009, J NEUROSCI, V29, P7540, DOI 10.1523/JNEUROSCI.2018-08.2009.
   Grant KW, 2004, SPEECH COMMUN, V44, P43, DOI 10.1016/j.specom.2004.06.004.
   Helbig HB, 2012, NEUROIMAGE, V60, P1063, DOI 10.1016/j.neuroimage.2011.09.072.
   Hillis JM, 2004, J VISION, V4, P967, DOI 10.1167/4.12.1.
   HIRSH IJ, 1961, J EXP PSYCHOL, V62, P423, DOI 10.1037/h0045283.
   Jacobs RA, 1999, VISION RES, V39, P3621, DOI 10.1016/S0042-6989(99)00088-7.
   Knill DC, 2003, VISION RES, V43, P2539, DOI 10.1016/S0042-6989(03)00458-9.
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007.
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943.
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882.
   Lahav A, 2007, J NEUROSCI, V27, P308, DOI 10.1523/JNEUROSCI.4822-06.2007.
   Landry SP, 2017, BRAIN COGNITION, V111, P156, DOI 10.1016/j.bandc.2016.12.001.
   Lee H, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00868.
   Lee H, 2014, CURR BIOL, V24, pR309, DOI 10.1016/j.cub.2014.02.007.
   Lee H, 2011, P NATL ACAD SCI USA, V108, pE1441, DOI 10.1073/pnas.1115267108.
   Lewis PA, 2003, NEUROPSYCHOLOGIA, V41, P1583, DOI 10.1016/S0028-3932(03)00118-0.
   Lewis R, 2010, J NEUROSCI, V30, P12329, DOI 10.1523/JNEUROSCI.5745-09.2010.
   Lu Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090686.
   Luck G, 2008, PSYCHOL MUSIC, V36, P81, DOI 10.1177/0305735607080832.
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229.
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798.
   Maier JX, 2011, J EXP PSYCHOL HUMAN, V37, P245, DOI 10.1037/a0019952.
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0.
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005.
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114.
   Muckli L, 2015, CURR BIOL, V25, P2690, DOI 10.1016/j.cub.2015.08.057.
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811.
   Munte TF, 2002, NAT REV NEUROSCI, V3, P473, DOI 10.1038/nrn843.
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104.
   Nahorna O, 2015, J ACOUST SOC AM, V137, P362, DOI 10.1121/1.4904536.
   Nichols ES, 2016, NEUROPSYCHOLOGIA, V91, P199, DOI 10.1016/j.neuropsychologia.2016.08.011.
   Noesselt T, 2007, J NEUROSCI, V27, P11431, DOI 10.1523/JNEUROSCI.2252-07.2007.
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091.
   O'Reilly JX, 2008, J NEUROSCI, V28, P2252, DOI 10.1523/JNEUROSCI.2742-07.2008.
   Pantev C, 2015, EUR J NEUROSCI, V41, P709, DOI 10.1111/ejn.12788.
   Paraskevopoulos E, 2015, P NATL ACAD SCI USA, V112, P12522, DOI 10.1073/pnas.1510662112.
   Paraskevopoulos E, 2014, J COGNITIVE NEUROSCI, V26, P2224, DOI 10.1162/jocn\_a\_00620.
   Paraskevopoulos E, 2012, J NEUROSCI, V32, P18196, DOI 10.1523/JNEUROSCI.1947-12.2012.
   Parise CV, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11543.
   Parise CV, 2012, CURR BIOL, V22, P46, DOI 10.1016/j.cub.2011.11.039.
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003.
   Penhune VB, 1998, J COGNITIVE NEUROSCI, V10, P752, DOI 10.1162/089892998563149.
   Petrini K, 2011, NEUROIMAGE, V56, P1480, DOI 10.1016/j.neuroimage.2011.03.009.
   Petrini K, 2010, J VISION, V10, DOI 10.1167/10.5.2.
   Petrini K, 2009, EXP BRAIN RES, V198, P339, DOI 10.1007/s00221-009-1817-2.
   Petrini K, 2009, COGNITION, V110, P432, DOI 10.1016/j.cognition.2008.11.015.
   Powers AR, 2012, J NEUROSCI, V32, P6263, DOI 10.1523/JNEUROSCI.6138-11.2012.
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009.
   Rohe T, 2016, CURR BIOL, V26, P509, DOI 10.1016/j.cub.2015.12.056.
   Rohe T, 2015, J VISION, V15, DOI 10.1167/15.5.22.
   Rohe T, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002073.
   SALDANA HM, 1993, PERCEPT PSYCHOPHYS, V54, P406, DOI 10.3758/BF03205276.
   Sanchez-Garcia C, 2013, EXP BRAIN RES, V225, P499, DOI 10.1007/s00221-012-3390-3.
   Schutz M, 2009, J EXP PSYCHOL HUMAN, V35, P1791, DOI 10.1037/a0016455.
   Sedley W, 2016, ELIFE, V5, DOI 10.7554/eLife.11476.
   Shams L, 2010, TRENDS COGN SCI, V14, P425, DOI 10.1016/j.tics.2010.07.001.
   Shen S, 2016, PSYCHOL REV, V123, P452, DOI 10.1037/rev0000028.
   Simon DM, 2017, FRONT INTEGR NEUROSC, V11, DOI 10.3389/fnint.2017.00008.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Stevenson RA, 2013, EXP BRAIN RES, V225, P479, DOI 10.1007/s00221-012-3387-y.
   Stone JV, 2001, P ROY SOC B-BIOL SCI, V268, P31, DOI 10.1098/rspb.2000.1326.
   Summerfield C, 2006, SCIENCE, V314, P1311, DOI 10.1126/science.1132028.
   Tuennerhoff J, 2016, NEUROIMAGE, V124, P641, DOI 10.1016/j.neuroimage.2015.09.004.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001.
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871.
   Vroomen J, 2009, LANG SPEECH, V52, P341, DOI 10.1177/0023830909103178.
   Wallace MT, 2004, EXP BRAIN RES, V158, P252, DOI 10.1007/s00221-004-1899-9.
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2.
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872.
   Wozny DR, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000871.
   Yuan XY, 2014, NEUROSCI LETT, V569, P148, DOI 10.1016/j.neulet.2014.03.057.
   Zampini M, 2005, PERCEPT PSYCHOPHYS, V67, P531, DOI 10.3758/BF03193329.
   Zampini M, 2003, EXP BRAIN RES, V152, P198, DOI 10.1007/s00221-003-1536-z.
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152.}},
Number-of-Cited-References = {{97}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Ann. N.Y. Acad. Sci.}},
Doc-Delivery-Number = {{GN3FY}},
Unique-ID = {{ISI:000438890800012}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000432879300001,
Author = {Oestreich, Lena K. L. and Whitford, Thomas J. and Garrido, I, Marta},
Title = {{Prediction of Speech Sounds Is Facilitated by a Functional
   Fronto-Temporal Network}},
Journal = {{FRONTIERS IN NEURAL CIRCUITS}},
Year = {{2018}},
Volume = {{12}},
Month = {{MAY 23}},
Abstract = {{Predictive coding postulates that the brain continually predicts
   forthcoming sensory events based on past experiences in order to process
   sensory information and respond to unexpected events in a fast and
   efficient manner. Predictive coding models in the context of overt
   speech are believed to operate along auditory white matter pathways such
   as the arcuate fasciculus and the frontal aslant. The aim of this study
   was to investigate whether brain regions that are structurally connected
   via these white matter pathways are also effectively engaged when
   listening to externally-generated, temporally-predicable speech sounds.
   Using Electroencephalography (EEG) and Dynamic Causal Modeling (DCM) we
   investigated network models that are structurally connected via the
   arcuate fasciculus from primary auditory cortex to Wernicke's and via
   Geschwind's territory to Broca's area. Connections between Broca's and
   supplementary motor area, which are structurally connected by the
   frontal aslant, were also included. The results revealed that bilateral
   areas interconnected by indirect and direct pathways of the arcuate
   fasciculus, in addition to regions interconnected by the frontal aslant
   best explain the EEG responses to speech that is externally-generated
   but temporally predictable. These findings indicate that structurally
   connected brain regions involved in the production and processing of
   auditory stimuli are also effectively connected.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Oestreich, LKL (Corresponding Author), Univ Queensland, Queensland Brain Inst, Brisbane, Qld, Australia.
   Oestreich, LKL (Corresponding Author), Univ Queensland, Ctr Adv Imaging, Brisbane, Qld, Australia.
   Oestreich, Lena K. L.; Garrido, Marta, I, Univ Queensland, Queensland Brain Inst, Brisbane, Qld, Australia.
   Oestreich, Lena K. L.; Garrido, Marta, I, Univ Queensland, Ctr Adv Imaging, Brisbane, Qld, Australia.
   Whitford, Thomas J., Univ New South Wales, Sch Psychol, Sydney, NSW, Australia.
   Garrido, Marta, I, Univ Queensland, Australian Ctr Excellence Integrat Brain Funct, Brisbane, Qld, Australia.
   Garrido, Marta, I, Univ Queensland, Sch Math \& Phys, Brisbane, Qld, Australia.}},
DOI = {{10.3389/fncir.2018.00043}},
Article-Number = {{43}},
ISSN = {{1662-5110}},
Keywords = {{predictive coding; electroencephalography (EEG); dynamic causal modeling
   (DCM); effective connectivity; structural connectivity}},
Keywords-Plus = {{COROLLARY DISCHARGE DYSFUNCTION; BAYESIAN MODEL SELECTION;
   ELECTROPHYSIOLOGICAL EVIDENCE; NEUROPHYSIOLOGICAL EVIDENCE;
   COMPUTATIONAL ARCHITECTURE; AUDITORY-CORTEX; HUMAN BRAIN; SCHIZOPHRENIA;
   RESPONSES; CONNECTIONS}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{l.oestreich@uq.edu.au}},
ResearcherID-Numbers = {{Oestreich, Lena/X-7182-2018
   }},
ORCID-Numbers = {{Oestreich, Lena/0000-0002-4978-7794
   Garrido, Marta/0000-0003-0679-4959}},
Funding-Acknowledgement = {{University of Queensland Fellowship {[}2016000071]; University of
   Queensland FoundationUniversity of Queensland {[}2016001844]; Australian
   Research Council (ARC) Centre of Excellence for Integrative Brain
   FunctionAustralian Research Council {[}ARC CE140100007]; ARCAustralian
   Research Council {[}DP140104394]; National Health and Medical Research
   Council of AustraliaNational Health and Medical Research Council of
   Australia {[}APP1090507]}},
Funding-Text = {{MG is supported by a University of Queensland Fellowship (2016000071), a
   University of Queensland Foundation Research Excellence Award
   (2016001844) and the Australian Research Council (ARC) Centre of
   Excellence for Integrative Brain Function (ARC CE140100007). TW is
   supported by a Discovery Project from the ARC (DP140104394) and a Career
   Development Fellowship from the National Health and Medical Research
   Council of Australia (APP1090507).}},
Cited-References = {{American Psychiatric Association, 2000, DIAGN STAT MAN MENT.
   Catani M, 2005, BRAIN, V128, P2224, DOI 10.1093/brain/awh622.
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319.
   Catani M, 2013, BRAIN, V136, P2619, DOI 10.1093/brain/awt163.
   Catani M, 2012, CORTEX, V48, P273, DOI 10.1016/j.cortex.2011.12.001.
   Chen CC, 2009, NEUROIMAGE, V45, P453, DOI 10.1016/j.neuroimage.2008.12.041.
   David O, 2005, NEUROIMAGE, V25, P756, DOI 10.1016/j.neuroimage.2004.12.030.
   David O, 2003, NEUROIMAGE, V20, P1743, DOI 10.1016/j.neuroimage.2003.07.015.
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1.
   Ford JM, 2004, J PSYCHIATR RES, V38, P37, DOI 10.1016/S0022-3956(03)00095-5.
   Ford JM, 2001, AM J PSYCHIAT, V158, P2069, DOI 10.1176/appi.ajp.158.12.2069.
   Ford JM, 2007, PSYCHOPHYSIOLOGY, V44, P522, DOI 10.1111/j.1469-8986.2007.00533.x.
   Ford JM, 2016, NEUROIMAGE-CLIN, V12, P429, DOI 10.1016/j.nicl.2016.08.009.
   Ford JM, 2014, SCHIZOPHRENIA BULL, V40, P804, DOI 10.1093/schbul/sbt072.
   Friston KJ, 2016, NEUROIMAGE, V128, P413, DOI 10.1016/j.neuroimage.2015.11.015.
   Friston KJ, 2013, NEUROIMAGE, V75, P275, DOI 10.1016/j.neuroimage.2011.11.064.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Fujii M, 2016, NEUROL MED-CHIR, V56, P379, DOI 10.2176/nmc.ra.2016-0014.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Garrido MI, 2008, NEUROIMAGE, V42, P936, DOI 10.1016/j.neuroimage.2008.05.018.
   Garrido MI, 2007, P NATL ACAD SCI USA, V104, P20961, DOI 10.1073/pnas.0706274105.
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9.
   Hickok G, 2013, BEHAV BRAIN SCI, V36, P358, DOI 10.1017/S0140525X12002750.
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213.
   Jackson J. Hughlings, 1958, SELECTED WRITINGS JH.
   JANSEN BH, 1995, BIOL CYBERN, V73, P357, DOI 10.1007/BF00199471.
   Kiebel SJ, 2007, NEUROIMAGE, V36, P332, DOI 10.1016/j.neuroimage.2007.02.046.
   Kiebel SJ, 2008, COGN NEURODYNAMICS, V2, P121, DOI 10.1007/s11571-008-9038-0.
   Kubicki M, 2005, NEUROIMAGE, V26, P1109, DOI 10.1016/j.neuroimage.2005.03.026.
   Lohmann G, 2012, NEUROIMAGE, V59, P2322, DOI 10.1016/j.neuroimage.2011.09.025.
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477.
   MUMFORD D, 1991, BIOL CYBERN, V65, P135, DOI 10.1007/BF00202389.
   Oestreich LKL, 2016, CLIN EEG NEUROSCI, V47, P3, DOI 10.1177/1550059415581708.
   Oestreich LKL, 2015, INT J PSYCHOPHYSIOL, V97, P131, DOI 10.1016/j.ijpsycho.2015.05.014.
   Penny WD, 2004, NEUROIMAGE, V22, P1157, DOI 10.1016/j.neuroimage.2004.03.026.
   Perez VB, 2012, SCHIZOPHRENIA BULL, V38, P1216, DOI 10.1093/schbul/sbr124.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rigoux L, 2014, NEUROIMAGE, V84, P971, DOI 10.1016/j.neuroimage.2013.08.065.
   Stephan KE, 2010, NEUROIMAGE, V49, P3099, DOI 10.1016/j.neuroimage.2009.11.015.
   Stephan KE, 2009, NEUROIMAGE, V46, P1004, DOI 10.1016/j.neuroimage.2009.03.025.
   Sun JF, 2012, IEEE T BIO-MED ENG, V59, P2254, DOI 10.1109/TBME.2012.2199490.
   Uranova NA, 2007, INT J NEUROPSYCHOPH, V10, P537, DOI 10.1017/S1461145707007626.
   Wang J, 2014, NEUROIMAGE, V91, P91, DOI 10.1016/j.neuroimage.2014.01.003.
   Whitford TJ, 2011, PSYCHOL MED, V41, P959, DOI 10.1017/S0033291710001376.
   Whitford TJ, 2018, SCHIZOPHRENIA BULL, V44, P1312, DOI 10.1093/schbul/sbx144.}},
Number-of-Cited-References = {{45}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Front. Neural Circuits}},
Doc-Delivery-Number = {{GG7LI}},
Unique-ID = {{ISI:000432879300001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000429540400007,
Author = {Falch, Thomas L. and Elster, Anne C.},
Title = {{ImageCL: Language and source-to-source compiler for performance
   portability, load balancing, and scalability prediction on heterogeneous
   systems}},
Journal = {{CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE}},
Year = {{2018}},
Volume = {{30}},
Number = {{9, SI}},
Month = {{MAY 10}},
Abstract = {{Applications written for heterogeneous CPU-GPU systems often suffer from
   poor performance portability. Finding good work partitions can also be
   challenging as different devices are suited for different applications.
   This article describes ImageCL, a high-level domain-specific language
   and source-to-source compiler, targeting single system as well as
   distributed heterogeneous hardware. Initially targeting image processing
   algorithms, our framework now also handles general stencil-based
   operations. It resembles OpenCL, but abstracts away performance
   optimization details which instead are handled by our source-to-source
   compiler. Machine learning-based auto-tuning is used to determine which
   optimizations to apply. For the distributed case, by measuring
   performance counters on a small input on one device, previously trained
   performance models are used to predict the throughput of the application
   on multiple different devices, making it possible to balance the load
   evenly. Models for the communication overhead are created in a similar
   fashion and used to predict the optimal number of nodes to use. ImageCL
   outperforms other state-of-the-art solutions on image processing
   benchmarks in several cases, achieving speedups of up to 4.57x. On both
   CPUs and GPUs we are only 3\% and 2\% slower than an oracle for load
   balancing and scalability prediction, respectively, using synthetic
   benchmarks.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Elster, AC (Corresponding Author), Norwegian Univ Sci \& Technol NTNU, Dept Comp Sci, Trondheim, Norway.
   Falch, Thomas L.; Elster, Anne C., Norwegian Univ Sci \& Technol NTNU, Dept Comp Sci, Trondheim, Norway.}},
DOI = {{10.1002/cpe.4384}},
Article-Number = {{e4384}},
ISSN = {{1532-0626}},
EISSN = {{1532-0634}},
Keywords = {{load balancing; machine learning; source-to-source compilation;
   performance portability; scalability prediction}},
Keywords-Plus = {{MODEL; IMPLEMENTATION; PARALLELISM; CUDA}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Computer Science, Theory \&
   Methods}},
Author-Email = {{elster@ntnu.no}},
Funding-Acknowledgement = {{European UnionEuropean Union (EU) {[}643946]}},
Funding-Text = {{European Union's Horizon 2020 Research and Innovation Programme,
   Grant/Award Number: 643946}},
Cited-References = {{Alpaydin E., 2010, INTRO MACHINE LEARNI.
   Ardalani N, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P725, DOI 10.1145/2830772.2830780.
   Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631.
   Ayguade E, 2009, LECT NOTES COMPUT SC, V5704, P851, DOI 10.1007/978-3-642-03869-3\_79.
   Barak A., 2010, 2010 IEEE INT C CLUS, P1, DOI DOI 10.1109/CLUSTERWKSP.2010.5613086.
   Barnes BJ, 2008, ICS'08: PROCEEDINGS OF THE 2008 ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P368.
   Becchi M, 2010, SPAA `10: PROCEEDINGS OF THE TWENTY-SECOND ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P82.
   Bergstra J, 2012, INNOVATIVE PARALLEL, P1, DOI {[}DOI 10.1109/INPAR.2012.6339587, 10.1109/InPar.2012.6339587].
   Boyer M., 2013, P ACM INT C COMP FRO.
   Browne S, 2000, INT J HIGH PERFORM C, V14, P189, DOI 10.1177/109434200001400303.
   Calotoiu A, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503277.
   Chen L., 2010, IEEE INT S PAR DISTR, DOI DOI 10.1109/IPDPS.2010.5470413.
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45.
   Christen M., 2011, Proceedings of the 25th IEEE International Parallel \& Distributed Processing Symposium (IPDPS 2011), P676, DOI 10.1109/IPDPS.2011.70.
   de la Lama C. S., 2012, 2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P675, DOI 10.1109/ISPA.2012.100.
   Du P, 2012, PARALLEL COMPUT, V38, P391, DOI 10.1016/j.parco.2011.10.002.
   Elster A. C., 2009, P IEEE INT S PAR DIS, V1-5, P1.
   Falch TL, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4029.
   Falch TL, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING \& SIMULATION (HPCS 2016), P562, DOI 10.1109/HPCSim.2016.7568385.
   Falch TL, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P1231, DOI 10.1109/IPDPSW.2015.85.
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301.
   Grasso I, 2013, P 27 INT ACM C INT C, P161.
   Grasso I, 2013, ACM SIGPLAN NOTICES, V48, P281, DOI 10.1145/2517327.2442545.
   Grewe D, 2011, STATIC TASK PARTITIO.
   Hijma P, 2015, INT PARALL DISTRIB P, P135, DOI 10.1109/IPDPS.2015.38.
   Khan M, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400690.
   Khan MM, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING \& SIMULATION (HPCS 2016), P840, DOI 10.1109/HPCSim.2016.7568422.
   Kim J., 2012, P 26 ACM INT C SUP I, P341, DOI DOI 10.1145/2304576.2304623.
   Kofler K., 2013, P 27 INT ACM C INT C, P149, DOI DOI 10.1145/2464996.2465007.
   Lin Z, 2014, LANGUAGES COMPILERS, P36.
   Lynn T, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND SERVICES SCIENCE, VOL 1 (CLOSER), P333, DOI 10.5220/0005921503330338.
   Madougou S, 2016, PARALLEL COMPUT, V56, P18, DOI 10.1016/j.parco.2016.04.002.
   Magni A., 2013, P INT C HIGH PERF CO, P1.
   Membarth R, 2016, IEEE T PARALL DISTR, V27, P210, DOI 10.1109/TPDS.2015.2394802.
   Meyer J., 2012, THESIS.
   Mullapudi RT, 2015, ACM SIGPLAN NOTICES, V50, P429, DOI {[}10.1145/2775054.2694364, 10.1145/2694344.2694364].
   Nugteren C, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P195, DOI 10.1109/MCSoC.2015.10.
   Numascale, 2014, NUM AD N323.
   Pallipuram VK, 2014, CONCURR COMP-PRACT E, V26, P532, DOI 10.1002/cpe.3017.
   Pennycook SJ, 2013, J PARALLEL DISTR COM, V73, P1439, DOI 10.1016/j.jpdc.2012.07.005.
   Pusukuri KK, 2011, I S WORKL CHAR PROC, P116, DOI 10.1109/IISWC.2011.6114208.
   Quinlan D., 2011, CET US COMP INFR WOR, V2011, P1.
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176.
   Shen J, 2016, IEEE T PARALL DISTR, V27, P2766, DOI 10.1109/TPDS.2015.2509972.
   Smistad E, 2015, INT J COMPUTER ASSIS, V10, P1.
   Smistad E, 2015, MED IMAGE ANAL, V20, P1, DOI 10.1016/j.media.2014.10.012.
   Sujeeth AK, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584665.
   Ueng SZ, 2008, LECT NOTES COMPUT SC, V5335, P1, DOI 10.1007/978-3-540-89740-8\_1.
   VALIANT LG, 1990, COMMUN ACM, V33, P103, DOI 10.1145/79173.79181.
   van Deursen A, 2000, ACM SIGPLAN NOTICES, V35, P26, DOI 10.1145/352029.352035.
   Wang Z, 2009, ACM SIGPLAN NOTICES, V44, P75, DOI 10.1145/1594835.1504189.
   Whaley RC, 2005, SOFTWARE PRACT EXPER, V35, P101, DOI 10.1002/spe.626.
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063.
   Yang Y, 2013, INT J PARALLEL PROG, V41, P768, DOI 10.1007/s10766-012-0228-3.
   Yotov K, 2003, ACM SIGPLAN NOTICES, V38, P63, DOI 10.1145/780822.781140.
   Zhang Y, 2013, LECT NOTES COMPUT SC, V7905, P136, DOI 10.1007/978-3-642-38750-0\_11.}},
Number-of-Cited-References = {{56}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Concurr. Comput.-Pract. Exp.}},
Doc-Delivery-Number = {{GC1KK}},
Unique-ID = {{ISI:000429540400007}},
OA = {{Other Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000440877900008,
Author = {Vestman, Ville and Gowda, Dhananjaya and Sahidullah, Md and Alku, Paavo
   and Kinnunen, Tomi},
Title = {{Speaker recognition from whispered speech: A tutorial survey and an
   application of time-varying linear prediction}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2018}},
Volume = {{99}},
Pages = {{62-79}},
Month = {{MAY}},
Abstract = {{From the available biometric technologies, automatic speaker recognition
   is one of the most convenient and accessible ones due to abundance of
   mobile devices equipped with a microphone, allowing users to be
   authenticated across multiple environments and devices. Speaker
   recognition also finds use in forensics and surveillance. Due to the
   acoustic mismatch induced by varied environments and devices of the same
   speaker, leading to increased number of identification errors, much of
   the research focuses on compensating for such technology-induced
   variations, especially using machine learning at the statistical
   back-end. Another much less studied but at least as detrimental source
   of acoustic variation, however, arises from mismatched speaking styles
   induced by the speaker, leading to a substantial performance drop in
   recognition accuracy. This is a major problem especially in forensics
   where perpetrators may purposefully disguise their identity by varying
   their speaking style. We focus on one of the most commonly used ways of
   disguising one's speaker identity, namely, whispering. We approach the
   problem of normal-whisper acoustic mismatch compensation from the
   viewpoint of robust feature extraction. Since whispered speech is
   intelligible, yet a low-intensity signal and therefore prone to
   extrinsic distortions, we take advantage of robust, long-term speech
   analysis methods that utilize slow articulatory movements in speech
   production. In specific, we address the problem using a novel method,
   frequency-domain linear prediction with time-varying linear prediction
   (FDLP-TVLP), which is an extension of the 2-dimensional autoregressive
   (2DAR) model that allows vocal tract filter parameters to be
   time-varying, rather than piecewise constant as in classic short-term
   speech analysis. Our speaker recognition experiments on the whisper
   subset of the CHAINS corpus indicate that when tested in normal-whisper
   mismatched conditions, the proposed FDLP-TVLP features improve speaker
   recognition performance by 7-10\% over standard MFCC features in
   relative terms. We further observe that the proposed FDLP-TVLP features
   perform better than the FDLP and 2DAR methods for whispered speech.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Vestman, V (Corresponding Author), Univ Eastern Finland, Sch Comp, Kuopio, Finland.
   Vestman, Ville; Sahidullah, Md; Kinnunen, Tomi, Univ Eastern Finland, Sch Comp, Kuopio, Finland.
   Gowda, Dhananjaya, Samsung Elect, DMC R\&D Ctr, Seoul, South Korea.
   Alku, Paavo, Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.}},
DOI = {{10.1016/j.specom.2018.02.009}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Speaker recognition; Speaking style mismatch; Disguise; Whisper;
   2-Dimensional autoregression (2D-AR); Time-varying linear prediction
   (TVLP)}},
Keywords-Plus = {{FRONT-END; IDENTIFICATION; VERIFICATION; AUTOREGRESSIONS; PITCH}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{ville.vestman@uef.fi}},
ResearcherID-Numbers = {{Sahidullah/E-2953-2013
   Alku, Paavo/E-2400-2012
   }},
ORCID-Numbers = {{Sahidullah, Md/0000-0002-0624-2903
   Alku, Paavo/0000-0002-8173-9418}},
Funding-Acknowledgement = {{Academy of FinlandAcademy of Finland {[}309629, 312490]}},
Funding-Text = {{This work was partially funded by Academy of Finland (projects 309629
   and 312490).}},
Cited-References = {{Athineos M., 2004, ISCA TUT RES WORKSH.
   Athineos M, 2007, IEEE T SIGNAL PROCES, V55, P5237, DOI 10.1109/TSP.2007.898783.
   Bengio S., 2004, P OD 2004 SPEAK LANG.
   Boersma P., 2017, PRAAT DOING PHONETIC.
   Cummins F., 2006, P SPECOM ST PET RUSS, P431.
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307.
   Delgado  H., 2016, IEEE SPOK LANG TECHN.
   Dey S, 2017, SPEECH COMMUN, V88, P96, DOI 10.1016/j.specom.2017.01.009.
   Ellis D., 2003, DYNAMIC TIME WARP DT.
   Fan X., 2011, INTERSPEECH, P2425.
   Fan X., 2009, INTERSPEECH, P896.
   Fan X, 2013, SPEECH COMMUN, V55, P119, DOI 10.1016/j.specom.2012.07.002.
   Fan X, 2011, IEEE T AUDIO SPEECH, V19, P1408, DOI 10.1109/TASL.2010.2091631.
   Fan X, 2010, INT CONF ACOUST SPEE, P5046, DOI 10.1109/ICASSP.2010.5495059.
   Fan X, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1313.
   Fan X, 2009, INT CONF ACOUST SPEE, P4553, DOI 10.1109/ICASSP.2009.4960643.
   Friedman J., 2009, ELEMENTS STAT LEARNI.
   Ganapathy S, 2014, IEEE-ACM T AUDIO SPE, V22, P1285, DOI 10.1109/TASLP.2014.2329190.
   Garcia-Romero D, 2012, INT CONF ACOUST SPEE, P4257, DOI 10.1109/ICASSP.2012.6288859.
   GRENIER Y, 1983, IEEE T ACOUST SPEECH, V31, P899, DOI 10.1109/TASSP.1983.1164152.
   Grimaldi M, 2008, IEEE T AUDIO SPEECH, V16, P1097, DOI 10.1109/TASL.2008.2001109.
   HALL MG, 1983, SIGNAL PROCESS, V5, P267, DOI 10.1016/0165-1684(83)90074-9.
   Hansen JHL, 2017, J ACOUST SOC AM, V141, P2957, DOI 10.1121/1.4979337.
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851.
   Hautamaki RG, 2017, SPEECH COMMUN, V95, P1, DOI 10.1016/j.specom.2017.10.002.
   Heeren WFL, 2015, J ACOUST SOC AM, V138, P3800, DOI 10.1121/1.4937762.
   Heigold G, 2016, INT CONF ACOUST SPEE, P5115, DOI 10.1109/ICASSP.2016.7472652.
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616.
   Herre J., 1996, AUD ENG SOC CONV 101.
   Higashikawa M, 1996, J VOICE, V10, P155, DOI 10.1016/S0892-1997(96)80042-7.
   Ito T, 2005, SPEECH COMMUN, V45, P139, DOI 10.1016/j.specom.2003.10.005.
   Jawarkar NP, 2013, INT CONF COMM SYST, P778, DOI 10.1109/CSNT.2013.167.
   Jin Q, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1027.
   JUNQUA JC, 1993, J ACOUST SOC AM, V93, P510, DOI 10.1121/1.405631.
   Kenny P, 2006, CRIM0608I4.
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009.
   Kumaresan R, 1999, J ACOUST SOC AM, V105, P1912, DOI 10.1121/1.426727.
   Kunzel H., 2000, FORENSIC LINGUIST, V7, P149, DOI DOI 10.1558/SLL.2000.7.2.149.
   Lee C.-H., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P558, DOI 10.1109/ICASSP.1993.319368.
   Lee P. X., 2014, P ANN C INT SPEECH C, P1598.
   Li LT, 2016, IEEE-ACM T AUDIO SPE, V24, P1129, DOI 10.1109/TASLP.2016.2544660.
   Lim P. P, 2011, COMPUTATIONAL DIFFER.
   LIPORACE LA, 1975, J ACOUST SOC AM, V58, P1288, DOI 10.1121/1.380811.
   Liu G, 2012, INT CONF ACOUST SPEE, P4233, DOI 10.1109/ICASSP.2012.6288853.
   Liu Y, 2015, SPEECH COMMUN, V73, P1, DOI 10.1016/j.specom.2015.07.003.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   MASTHOFF H, 1996, FORENSIC LINGUIST, V3, P160, DOI DOI 10.1558/IJSLL.V3I1.160.
   Murthi MN, 2000, IEEE T SPEECH AUDI P, V8, P221, DOI 10.1109/89.841206.
   Pohjalainen J, 2014, IEEE SIGNAL PROC LET, V21, P1516, DOI 10.1109/LSP.2014.2339632.
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751.
   Rajan P., 2013, INTERSPEECH, P3694.
   Rajan P, 2014, DIGIT SIGNAL PROCESS, V31, P93, DOI 10.1016/j.dsp.2014.05.001.
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379.
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361.
   Rudoy D, 2011, IEEE T AUDIO SPEECH, V19, P977, DOI 10.1109/TASL.2010.2073704.
   Sadjadi SO, 2015, SPEECH COMMUN, V72, P138, DOI 10.1016/j.specom.2015.04.005.
   Saeidi R, 2016, IEEE-ACM T AUDIO SPE, V24, P42, DOI 10.1109/TASLP.2015.2493366.
   Sarria-Paja M, 2015, J CAN ACOUST ASS, V43, P31.
   Sarria-Paja M, 2017, COMPUT SPEECH LANG, V45, P437, DOI 10.1016/j.csl.2017.04.004.
   Sarria-Paja M, 2016, INT CONF ACOUST SPEE, P5480, DOI 10.1109/ICASSP.2016.7472725.
   Sarria-Paja M, 2015, CAN CON EL COMP EN, P1254, DOI 10.1109/CCECE.2015.7129458.
   Sarria-Paja M, 2013, INT CONF ACOUST SPEE, P7209, DOI 10.1109/ICASSP.2013.6639062.
   Senoussaoui M, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P28.
   Sharma R, 2017, SPEECH COMMUN, V91, P1, DOI 10.1016/j.specom.2017.04.006.
   Shue Y.-L., 2011, P ICPHS, P1846.
   Snyder D, 2016, IEEE W SP LANG TECH, P165, DOI 10.1109/SLT.2016.7846260.
   TARTTER VC, 1989, J ACOUST SOC AM, V86, P1678, DOI 10.1121/1.398598.
   Thomas S, 2008, IEEE SIGNAL PROC LET, V15, P681, DOI 10.1109/LSP.2008.2002708.
   Vestman V, 2017, INTERSPEECH, P1512, DOI 10.21437/Interspeech.2017-734.
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027.
   Weninger F., 2011, MACHINE LISTENING MU.
   Zeinali H, 2017, IEEE-ACM T AUDIO SPE, V25, P1421, DOI 10.1109/TASLP.2017.2694708.
   Zeinali H, 2016, INTERSPEECH, P440, DOI 10.21437/Interspeech.2016-1174.
   Zhang C., 2007, INTERSPEECH 2007, P2289.
   Zhang C., 2009, P ISCA INT, P860.}},
Number-of-Cited-References = {{76}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{GP4YI}},
Unique-ID = {{ISI:000440877900008}},
DA = {{2020-12-06}},
}

@article{ ISI:000440877900012,
Author = {Moungsri, Decha and Koriyama, Tomoki and Kobayashi, Takao},
Title = {{GPR-based Thai speech synthesis using multi-level duration prediction}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2018}},
Volume = {{99}},
Pages = {{114-123}},
Month = {{MAY}},
Abstract = {{This paper proposes a multi-level Gaussian process regression
   (GPR)-based method for duration prediction by incorporating phone- and
   syllable-level duration models. In this method, we first train the
   syllable model and predict syllable durations for a given input of
   context labels. Then, we use the predicted syllable duration as an
   additional context for the phone-level model to predict phone durations.
   To apply multi-level duration prediction to the GPR-based speech
   synthesis framework, we designed phone- and syllable- level context sets
   for Thai that include linguistic information and the relative positions
   of speech units. We also examined the multilevel deep neural network
   (DNN)-based duration-prediction method by using the same approach as for
   the proposed multi-level GPR-based one. We conducted objective and
   subjective evaluations using two-hour training data to compare the
   proposed method with single-level ones. The results indicate that the
   proposed multi-level duration-prediction method outperformed
   single-level ones in DNN-, and GPR-based frameworks. They also indicate
   that the proposed multi-level GPR-based method can provide better
   performance than the multi-level HMM-based duration-prediction method.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Moungsri, D (Corresponding Author), Tokyo Inst Technol, Interdisciplinary Grad Sch Sci \& Engn, Yokohama, Kanagawa 2268502, Japan.
   Moungsri, Decha, Tokyo Inst Technol, Interdisciplinary Grad Sch Sci \& Engn, Yokohama, Kanagawa 2268502, Japan.
   Koriyama, Tomoki; Kobayashi, Takao, Tokyo Inst Technol, Sch Engn, Yokohama, Kanagawa 2268502, Japan.}},
DOI = {{10.1016/j.specom.2018.03.005}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Thai language; Speech synthesis; Gaussian process regression;
   Multi-level model; Prosody; Duration prediction}},
Keywords-Plus = {{NEURAL-NETWORKS; REGRESSION}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{moungsri.d.aa@m.titech.ac.jp
   koriyama@ip.titech.ac.jp
   takao.kobayashi@ip.titech.ac.jp}},
Funding-Acknowledgement = {{JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) {[}JP15H02724];
   Grants-in-Aid for Scientific ResearchMinistry of Education, Culture,
   Sports, Science and Technology, Japan (MEXT)Japan Society for the
   Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)
   {[}15H02724] Funding Source: KAKEN}},
Funding-Text = {{We would like to thank Dr. Vataya Chunwijitra of NECTEC, Thailand, for
   providing the T-Sync-1 speech database. A part of this work was
   supported by JSPS KAKENHI Grant Number JP15H02724.}},
Cited-References = {{Campbell W., 1993, P EUR C SPEECH COMM, P1081.
   Campbell W Nick, 1992, TALKING MACHINES THE, P211.
   CAMPBELL WN, 1991, J PHONETICS, V19, P37, DOI 10.1016/S0095-4470(19)30315-8.
   Chen SH, 2003, IEEE T SPEECH AUDI P, V11, P308, DOI 10.1109/TSA.2003.814377.
   Chomphan S., 2007, P INTERSPEECH, P2849.
   CHOMPHAN S, 2007, P 6 ISCA WORKSH SPEE, P160.
   Chomphan S, 2008, SPEECH COMMUN, V50, P392, DOI 10.1016/j.specom.2007.12.002.
   GAO BH, 2008, P INT, P2266.
   Goubanova O, 2008, SPEECH COMMUN, V50, P301, DOI 10.1016/j.specom.2007.10.002.
   Hansakunbuntheung C., 2003, Proceedings of the Oriental COCOSDA 2003. International Coordinating Committee on Speech Databases and Speech I/O System Assessment, P97.
   Hansakunbuntheung C., 2005, P SNLP, P127.
   HENTER GE, 2016, P ICASSP, P5130.
   Iwahashi N, 2000, IEICE T INF SYST, VE83D, P1550.
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5.
   Koriyama Tomoki, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3834, DOI 10.1109/ICASSP.2014.6854319.
   Koriyama T., 2013, P INTERSPEECH, P1072.
   Koriyama T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3496.
   Koriyama T, 2015, INT CONF ACOUST SPEE, P4929, DOI 10.1109/ICASSP.2015.7178908.
   Koriyama T, 2014, IEEE J-STSP, V8, P173, DOI 10.1109/JSTSP.2013.2283461.
   Koriyama T, 2013, INT CONF ACOUST SPEE, P8007, DOI 10.1109/ICASSP.2013.6639224.
   Lazaridis A., 2014, TECHNICAL REPORT.
   Lazaridis A, 2012, COMPUT SPEECH LANG, V26, P274, DOI 10.1016/j.csl.2012.01.009.
   Lazaridis A, 2011, SPEECH COMMUN, V53, P85, DOI 10.1016/j.specom.2010.07.005.
   Luksaneeyanawin S, 1983, INTONATION IN THAI.
   Moungsri D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1591.
   Nagy P, 2016, LECT NOTES COMPUT SC, V9811, P254, DOI 10.1007/978-3-319-43958-7\_30.
   Peyasantiwong P, 1986, MICHIGAN PAPERS S SE, P19.
   Potisuk S, 1996, PHONETICA, V53, P200, DOI 10.1159/000262201.
   POTISUK S, 1998, ACTA LINGUIST HAF, V30, P39.
   Qian Y., 2014, AC SPEECH SIGN PROC, P3829.
   Qian Y, 2011, IEEE T AUDIO SPEECH, V19, P1702, DOI 10.1109/TASL.2010.2097248.
   Rao KS, 2007, COMPUT SPEECH LANG, V21, P282, DOI 10.1016/j.csl.2006.06.003.
   Sainz I., 2011, P INTERSPEECH, P333.
   Shinoda K., 2000, Journal of the Acoustical Society of Japan (E), V21, P79, DOI 10.1250/ast.21.79.
   Teixeira J.P, 2003, P EUR C SPEECH COMM, P169.
   VANSANTEN JPH, 1992, SPEECH COMMUN, V11, P513, DOI 10.1016/0167-6393(92)90027-5.
   Wang Y, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2197.
   Wutiwiwatchsi C, 2007, SPEECH COMMUN, V49, P8, DOI 10.1016/j.specom.2006.10.004.
   Yamagishi J, 2008, SPEECH COMMUN, V50, P405, DOI 10.1016/j.specom.2007.12.003.
   Yoshimura T., 1998, P ICSLP, V2, P29.
   Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825.
   Zen HG, 2015, INT CONF ACOUST SPEE, P4470, DOI 10.1109/ICASSP.2015.7178816.
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{GP4YI}},
Unique-ID = {{ISI:000440877900012}},
DA = {{2020-12-06}},
}

@article{ ISI:000429058000001,
Author = {Beier, Eleonora J. and Ferreira, Fernanda},
Title = {{The Temporal Prediction of Stress in Speech and Its Relation to Musical
   Beat Perception}},
Journal = {{FRONTIERS IN PSYCHOLOGY}},
Year = {{2018}},
Volume = {{9}},
Month = {{APR 3}},
Abstract = {{While rhythmic expectancies are thought to be at the base of beat
   perception in music, the extent to which stress patterns in speech are
   similarly represented and predicted during on-line language
   comprehension is debated. The temporal prediction of stress may be
   advantageous to speech processing, as stress patterns aid segmentation
   and mark new information in utterances. However, while linguistic stress
   patterns may be organized into hierarchical metrical structures
   similarly to musical meter, they do not typically present the same
   degree of periodicity. We review the theoretical background for the idea
   that stress patterns are predicted and address the following questions:
   First, what is the evidence that listeners can predict the temporal
   location of stress based on preceding rhythm? If they can, is it thanks
   to neural entrainment mechanisms similar to those utilized for musical
   beat perception? And lastly, what linguistic factors other than rhythm
   may account for the prediction of stress in natural speech? We conclude
   that while expectancies based on the periodic presentation of stresses
   are at play in some of the current literature, other processes are
   likely to affect the prediction of stress in more naturalistic, less
   isochronous speech. Specifically, aspects of prosody other than
   amplitude changes (e.g., intonation) as well as lexical, syntactic and
   information structural constraints on the realization of stress may all
   contribute to the probabilistic expectation of stress in speech.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Beier, EJ (Corresponding Author), Univ Calif Davis, Dept Psychol, Davis, CA 95616 USA.
   Beier, Eleonora J.; Ferreira, Fernanda, Univ Calif Davis, Dept Psychol, Davis, CA 95616 USA.}},
DOI = {{10.3389/fpsyg.2018.00431}},
Article-Number = {{431}},
ISSN = {{1664-1078}},
Keywords = {{rhythm; stress; speech; music; meter; prediction; prosody; language}},
Keywords-Plus = {{PROSODIC PROMINENCE; LANGUAGE PRODUCTION; LINGUISTIC RHYTHM;
   REACTION-TIME; METER; COMPREHENSION; OSCILLATIONS; ENTRAINMENT;
   SEGMENTATION; REGULARITY}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{ejbeier@ucdavis.edu}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF) {[}1650042,
   BCS-1650888]}},
Funding-Text = {{The authors acknowledge support from the National Science Foundation
   GRFP number 1650042 awarded to EB and National Science Foundation
   research grant BCS-1650888 awarded to FF.}},
Cited-References = {{Abercrombie D., 1967, ELEMENTS GEN PHONETI.
   Altman G., 1989, Computer Speech and Language, V3, P265, DOI 10.1016/0885-2308(89)90022-3.
   Aylett M, 2004, LANG SPEECH, V47, P31, DOI 10.1177/00238309040470010201.
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442.
   Breen M, 2011, J MEM LANG, V64, P153, DOI 10.1016/j.jml.2010.11.001.
   Breen M, 2010, LANG COGNITIVE PROC, V25, P1044, DOI 10.1080/01690965.2010.504378.
   Brown M, 2015, J EXP PSYCHOL HUMAN, V41, P306, DOI 10.1037/a0038689.
   Calhoun S, 2010, LANG COGNITIVE PROC, V25, P1099, DOI 10.1080/01690965.2010.491682.
   Cason N, 2012, NEUROPSYCHOLOGIA, V50, P2652, DOI 10.1016/j.neuropsychologia.2012.07.018.
   Clifton C, 2002, LANG SPEECH, V45, P87, DOI 10.1177/00238309020450020101.
   Cummins F, 1998, J PHONETICS, V26, P145, DOI 10.1006/jpho.1998.0070.
   CUTLER A, 1977, LANG SPEECH, V20, P1.
   CUTLER A, 1976, PERCEPT PSYCHOPHYS, V20, P55, DOI 10.3758/BF03198706.
   CUTLER A, 1979, COGNITION, V7, P49, DOI 10.1016/0010-0277(79)90010-6.
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4.
   Dimitrova DV, 2012, J COGNITIVE NEUROSCI, V24, P2400, DOI 10.1162/jocn\_a\_00302.
   Falk S, 2017, COGNITION, V163, P80, DOI 10.1016/j.cognition.2017.02.017.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   FERREIRA F, 1993, PSYCHOL REV, V100, P233, DOI 10.1037/0033-295X.100.2.233.
   Ferreira F, 2007, LANG COGNITIVE PROC, V22, P1151, DOI 10.1080/01690960701461293.
   FRY DB, 1955, J ACOUST SOC AM, V27, P765, DOI 10.1121/1.1908022.
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934.
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063.
   Goswami U, 2012, EMPIR MUSICOL REV, V7, P57, DOI 10.18061/1811/52980.
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001.
   GOW DW, 1993, J PSYCHOLINGUIST RES, V22, P545.
   HAYES B, 1983, LINGUIST INQ, V14, P357.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Klassen J, 2017, J MEM LANG, V92, P305, DOI 10.1016/j.jml.2016.06.012.
   Kosem A, 2017, LANG COGN NEUROSCI, V32, P536, DOI 10.1080/23273798.2016.1238495.
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735.
   Large E. W., 1994, Connection Science, V6, P177, DOI 10.1080/09540099408915723.
   Large EW, 2002, PSYCHOL RES-PSYCH FO, V66, P3, DOI 10.1007/s004260100069.
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119.
   Lehiste I, 1977, J PHONETICS, V5, P253.
   Leong V, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144411.
   LIBERMAN M, 1977, LINGUIST INQ, V8, P249.
   London J, 2012, EMPIR MUSICOL REV, V7, P5, DOI 10.18061/1811/52973.
   MARTIN JG, 1972, PSYCHOL REV, V79, P487, DOI 10.1037/h0033467.
   Meyer L., 2017, EUR J NEUROSCI, DOI {[}10.1111/ijlh.12426, DOI 10.1111/IJLH.12426].
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405.
   Nazzi T, 2003, SPEECH COMMUN, V41, P233, DOI 10.1016/S0167-6393(02)00106-1.
   NORRIS D, 1995, J EXP PSYCHOL LEARN, V21, P1209, DOI 10.1037/0278-7393.21.5.1209.
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011.
   Otterbein S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051419.
   Patel A., 2011, MUSIC PERCEPT, V24, P99, DOI {[}10.1525/rep.2008.104.1.92.This, DOI 10.1525/REP.2008.104.1.92.THIS].
   Patel A.D., 2008, MUSIC LANGUAGE BRAIN.
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   PITT MA, 1990, J EXP PSYCHOL HUMAN, V16, P564, DOI 10.1037/0096-1523.16.3.564.
   Port RF, 2003, J PHONETICS, V31, P599, DOI 10.1016/j.wocn.2003.08.001.
   Quene H, 2005, PHONETICA, V62, P1, DOI 10.1159/000087222.
   Rothermich K, 2013, NEUROIMAGE, V70, P89, DOI 10.1016/j.neuroimage.2012.12.013.
   Rothermich K, 2012, NEUROPSYCHOLOGIA, V50, P232, DOI 10.1016/j.neuropsychologia.2011.10.025.
   Sanders LD, 2000, J SPEECH LANG HEAR R, V43, P1301, DOI 10.1044/jslhr.4306.1301.
   Schmidt-Kassow M, 2009, NEUROREPORT, V20, P1643, DOI 10.1097/WNR.0b013e328333b0c6.
   Schmidt-Kassow M, 2009, J COGNITIVE NEUROSCI, V21, P1693, DOI 10.1162/jocn.2008.21153.
   Schwartze M, 2013, NEUROSCI BIOBEHAV R, V37, P2587, DOI 10.1016/j.neubiorev.2013.08.005.
   Selkirk Elisabeth, 1984, PHONOLOGY SYNTAX REL.
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572.
   SHIELDS JL, 1974, J EXP PSYCHOL, V102, P250, DOI 10.1037/h0035855.
   Sluijter AMC, 1996, J ACOUST SOC AM, V100, P2471, DOI 10.1121/1.417955.
   Weber A, 2006, LANG SPEECH, V49, P367, DOI 10.1177/00238309060490030301.}},
Number-of-Cited-References = {{65}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Front. Psychol.}},
Doc-Delivery-Number = {{GB4UW}},
Unique-ID = {{ISI:000429058000001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000429846300005,
Author = {Parackal, Mathew and Mather, Damien and Holdsworth, David},
Title = {{Value-based prediction of election results using natural language
   processing: A case of the New Zealand General Election}},
Journal = {{INTERNATIONAL JOURNAL OF MARKET RESEARCH}},
Year = {{2018}},
Volume = {{60}},
Number = {{2, SI}},
Pages = {{156-168}},
Month = {{MAR}},
Abstract = {{In this article, we report the results of a study that tested a
   values-based method of predicting political election results. The study
   was carried out on the 2014 New Zealand General Election, randomly
   selecting a stratified sample from a consumer panel. The survey of 858
   participants used open-ended questions to invoke and capture values
   relevant to the election. By using corpus linguistic analysis
   techniques, terms were ranked by weighting based on a log-frequency
   entropy method. Lexicons for Lasswell and Kaplan's societal value
   framework reduced the corpus of term-weighted documents to a workable
   number of eight user-defined societal value-topics. The topics were
   regressed onto the individual voting decision using a multinomial logit
   (MNL) regression. The mean absolute deviation (MAD) from the actual vote
   was 1.8\%, much less than the margin of error of 3.5\% expected from
   sampling error alone. The methodology was successful in predicting the
   outcome for the minor parties with good accuracy, for example, the
   prediction for the then newly formed Internet-Mana was out by about
   0.5\%. The framing-balanced, value-based predictions exhibited
   reasonable stability, considering they were made six weeks before
   Election Day. Thus the values relevant to the voters and a good
   prediction of the voting behavior became evident ahead of the official
   campaign period, which started four weeks before Election Day in New
   Zealand. Our study concluded that the value-based prediction shows
   promise for improving the quality of political journalism and public
   engagement in the period of election campaigns, and will assist greatly
   in focusing public debate more on values that are influential on
   citizens' voting decisions.}},
Publisher = {{SAGE PUBLICATIONS LTD}},
Address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Parackal, M (Corresponding Author), Univ Otago, 60 Clyde St, Dunedin 9054, New Zealand.
   Parackal, Mathew; Mather, Damien; Holdsworth, David, Univ Otago, 60 Clyde St, Dunedin 9054, New Zealand.}},
DOI = {{10.1177/1470785318762234}},
ISSN = {{1470-7853}},
EISSN = {{2515-2173}},
Keywords = {{Prediction; General Election results; Value; Natural language
   processing; Supervised machine learning}},
Keywords-Plus = {{BASIC PERSONAL VALUES; MORAL VALUES; FORECASTS; ISSUES; CHOICE}},
Research-Areas = {{Business \& Economics}},
Web-of-Science-Categories  = {{Business}},
Author-Email = {{mathew.parackal@otago.ac.nz}},
ResearcherID-Numbers = {{Parackal, Mathew/ABD-5501-2020
   Mather, Damien/H-4302-2019}},
ORCID-Numbers = {{Mather, Damien/0000-0002-8495-1764}},
Cited-References = {{Armstrong J.S., 2001, PRINCIPLES FORECASTI.
   ARMSTRONG JS, 1989, INT J FORECASTING, V5, P585, DOI 10.1016/0169-2070(89)90013-7.
   Bafumi J, 2009, J POLIT, V71, P1, DOI 10.1017/S0022381608090014.
   BAKER EJ, 1980, ENVIRON BEHAV, V12, P367, DOI 10.1177/0013916580123005.
   Bartels LN, 2006, Q J POLIT SCI, V1, P201, DOI 10.1561/100.00000010.
   BATCHELOR R, 1995, MANAGE SCI, V41, P68, DOI 10.1287/mnsc.41.1.68.
   BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764.
   Bhalla A, 1997, DEV CHANGE, V28, P413, DOI 10.1111/1467-7660.00049.
   Boyd M, 2015, POLIT SCI, V67, P143, DOI 10.1177/0032318715609077.
   Brewer PR, 2005, POLIT PSYCHOL, V26, P929, DOI 10.1111/j.1467-9221.2005.00451.x.
   Brewer PR, 2002, POLIT COMMUN, V19, P303, DOI 10.1080/01957470290055510.
   Caprara GV, 2006, POLIT PSYCHOL, V27, P1, DOI 10.1111/j.1467-9221.2006.00447.x.
   Chakraborty G, 2013, TEXT MINING ANAL PRA.
   Chief Electoral Office, 2014, 2014 GEN EL OFF RES.
   Chong D, 2007, AM POLIT SCI REV, V101, P637, DOI 10.1017/S0003055407070554.
   Clemens R.T., 1990, LONG RANGE PLANN, V23, P132, DOI {[}10.1016/0024-6301(90)90316-V, DOI 10.1016/0024-6301(90)90316-V].
   CUZAN AG, 2005, ANN M SO POL SCI ASS.
   Demidenko E, 2007, STAT MED, V26, P3385, DOI 10.1002/sim.2771.
   Furnas G. W., 1988, P 11 ANN INT ACM SIG.
   Gigerenzer G, 2011, ANNU REV PSYCHOL, V62, P451, DOI 10.1146/annurev-psych-120709-145346.
   Graefe A, 2009, FORESIGHT.
   Graefe A, 2014, PS-POLIT SCI POLIT, V47, P427, DOI 10.1017/S1049096514000341.
   Graefe A, 2012, J BEHAV DECIS MAKING, V25, P41, DOI 10.1002/bdm.710.
   Graham J, 2011, J PERS SOC PSYCHOL, V101, P366, DOI 10.1037/a0021847.
   Hillygus DS, 2005, PS-POLIT SCI POLIT, V38, P201.
   Hopkins K, 2012, MEDIA INT AUST, P108.
   Jacob M, 2012, CHICAGO TRIBUNE 1014, P3.
   Jones Tim., 2007, CHICAGO TRIBUNE.
   Knuckey J, 2007, POLITICS POLICY, V35, P222, DOI 10.1111/j.1747-1346.2007.00058.x.
   Langer G, 2005, PUBLIC OPIN QUART, V69, P744, DOI 10.1093/poq/nfi060.
   Largeron C, 2011, P 2011 ACM S APPL CO, P924, DOI {[}10.2202/1540-8884.1123, DOI 10.2202/1540-8884.1123].
   Lasswell Harold, 1952, POWER SOC FRAMEWORK.
   Lewis-Beck Michael S., 2005, BRIT J POLIT INT REL, V7, P145, DOI DOI 10.1111/J.1467-856X.2005.00178.X.
   MAKRIDAKIS S, 1983, MANAGE SCI, V29, P987, DOI 10.1287/mnsc.29.9.987.
   McFadden D., 1972, FRONTIERS ECONOMETRI, P105.
   Mulligan K, 2008, PS-POLIT SCI POLIT, V41, P109, DOI 10.1017/S1049096508080177.
   NORMAN KL, 1974, J APPL PSYCHOL, V59, P753, DOI 10.1037/h0037496.
   Parackal M, 2016, J HAPPINESS STUD, V17, P1529, DOI 10.1007/s10902-015-9657-1.
   Piurko Y, 2011, POLIT PSYCHOL, V32, P537, DOI 10.1111/j.1467-9221.2011.00828.x.
   RAO P, 1971, AM STAT, V25, P37, DOI 10.2307/2686082.
   Redlawsk DP, 2004, POLIT PSYCHOL, V25, P595, DOI 10.1111/j.1467-9221.2004.00389.x.
   Rosenberg J., 2015, DEWEY DEFEATS TRUMAN.
   Schuman H, 2006, FORUM, V4, DOI {[}10.2202/1540-8884.1123, DOI 10.2202/1540-8884.1123].
   SCHWARTZ SH, 1992, ADV EXP SOC PSYCHOL, V25, P1, DOI 10.1016/s0065-2601(08)60281-6.
   Schwartz SH, 2010, POLIT PSYCHOL, V31, P421, DOI 10.1111/j.1467-9221.2010.00764.x.
   Silva C, 2003, IEEE IJCNN, P1661.
   Stone P.J., 1966, GEN INQUIRER COMPUTE.
   Theunissen M., 2014, NZ HERALD.
   TVERSKY A, 1986, J BUS, V59, pS251, DOI 10.1086/296365.
   Vourvachis P, 2015, J APPL ACCOUNT RES, V16, P166, DOI 10.1108/JAAR-04-2013-0027.
   Warner J, 2007, J AM SOC INF SCI TEC, V58, P309, DOI 10.1002/asi.20490.}},
Number-of-Cited-References = {{51}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Int. J. Market Res.}},
Doc-Delivery-Number = {{GC5RR}},
Unique-ID = {{ISI:000429846300005}},
DA = {{2020-12-06}},
}

@article{ ISI:000416506600004,
Author = {Spille, Constantin and Ewert, Stephan D. and Kollmeier, Birger and
   Meyer, Bernd T.},
Title = {{Predicting speech intelligibility with deep neural networks}},
Journal = {{COMPUTER SPEECH AND LANGUAGE}},
Year = {{2018}},
Volume = {{48}},
Pages = {{51-66}},
Month = {{MAR}},
Abstract = {{An accurate objective prediction of human speech intelligibility is of
   interest for many applications such as the evaluation of signal
   processing algorithms. To predict the speech recognition threshold (SRT)
   of normal-hearing listeners, an automatic speech recognition (ASR)
   system is employed that uses a deep neural network (DNN) to convert the
   acoustic input into phoneme predictions, which are subsequently decoded
   into word transcripts. ASR results are obtained with and compared to
   data presented in Schubotz et al. (2016), which comprises eight
   different additive maskers that range from speech-shaped stationary
   noise to a single -talker interferer and responses from eight
   normal-hearing subjects. The task for listeners and ASR is to identify
   noisy words from a German matrix sentence test in monaural conditions.
   Two ASR training schemes typically used in applications are considered:
   (A) matched training, which uses the same noise type for training and
   testing and (B) multi-condition training, which covers all eight
   maskers. For both training schemes, ASR-based predictions outperform
   established measures such as the extended speech intelligibility index
   (ESII), the multi-resolution speech envelope power spectrum model
   (mr-sEPSM) and others. This result is obtained with a
   speaker-independent model that compares the word labels of the utterance
   with the ASR transcript, which does not require separate noise and
   speech signals. The best predictions are obtained for multi-condition
   training with amplitude modulation features, which implies that the
   noise type has been seen during training. Predictions and measurements
   are analyzed by comparing speech recognition thresholds and individual
   psychometric functions to the DNN-based results. (C) 2017 Elsevier Ltd.
   All rights reserved.}},
Publisher = {{ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD}},
Address = {{24-28 OVAL RD, LONDON NW1 7DX, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Spille, C; Meyer, BT (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Med Phys, Kupkersweg 74, D-26129 Oldenburg, Germany.
   Spille, Constantin; Meyer, Bernd T., Carl von Ossietzky Univ Oldenburg, Med Phys, Kupkersweg 74, D-26129 Oldenburg, Germany.
   Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Kupkersweg 74, D-26129 Oldenburg, Germany.}},
DOI = {{10.1016/j.csl.2017.10.004}},
ISSN = {{0885-2308}},
EISSN = {{1095-8363}},
Keywords = {{Speech intelligibility prediction; Deep neural networks; Automatic
   speech recognition}},
Keywords-Plus = {{FREQUENCY-SELECTIVITY; RECEPTION THRESHOLD; NORMAL-HEARING; RECOGNITION;
   NOISE; MODEL; INDEX; RATIO}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{constantin.spille@uni-oldenburg.de
   bernd.meyer@uni-oldenburg.de}},
Funding-Acknowledgement = {{DFG (Cluster of Excellence)German Research Foundation (DFG) {[}1077/1]}},
Funding-Text = {{This research was supported by the DFG (Cluster of Excellence 1077/1
   ``Hearing4all{''} and SFB/TRR 31 `The active auditory system': URLs:
   http://hearing4all.eu and http://www.sfb-trr31.uni-oldenhurg.de). The
   authors would like to thank Niko Moritz for providing the code of the
   AMFB feature calculation.}},
Cited-References = {{ANSI, 1997, METH CALC SPEECH INT, V1969, P1.
   Athineos M, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU `03, P261, DOI 10.1109/ASRU.2003.1318451.
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140.
   Barker J, 2007, SPEECH COMMUN, V49, P402, DOI 10.1016/j.specom.2006.11.003.
   Bhargava M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P6.
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152.
   Bronkhorst AW, 2000, ACUSTICA, V86, P117.
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600.
   Dau T, 1997, J ACOUST SOC AM, V102, P2906, DOI 10.1121/1.420345.
   Dubbelboer F, 2008, J ACOUST SOC AM, V124, P3937, DOI 10.1121/1.3001713.
   Durlach NI, 2003, J ACOUST SOC AM, V114, P368, DOI 10.1121/1.1577562.
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302.
   Ewert SD, 2000, J ACOUST SOC AM, V108, P1181, DOI 10.1121/1.1288665.
   Exter M, 2016, INTERSPEECH, P615, DOI 10.21437/Interspeech.2016-1285.
   Greenberg S., 1996, ICSLP 96, pS24.
   Hautamaki RG, 2015, SPEECH COMMUN, V72, P13, DOI 10.1016/j.specom.2015.05.002.
   Hermansky H., 1999, P 1999 IEEE INT C AC, V1, P289, DOI 10.1109/LCASSP.1W./D8119.
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616.
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527.
   Holube I, 2010, INT J AUDIOL, V49, P891, DOI 10.3109/14992027.2010.506889.
   Hoshen Y, 2015, INT CONF ACOUST SPEE, P4624, DOI 10.1109/ICASSP.2015.7178847.
   HOUTGAST T, 1989, J ACOUST SOC AM, V85, P1676, DOI 10.1121/1.397956.
   Jorgensen S, 2013, J ACOUST SOC AM, V134, P436, DOI 10.1121/1.4807563.
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502.
   Jurgens T, 2009, J ACOUST SOC AM, V126, P2635, DOI 10.1121/1.3224721.
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514.
   Kingsbury BED, 1998, SPEECH COMMUN, V25, P117, DOI 10.1016/S0167-6393(98)00032-6.
   Kollmeier B, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516655795.
   Kollmeier B, 2015, INT J AUDIOL, V54, P3, DOI 10.3109/14992027.2015.1020971.
   Ma N, 2016, INTERSPEECH, P3359, DOI 10.21437/Interspeech.2016-1149.
   Mallidi SH, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3551.
   MARAGOS P, 1993, IEEE T SIGNAL PROCES, V41, P3024, DOI 10.1109/78.277799.
   Meyer BT, 2017, INT CONF ACOUST SPEE, P5330, DOI 10.1109/ICASSP.2017.7953174.
   Meyer BT, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2982.
   Meyer BT, 2011, SPEECH COMMUN, V53, P753, DOI 10.1016/j.specom.2010.07.002.
   Meyer BT, 2011, J ACOUST SOC AM, V129, P388, DOI 10.1121/1.3514525.
   Mitra V, 2012, INT CONF ACOUST SPEE, P4117, DOI 10.1109/ICASSP.2012.6288824.
   Mohamed AR, 2012, INT CONF ACOUST SPEE, P4273, DOI 10.1109/ICASSP.2012.6288863.
   Moritz N, 2013, P 2 INT WORKSH MACH, P1.
   Moritz N, 2017, COMPUT SPEECH LANG, V46, P558, DOI 10.1016/j.csl.2016.11.004.
   Moritz N, 2016, IEEE-ACM T AUDIO SPE, V24, P2439, DOI 10.1109/TASLP.2016.2615239.
   Moritz N, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P468, DOI 10.1109/ASRU.2015.7404832.
   Moritz N, 2015, IEEE-ACM T AUDIO SPE, V23, P1926, DOI 10.1109/TASLP.2015.2456420.
   Palaz D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P11.
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964.
   Parihar N., 2002, AU38402 LVCSR, DOI 1.
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357.
   PLOMP R, 1978, J ACOUST SOC AM, V63, P533, DOI 10.1121/1.381753.
   Povey Daniel, 2011, IEEE 2011 WORKSH AUT.
   Rhebergen KS, 2006, J ACOUST SOC AM, V120, P3988, DOI 10.1121/1.2358008.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0.
   Schadler MR, 2015, INT J AUDIOL, V54, P100, DOI 10.3109/14992027.2015.1061708.
   Schubotz W, 2016, J ACOUST SOC AM, V140, P524, DOI 10.1121/1.4955079.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Tuske Z, 2014, INTERSPEECH, P890.
   Wagener K, 1999, Z AUDIOL, V38, P86.
   Xiong F., 2014, REV WORKSH, P1.
   Xiong W., 2016, ARXIV161005256 CORR.
   Zhang XL, 2016, IEEE-ACM T AUDIO SPE, V24, P967, DOI 10.1109/TASLP.2016.2536478.}},
Number-of-Cited-References = {{61}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{21}},
Journal-ISO = {{Comput. Speech Lang.}},
Doc-Delivery-Number = {{FO1GY}},
Unique-ID = {{ISI:000416506600004}},
DA = {{2020-12-06}},
}

@article{ ISI:000422959200017,
Author = {Corcoran, Cheryl M. and Carrillo, Facundo and Fernandez-Slezak, Diego
   and Bedi, Gillinder and Klim, Casimir and Javitt, Daniel C. and Bearden,
   Carrie E. and Cecchi, Guillermo A.},
Title = {{Prediction of psychosis across protocols and risk cohorts using
   automated language analysis}},
Journal = {{WORLD PSYCHIATRY}},
Year = {{2018}},
Volume = {{17}},
Number = {{1}},
Pages = {{67-75}},
Month = {{FEB}},
Abstract = {{Language and speech are the primary source of data for psychiatrists to
   diagnose and treat mental disorders. In psychosis, the very structure of
   language can be disturbed, including semantic coherence (e.g.,
   derailment and tangentiality) and syntactic complexity (e.g.,
   concreteness). Subtle disturbances in language are evident in
   schizophrenia even prior to first psychosis onset, during prodromal
   stages. Using computer-based natural language processing analyses, we
   previously showed that, among English-speaking clinical (e.g., ultra)
   high-risk youths, baseline reduction in semantic coherence (the flow of
   meaning in speech) and in syntactic complexity could predict subsequent
   psychosis onset with high accuracy. Herein, we aimed to cross-validate
   these automated linguistic analytic methods in a second larger risk
   cohort, also English-speaking, and to discriminate speech in psychosis
   from normal speech. We identified an automated machine-learning speech
   classifier - comprising decreased semantic coherence, greater variance
   in that coherence, and reduced usage of possessive pronouns - that had
   an 83\% accuracy in predicting psychosis onset (intra-protocol), a
   cross-validated accuracy of 79\% of psychosis onset prediction in the
   original risk cohort (cross-protocol), and a 72\% accuracy in
   discriminating the speech of recent-onset psychosis patients from that
   of healthy individuals. The classifier was highly correlated with
   previously identified manual linguistic predictors. Our findings support
   the utility and validity of automated natural language processing
   methods to characterize disturbances in semantics and syntax across
   stages of psychotic disorder. The next steps will be to apply these
   methods in larger risk cohorts to further test reproducibility, also in
   languages other than English, and identify sources of variability. This
   technology has the potential to improve prediction of psychosis outcome
   among at-risk youths and identify linguistic targets for remediation and
   preventive intervention. More broadly, automated linguistic analysis can
   be a powerful tool for diagnosis and treatment across neuropsychiatry.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Corcoran, CM (Corresponding Author), Icahn Sch Med Mt Sinai, Dept Psychiat, New York, NY 10029 USA.
   Corcoran, CM (Corresponding Author), New York State Psychiat Inst \& Hosp, New York, NY 10032 USA.
   Corcoran, Cheryl M., Icahn Sch Med Mt Sinai, Dept Psychiat, New York, NY 10029 USA.
   Corcoran, Cheryl M.; Bedi, Gillinder; Klim, Casimir; Javitt, Daniel C., New York State Psychiat Inst \& Hosp, New York, NY 10032 USA.
   Carrillo, Facundo; Fernandez-Slezak, Diego, Univ Buenos Aires, Dept Computac, Fac Ciencias Exactas \& Nat, Buenos Aires, DF, Argentina.
   Carrillo, Facundo; Fernandez-Slezak, Diego, Univ Buenos Aires, Inst Invest Ciencias Computac, Buenos Aires, DF, Argentina.
   Bedi, Gillinder; Klim, Casimir; Javitt, Daniel C., Columbia Univ, Dept Psychiat, Med Ctr, New York, NY USA.
   Bedi, Gillinder, Univ Melbourne, Ctr Youth Mental Hlth, Melbourne, Vic, Australia.
   Bedi, Gillinder, Orygen Natl Ctr Excellence Youth Mental Hlth, Melbourne, Vic, Australia.
   Bearden, Carrie E., Univ Calif Los Angeles, Dept Psychiat \& Biobehav Sci \& Psychol, Los Angeles, CA USA.
   Bearden, Carrie E., Semel Inst Neurosci \& Human Behav, Los Angeles, CA USA.
   Cecchi, Guillermo A., IBM Corp, TJ Watson Res Ctr, Computat Biol Ctr Neurosci, Ossining, NY USA.}},
DOI = {{10.1002/wps.20491}},
ISSN = {{2051-5545}},
Keywords = {{Automated language analysis; prediction of psychosis; semantic
   coherence; syntactic complexity; high-risk youths; machine learning}},
Keywords-Plus = {{LATENT SEMANTIC ANALYSIS; FORMAL THOUGHT-DISORDER; CLINICAL HIGH-RISK;
   COMMUNICATION DISORDERS; PRODROMAL-SYMPTOMS; SCHIZOPHRENIA; SPEECH;
   RELIABILITY; DISCOURSE; VALIDITY}},
Research-Areas = {{Psychiatry}},
Web-of-Science-Categories  = {{Psychiatry}},
ResearcherID-Numbers = {{Bedi, Gillinder/H-9347-2019
   Javitt, Daniel/U-6015-2019
   }},
ORCID-Numbers = {{Bearden, Carrie/0000-0002-8516-923X
   Bedi, Gillinder/0000-0002-6718-0099}},
Funding-Acknowledgement = {{US National Institute of Mental HealthUnited States Department of Health
   \& Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) {[}R01 MH 107558, R03 MH 108933 02];
   New York State Office of Mental Health; NARSAD/BBRF Young Investigator
   Award; Miller Family Term Chair; NATIONAL INSTITUTE OF MENTAL
   HEALTHUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) {[}R01MH107558, R03MH108933, R01MH107558, R03MH108933,
   R01MH107558, R01MH107558, R01MH107558, R01MH107558, R01MH115332,
   R01MH115332, R03MH108933, R01MH107558, R01MH115332] Funding Source: NIH
   RePORTER}},
Funding-Text = {{This research was supported by the US National Institute of Mental
   Health (R01 MH 107558; R03 MH 108933 02), the New York State Office of
   Mental Health, and a NARSAD/BBRF Young Investigator Award and Miller
   Family Term Chair to C.E. Bearden. These funding sources had no role in
   the design and conduct of the study; collection, management, analysis
   and interpretation of the data; preparation, review or approval of the
   manuscript; and the decision to submit the manuscript for publication.}},
Cited-References = {{Addington J, 2015, J NERV MENT DIS, V203, P328, DOI 10.1097/NMD.0000000000000290.
   ANDREASEN NC, 1979, ARCH GEN PSYCHIAT, V36, P1325.
   ANDREASEN NC, 1979, ARCH GEN PSYCHIAT, V36, P1315, DOI 10.1001/archpsyc.1979.01780120045006.
   ANDREASEN NC, 1986, SCHIZOPHRENIA BULL, V12, P348, DOI 10.1093/schbul/12.3.348.
   Ashburner J, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P49, DOI 10.1016/B978-012372560-8/50004-8.
   Baker JT, 2016, IPROC, V2, pe44.
   Bearden CE, 2011, J AM ACAD CHILD PSY, V50, P669, DOI 10.1016/j.jaac.2011.03.021.
   Bedi G, 2015, NPJ SCHIZOPHR, V1, DOI 10.1038/npjschz.2015.30.
   Bedi G, 2014, NEUROPSYCHOPHARMACOL, V39, P2340, DOI 10.1038/npp.2014.80.
   Ben-David S, 2014, PSYCHIAT SERV, V65, P1499, DOI 10.1176/appi.ps.201300527.
   Bird S, 2009, COMPUT LINGUIST, V35, P469, DOI 10.1162/coli.35.3.469.
   Bleuler E., 1911, DEMENTIA PRAECOX ODE.
   Buck B, 2015, J NERV MENT DIS, V203, P702, DOI 10.1097/NMD.0000000000000354.
   CAPLAN R, 1989, J AM ACAD CHILD PSY, V28, P408, DOI 10.1097/00004583-198905000-00018.
   Cornblatt BA, 2015, AM J PSYCHIAT, V172, P986, DOI 10.1176/appi.ajp.2015.13121686.
   DeVylder JE, 2014, SCHIZOPHR RES, V159, P278, DOI 10.1016/j.schres.2014.08.008.
   Elvevag B, 2007, SCHIZOPHR RES, V93, P304, DOI 10.1016/j.schres.2007.03.001.
   Elvevag B, 2010, J NEUROLINGUIST, V23, P270, DOI 10.1016/j.jneuroling.2009.05.002.
   Garcia AM, 2016, BRAIN LANG, V162, P19, DOI 10.1016/j.bandl.2016.07.008.
   Gooding DC, 2013, PSYCHOL MED, V43, P1003, DOI 10.1017/S0033291712001791.
   Gutierrez ED, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P183.
   Haxby JV, 2011, NEURON, V72, P404, DOI 10.1016/j.neuron.2011.08.026.
   HOFFMAN RE, 1985, J COMMUN DISORD, V18, P183, DOI 10.1016/0021-9924(85)90020-6.
   HOFFMAN RE, 1986, ARCH GEN PSYCHIAT, V43, P831.
   Jorge-Botana G, WILEY INTER IN PRESS.
   Kraepelin E, 1899, PSYCHIAT LEHRBUCH ST.
   Kuperberg GR, 2010, LANG LINGUIST COMPAS, V4, P590, DOI 10.1111/j.1749-818x.2010.00217.x.
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028.
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211.
   Mandera P, 2015, Q J EXP PSYCHOL, V68, P1623, DOI 10.1080/17470218.2014.988735.
   Miller TJ, 2003, SCHIZOPHRENIA BULL, V29, P703, DOI 10.1093/oxfordjournals.schbul.a007040.
   MOLLICA RF, 1986, AM J PSYCHIAT, V143, P12.
   Mota NB, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034928.
   Nelson B, 2013, JAMA PSYCHIAT, V70, P793, DOI 10.1001/jamapsychiatry.2013.1270.
   Nippold MA, 2005, LANG SPEECH HEAR SER, V36, P125, DOI 10.1044/0161-1461(2005/012).
   NoelJorand MC, 1997, SCHIZOPHR RES, V25, P183, DOI 10.1016/S0920-9964(97)00022-4.
   Roche E, 2015, SCHIZOPHRENIA BULL, V41, P951, DOI 10.1093/schbul/sbu129.
   Santorini B., 1990, PART OF SPEECH TAGGI.
   SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451.
   Silbert LJ, 2014, P NATL ACAD SCI USA, V111, pE4687, DOI 10.1073/pnas.1323812111.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{60}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{25}},
Journal-ISO = {{World Psychiatry}},
Doc-Delivery-Number = {{FT2GQ}},
Unique-ID = {{ISI:000422959200017}},
OA = {{Green Published, Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000429106500038,
Author = {Jimenez, J. L. and Gonzalez-Carrasco, I. and Lopez-Cuadrado, J. L.},
Title = {{Challenges And Opportunities In Analytic-Predictive Environments Of Big
   Data And Natural Language Processing For Social Network Rating Systems}},
Journal = {{IEEE LATIN AMERICA TRANSACTIONS}},
Year = {{2018}},
Volume = {{16}},
Number = {{2}},
Pages = {{592-597}},
Month = {{FEB}},
Abstract = {{Social Media is playing a key role in today's society. Many of the
   events that are taking place in diverse human activities could be
   explained by the study of these data. Big Data is a relatively new
   parading in Computer Science that is gaining increasing interest by the
   scientific community. Big Data Predictive Analytics is a Big Data
   discipline that is mostly used to analyze what is in the huge amounts of
   data and then perform predictions based on such analysis using advanced
   mathematics and computing techniques. The study of Social Media Data
   involves disciplines like Natural Language Processing, by the
   integration of this area to academic studies, useful findings have been
   achieved. Social Network Rating Systems are online platforms that allow
   users to know about goods and services, the way in how users review and
   rate their experience is a field of evolving research. This paper
   presents a deep investigation in the state of the art of these areas to
   discover and analyze the current status of the research that has been
   developed so far by academics of diverse background.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{Spanish}},
Affiliation = {{Jimenez, JL (Corresponding Author), Univ Carlos III Madrid, Dept Informat, Madrid, Spain.
   Jimenez, J. L.; Gonzalez-Carrasco, I.; Lopez-Cuadrado, J. L., Univ Carlos III Madrid, Dept Informat, Madrid, Spain.}},
ISSN = {{1548-0992}},
Keywords = {{Big Data analytics; Big Data predictive; Natural Language Processing;
   Social network rating systems}},
Keywords-Plus = {{LATENT DIRICHLET ALLOCATION; ONLINE REVIEWS; HELPFULNESS; SATISFACTION;
   MANAGEMENT; EMOTIONS}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic}},
Author-Email = {{100339395@alumnos.uc3m.es
   igcarras@inf.uc3m.es
   jllopez@inf.uc3m.es}},
ResearcherID-Numbers = {{CARRASCO, ISRAEL GONZALEZ/Q-5102-2017
   }},
ORCID-Numbers = {{CARRASCO, ISRAEL GONZALEZ/0000-0001-8294-3157
   Jimenez-Marquez, Jose Luis/0000-0002-1046-7726
   LOPEZ, JOSE LUIS/0000-0001-6115-0641}},
Cited-References = {{Agerri R, 2015, KNOWL-BASED SYST, V79, P36, DOI 10.1016/j.knosys.2014.11.007.
   Allahbakhsh M, 2014, COMPUT SECUR, V41, P68, DOI 10.1016/j.cose.2013.09.008.
   Baruh L., 2015, BIG DATA ANAL LIMITS.
   Belaud JP, 2014, COMPUT IND, V65, P521, DOI 10.1016/j.compind.2014.01.009.
   Cali Davide, 2011, PROCEDIA COMPUTER SC, V5, P920.
   De Mauro A, 2015, AIP CONF PROC, V1644, P97, DOI 10.1063/1.4907823.
   Ekmekci M, 2011, J ECON THEORY, V146, P479, DOI 10.1016/j.jet.2010.02.015.
   Elgendy N, 2016, PROCEDIA COMPUT SCI, V100, P1071, DOI 10.1016/j.procs.2016.09.251.
   Erevelles S, 2016, J BUS RES, V69, P897, DOI 10.1016/j.jbusres.2015.07.001.
   Felbermayr A, 2016, J INTERACT MARK, V36, P60, DOI 10.1016/j.intmar.2016.05.004.
   Gross A, 2014, NEURAL NETWORKS, V58, P38, DOI 10.1016/j.neunet.2014.05.008.
   Gudivada V. N., 2015, BIG DATA ANAL, V33, P203.
   Guo Y, 2017, TOURISM MANAGE, V59, P467, DOI 10.1016/j.tourman.2016.09.009.
   Iqbal R., 2016, INT J INFORM MANAGE, P1.
   Khanaferov D, 2014, IEEE INT C SEMANT CO, P250, DOI 10.1109/ICSC.2014.48.
   Kumar NMS, 2015, PROCEDIA COMPUT SCI, V50, P203, DOI 10.1016/j.procs.2015.04.069.
   Lee S, 2014, EXPERT SYST APPL, V41, P3041, DOI 10.1016/j.eswa.2013.10.034.
   Liu XL, 2015, PHYSICA A, V436, P629, DOI 10.1016/j.physa.2015.05.043.
   Liu Y, 2017, TOURISM MANAGE, V59, P554, DOI 10.1016/j.tourman.2016.08.012.
   Maletti A., 2016, THEORETICAL COMPUTER, P1.
   Marine-Roig E, 2015, J DESTIN MARK MANAGE, V4, P162, DOI 10.1016/j.jdmm.2015.06.004.
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464.
   Nesi P, 2015, J VISUAL LANG COMPUT, V31, P130, DOI 10.1016/j.jvlc.2015.10.017.
   Ngo-Ye TL, 2014, DECIS SUPPORT SYST, V61, P47, DOI 10.1016/j.dss.2014.01.011.
   Ozkose H, 2015, WORLD CONFERENCE ON TECHNOLOGY, INNOVATION AND ENTREPRENEURSHIP, P1042, DOI 10.1016/j.sbspro.2015.06.147.
   Pare G, 2015, INFORM MANAGE-AMSTER, V52, P183, DOI 10.1016/j.im.2014.08.008.
   Perrons RK, 2015, RESOUR POLICY, V46, P234, DOI 10.1016/j.resourpol.2015.10.007.
   Qi JY, 2016, INFORM MANAGE-AMSTER, V53, P951, DOI 10.1016/j.im.2016.06.002.
   Rahman MN, 2016, BIG DATA RES, V5, P9, DOI 10.1016/j.bdr.2016.02.002.
   Salehan M, 2016, DECIS SUPPORT SYST, V81, P30, DOI 10.1016/j.dss.2015.10.006.
   Shah N, 2017, J BUS RES, V70, P366, DOI 10.1016/j.jbusres.2016.08.010.
   Tan W., 2013, IEEE COMPUTER SOC.
   Tanana M, 2016, J SUBST ABUSE TREAT, V65, P43, DOI 10.1016/j.jsat.2016.01.006.
   Wamba SF, 2015, INT J PROD ECON, V165, P234, DOI 10.1016/j.ijpe.2014.12.031.
   Wang G, 2016, INT J PROD ECON, V176, P98, DOI 10.1016/j.ijpe.2016.03.014.
   Winkler M, 2016, DECIS SUPPORT SYST, V90, P23, DOI 10.1016/j.dss.2016.06.016.
   Yang ZH, 2016, KNOWL-BASED SYST, V111, P144, DOI 10.1016/j.knosys.2016.08.011.
   Yin DZ, 2014, MIS QUART, V38, P539, DOI 10.25300/MISQ/2014/38.2.10.
   Yue XG, 2012, PROCEDIA ENGINEER, V29, P1636, DOI 10.1016/j.proeng.2012.01.186.
   Zhu L, 2014, J ELECTRON COMMER RE, V15, P267.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{IEEE Latin Am. Trans.}},
Doc-Delivery-Number = {{GB5LV}},
Unique-ID = {{ISI:000429106500038}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000479297500014,
Author = {Xue, Suiqing and Min, Gang and Ren, Guolei},
Editor = {{Su, Y and Su, Y and Xu, P}},
Title = {{A Multipulse Speech Coding Model via l1/2-norm Minimization based Linear
   Prediction and Sparse Decomposition}},
Booktitle = {{PROCEEDINGS OF THE 2018 8TH INTERNATIONAL CONFERENCE ON APPLIED SCIENCE,
   ENGINEERING AND TECHNOLOGY (ICASET 2018)}},
Series = {{AER-Advances in Engineering Research}},
Year = {{2018}},
Volume = {{159}},
Pages = {{66-73}},
Note = {{8th International Conference on Applied Science, Engineering and
   Technology (ICASET), Qingdao, PEOPLES R CHINA, MAR 25-26, 2018}},
Abstract = {{Sparse linear predictive analysis using the l(1)-norm minimization
   criterion has been shown to provide a valid alternative to the
   traditional linear predictive approach. The sparser the resulted speech
   residual is, the fewer pulses needed to represent it. To find a sparse
   residual further, we propose to use the l(1/2)-norm as the optimization
   objective of linear prediction, and use an iteratively reweighted l(1)
   minimization approach to solve it. We also find that the procedure of
   determining the locations and amplitudes of the optimal pulses in the
   multipulse analysis is equivalent to a sparse decomposition problem,
   which is efficiently solved by the optimized orthogonal matching pursuit
   approach. The objective and informal subjective evaluations over the
   TIMIT database give proof of the effectiveness of this new model,
   performing better than the traditional approach for modeling and coding
   of speech.}},
Publisher = {{ATLANTIS PRESS}},
Address = {{29 AVENUE LAVMIERE, PARIS, 75019, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Xue, SQ (Corresponding Author), Natl Univ Def Technol, Coll Informat \& Commun, Wuhan 430010, Hubei, Peoples R China.
   Xue, Suiqing; Min, Gang; Ren, Guolei, Natl Univ Def Technol, Coll Informat \& Commun, Wuhan 430010, Hubei, Peoples R China.}},
ISSN = {{2352-5401}},
ISBN = {{978-94-6252-516-0}},
Keywords = {{Multipulse speech coding; l(1/2)-norm; Sparse linear prediction; Sparse
   decomposition}},
Research-Areas = {{Engineering; Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Engineering, Multidisciplinary; Multidisciplinary Sciences}},
Author-Email = {{175535882@qq.com
   mgxaty@gmail.com
   dzxxlab@163.com}},
Cited-References = {{Alipoor G, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P454, DOI 10.1109/TSP.2012.6256335.
   Atal B. S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P614.
   Atal BS, 2006, IEEE SIGNAL PROC MAG, V23, P154, DOI 10.1109/MSP.2006.1598091.
   ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679.
   Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x.
   Giacobello D, 2014, IEEE-ACM T AUDIO SPE, V22, P912, DOI 10.1109/TASLP.2014.2311324.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Khanagha V, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-3.
   LEE CH, 1988, IEEE T ACOUST SPEECH, V36, P642, DOI 10.1109/29.1574.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Rebollo-Neira L, 2002, IEEE SIGNAL PROC LET, V9, P137, DOI 10.1109/LSP.2002.1001652.
   Xu ZB, 2010, SCI CHINA INFORM SCI, V53, P1159, DOI 10.1007/s11432-010-0090-0.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BN3KJ}},
Unique-ID = {{ISI:000479297500014}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000475971500041,
Author = {Palagan, C. Anna},
Book-Group-Author = {{IEEE}},
Title = {{Joint Noise Suppression and Dereverberation of separating speech signals
   by using prediction and separation matrix}},
Booktitle = {{PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION AND
   ELECTRONICS SYSTEMS (ICCES 2018)}},
Year = {{2018}},
Pages = {{202-207}},
Note = {{3rd IEEE International Conference on Communication and Electronics
   Systems (ICCES), Coimbatore, INDIA, OCT 15-16, 2018}},
Organization = {{IEEE; PPG Inst Technol}},
Abstract = {{Separation of speech signal is an difficult task for researchers for
   separation of speech and noise from the mixing signals in the field of
   speech processing. The mixing and unmixing estimation technique is used
   commonly in the blind source separation (BSS) algorithms; however there
   is many limitations in separating of speech and noises such as echoes
   and dereverberation from the speech signal. The removal of noises are
   very much significant of all related testing and training done in
   auditory system. In this paper an newly invented method has been
   introduced by joint noise suppression and dereverberation by using the
   separation and prediction matrix which acts as an processing element.
   Due to the analysis of prediction matrix and separation matrix the
   results show that this joint noise suppression and dereverberation
   provides good Signal to Interference Ratio (SIR) and Direct to
   Reverberation Ratio (DRR) as 3 dB and 1.8 dB respectively. By using the
   proposed method the recognition accuracy improves to 92\%. The results
   shown that the new method achieving better accuracy, separation, noise
   separation and enhanced accuracy in separated speech signals.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Palagan, CA (Corresponding Author), Malla Reddy Engn Coll Autonomous, Dept ECE, Hyderabad, India.
   Palagan, C. Anna, Malla Reddy Engn Coll Autonomous, Dept ECE, Hyderabad, India.}},
ISBN = {{978-1-5386-4765-3}},
Keywords = {{Separation Matrix; Prediction Matrix; Blind Source Separation (BSS);
   Blind Dereverberation (BD); Short Time Fourier Transform (STFT)}},
Keywords-Plus = {{MULTICHANNEL BLIND DECONVOLUTION; CONVOLUTIVE MIXTURES}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{annapalaganc7467@gmail.com}},
Cited-References = {{Araki S, 2003, IEEE T SPEECH AUDI P, V11, P109, DOI 10.1109/TSA.2003.809193.
   Buchner H, 2005, IEEE T SPEECH AUDI P, V13, P120, DOI 10.1109/TSA.2004.838775.
   Buchner H, 2007, SIGNALS COMMUN TECHN, P101, DOI 10.1007/978-1-4020-6479-1\_4.
   Choi S, 2005, NEURAL INFORM PROCES, V6, P1.
   DEVILLE Y, 2003, P ICA2003, P1059.
   Douglas SC, 2005, IEEE T SPEECH AUDI P, V13, P92, DOI 10.1109/TSA.2004.838538.
   Feng DZ, 2011, IEEE T SIGNAL PROCES, V59, P3636, DOI 10.1109/TSP.2011.2150217.
   GIANNAKIS G, 2001, SIGNAL PROCESSING AD, V1.
   Huang YTA, 2005, IEEE T SPEECH AUDI P, V13, P882, DOI 10.1109/TSA.2005.851941.
   Kokkinakis K, 2006, IEEE T AUDIO SPEECH, V14, P200, DOI 10.1109/TSA.2005.854109.
   Matsuoka K., 2001, P INT C IND COMP AN, P722.
   Parra L, 2000, IEEE T SPEECH AUDI P, V8, P320, DOI 10.1109/89.841214.
   SAWADA H, 2005, SPEECH ENHANCEMENT.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BN2CW}},
Unique-ID = {{ISI:000475971500041}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000474785000021,
Author = {Jaidka, Kokil and Goyal, Tanya and Chhaya, Niyati},
Book-Group-Author = {{Assoc Comp Machinery}},
Title = {{Predicting Email and Article Clickthroughs with Domain-adaptive Language
   Models}},
Booktitle = {{WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE}},
Year = {{2018}},
Pages = {{177-184}},
Note = {{10th ACM Conference on Web Science (WebSci), Amsterdam, NETHERLANDS, MAY
   27-30, 2018}},
Organization = {{Assoc Comp Machinery; ACM SIGWEB}},
Abstract = {{Marketing practices have adopted the use of computational approaches in
   order to optimize the performance of their promotional emails and site
   advertisements. In the case of promotional emails, subject lines have
   been found to offer a reliable signal of whether the recipient will open
   an email or not. Clickbait headlines are also known to drive reader
   engagement. In this study, we explore the differences in recipients'
   preferences for subject lines of marketing emails from different
   industries, in terms of their clickthrough rates on marketing emails
   sent by different businesses in Finance, Cosmetics and Television
   industries. Different stylistic strategies of subject lines characterize
   high clickthroughs in different commercial verticals. For instance,
   words providing insight and signaling cognitive processing lead to more
   clickthroughs for the Finance industry; on the other hand, social words
   yield more clickthroughs for the Movies and Television industry. Domain
   adaptation can further improve predictive performance for unseen
   businesses by an average of 16.52\% over generic industry-specific
   predictive models. We conclude with a discussion on the implications of
   our findings and suggestions for future work.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Jaidka, K (Corresponding Author), Univ Penn, Philadelphia, PA 19104 USA.
   Jaidka, Kokil, Univ Penn, Philadelphia, PA 19104 USA.
   Goyal, Tanya, Univ Texas Austin, Austin, TX 78712 USA.
   Chhaya, Niyati, Adobe Res, Bangalore, Karnataka, India.}},
DOI = {{10.1145/3201064.3201071}},
ISBN = {{978-1-4503-5563-6}},
Keywords = {{email marketing; subject lines; linguistic analysis; copy-writing
   strategies; machine learning; domain adaptation; open rate prediction;
   clickthroughs; online ads; advertisements}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{jaidka@sas.upenn.edu
   tanyagoyal.93@gmail.com
   nchhaya@adobe.com}},
ResearcherID-Numbers = {{Jaidka, Kokil/AAK-2618-2020}},
ORCID-Numbers = {{Jaidka, Kokil/0000-0002-8127-1157}},
Cited-References = {{Aberdeen Douglas, 2010, LCCC NIPS 2010 WORKS.
   Balakrishnan R, 2014, IEEE INT CONF BIG DA, P579, DOI 10.1109/BigData.2014.7004277.
   Blom JN, 2015, J PRAGMATICS, V76, P87, DOI 10.1016/j.pragma.2014.11.010.
   Chakraborty A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P9, DOI 10.1109/ASONAM.2016.7752207.
   Chen Yi-Ting, 2013, ROCLING.
   Chen-Guang He, 2010, Proceedings 2010 IEEE Youth Conference on Information, Computing and Telecommunications (YC-ICT 2010), P351, DOI 10.1109/YCICT.2010.5713117.
   Daume H., 2009, ARXIV09071815.
   Dave K, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P897.
   Di Castro D, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P307, DOI 10.1145/2835776.2835811.
   Ferreira Ana, 2017, Financial Cryptography and Data Security. FC 2017 International Workshops WAHC, BITCOIN, VOTING, WTSC, and TA. Revised Selected Papers: LNCS 10323, P597, DOI 10.1007/978-3-319-70278-0\_38.
   Gianotto Alison, 2014, DOWNWORTHY BROWSER P.
   Guo Q, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P319.
   Guo Qi, 2008, INFORM RETRIEVAL ADV.
   Jones Simon, 2015, INT C ENG DES 2015 I.
   Kim S, 2014, INFORM SCIENCES, V276, P242, DOI 10.1016/j.ins.2014.02.058.
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050.
   Lim KH, 2016, PROCEEDINGS OF THE 27TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT'16), P255, DOI 10.1145/2914586.2914619.
   Luo X, 2015, LECT NOTES ARTIF INT, V9356, P116, DOI 10.1007/978-3-319-24282-8\_11.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Miller R, 2016, INT CONF ADV ICT, P58, DOI 10.1109/ICTER.2016.7829899.
   Owoputi Olutobi, 2013, IMPROVED PART SPEECH.
   Phelps JE, 2004, J ADVERTISING RES, V44, P333, DOI 10.1017/S0021849904040371.
   Potthast Martin, 2016, Advances in Information Retrieval. 38th European Conference on IR Research, ECIR 2016. Proceedings; LNCS 9626, P810, DOI 10.1007/978-3-319-30671-1\_72.
   Preotiuc-Pietro Daniel, 2015, ANAL USER OCCUPATION.
   Quaresma Rui Filipe Cerqueira, 2013, JISTEM J.Inf.Syst. Technol. Manag., V10, P5, DOI 10.1590/S1807-17752013000100002.
   Richardson M., 2007, P 16 INT C WORLD WID, P521, DOI DOI 10.1145/1242572.1242643.
   Sahni Navdeep S, 2016, PERSONALIZATION EMAI.
   Jose-Cabezudo RS, 2012, J ADVERTISING, V41, P97, DOI 10.2753/JOA0091-3367410207.
   Schwartz HA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073791.
   Schwartz H. Andrew, 2017, P 2017 C EMP METH NA, P55, DOI DOI 10.18653/V1/D17-2010.
   Shih DH, 2005, INFORM SCIENCES, V172, P241, DOI 10.1016/j.ins.2004.06.003.
   Stone P.J., 1966, GEN INQUIRER COMPUTE.
   Sun B., 2015, ARXIV151105547.
   Wilson EV, 2015, COMPUT HUM BEHAV, V52, P307, DOI 10.1016/j.chb.2015.06.014.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BN1PH}},
Unique-ID = {{ISI:000474785000021}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000465363900010,
Author = {Zheng, Yibin and Tao, Jianhua and Wen, Zhengqi and Li, Ya},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{BLSTM-CRF Based End-to-End Prosodic Boundary Prediction with Context
   Sensitive Embeddings in A Text-to-Speech Front-End}},
Booktitle = {{19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES}},
Series = {{Interspeech}},
Year = {{2018}},
Pages = {{47-51}},
Note = {{19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018),
   Hyderabad, INDIA, AUG 02-SEP 06, 2018}},
Organization = {{Int Speech Commun Assoc}},
Abstract = {{In this paper, we propose a language-independent end-to-end architecture
   for prosodic boundary prediction based on BLSTMCRF. The proposed
   architecture has three components, word embedding layer, BLSTM layer and
   CRF layer. The word embedding layer is employed to learn the
   task-specific embeddings for prosodic boundary prediction. The BLSTM
   layer can efficiently use both past and future input features, while the
   CRF layer can efficiently use sentence level information. We integrate
   these three components and learn the whole process end to -end. In
   addition, we investigate both character-level embed dings and context
   sensitive embeddings to this model, and employ an attention mechanism
   for combining alternative word level embeddings. By using an attention
   mechanism, the model is able to decide how much information to use from
   each level of embeddings. Objective evaluation results show the proposed
   BLSTM-CRF architecture achieves the best results on both Mandarin and
   English datasets, with an absolute improvement of 3.21\% and 3.74\% in
   Fl score, respectively, for intonational phrase prediction, compared to
   previous state-of-the-art method (BLSTM). The subjective evaluation
   results further indicate the effectiveness of the proposed methods.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zheng, YB (Corresponding Author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   Zheng, YB (Corresponding Author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
   Zheng, Yibin; Tao, Jianhua; Wen, Zhengqi; Li, Ya, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   Zheng, Yibin; Tao, Jianhua, Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-7221-9}},
Keywords = {{prosodic boundary prediction; BLSTM-CRF; attention; context sensitive
   embeddings; end-to-end}},
Keywords-Plus = {{SYNTACTIC FEATURES; MODEL}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{yibin.zheng@nlpr.ia.ac.cn
   jhtao@nlpr.ia.ac.cn
   zgwen@nlpr.ia.ac.cn
   yli@nlpr.ia.ac.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) {[}61425017, 61773379, 61603390,
   61771472]; National Key Research \& Development Plan of China
   {[}2017YFC0820602]; Inria-CAS Joint Research Project
   {[}173211KYSB20170061]}},
Funding-Text = {{This work is supported by the National Natural Science Foundation of
   China (NSFC) (No.61425017, No. 61773379, No. 61603390, No. 61771472),
   the National Key Research \& Development Plan of China (No.
   2017YFC0820602) and Inria-CAS Joint Research Project
   (173211KYSB20170061).}},
Cited-References = {{Ananthakrishnan S, 2005, INT CONF ACOUST SPEE, P269.
   Ando R. K., 2005, FRAMEWORK LEARNING P.
   Busser B., 2001, P 4 ISCA TUT RES WOR, P29.
   Che H, 2016, J SIGNAL PROCESS SYS, V82, P263, DOI 10.1007/s11265-015-1013-5.
   Chen ZG, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1421.
   Chu M., 2008, COMPUT LINGUIST, V6, P61.
   Ding C, 2016, AUTOMATIC SPEECH REC, P98.
   Fernandez R, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1429.
   Graves A., 2012, LONG SHORT TERM MEMO.
   Huang ZH, 2015, COMPUT INTEL NEUROSC, DOI 10.1155/2015/685404.
   King  S., 2011, INTERSPEECH, P2157.
   Lai SW, 2016, IEEE INTELL SYST, V31, P5, DOI 10.1109/MIS.2016.45.
   Lample G., 2016, ARXIV160301360.
   Mikolov T., 2013, COMPUTER SCI.
   Oord A. v. d., 2016, WAVENET GENERATIVE M.
   Qian Y., 2011, INT S CHIN SPOK LANG, P135.
   Read I., 2007, AUTOMATIC PITCH ACCE.
   Rei M., 2016, ATTENDING CHARACTERS.
   Rei M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2121, DOI 10.18653/v1/P17-1194.
   Rendel A, 2016, INT CONF ACOUST SPEE, P5655, DOI 10.1109/ICASSP.2016.7472760.
   Rosenberg A., 2015, INTERSPEECH.
   Rosenberg A., 2012, INTERSPEECH.
   Sridhar VKR, 2008, IEEE T AUDIO SPEECH, V16, P797, DOI 10.1109/TASL.2008.917071.
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929.
   Team T. D., 2017, THEANO PYTHON FRAMEW.
   Vania C., 2017, CHARACTERS WORDS DO, P2016.
   Zaremba W., 2014, RECURRENT NEURAL NET.
   Zeiler M. D., 2012, COMPUTER SCI.
   Zheng YB, 2016, INTERSPEECH, P3201, DOI 10.21437/Interspeech.2016-1060.
   1989, SPEECH COMMUNICATION, V8, P137.
   2011, LINGUA, V121, P1863, DOI DOI 10.1016/J.LINGUA.2011.09.001.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM5PH}},
Unique-ID = {{ISI:000465363900010}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000465363900147,
Author = {Airaksinen, Manu and Juvela, Lauri and Rasanen, Okka and Alku, Paavo},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Time-regularized linear prediction for noise-robust extraction of the
   spectral envelope of speech}},
Booktitle = {{19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES}},
Series = {{Interspeech}},
Year = {{2018}},
Pages = {{701-705}},
Note = {{19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018),
   Hyderabad, INDIA, AUG 02-SEP 06, 2018}},
Organization = {{Int Speech Commun Assoc}},
Abstract = {{Feature extraction of speech signals is typically performed in
   short-time frames by assuming that the signal is stationary within each
   frame. For the extraction of the spectral envelope of speech, which
   conveys the formant frequencies produced by the resonances of the slowly
   varying vocal tract, an often used frame length is within 20-30 ms.
   However, this kind of conventional frame-based spectral analysis is
   oblivious of the broader temporal context of the signal and is prone to
   degradation by, for example, environmental noise.
   In this paper, we propose a new frame-based linear prediction (LP)
   analysis method that includes a regularization term that penalizes
   energy differences in consecutive frames of an all-pole spectral
   envelope model. This integrates the slowly varying nature of the vocal
   tract as a part of the analysis. Objective evaluations related to
   feature distortion and phonetic representational capability were
   performed by studying the properties of the mel-frequency cepstral
   coefficient (MFCC) representations computed from different spectral
   estimation methods under noisy conditions using the TIMIT database. The
   results show that the proposed time-regularized LP approach exhibits
   superior MFCC distortion behavior while simultaneously having the
   greatest average separability of different phoneme categories in
   comparison to the other methods.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Airaksinen, M (Corresponding Author), Aalto Univ, Espoo, Finland.
   Airaksinen, Manu; Juvela, Lauri; Rasanen, Okka; Alku, Paavo, Aalto Univ, Espoo, Finland.}},
DOI = {{10.21437/Interspeech.2018-1230}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-7221-9}},
Keywords = {{speech analysis; linear prediction; robust features}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{manu.airaksinen@aalto.fi
   paavo.alku@aalto.fi}},
ResearcherID-Numbers = {{Alku, Paavo/E-2400-2012
   }},
ORCID-Numbers = {{Alku, Paavo/0000-0002-8173-9418
   Airaksinen, Manu/0000-0002-8031-2260}},
Funding-Acknowledgement = {{Academy of FinlandAcademy of Finland {[}256961, 312490]}},
Funding-Text = {{The research leading to these results has received funding from the
   Academy of Finland (project no. 256961, 312490).}},
Cited-References = {{Airaksinen M., 2012, THESIS.
   Antal M., 2004, STUDIA U BABES BOLYA, V49.
   Ekman LA, 2008, IEEE T AUDIO SPEECH, V16, P65, DOI 10.1109/TASL.2007.909448.
   Fant G., 1960, ACOUSTIC THEORY SPEE.
   Ganapathy S., 2012, IEEE SPEAKER ODYSSEY.
   Ganapathy S, 2014, IEEE-ACM T AUDIO SPE, V22, P1285, DOI 10.1109/TASLP.2014.2329190.
   GRENIER Y, 1983, IEEE T ACOUST SPEECH, V31, P899, DOI 10.1109/TASSP.1983.1164152.
   HALL MG, 1983, SIGNAL PROCESS, V5, P267, DOI 10.1016/0165-1684(83)90074-9.
   ITAKURA F, 1975, J ACOUST SOC AM, V57, pS35, DOI 10.1121/1.1995189.
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532.
   MA CX, 1993, SPEECH COMMUN, V12, P69, DOI 10.1016/0167-6393(93)90019-H.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   O'Saughnessy D., 2000, SPEECH COMMUNICATION.
   Pohjalainen J., 2008, P INTERSPEECH.
   Rabiner L. R., 1978, DIGITAL PROCESSING S.
   STRUBE HW, 1980, J ACOUST SOC AM, V68, P1071, DOI 10.1121/1.384992.
   Tikhonov A., 1977, SCRIPTS SERIES MATH.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.
   Vestman V, 2017, INTERSPEECH, P1512, DOI 10.21437/Interspeech.2017-734.
   2003, SPEECH COMMUNICATION, V40, P189.
   1998, SPEECH COMMUNICATION, V25, P133.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM5PH}},
Unique-ID = {{ISI:000465363900147}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000465363900203,
Author = {Ooster, Jasper and Huber, Rainer and Meyer, Bernd T.},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Prediction of Perceived Speech Quality Using Deep Machine Listening}},
Booktitle = {{19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES}},
Series = {{Interspeech}},
Year = {{2018}},
Pages = {{976-980}},
Note = {{19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018),
   Hyderabad, INDIA, AUG 02-SEP 06, 2018}},
Organization = {{Int Speech Commun Assoc}},
Abstract = {{Subjective ratings of speech quality (SQ) are essential for evaluating
   algorithms for speech transmission and enhancement. In this paper we
   explore a non -intrusive model for SQ prediction based on the output of
   a deep neural net (DNN) from a regular automatic speech recognizer. The
   degradation of phoneme probabilities obtained from the net is quantified
   with the mean temporal distance proposed earlier for multi -stream ASR.
   The SQ predicted with this method is compared with average subject
   ratings from the TCD-VoIP speech quality database that covers several
   effects of SQ degradation that can occur in VoIP applications such as
   clipping, packet loss, echo effects, background noise, and competing
   speakers. Our approach is tailored to speech and therefore not
   applicable when quality is degraded by a competing speaker, which is
   reflected by an insignificant correlation between model output and
   subjective SQ. In all other conditions mentioned above, the model
   reaches an average correlation of r =0.87, which is higher than the
   correlation achieved with the baseline ITU-T P.563 (r =0.71) and the
   American National Standard ANIQUE+ (r =0.75). Since the most robust ASR
   system is not necessarily the best model to predict SQ, we investigate
   the effect of the amount of training data on quality prediction.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ooster, J (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   Ooster, J (Corresponding Author), Cluster Excellence Hearing4all, Oldenburg, Germany.
   Ooster, Jasper; Meyer, Bernd T., Carl von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   Huber, Rainer, Fraunhofer IDMT Hearing Speech \& Audio Technol, Oldenburg, Germany.
   Ooster, Jasper; Huber, Rainer; Meyer, Bernd T., Cluster Excellence Hearing4all, Oldenburg, Germany.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-7221-9}},
Keywords = {{single-ended speech-quality prediction; deep learning; mean temporal
   distance}},
Keywords-Plus = {{SINGLE-ENDED PREDICTION}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{jasper.ooster@uni-oldenburg.de
   rainer.huber@idmt.fraunhofer.de
   bernd.meyer@uni-oldenburg.de}},
Funding-Acknowledgement = {{DFG (Cluster of Excellence 1077/1 Hearing4all)German Research Foundation
   (DFG); DFGGerman Research Foundation (DFG) {[}CRC TRR 31]}},
Funding-Text = {{This research was supported by the DFG (Cluster of Excellence 1077/1
   Hearing4all: URL: http://hearing4all.eu and the CRC TRR 31, Transfer
   Project T01).}},
Cited-References = {{European Telecommunications Standards Institute, 2008, 2023961 ETSI EG.
   Falk TH, 2006, IEEE T AUDIO SPEECH, V14, P1935, DOI 10.1109/TASL.2006.883253.
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043.
   Gopinath RA, 1998, INT CONF ACOUST SPEE, P661, DOI 10.1109/ICASSP.1998.675351.
   Harte N, 2015, INT WORK QUAL MULTIM.
   Hermansky H, 2013, INT CONF ACOUST SPEE, P7423, DOI 10.1109/ICASSP.2013.6639105.
   Huber R, 2017, INTERSPEECH, P1168, DOI 10.21437/Interspeech.2017-1360.
   Huber R, 2018, J AUDIO ENG SOC, V66, P759, DOI 10.17743/jaes.2018.0041.
   Huber R, 2018, HEARING RES, V359, P40, DOI 10.1016/j.heares.2017.12.014.
   ITU-T, 2011, REC P 862 PERC EV SP.
   ITU-T, 1996, REC P 800 METH SUBJ.
   ITU-T, 2011, REC P 341 TRANSM CHA, P30.
   ITU-T, 2004, REC P 563 SINGL END.
   ITU-T, 2011, REC P 863 PERC OBJ L.
   Kim DS, 2007, BELL LABS TECH J, V12, P221, DOI 10.1002/bltj.20228.
   Mallidi H, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P283, DOI 10.1109/ASRU.2015.7404806.
   Meyerl BT, 2016, IEEE W SP LANG TECH, P50, DOI 10.1109/SLT.2016.7846244.
   Moller S, 2011, IEEE SIGNAL PROC MAG, V28, P18, DOI 10.1109/MSP.2011.942469.
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382.
   Povey D., 2011, P ASRU, P1, DOI DOI 10.1017/CBO9781107415324.004.
   VESELY K, 2013, P INTERSPEECH, P2344.
   Xiong W, 2016, ACHIEVING HUMAN PARI.
   2012, IEEE SIGNAL PROCESSI, V29, P82, DOI DOI 10.1109/MSP.2012.2205597.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM5PH}},
Unique-ID = {{ISI:000465363900203}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000465363900381,
Author = {Fernando, Sarith and Sethu, Vidhyasaharan and Ambikairajah, Eliathamby},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Sub-band Envelope Features using Frequency Domain Linear Prediction for
   Short Duration Language Identification}},
Booktitle = {{19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES}},
Series = {{Interspeech}},
Year = {{2018}},
Pages = {{1818-1822}},
Note = {{19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018),
   Hyderabad, INDIA, AUG 02-SEP 06, 2018}},
Organization = {{Int Speech Commun Assoc}},
Abstract = {{Mismatch between training and testing utterances can significantly
   degrade the performance of language identification (LID) systems,
   especially in the case of short duration utterances. This work explores
   the hypothesis that long-term trends are less affected by this mismatch
   compared to short-term features. In particular, it proposes the use of
   features based on temporal envelopes within sub-bands. In this work, the
   temporal envelopes are obtained using linear prediction in the frequency
   domain. These envelopes are then transformed into cepstral features. The
   proposed features are then used as a front-end to a bidirectional long
   short term memory recurrent neural network to identify languages.
   Experimental evaluations on the AP17-OLR dataset under different
   conditions indicate that the proposed features exhibit substantially
   greater robustness under different noise and mismatch conditions,
   compared to baseline features. Specifically, the proposed features
   outperform state-of-the-art bottleneck features and show a relative
   improvement of 38.4\% averaged across the test set.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Fernando, S (Corresponding Author), UNSW Sydney, Sch Elect Engn \& Telecommun, Sydney, NSW, Australia.
   Fernando, S (Corresponding Author), CSIRO, DATA61, Sydney, NSW, Australia.
   Fernando, Sarith; Sethu, Vidhyasaharan; Ambikairajah, Eliathamby, UNSW Sydney, Sch Elect Engn \& Telecommun, Sydney, NSW, Australia.
   Fernando, Sarith; Ambikairajah, Eliathamby, CSIRO, DATA61, Sydney, NSW, Australia.}},
DOI = {{10.21437/Interspeech.2018-1805}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-7221-9}},
Keywords = {{Language Identification; Frequency domain linear prediction; Bottleneck
   features; Temporal envelope features; Bidirectional modelling}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{sarith.fernando@unsw.edu.au}},
ResearcherID-Numbers = {{Sethu, Vidhyasaharan/B-5197-2013}},
ORCID-Numbers = {{Ambikairajah, Eliathamby/0000-0003-4673-6534
   Sethu, Vidhyasaharan/0000-0001-8492-1787}},
Cited-References = {{Ambikairajah E, 2011, IEEE CIRC SYST MAG, V11, P82, DOI 10.1109/MCAS.2011.941081.
   Fernando S, 2018, ELECTRON LETT, V54, DOI 10.1049/el.2017.4027.
   Fernando S., 2016, SST2016 PARR AUSTR.
   Fernando S., 2018, ICASSP CALG ALB CAN.
   Fernando  S., 2017, INT 2017 SWED.
   Fernando S, 2016, INTERSPEECH, P2925, DOI 10.21437/Interspeech.2016-560.
   FoCal, 2008, TOOLK EV FUS CAL STA.
   Ganapathy S, 2010, J ACOUST SOC AM, V128, P3769, DOI 10.1121/1.3504658.
   Gonzalez-Dominguez J, 2015, NEURAL NETWORKS, V64, P49, DOI 10.1016/j.neunet.2014.08.006.
   Jackson L.B., 1996, DIGITAL FILTERS SIGN.
   Jiang B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100795.
   Kumaresan R, 1999, J ACOUST SOC AM, V105, P1912, DOI 10.1121/1.426727.
   LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L.
   Lozano-Diez A., 2015, P ANN C INT SPEECH C.
   Mohammed E. M., 2013, LPC MFCC PERFORMANCE.
   Richardson Fred, 2015, ARXIV150400923.
   Schwarz Petr, 2008, THESIS.
   Tang Zhiyuan, 2017, ARXIV170609742.
   Travadi  R., 2014, 15 ANN C INT SPEECH.
   Wang MG, 2013, INT CONF ACOUST SPEE, P7354, DOI 10.1109/ICASSP.2013.6639091.
   2006, PATTERN RECOGNITION, P254.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BM5PH}},
Unique-ID = {{ISI:000465363900381}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000465363900552,
Author = {Zelasko, Piotr and Szymanski, Piotr and Mizgajski, Jan and Szymczak,
   Adrian and Carmiel, Yishay and Dehak, Najim},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Punctuation Prediction Model for Conversational Speech}},
Booktitle = {{19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES}},
Series = {{Interspeech}},
Year = {{2018}},
Pages = {{2633-2637}},
Note = {{19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018),
   Hyderabad, INDIA, AUG 02-SEP 06, 2018}},
Organization = {{Int Speech Commun Assoc}},
Abstract = {{An ASR system usually does not predict any punctuation or
   capitalization. Lack of punctuation causes problems in result
   presentation and confuses both the human reader and off-the-shelf
   natural language processing algorithms. To overcome these limitations,
   we train two variants of Deep Neural Network (DNN) sequence labelling
   models - a Bidirectional Long Short-Term Memory (BLSTM) and a
   Convolutional Neural Network (CNN), to predict the punctuation. The
   models are trained on the Fisher corpus which includes punctuation
   annotation. In our experiments, we combine time-aligned and punctuated
   Fisher corpus transcripts using a sequence alignment algorithm. The
   neural networks are trained on Common Web Crawl GloVe embedding of the
   words in Fisher transcripts aligned with conversation side indicators
   and word time infomation. The CNNs yield a better precision and BLSTMs
   tend to have better recall. While BLSTMs make fewer mistakes overall,
   the punctuation predicted by the CNN is more accurate especially in the
   case of question marks. Our results constitute significant evidence that
   the distribution of words in time, as well as pre-trained embeddings,
   can be useful in the punctuation prediction task.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zelasko, P (Corresponding Author), Intelligent Wire, Seattle, WA 98121 USA.
   Zelasko, P (Corresponding Author), AGH Univ Sci \& Technol, Dept Comp Sci Elect \& Telecommun, Al Mickiewicza 30, Krakow, Poland.
   Zelasko, Piotr; Szymanski, Piotr; Mizgajski, Jan; Szymczak, Adrian; Carmiel, Yishay, Intelligent Wire, Seattle, WA 98121 USA.
   Zelasko, Piotr, AGH Univ Sci \& Technol, Dept Comp Sci Elect \& Telecommun, Al Mickiewicza 30, Krakow, Poland.
   Szymanski, Piotr, Wroclaw Univ Technol, Dept Computat Intelligence, Wybrzeze Stanislawa Wyspianskiego 27, PL-50370 Wroclaw, Poland.
   Dehak, Najim, Johns Hopkins Univ, Ctr Language \& Speech Proc, Baltimore, MD USA.}},
DOI = {{10.21437/Interspeech.2018-1096}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-7221-9}},
Keywords = {{punctuation prediction; speech recognition}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{pzelasko@intelligentwire.com
   piotr.szymanski@spoken.com
   jan.mizgajski@spoken.com
   adrian.szymczak@spoken.com
   ycarmiel@intelligentwire.com
   ndehak3@jhu.edu}},
ResearcherID-Numbers = {{Zelasko, Piotr/AAA-6412-2019
   Zelasko, Piotr/C-1340-2016}},
ORCID-Numbers = {{Zelasko, Piotr/0000-0002-8245-0413
   Zelasko, Piotr/0000-0002-8245-0413}},
Cited-References = {{Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265.
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621.
   Chollet Francois, 2015, KERAS.
   Christensen Heidi, 2001, ISCA TUT RES WORKSH.
   Cieri C., 2004, L REC, P69.
   Cock PJA, 2009, BIOINFORMATICS, V25, P1422, DOI 10.1093/bioinformatics/btp163.
   Huang Jing, 2002, 7 INT C SPOK LANG PR.
   Igras-Cybulska M, 2016, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-016-0096-7.
   IOFFE S, 2015, ARXIV 1502 03167, V1502, DOI DOI 10.1007/S13398-014-0173-7.2.
   Kingma Diederik P, 2014, ARXIV14126980.
   Klambauer G., 2017, ADV NEURAL INFORM PR, P972, DOI DOI 10.1177/1753193417719371.
   Lu Wei, 2010, P 2010 C EMP METH NA, P177.
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4.
   Pennington J., 2014, P EMNLP C, P1532, DOI DOI 10.3115/V1/D14-1162.
   Povey D, 2016, INTERSPEECH, P2751, DOI 10.21437/Interspeech.2016-595.
   Povey Daniel, 2011, IEEE 2011 WORKSH AUT.
   Stolcke A, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1005, DOI 10.1109/ICSLP.1996.607773.
   Tilk O, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P683.
   Ueffing N, 2013, INTERSPEECH, P3096.
   Vinod N., 2010, ICML, P807, DOI DOI 10.0RG/PAPERS/432.PDF.
   2016, INTERSPEECH, P3047, DOI DOI 10.21437/INTERSPEECH.2016-1517.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM5PH}},
Unique-ID = {{ISI:000465363900552}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000467845100342,
Author = {Giacobello, Daniele and Murthi, Manohar and Jensen, Tobias Lindstrom and
   Christensen, Mads Graesboll},
Editor = {{Matthews, MB}},
Title = {{REVISITING THE LINEAR PREDICTION ANALYSIS-BY-SYNTHESIS SPEECH CODING PA
   DIGM USING REAL-TIME CONVEX OPTIMIZATION}},
Booktitle = {{2018 CONFERENCE RECORD OF 52ND ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS,
   AND COMPUTERS}},
Series = {{Conference Record of the Asilomar Conference on Signals Systems and
   Computers}},
Year = {{2018}},
Pages = {{1947-1952}},
Note = {{52nd Asilomar Conference on Signals, Systems, and Computers, Pacific
   Grove, CA, OCT 28-NOV 01, 2018}},
Organization = {{IEEE Signal Proc Soc}},
Abstract = {{In this work, we propose a novel approach to speech coding by rewriting
   the nonlinear analysis-by-synthesis linear prediction scheme as a convex
   problem. This allows for detennining trade-offs between, on one hand,
   the reconstruction error and, on the other, the sparsity of the
   predictor and the residual used to parametrize the speech signal.
   Differently from traditional coding schemes where the parameters are
   chosen throughout multiple optimization stages, our scheme produces a
   one-shot parametrization of a speech segment that intrinsically takes
   into consideration the voiced or unvoiced nature of a speech segment
   providing a better balance between residual and predictor and,
   consequently, a more appropriate bit allocation.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Giacobello, D (Corresponding Author), Sonos Inc, Santa Barbara, CA 93103 USA.
   Giacobello, Daniele, Sonos Inc, Santa Barbara, CA 93103 USA.
   Murthi, Manohar, Univ Miami, Elect \& Comp Engn Dept, Coral Gables, FL 33124 USA.
   Jensen, Tobias Lindstrom, Aalborg Univ, Dept Elect Syst, Signal \& Informat Proc, Aalborg, Denmark.
   Christensen, Mads Graesboll, Aalborg Univ, AD MT, Audio Anal Lab, Aalborg, Denmark.}},
ISSN = {{1058-6393}},
ISBN = {{978-1-5386-9218-9}},
Keywords = {{Sparse linear prediction; convex optimization; real-time implementation;
   speech coding}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{giacobello@ieee.org}},
ResearcherID-Numbers = {{Giacobello, Daniele/AAI-3724-2020}},
ORCID-Numbers = {{Giacobello, Daniele/0000-0001-8708-8604}},
Funding-Acknowledgement = {{Marie Curie EST-SIGNAL FellowshipEuropean Union (EU)
   {[}MEST-CT-2005-021175]; Danish Council for Strategic ResearchDanske
   Strategiske Forskningsrad (DSF) {[}4005-00122]}},
Funding-Text = {{The work of D. Giacobello was supported by the Marie Curie EST-SIGNAL
   Fellowship under Contract MEST-CT-2005-021175 and was carried out at the
   Department of Electronic Systems, Aalborg University. The work of T. L.
   Jensen was supported by The Danish Council for Strategic Research under
   grant number 4005-00122.}},
Cited-References = {{Backstrom  T., 2013, P WORKSH APPL SIGN P.
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542.
   Bessette B, 2002, IEEE T SPEECH AUDI P, V10, P620, DOI 10.1109/TSA.2002.804299.
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319.
   Candes E. J., 2005, INT S EL IM.
   Chen  J.-H., 2008, SPRINGER HDB SPEECH, P351.
   CHEN JH, 1995, INT CONF ACOUST SPEE, P9, DOI 10.1109/ICASSP.1995.479261.
   Combettes P. L., 2010, FIXED POINT ALGORITH.
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090.
   Dahl J, 2010, NUMER ALGORITHMS, V53, P67, DOI 10.1007/s11075-009-9310-3.
   Defraene B, 2014, IEEE-ACM T AUDIO SPE, V22, P1648, DOI 10.1109/TASLP.2014.2344862.
   Defraene B, 2012, IEEE T AUDIO SPEECH, V20, P2657, DOI 10.1109/TASL.2012.2210875.
   Fischer J, 2015, EUR SIGNAL PR CONF, P804, DOI 10.1109/EUSIPCO.2015.7362494.
   Fratti M., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P73, DOI 10.1109/ICASSP.1992.225969.
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301.
   Ghido F, 2013, IEEE T AUDIO SPEECH, V21, P12, DOI 10.1109/TASL.2012.2211014.
   Giacobello Daniele, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P1770, DOI 10.1109/ACSSC.2009.5470202.
   Giacobello D, 2010, EUR SIGNAL PR CONF, P234.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   KLEIJN WB, 1990, IEEE T ACOUST SPEECH, V38, P1330, DOI 10.1109/29.57568.
   Kroon  P., 1995, SPEECH CODING SYNTHE, P79.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   MURTHI MN, 1998, ACOUST SPEECH SIG PR, P369.
   Nesterov Y., 2004, INTRO LECT CONVEX OP.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   Prandoni P, 2000, IEEE T SPEECH AUDI P, V8, P646, DOI 10.1109/89.876298.
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373.
   Singhal S., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P781.
   Songsiri  J., 2011, P AS S AUT CONTR.
   TZENG FF, 1990, GLOBECOM 90 - IEEE GLOBAL TELECOMMUNICATIONS CONFERENCE \& EXHIBITION, VOLS 1-3, P962, DOI 10.1109/GLOCOM.1990.116645.
   van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488.
   Weidmann C, 2012, IEEE T INFORM THEORY, V58, P4969, DOI 10.1109/TIT.2012.2201335.
   Woodard J. P., 1995, Sixth International Conference on Radio Receivers and Associated Systems (Conf. Publ. No.415), P114, DOI 10.1049/cp:19951129.
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM7FG}},
Unique-ID = {{ISI:000467845100342}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000462057000130,
Author = {Harshita, P. and Adiga, Akshay R.},
Book-Group-Author = {{IEEE}},
Title = {{Speech Recognition with Frequency Domain Linear Prediction}},
Booktitle = {{PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION
   AND SIGNAL PROCESSING (ICCSP)}},
Year = {{2018}},
Pages = {{630-634}},
Note = {{7th IEEE International Conference on Communication and Signal Processing
   (IEEE ICCSP), Adhiparasakthi Engn Coll, Melmaruvathur, INDIA, APR 03-05,
   2018}},
Organization = {{IEEE; IEEE MAS Sect; APEC}},
Abstract = {{This paper deals with the main objective to design an efficient
   algorithm to enhance speech recognition. The conventional speech
   recognition does not work well in conditions of noise and reverberation.
   The accuracy and performance of an automatic speech recognition system
   is dependent on the feature vector generated which characterizes the
   signal. The feature extracted must be independent of speaker
   variability, noise and other parameters. Hence, the only solution is to
   have a more robust feature vector. The feature vector must be such that
   it models only the intelligible data and not influenced by artifacts in
   any form. The proposed feature vector with maximum accuracy is a
   combination of MFCC (Mel-Frequency Cepstral Coefficients) and FDLP
   (Frequency Domain Linear Prediction) after applying Short Time Energy
   (STE) to find the highest energy indexed block of 400 samples. The
   chosen block is used for analysis. We have used Artificial Neural
   Network (ANN) for classification of samples (digits from 0-9)}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Harshita, P (Corresponding Author), RV Coll Engn, Engn Elect \& Commun, Bangalore, Karnataka, India.
   Harshita, P.; Adiga, Akshay R., RV Coll Engn, Engn Elect \& Commun, Bangalore, Karnataka, India.}},
ISBN = {{978-1-5386-3521-6}},
Keywords = {{ANN; FDLP; Linear Prediction; MFCC; Speech Recognition}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{harshitabhat1996@gmail.com
   akshayradiga@gmail.com}},
Cited-References = {{Betkowska A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/20593.
   Ganapathy S, 2012, J ACOUST SOC AM, V132, pEL436, DOI 10.1121/1.4758826.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   Low R., 1998, P 5 INT C SPOK LANG.
   Muda L., 2010, J COMP, V2, P138, DOI DOI 10.5815/IJIGSP.2016.09.03.
   Ostrander J. L., 1982, RSDTR182 U MICH.
   PAUL D, 2011, INT J ENG SCI TECHNO, V3, P4993.
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626.
   Thiang, 2011, INT PROC COMPUT SCI, V6, P179.
   Vaidyanathan P. P., 2007, SYNTHESIS LECT SIGNA, V2, P1, DOI DOI 10.2200/S00086ED-1V01Y200712SPR003.
   Zolnay A, 2005, INT CONF ACOUST SPEE, P457.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM3FY}},
Unique-ID = {{ISI:000462057000130}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000461021200086,
Author = {Shah, Devavrat and Burle, Sai and Doshi, Vishal and Huang, Ying-zong and
   Rengarajan, Balaji},
Book-Group-Author = {{IEEE}},
Title = {{Prediction Query Language}},
Booktitle = {{2018 56TH ANNUAL ALLERTON CONFERENCE ON COMMUNICATION, CONTROL, AND
   COMPUTING (ALLERTON)}},
Series = {{Annual Allerton Conference on Communication Control and Computing}},
Year = {{2018}},
Pages = {{611-616}},
Note = {{56th Annual Allerton Conference on Communication, Control, and Computing
   (Allerton), Monticello, IL, OCT 02-05, 2018}},
Organization = {{Coordinated Sci Lab; Univ Illinois Urbana Champaign, Dept Elect \& Comp
   Engn}},
Abstract = {{In this paper, we introduce an enhanced schema-less database language
   that supports prediction queries natively - the Prediction Query
   Language (PQL). Data in the PQL representation can be naturally modeled
   as an exchangeable multi-dimensional array. The seminal result by Aldous
   and Hoover (1980s), generalizing the classical result of De Finetti
   (1937), provides a canonical latent variable model characterization for
   such an exchangeable multi-dimensional array. We present a threelayer
   neural-network-based architecture that encodes this latent variable
   model representation and realizes an atomic prediction query. Using PQL,
   learning problems of Regression, Classification, Time-Series, Matrix and
   Tensor Completion can be solved simply by defining ``schema{''} in PQL
   and then running predictive query. With the help of various benchmark
   datasets for each of Classification, Regression, Time Series and Matrix
   /Tensor Completion, we find that this out-of-the-box performance of PQL
   is comparable with the state-of-the-art results obtained with solutions
   tailored specifically for the scenarios.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Shah, D (Corresponding Author), MIT, Cambridge, MA 02139 USA.
   Shah, Devavrat, MIT, Cambridge, MA 02139 USA.
   Burle, Sai; Doshi, Vishal; Huang, Ying-zong; Rengarajan, Balaji, Celect Inc, Boston, MA USA.}},
ISSN = {{2474-0195}},
ISBN = {{978-1-5386-6596-1}},
Keywords = {{Prediction; Query Language}},
Keywords-Plus = {{ARRAYS}},
Research-Areas = {{Automation \& Control Systems; Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Theory \& Methods;
   Telecommunications}},
Funding-Acknowledgement = {{NSFNational Science Foundation (NSF) {[}CMMI-1634259, CMMI-1462158,
   CNS-1523546]}},
Funding-Text = {{During this work conducted, DS was supported in parts by NSF
   CMMI-1462158, NSF CMMI-1634259 and NSF CNS-1523546.}},
Cited-References = {{ALDOUS DJ, 1981, J MULTIVARIATE ANAL, V11, P581, DOI 10.1016/0047-259X(81)90099-3.
   Austin  Tim, 2012, IAS WORSKH.
   Chamberlin D. D., 1974, P 1974 ACM SIGFIDET, P249, DOI DOI 10.1145/800296.811515.
   De Cock D, 2011, J STAT EDUC, V19, DOI 10.1080/10691898.2011.11889627.
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872.
   Hatinguais  Victor, 2018, MOVIE RECOMMENDER SY.
   Hoover D. N., 1981, EXCHANGEABILITY PROB, P281.
   Kingma Diederik P, 2014, ARXIV14126980.
   Mansinghka V., 2015, ARXIV151205006.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Orbanz P, 2015, IEEE T PATTERN ANAL, V37, P437, DOI 10.1109/TPAMI.2014.2334607.
   Saad F., 2016, ADV NEURAL INFORM PR, V29, P2011.
   Schreiber  Jacob, 2017, DEEP MATRIX FACTORIZ.
   Seeger M., 2009, KEY VALUE STORES PRA.
   Simonyan K., 2014, ARXIV14091556.
   Strub F, 2016, P 1 WORKSH DEEP LEAR, P11, DOI DOI 10.1145/2988450.2988456.
   Wan L, 2013, P 30 INT C MACH LEAR, P1058.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM2HE}},
Unique-ID = {{ISI:000461021200086}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000458678200014,
Author = {Liu, Xin and Liu, Yi and Song, Xiao},
Editor = {{Dong, M and Bijaksana, MA and Sujaini, H and Bijaksana, A and Romadhony, A and Ruskanda, FZ and Nurfadhilah, E and Aini, LR}},
Title = {{Investigating for Punctuation Prediction in Chinese Speech
   Transcriptions}},
Booktitle = {{2018 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP)}},
Series = {{International Conference on Asian Language Processing}},
Year = {{2018}},
Pages = {{74-78}},
Note = {{International Conference on Asian Language Processing (IALP), Telkom
   Univ, Bandung, INDONESIA, NOV 15-17, 2018}},
Organization = {{Indonesia Assoc Computat Lingust; COLIPS; Telkon Univ; IEEE; IEEE,
   Indonesia Sect Comp Soc Chapter}},
Abstract = {{Many automatic speech recognition (ASR) systems typically produce text
   without punctuation. However, the lack of punctuation information makes
   it less readability and even difficult to understand. It is also not be
   appropriate for the subsequent natural language processing (NLP).
   Meanwhile, it makes the punctuation prediction more difficult that the
   Chinese language is quite distinct from other letters' languages. Thus,
   we concentrate on the unique pitch feature of Chinese and introduce a
   three-stage based on long short-term memory (LSTM) to predict
   punctuation in Chinese corpus. Then, based on the success of the
   combination between lexical features and pause time, we fuse pitch
   information into the lexical and pause time for predicting punctuation.
   This implementation is the way that utilizes three multi-modal features,
   which are the lexical, pause time and pitch, respectively. Experimental
   results on Chinese data set demonstrate that the effectiveness and
   superiority of the proposed model by using a three-stage recurrent
   neural network.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Liu, Y (Corresponding Author), PKU Shenzhen Inst, Shenzhen, Peoples R China.
   Liu, Xin, Anhui Univ, Sch Comp Sci \& Technol, Hefei 230601, Anhui, Peoples R China.
   Liu, Xin; Liu, Yi, PKU Shenzhen Inst, Shenzhen, Peoples R China.
   Song, Xiao, Shenzhen Raisound Technol Co Ltd, Shenzhen, Peoples R China.}},
ISSN = {{2159-1962}},
EISSN = {{2159-1970}},
ISBN = {{978-1-7281-1176-6}},
Keywords = {{punctuation prediction; LSTM; multi-modal; pitch}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{yi.liu@imsl.org.cn}},
Funding-Acknowledgement = {{Shenzhen Science \& Research projects {[}JCYJ20170817155939233,
   JCYJ20160331104524983]}},
Funding-Text = {{This work is partially supported by Shenzhen Science \& Research
   projects (No: JCYJ20160331104524983) and Shenzhen Science \& Research
   projects (No: JCYJ20170817155939233).}},
Cited-References = {{Che  X., 2016, 10 INT C LANG RES EV.
   Cho  E., 2015, P 11 INT WORKSH SPOK.
   Duchi J, 2011, J MACH LEARN RES, V12, P2121.
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015.
   Gotoh  Y., 2001, P ISCA WORKSH PROS S, P35.
   Gravano A, 2009, INT CONF ACOUST SPEE, P4741, DOI 10.1109/ICASSP.2009.4960690.
   Graves A, 2012, SUPERVISED SEQUENCE.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Levy Tal, 2012, EL EL ENG ISR IEEEI, P1.
   Lu Wei, 2010, P 2010 C EMP METH NA, P177.
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045.
   Pascanu R, 2013, INT C MACH LEARN, P1310, DOI DOI 10.1109/72.279181.
   Peitz Stephan, 2011, IWSLT, P238.
   Povey D., 2011, ASRU.
   Sak H, 2014, INTERSPEECH, P338.
   Tilk  O., 2015, INTERSPEECH.
   Ueffing N, 2013, INTERSPEECH, P3096.
   Zhang D., 2013, ACL, P752.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM0DT}},
Unique-ID = {{ISI:000458678200014}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000458323900045,
Author = {Dietzen, Thomas and Doclo, Simon and Moonen, Marc and van Waterschoot,
   Toon},
Book-Group-Author = {{IEEE}},
Title = {{JOINT MULTI-MICROPHONE SPEECH DEREVERBERATION AND NOISE REDUCTION USING
   INTEGRATED SIDELOBE CANCELLATION AND LINEAR PREDICTION}},
Booktitle = {{2018 16TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC)}},
Series = {{International Workshop on Acoustic Signal Enhancement}},
Year = {{2018}},
Pages = {{221-225}},
Note = {{16th International Workshop on Acoustic Signal Enhancement (IWAENC),
   Tokyo, JAPAN, SEP 17-20, 2018}},
Organization = {{Ichimura Fdn New Technol; Tateisi Sci \& Technol Fdn; Yahoo! Japan;
   Google; Microsoft; Adobe; Hitachi; Dialog Semiconductor; Support Ctr Adv
   Telecommun Technol Res; mhacoustics; RION; IEEE; IEEE Signal Proc Soc;
   EiC; Informat Proc Soc Japan}},
Abstract = {{In multi-microphone speech enhancement, reverberation and noise are
   commonly suppressed by deconvolution and spatial filtering, i.e. using
   multi-channel linear prediction (MCLP) on the one hand and beamforming,
   e.g., a generalized sidelobe canceler (GSC), on the other hand. In this
   paper, in order to perform both deconvolution and spatial filtering, we
   propose to integrate MCLP and the GSC into a novel framework referred to
   as integrated sidelobe cancellation and linear prediction (ISCLP),
   wherein the sidelobe-cancellation (SC) filter and the linear prediction
   (LP) filter operate in parallel. Further, within this framework, we
   propose to estimate both filters jointly by means of a single Kalman
   filter. While ISCLP is roughly M times less expensive than a
   corresponding cascade of multiple-output MCLP and the GSC, where M
   denotes the number of microphones, it performs equally well in terms of
   dereverberation and noise reduction, as shown in simulations using one
   localized noise source.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Dietzen, T (Corresponding Author), Katholieke Univ Leuven, Dept Elect Engn, ESAT STADIUS, Leuven, Belgium.
   Dietzen, T (Corresponding Author), Katholieke Univ Leuven, Dept Elect Engn, ESAT ETC, Leuven, Belgium.
   Dietzen, Thomas; Moonen, Marc; van Waterschoot, Toon, Katholieke Univ Leuven, Dept Elect Engn, ESAT STADIUS, Leuven, Belgium.
   Dietzen, Thomas; van Waterschoot, Toon, Katholieke Univ Leuven, Dept Elect Engn, ESAT ETC, Leuven, Belgium.
   Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, Oldenburg, Germany.
   Doclo, Simon, Cluster Excellence Hearing4All, Oldenburg, Germany.}},
ISSN = {{2639-4316}},
ISBN = {{978-1-5386-8151-0}},
Keywords = {{Dereverberation; Noise Reduction; Beamforming; Multi-Channel Linear
   Prediction; Kalman Filter; Generalized Eigenvalue Decomposition}},
Research-Areas = {{Automation \& Control Systems; Engineering}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Engineering, Electrical \& Electronic}},
Funding-Acknowledgement = {{KU Leuven internal fund project {[}C2-16-00449]; KU Leuven Impulsfonds
   project {[}IMP/14/037]; KU Leuven Internal Funds project {[}VES/16/032];
   European CommissionEuropean CommissionEuropean Commission Joint Research
   Centre {[}316969, 773268]; Flemish Government {[}150611, HBC.2016.0085]}},
Funding-Text = {{This research work was carried out at the ESAT Laboratory of KU Leuven,
   in the frame of KU Leuven internal funding project C2-16-00449
   `Distributed Digital Signal Processing for Ad-hoc Wireless Local Area
   Audio Networking', KU Leuven Impulsfonds project IMP/14/037, KU Leuven
   Internal Funds project VES/16/032, and was supported by the European
   Commission under Grant Agreement no. 316969 (FP7-PEOPLE Marie Curie ITN
   `Dereverberation and Reverberation of Audio, Music, and Speech
   (DREAMS)') and no. 773268 (H2020-ERC-CoG `The Spatial Dynamics of Room
   Acoustics (SONORA)'), and by the Flemish Government under Project no.
   150611 (VLAIO O\&O Project `Proof-of-concept of a Rationed Architecture
   for Vehicle Entertainment and NVH Next-generation Acoustics (RAVENNA)')
   and no. HBC.2016.0085 (VLAIO TETRA Project `Innovative use of sensors in
   mobile platforms (m-sense)'). The scientific responsibility is assumed
   by its authors.}},
Cited-References = {{Bang, 1992, MUS ARCH.
   Braun S., 2018, IEEE-ACM T AUDIO SPE, V26, P240.
   Braun S, 2016, IEEE SIGNAL PROC LET, V23, P1741, DOI 10.1109/LSP.2016.2616888.
   Delcroix M, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0245-7.
   Dietzen  T., 2017, IEEE WORKSH APPL SIG.
   Dietzen T., 2016, P INT WORKSH AC SIGN, P1.
   Dietzen  T., 2018, AUDIO EXAMPLES IWAEN.
   Habets EAP, 2013, IEEE T AUDIO SPEECH, V21, P945, DOI 10.1109/TASL.2013.2239292.
   Hadad E, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P313, DOI 10.1109/IWAENC.2014.6954309.
   Haykin S., 2002, ADAPTIVE FILTER THEO.
   Jukic A, 2017, IEEE SIGNAL PROC LET, V24, P101, DOI 10.1109/LSP.2016.2640939.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kodrasi I, 2017, INT CONF ACOUST SPEE, P611, DOI 10.1109/ICASSP.2017.7952228.
   Kodrasi I, 2017, 2017 HANDS-FREE SPEECH COMMUNICATIONS AND MICROPHONE ARRAYS (HSCMA 2017), P116, DOI 10.1109/HSCMA.2017.7895573.
   Markovich S, 2009, IEEE T AUDIO SPEECH, V17, P1071, DOI 10.1109/TASL.2009.2016395.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Schwartz O, 2015, INT CONF ACOUST SPEE, P106, DOI 10.1109/ICASSP.2015.7177941.
   Schwartz O, 2015, IEEE-ACM T AUDIO SPE, V23, P240, DOI 10.1109/TASLP.2014.2372335.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL9TP}},
Unique-ID = {{ISI:000458323900045}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000458744200004,
Author = {Zhao, Huijuan and Ye, Ning and Wang, Ruchuan},
Book-Group-Author = {{IEEE}},
Title = {{Transferring Age and Gender Attributes for Dimensional Emotion
   Prediction from Big Speech Data using Hierarchical Deep Learning}},
Booktitle = {{2018 IEEE 4TH INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD
   (BIGDATASECURITY), 4THIEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE
   AND SMART COMPUTING, (HPSC) AND 3RD IEEE INTERNATIONAL CONFERENCE ON
   INTELLIGENT DATA AND SECURITY (IDS)}},
Year = {{2018}},
Pages = {{20-24}},
Note = {{4th IEEE International Conference on Big Data Security on Cloud
   (BigDataSecurity) / 4th IEEE International Conference on High
   Performance and Smart Computing (HPSC) / 3rd IEEE International
   Conference on Intelligent Data and Security (IDS), Omaha, NE, MAY 03-05,
   2018}},
Organization = {{IEEE; IEEE Comp Soc; IEEE TCSC; IEEE STC Smart Comp; Columbia Univ; Univ
   Nebraska; N Amer Chinese Talents Assoc; Pace Univ; Peking Univ; Univ Int
   Relat}},
Abstract = {{The continous speech emotion prediction is a challenging task. This
   research has many important applications in real-life, especially on
   human-computer interaction and its applications are expected to become
   increasingly wider and deeper. Previous studies have show that three
   dimensional attributes of emotion such as arousal, valence and dominance
   are related each other. Moreover, age and gender of speaker affect the
   recognition of speech emotion. Based on these observation, we propose a
   new dimensional attributes prediction model using multi-task learning,
   aiming to improve the emotion recognition performance and generalization
   capabilities. The present methods utilize the big speech data to train
   the age and gender submodel, which will be transferred to the main
   modellla hierarchical deep learning model, using age and gender as the
   high level attributes of the emotion. The publicly available databases
   IEMOCAP and aGender have been conducted to evaluate the performance and
   the accuracy of the proposed work. Experiment results of within-corpus
   evaluation show that the proposed approach has superior performance
   compared to state of the art result.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhao, HJ (Corresponding Author), Nanjing Univ Posts \& Telecommun, Coll Internet Things, Nanjing, Jiangsu, Peoples R China.
   Zhao, HJ (Corresponding Author), Nanjing Inst Ind Technol, Coll Comp \& Software, Nanjing, Jiangsu, Peoples R China.
   Zhao, Huijuan, Nanjing Univ Posts \& Telecommun, Coll Internet Things, Nanjing, Jiangsu, Peoples R China.
   Zhao, Huijuan, Nanjing Inst Ind Technol, Coll Comp \& Software, Nanjing, Jiangsu, Peoples R China.
   Ye, Ning; Wang, Ruchuan, Nanjing Univ Posts \& Telecommun, Coll Comp, Nanjing, Jiangsu, Peoples R China.
   Wang, Ruchuan, Jiangsu High Technol Res Key Lab Wireless Sensor, Nanjing, Jiangsu, Peoples R China.}},
DOI = {{10.1109/BDS/HPSC/IDS18.2018.00018}},
ISBN = {{978-1-5386-4399-0}},
Keywords = {{speech emotion prediction; big data; multi-task learning; transfer
   learning; deep learning}},
Keywords-Plus = {{RECOGNITION; VALENCE; AROUSAL}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Funding-Acknowledgement = {{National Natural Science Foundation of P. R. ChinaNational Natural
   Science Foundation of China (NSFC) {[}61572260]; Postgraduate Research
   \& Practice Innovation Program of Jiangsu Province {[}No.KYCX17\_0789];
   Key Research and Development Plan Project of Jiangsu Province}},
Funding-Text = {{The subject is sponsored by the National Natural Science Foundation of
   P. R. China (No.61572260) and Postgraduate Research \& Practice
   Innovation Program of Jiangsu Province(No.KYCX17\_0789) and Key Research
   and Development Plan Project of Jiangsu Province(No.BE2015702)}},
Cited-References = {{Bisio I, 2013, IEEE T EMERG TOP COM, V1, P244, DOI 10.1109/TETC.2013.2274797.
   Burkhardt  F., 2010, INT C LANG RES EV LR.
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6.
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734.
   Chen Shizhe, 2017, P 7 ANN WORKSH AUD V, P19, DOI DOI 10.1145/3133944.3133949.
   Davis I. L., 1995, INT C INT ROB SYST, P3338.
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020.
   Han H., 2017, IEEE T PATTERN ANAL, P1.
   Kaya  H., 1994, J BACTERIOL, V176, P5131.
   Kim  J., 2017, SPEECH EMOTION RECOG.
   Lewis PA, 2007, CEREB CORTEX, V17, P742, DOI 10.1093/cercor/bhk024.
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9.
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191.
   Parthasarathy S, 2017, INTERSPEECH, P1103, DOI 10.21437/Interspeech.2017-1494.
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002.
   Qian  Y., 2016, AUTOMATIC SPEECH REC, P310.
   Schuller B., 2010, INTERSPEECH, P2794.
   Valstar  M., 2013, AVEC 2013 CONTINUOUS.
   Varnek A, 2009, J CHEM INF MODEL, V49, P133, DOI 10.1021/ci8002914.
   Xia  R., 2017, IEEE T AFFECT COMPUT, P1.
   Yin H, 2015, IEEE I C EMBED SOFTW, P1314, DOI 10.1109/HPCC-CSS-ICESS.2015.205.
   Yishuang Ning Z. W., 2017, P 31 AAAI C ART INT.
   Zhang  B., 1949, IEEE T AFFECT COMPUT, P1.
   Zhang Y., 2017, IEEE INT C AC SPEECH.
   ZHOU ZH, 2004, NEURAL NETWORK ITS A.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM0GR}},
Unique-ID = {{ISI:000458744200004}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000458567200007,
Author = {Gamage, Kalani Wataraka and Dang, Ting and Sethu, Vidhyasaharan and
   Epps, Julien and Ambikairajah, Eliathamby},
Book-Group-Author = {{ACM}},
Title = {{Speech-based Continuous Emotion Prediction by Learning Perception
   Responses related to Salient Events: A Study based on Vocal Affect
   Bursts and Cross-Cultural Affect in AVEC 2018}},
Booktitle = {{PROCEEDINGS OF THE 2018 AUDIO/VISUAL EMOTION CHALLENGE AND WORKSHOP
   (AVEC'18)}},
Year = {{2018}},
Pages = {{47-55}},
Note = {{8th Workshop on Audio-Visual Emotion Challenge (AVEC), Seoul, SOUTH
   KOREA, OCT 22, 2018}},
Organization = {{Assoc Comp Machinery; ACM SIGMM}},
Abstract = {{This paper presents a novel framework for speech-based continuous
   emotion prediction. The proposed model characterises the perceived
   emotion estimation as time-invariant responses to salient events. Then
   arousal and valence variation over time is modelded as the ouput of a
   parallel array of time-invariant filters where each filter represents a
   salient event in this context, and the impulse response of the filter
   represents the learned perception emotion response.
   The proposed model is evaluted by considering vocal affect
   bursts/non-verbal vocal gestures as salient event candidates. The
   proposed model is validated based on the development dataset of AVEC
   2018 challenge development dataset and achieves the highest accuracy of
   valence prediction among single modal methods based on speech or
   speech-transcript. We tested this model on cross-cultural settings
   provided by AVEC 2018 challenge test set, and the model performs
   reasonably well for an unseen culture as well and outperform
   speech-based baselines. Further we explore inclusion of interlocutor
   related cues to the proposed model and decision level fusion with
   existing features. Since the proposed model was evaluated solely based
   on laughter and slight laughter affect bursts which were nominated as
   salient by proposed saliency constrains of the model, the results
   presented highlight the significance of aforementioned gestures in human
   emotion expression and perception.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gamage, KW (Corresponding Author), Univ New South Wales, Sch Elect Engn \& Tele, Sydney, NSW, Australia.
   Gamage, KW (Corresponding Author), CSIRO, Data61, Canberra, ACT, Australia.
   Gamage, Kalani Wataraka; Dang, Ting; Sethu, Vidhyasaharan; Epps, Julien; Ambikairajah, Eliathamby, Univ New South Wales, Sch Elect Engn \& Tele, Sydney, NSW, Australia.
   Gamage, Kalani Wataraka; Dang, Ting; Epps, Julien; Ambikairajah, Eliathamby, CSIRO, Data61, Canberra, ACT, Australia.}},
DOI = {{10.1145/3266302.3266314}},
ISBN = {{978-1-4503-5983-2}},
Keywords = {{Continuous emotion prediction; speech-based emotion recognition;
   non-verbal vocal events; affect-bursts; cross-cultural affect}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{wgkalani@gmail.com
   ting.dang@unsw.edu.au
   v.sethu@unsw.edu.au
   j.epps@unsw.edu.au
   e.ambikairajah@unsw.edu.au}},
ResearcherID-Numbers = {{dang, ting/R-1021-2019
   Sethu, Vidhyasaharan/B-5197-2013
   }},
ORCID-Numbers = {{Sethu, Vidhyasaharan/0000-0001-8492-1787
   Ambikairajah, Eliathamby/0000-0003-4673-6534
   Epps, Julien/0000-0001-6624-5551}},
Cited-References = {{Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5.
   Chen Shizhe, 2017, P 7 ANN WORKSH AUD V, P19, DOI DOI 10.1145/3133944.3133949.
   Ellsworth PC, 2003, SER AFFECTIVE SCI, P572.
   Gamage KW, 2017, INT CONF AFFECT, P518, DOI 10.1109/ACII.2017.8273648.
   Lee CC, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1955.
   Metallinou A, 2012, INT CONF ACOUST SPEE, P2401, DOI 10.1109/ICASSP.2012.6288399.
   Moore JD, 2014, LECT NOTES COMPUT SC, V8404, P17, DOI 10.1007/978-3-642-54903-8\_2.
   Moors A, 2013, EMOT REV, V5, P119, DOI 10.1177/1754073912468165.
   Ringeval F., 2017, P 7 ANN WORKSH AUD V, P3, DOI DOI 10.1145/3133944.3133953.
   Ringeval F., 2018, P 8 ANN WORK AUD VIS.
   Ringeval F, 2013, IEEE INT CONF AUTOMA.
   Ritter N., 2010, SW ED RES ASS SERA C.
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106.
   Scherer K.R., 1988, J LANG SOC PSYCHOL, V7, P79, DOI DOI 10.1177/0261927X8800700201.
   Scherer K. R., 2013, SJ GOULD SCI LEGACY.
   Scherer KR, 2013, COMPUT SPEECH LANG, V27, P40, DOI 10.1016/j.csl.2011.11.003.
   SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161.
   Schrober M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X.
   Schuller B., 2013, COMPUTATIONAL PARALI.
   Tian LM, 2015, INT CONF AFFECT, P698, DOI 10.1109/ACII.2015.7344645.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM0AZ}},
Unique-ID = {{ISI:000458567200007}},
DA = {{2020-12-06}},
}

@article{ ISI:000458676400003,
Author = {Elloumi, Zied and Lecouteux, Benjamin and Galibert, Olivier and
   Besacier, Laurent},
Title = {{Performance prediction of automatic speech recognition systems using
   convolutional neural networks}},
Journal = {{TRAITEMENT AUTOMATIQUE DES LANGUES}},
Year = {{2018}},
Volume = {{59}},
Number = {{2}},
Pages = {{49-76}},
Abstract = {{This paper focuses on the ASR performance prediction task. Two
   prediction approaches are compared: a state-of-the-art performance
   prediction based on engineered features and a new strategy based on
   learnt features using convolutional neural networks. We also try to
   better understand which information is captured by the deep model and
   its relation with different conditioning factors. To take advantage of
   this analysis, we then try to leverage these 3 types of information at
   training time through multi-task learning, which is slightly more
   efficient on ASR performance prediction task.}},
Publisher = {{ASSOC TRADUCTION AUTOMATIQUE LINGUISTIQUE APPLIQUEE}},
Address = {{45 RUE ULM, CEDEX 5, PARIS, 75230, FRANCE}},
Type = {{Article}},
Language = {{French}},
Affiliation = {{Elloumi, Z (Corresponding Author), Lab Natl Metrol \& Essais LNE, Paris, France.
   Elloumi, Z (Corresponding Author), Univ Grenoble Alpes, CNRS, Grenoble INP, LIG, F-38000 Grenoble, France.
   Elloumi, Zied; Galibert, Olivier, Lab Natl Metrol \& Essais LNE, Paris, France.
   Elloumi, Zied; Lecouteux, Benjamin; Besacier, Laurent, Univ Grenoble Alpes, CNRS, Grenoble INP, LIG, F-38000 Grenoble, France.}},
ISSN = {{1248-9433}},
EISSN = {{1965-0906}},
Keywords = {{performance prediction; large vocabulary continuous speech recognition;
   convolutional neural networks}},
Research-Areas = {{Linguistics}},
Web-of-Science-Categories  = {{Linguistics}},
Author-Email = {{prenom.nom@univ-grenoble-alpes.fr}},
Cited-References = {{Asadi A., 1990, INT C AC SPEECH SIGN.
   Belinkov Y., 2017, P 8 INT JOINT C NAT, V1, P1.
   Belinkov  Yonatan, 2017, ADV NEURAL INFORM PR, P2438.
   Camargo de Souza J.G., 2013, P 8 WORKSH STAT MACH, P352.
   Chollet Francois, 2015, KERAS.
   Collobert R, 2011, J MACH LEARN RES, V12, P2493.
   Dai W, 2017, INT CONF ACOUST SPEE, P421, DOI 10.1109/ICASSP.2017.7952190.
   de Calmes M., 1998, 1 INT C LANG RES EV, P1129.
   de Souza Jose GC, 2015, P 2015 C N AM CHAPT, P714.
   Dreschler WA, 2001, AUDIOLOGY, V40, P148.
   Elloumi Z., 2018, INT C AC SPEECH SIGN.
   Eyben F., 2010, P 18 ACM INT C MULT, P1459, DOI DOI 10.1145/1873951.1874246.
   Ferreira S., 2018, P 32 JOURN ET PAR, P249.
   Galibert O, 2013, INTERSPEECH, P1130.
   Galliano S., 2005, EUR C SPEECH COMM TE, P1149.
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1.
   Gravier  G., 2012, LREC 8 INT C LANG RE.
   Hermansky H, 2013, INT CONF ACOUST SPEE, P7423, DOI 10.1109/ICASSP.2013.6639105.
   Jalalvand S., 2015, DRIVING ROVER SEGMEN, V01.
   Jalalvand S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1095.
   Jalalvand S, 2016, PROCEEDINGS OF 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL-2016): SYSTEM DEMONSTRATIONS, P43.
   Jalalvand S, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P409, DOI 10.1109/ASRU.2015.7404824.
   Jin M., 2016, P OD.
   Kahn J, 2012, CONT BAS MULT IND CB, P1.
   Kim Yoon, 2014, ARXIV14085882.
   Kingma Diederik P., 2014, CORR.
   McFee, 2015, LIBROSA AUDIO MUSIC.
   Meinshausen N, 2010, J R STAT SOC B, V72, P417, DOI 10.1111/j.1467-9868.2010.00740.x.
   Meyer BT, 2017, INT CONF ACOUST SPEE, P5330, DOI 10.1109/ICASSP.2017.7953174.
   Mikolov T., 2013, NIPS.
   Mohamed AR, 2012, INT CONF ACOUST SPEE, P4273, DOI 10.1109/ICASSP.2012.6288863.
   Nagamine T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1912.
   Negri Matteo, 2014, COLING, P1813.
   Palaz D, 2015, INT CONF ACOUST SPEE, P4295, DOI 10.1109/ICASSP.2015.7178781.
   Pellegrini T, 2016, INTERSPEECH, P1290, DOI 10.21437/Interspeech.2016-1299.
   Piczak K.J., 2015, 2015 IEEE 25 INT WOR, P1, DOI DOI 10.1109/MLSP.2015.7324337.
   Povey Daniel, 2011, IEEE 2011 WORKSH AUT.
   Sainath T.N., 2015, 16 ANN C INT SPEECH.
   Schmid Helmut, 1995, TREETAGGER LANGUAGE, V43, P28.
   Shi X., 2016, P 2016 C EMP METH NA, P1526, DOI DOI 10.18653/V1/D16-1159.
   Stolcke A., 2002, INTERSPEECH, V2, P901.
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579.
   Wang S, 2017, INTERSPEECH, P1497, DOI 10.21437/Interspeech.2017-1125.
   Wu Z., 2016, CORR.
   Young S. R., 1994, INT C AC SPEECH SIGN, V1, P21.
   Zeiler M.D, 2012, CORR.}},
Number-of-Cited-References = {{46}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Trait. Autom. Lang.}},
Doc-Delivery-Number = {{HL4HB}},
Unique-ID = {{ISI:000458676400003}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000454639700157,
Author = {Zhu Boliang and Cao Ruiyi and Zhu Yilin and Xia Wendi},
Book-Group-Author = {{IEEE}},
Title = {{Language Trend Prediction Based on Adaptive Composite Language Network}},
Booktitle = {{PROCEEDINGS 2018 33RD YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE
   ASSOCIATION OF AUTOMATION (YAC)}},
Year = {{2018}},
Pages = {{862-867}},
Note = {{33rd Youth Academic Annual Conference of Chinese Association of
   Automation (YAC), Nanjing, PEOPLES R CHINA, MAY 18-20, 2018}},
Organization = {{IEEE; IEEE Syst, Man \& Cybernetics Soc; CAA}},
Abstract = {{The evolution of global language distribution is a complex dynamic
   evolution system which is very difficult to analyze quantitatively. In
   order to solve this problem, an adaptive composite language network
   (ACLN) in which the population was chosen as the language carrier and
   the space region as the boundary, is presented. The ACLN network
   consists of a main network based on the nearest neighbor principle and
   several fully-connected language subnets. The bridge between the main
   network and each sub-network is established with the language family.
   Probability transfer matrix is adopted to describe the evolution process
   of ACLN network and the (Particle Swarm Optimization) PSO algorithm is
   applied to optimize probability transkr matrix adaptively. The model
   error analysis shows that the ACLN network is credible and the evolution
   of language distribution can be effectively quantified.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Xia, WD (Corresponding Author), Wuhan Univ Technol, Sch Automat, Wuhan, Hubei, Peoples R China.
   Zhu Boliang; Cao Ruiyi; Zhu Yilin; Xia Wendi, Wuhan Univ Technol, Sch Automat, Wuhan, Hubei, Peoples R China.}},
ISBN = {{978-1-5386-7255-6}},
Keywords = {{Language trend prediction; Language population; Adaptive composite
   network; PSO algorithm}},
Research-Areas = {{Automation \& Control Systems}},
Web-of-Science-Categories  = {{Automation \& Control Systems}},
Author-Email = {{w1753546595@163.com
   wendyxia@whut.edu.cn}},
Cited-References = {{Clingingsmith David, 2015, EC J, V127.
   Deng Xiaohua, 2015, LANGUAGE STUDIES, P12.
   Du HF, 2007, ACTA PHYS SIN-CH ED, V56, P6886.
   Erdo?s P, 1960, PUBL MATH I HUNG, V5, P17, DOI DOI 10.2307/1999405.
   Erdos P., 1959, PUBL MATH-DEBRECEN, V6, P290, DOI DOI 10.2307/1999405.
   He Chun, 2010, Journal of Guangdong University of Technology, V27, P31.
   Kennedy James, 2006, SWARM INTELLIGENCE, V2.
   Newman M.E.J., 0202005 SANT FE I.
   Schwammle V, 2009, PHYSICA A, V388, P2874, DOI 10.1016/j.physa.2009.03.038.
   Whalen A, 2017, J MATH PSYCHOL, V76, P1, DOI 10.1016/j.jmp.2016.10.008.
   Yang GY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/1/018901.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL6QM}},
Unique-ID = {{ISI:000454639700157}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000452643100076,
Author = {Wang Yu and Yuan Yan and Wu Shui-qing and Li Yan-chao},
Editor = {{Su, R}},
Title = {{Network traffic prediction platform based on distributed stream
   processing and supported by R language}},
Booktitle = {{2018 INTERNATIONAL CONFERENCE ON IMAGE AND VIDEO PROCESSING, AND
   ARTIFICIAL INTELLIGENCE}},
Series = {{Proceedings of SPIE}},
Year = {{2018}},
Volume = {{10836}},
Note = {{International Conference on Image and Video Processing, and Artificial
   Intelligence (IVPAI), Shanghai, PEOPLES R CHINA, AUG 15-17, 2018}},
Organization = {{Chinese Acad Sci, Shanghai Adv Res Inst}},
Abstract = {{The thesis develops a network traffic predication application. The
   application, built on the R language oriented distributed stream
   processing systems described above, uses JDSU micro probe systems and
   nProbe to collect network traffic data, make predication on ARIMA model,
   and provide the basic data visualization function. Compared to similar
   systems, our network predication platform, has higher scalability and
   serviceability thanks to the distributed stream processing system, and
   better development efficiency with the help of R and CRAN.}},
Publisher = {{SPIE-INT SOC OPTICAL ENGINEERING}},
Address = {{1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, Y (Corresponding Author), Univ Hohai, Coll Comp \& Informat, Nanjing Provence 211100, Peoples R China.
   Wang Yu; Yuan Yan; Wu Shui-qing, Univ Hohai, Coll Comp \& Informat, Nanjing Provence 211100, Peoples R China.
   Li Yan-chao, Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai Provence 200000, Peoples R China.}},
DOI = {{10.1117/12.2514036}},
Article-Number = {{UNSP 1083626}},
ISSN = {{0277-786X}},
EISSN = {{1996-756X}},
ISBN = {{978-1-5106-2311-8}},
Keywords = {{stream processing; R language; network traffic prediction}},
Research-Areas = {{Computer Science; Optics; Imaging Science \& Photographic Technology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Optics; Imaging Science \&
   Photographic Technology}},
Cited-References = {{Dagenais B., 2014, PY4J BRIDGE PYTHON J.
   Gulisano V., 2012, IEEE T PARALLEL DIST.
   Rush C, 2016, PROGRAMMING SPARK PH.
   Srinivasa K G, 2015, GUIDE HIGH PERFORMAN, P73.
   Toshniwa A, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P147, DOI 10.1145/2588555.2595641.}},
Number-of-Cited-References = {{5}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BL5SN}},
Unique-ID = {{ISI:000452643100076}},
DA = {{2020-12-06}},
}

@article{ ISI:000439030800002,
Author = {Speier, William and Arnold, Corey and Chandravadia, Nand and Roberts,
   Dustin and Pendekanti, Shrita and Pouratian, Nader},
Title = {{Improving P300 spelling rate using language models and predictive
   spelling}},
Journal = {{BRAIN-COMPUTER INTERFACES}},
Year = {{2018}},
Volume = {{5}},
Number = {{1}},
Pages = {{13-22}},
Abstract = {{The P300 speller brain-computer interface (BCI) provides a means of
   communication for those suffering from advanced neuromuscular diseases
   such as amyotrophic lateral sclerosis (ALS). Recent literature has
   incorporated language-based modeling, which uses previously chosen
   characters and the structure of natural language to modify the interface
   and classifier. Two complementary methods of incorporating language
   models have previously been independently studied: predictive spelling
   uses language models to generate suggestions of complete words to allow
   for the selection of multiple characters simultaneously, and
   language-model-based classifiers have used prior characters to create a
   prior probability distribution over the characters based on how likely
   they are to follow. In this study, we propose a combined method which
   extends a language-based classifier to generate prior probabilities for
   both individual characters and complete words. In order to gage the
   efficiency of this new model, results across 12 healthy subjects were
   measured. Incorporating predictive spelling increased typing speed using
   the P300 speller, with an average increase of 15.5\% in typing rate
   across subjects, demonstrating that language models can be effectively
   utilized to create full word suggestions for predictive spelling. When
   combining predictive spelling with language-model classification, typing
   speed is significantly improved, resulting in better typing performance.}},
Publisher = {{TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Pouratian, N (Corresponding Author), Univ Calif Los Angeles, Dept Neurosurg, Los Angeles, CA 90095 USA.
   Pouratian, N (Corresponding Author), Univ Calif Los Angeles, Neurosci Interdept Program, Los Angeles, CA 90095 USA.
   Pouratian, N (Corresponding Author), Univ Calif Los Angeles, Dept Bioengn, Los Angeles, CA 90095 USA.
   Pouratian, N (Corresponding Author), Univ Calif Los Angeles, Brain Res Inst, Los Angeles, CA 90024 USA.
   Speier, William; Roberts, Dustin; Pouratian, Nader, Univ Calif Los Angeles, Dept Neurosurg, Los Angeles, CA 90095 USA.
   Speier, William; Arnold, Corey, Univ Calif Los Angeles, Med Imaging Informat Grp, Los Angeles, CA 90095 USA.
   Chandravadia, Nand; Pendekanti, Shrita; Pouratian, Nader, Univ Calif Los Angeles, Neurosci Interdept Program, Los Angeles, CA 90095 USA.
   Pouratian, Nader, Univ Calif Los Angeles, Dept Bioengn, Los Angeles, CA 90095 USA.
   Pouratian, Nader, Univ Calif Los Angeles, Brain Res Inst, Los Angeles, CA 90024 USA.}},
DOI = {{10.1080/2326263X.2017.1410418}},
ISSN = {{2326-263X}},
EISSN = {{2326-2621}},
Keywords = {{P300 speller; electroencephalography; language models; predictive
   spelling}},
Keywords-Plus = {{BRAIN-COMPUTER INTERFACE; BCI COMPETITION 2003; DATA SET IIB;
   INFORMATION}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{NPouratian@mednet.ucla.edu}},
ORCID-Numbers = {{Pouratian, Nader/0000-0002-0426-3241
   Pendekanti, Shrita/0000-0001-7995-4541}},
Funding-Acknowledgement = {{National Institute of Biomedical Imaging and BioengineeringUnited States
   Department of Health \& Human ServicesNational Institutes of Health
   (NIH) - USANIH National Institute of Biomedical Imaging \&
   Bioengineering (NIBIB) {[}K23EB014326]; National Institutes of
   HealthUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USA {[}K23EB014326]; NATIONAL INSTITUTE OF
   BIOMEDICAL IMAGING AND BIOENGINEERINGUnited States Department of Health
   \& Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Biomedical Imaging \& Bioengineering (NIBIB)
   {[}K23EB014326, K23EB014326, K23EB014326, K23EB014326, K23EB014326]
   Funding Source: NIH RePORTER}},
Funding-Text = {{This work was supported by the National Institute of Biomedical Imaging
   and Bioengineering {[}grant number K23EB014326]; National Institutes of
   Health {[}grant number K23EB014326].}},
Cited-References = {{DARRAGH JJ, 1990, COMPUTER, V23, P41, DOI 10.1109/2.60879.
   Draper N. R., 1981, APPL REGRESSION ANAL.
   Dunlop M. D., 2000, Personal Technologies, V4, P134, DOI 10.1007/BF01324120.
   FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6.
   Francis W. N., 1979, BROWN CORPUS MANUAL.
   Jelinek F., 1998, STAT METHODS SPEECH.
   Jin J, 2011, MED BIOL ENG COMPUT, V49, P181, DOI 10.1007/s11517-010-0689-8.
   Jin J, 2010, BIOMED TECH, V55, P203, DOI 10.1515/BMT.2010.029.
   Kaper M, 2004, IEEE T BIO-MED ENG, V51, P1073, DOI 10.1109/TBME.2004.826698.
   Kaufmann T, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/5/056016.
   Kaufmann T, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00072.
   Kindermans P-J, 2012, P ADV NEURAL INFO PR, P710.
   Kindermans PJ, 2013, IEEE T BIO-MED ENG, V60, P2696, DOI 10.1109/TBME.2013.2262524.
   Krusienski DJ, 2006, J NEURAL ENG, V3, P299, DOI 10.1088/1741-2560/3/4/007.
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323.
   Lu J, 2013, CLIN NEUROPHYSIOL, V124, P306, DOI 10.1016/j.clinph.2012.08.002.
   McFarland DJ, 2011, CLIN NEUROPHYSIOL, V122, P731, DOI 10.1016/j.clinph.2010.10.029.
   McFarland DJ, 2003, BIOL PSYCHOL, V63, P237, DOI 10.1016/S0301-0511(03)00073-5.
   Oken BS, 2014, NEUROREHAB NEURAL RE, V28, P387, DOI 10.1177/1545968313516867.
   Orhan U, 2012, INT CONF ACOUST SPEE, P645, DOI 10.1109/ICASSP.2012.6287966.
   Park J, 2012, IEEE T NEUR SYS REH, V20, P584, DOI 10.1109/TNSRE.2012.2191979.
   Ryan DB, 2011, INT J HUM-COMPUT INT, V27, P69, DOI 10.1080/10447318.2011.535754.
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072.
   Sellers EW, 2006, BIOL PSYCHOL, V73, P242, DOI 10.1016/j.biopsycho.2006.04.007.
   Serby H, 2005, IEEE T NEUR SYS REH, V13, P89, DOI 10.1109/TNSRE.2004.841878.
   Speier W, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/4/046018.
   Speier W, 2016, INTERFACES, V4, P114.
   Speier W, 2014, IEEE T NEUR SYS REH, V22, P678, DOI 10.1109/TNSRE.2014.2300091.
   Speier W, 2013, I IEEE EMBS C NEUR E, P707, DOI 10.1109/NER.2013.6696032.
   Speier W, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078432.
   Speier W, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/1/016004.
   Townsend G, 2010, CLIN NEUROPHYSIOL, V121, P1109, DOI 10.1016/j.clinph.2010.01.030.
   Xu N, 2004, IEEE T BIO-MED ENG, V51, P1067, DOI 10.1109/TBME.2004.826699.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Brain Comput. Interfaces}},
Doc-Delivery-Number = {{GN4UG}},
Unique-ID = {{ISI:000439030800002}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000450799000121,
Author = {Thye, Melissa and Mirman, Daniel},
Title = {{Relative contributions of lesion location and lesion size to predictions
   of varied language deficits in post-stroke aphasia}},
Journal = {{NEUROIMAGE-CLINICAL}},
Year = {{2018}},
Volume = {{20}},
Pages = {{1129-1138}},
Abstract = {{Despite the widespread use of lesion-symptom mapping (LSM) techniques to
   study associations between location of brain damage and language
   deficits, the prediction of language deficits from lesion location
   remains a substantial challenge. The present study examined several
   factors which may impact lesion-symptom prediction by (1) testing the
   relative predictive advantage of general language deficit scores
   compared to composite scores that capture specific deficit types, (2)
   isolating the relative contribution of lesion location compared to
   lesion size, and (3) comparing standard voxel-based lesion-symptom
   mapping (VLSM) with a multivariate method (sparse canonical correlation
   analysis, SCCAN). Analyses were conducted on data from 128 participants
   who completed a detailed battery of psycholinguistic tests and underwent
   structural neuroimaging (MRI or CT) to determine lesion location. For
   both VLSM and SCCAN, overall aphasia severity (Western Aphasia Battery
   Aphasia Quotient) and object naming deficits were primarily predicted by
   lesion size, whereas deficits in Speech Production and Speech
   Recognition were better predicted by a combination of lesion size and
   location. The implementation of both VLSM and SCCAN raises important
   considerations regarding controlling for lesion size in lesion-symptom
   mapping analyses. These findings suggest that lesion-symptom prediction
   is more accurate for deficits within neurally-localized cognitive
   systems when both lesion size and location are considered compared to
   broad functional deficits, which can be predicted by overall lesion size
   alone.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Mirman, D (Corresponding Author), Univ Alabama Birmingham, Dept Psychol, CH 415,1300 Univ Blvd, Birmingham, AL 35294 USA.
   Thye, Melissa; Mirman, Daniel, Univ Alabama Birmingham, Dept Psychol, CH 415,1300 Univ Blvd, Birmingham, AL 35294 USA.
   Mirman, Daniel, Moss Rehabil Res Inst, Elkins Pk, PA USA.}},
DOI = {{10.1016/j.nicl.2018.10.017}},
ISSN = {{2213-1582}},
Keywords = {{Aphasia; Lesion-symptom prediction; Sparse canonical correlation
   analysis; Lesion size}},
Keywords-Plus = {{ANTERIOR TEMPORAL INVOLVEMENT; NEUROANATOMICAL DISSOCIATION; WORD
   RETRIEVAL; NEURAL BASIS; STROKE; RECOVERY; PROGNOSIS; SEVERITY; SUPPORT;
   IMPACT}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neuroimaging}},
Author-Email = {{dan@danmirman.org}},
ResearcherID-Numbers = {{Mirman, Daniel/ABA-6318-2020
   }},
ORCID-Numbers = {{Mirman, Daniel/0000-0001-5472-0220
   Thye, Melissa/0000-0002-6383-6361}},
Funding-Acknowledgement = {{University of Alabama at Birmingham; NIHUnited States Department of
   Health \& Human ServicesNational Institutes of Health (NIH) - USA
   {[}R01DC000191]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness \&
   Other Communication Disorders (NIDCD) {[}R01DC000191, R01DC000191,
   R01DC000191, R01DC000191, R01DC000191, R01DC000191, R01DC000191,
   R01DC000191, R01DC000191, R01DC000191, R01DC000191, R01DC000191,
   R01DC000191, R01DC000191, R01DC000191, R01DC000191, R01DC000191,
   R01DC000191, R01DC000191, R01DC000191, R01DC000191, R01DC000191,
   R01DC000191, R01DC000191, R01DC000191, R01DC000191, R01DC000191,
   R01DC000191, R01DC000191, R01DC000191, R01DC000191, R01DC000191,
   R01DC000191] Funding Source: NIH RePORTER}},
Funding-Text = {{This project was supported by the University of Alabama at Birmingham.
   The data analyzed here came from a project that was funded by a grant
   from the NIH (R01DC000191) to Myrna F. Schwartz. We thank Dr. Schwartz,
   Dr. Erica Middleton, and the Moss Rehabilitation Research Institute
   aphasia research group for providing the data for these analyses.}},
Cited-References = {{Avants BB, 2014, NEUROIMAGE, V84, P698, DOI 10.1016/j.neuroimage.2013.09.048.
   Avants BB, 2006, MED IMAGE ANAL, V10, P397, DOI 10.1016/j.media.2005.03.005.
   Bates E, 2003, NAT NEUROSCI, V6, P448, DOI 10.1038/nn1050.
   Binder JR, 2011, TRENDS COGN SCI, V15, P527, DOI 10.1016/j.tics.2011.10.001.
   Boehme AK, 2016, NEUROLOGY, V87, P2348, DOI 10.1212/WNL.0000000000003297.
   DeMarco AT, 2018, HUM BRAIN MAPP, V39, P4169, DOI 10.1002/hbm.24289.
   Flowers HL, 2016, ARCH PHYS MED REHAB, V97, P2188, DOI 10.1016/j.apmr.2016.03.006.
   Fridriksson J, 2016, P NATL ACAD SCI USA, V113, P15108, DOI 10.1073/pnas.1614038114.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Hilari K, 2011, DISABIL REHABIL, V33, P211, DOI 10.3109/09638288.2010.508829.
   Hope TMH, 2013, NEUROIMAGE-CLIN, V2, P424, DOI 10.1016/j.nicl.2013.03.005.
   Inoue K, 2014, NEUROIMAGE-CLIN, V6, P388, DOI 10.1016/j.nicl.2014.10.002.
   Lazar RM, 2008, J NEUROL NEUROSUR PS, V79, P530, DOI 10.1136/jnnp.2007.122457.
   Mah YH, 2014, BRAIN, V137, P2522, DOI 10.1093/brain/awu164.
   Mirman D., CURR DIR PSYCHOL SCI, DOI {[}10.1080/02643294.2011.574112, DOI 10.1080/02643294.2011.574112].
   Mirman D, 2018, NEUROPSYCHOLOGIA, V115, P112, DOI 10.1016/j.neuropsychologia.2017.08.025.
   Mirman D, 2015, NEUROPSYCHOLOGIA, V76, P208, DOI 10.1016/j.neuropsychologia.2015.02.014.
   Mirman D, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7762.
   Mirman D, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0388.
   Mirman D, 2013, J COGNITIVE NEUROSCI, V25, P1504, DOI 10.1162/jocn\_a\_00408.
   Mirman D, 2010, COGN NEUROPSYCHOL, V27, P495, DOI 10.1080/02643294.2011.574112.
   Pedersen PM, 2004, CEREBROVASC DIS, V17, P35, DOI 10.1159/000073896.
   Plowman E, 2012, J EVAL CLIN PRACT, V18, P689, DOI 10.1111/j.1365-2753.2011.01650.x.
   Price CJ, 2010, NAT REV NEUROL, V6, P202, DOI 10.1038/nrneurol.2010.15.
   Pustina D, 2018, NEUROPSYCHOLOGIA, V115, P154, DOI 10.1016/j.neuropsychologia.2017.08.027.
   Pustina D, 2017, HUM BRAIN MAPP, V38, P5603, DOI 10.1002/hbm.23752.
   Ralph MAL, 2017, NAT REV NEUROSCI, V18, P42, DOI 10.1038/nrn.2016.150.
   Schwartz MF, 2012, BRAIN, V135, P3799, DOI 10.1093/brain/aws300.
   Schwartz MF, 2011, P NATL ACAD SCI USA, V108, P8520, DOI 10.1073/pnas.1014935108.
   Schwartz MF, 2009, BRAIN, V132, P3411, DOI 10.1093/brain/awp284.
   Sperber C, 2017, HUM BRAIN MAPP, V38, P1692, DOI 10.1002/hbm.23490.
   Thothathiri M, 2012, J COGNITIVE NEUROSCI, V24, P212, DOI 10.1162/jocn\_a\_00118.
   Walker GM, 2011, BRAIN LANG, V117, P110, DOI 10.1016/j.bandl.2010.09.008.
   Xu TB, 2018, NEUROPSYCHOLOGIA, V115, P134, DOI 10.1016/j.neuropsychologia.2017.09.007.
   Yourganov G, 2015, CORTEX, V73, P203, DOI 10.1016/j.cortex.2015.09.005.
   Zhang YS, 2014, HUM BRAIN MAPP, V35, P5861, DOI 10.1002/hbm.22590.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{NeuroImage-Clin.}},
Doc-Delivery-Number = {{HB1QI}},
Unique-ID = {{ISI:000450799000121}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000450093300095,
Author = {Park, Sunchan and Jeong, Yongwon and Kim, Min Sik and Kim, Hyung Soon},
Book-Group-Author = {{IEEE}},
Title = {{Linear Prediction-based Dereverberation with Very Deep Convolutional
   Neural Networks for Reverberant Speech Recognition}},
Booktitle = {{2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND
   COMMUNICATION (ICEIC)}},
Series = {{IEEE International Conference on Electronics Information and Emergency
   Communication}},
Year = {{2018}},
Pages = {{310-311}},
Note = {{17th Annual International Conference on Electronics, Information, and
   Communication (ICEIC), Honolulu, HI, JAN 24-27, 2018}},
Organization = {{IEEE; Inst Elect \& Informat Engineers; Consumer Elect Soc}},
Abstract = {{Convolutional neural networks (CNNs) have been shown to improve
   classification tasks such as automatic speech recognition (ASR).
   Furthermore, the CNN with very deep architecture lowered the word error
   rate (WER) in reverberant and noisy environments. However, DNN-based ASR
   systems still perform poorly in unseen reverberant conditions. In this
   paper, we use the weighted prediction error (WPE)-based preprocessing
   for dereverberation. In our experiments on the ASR task of the REVERB
   Challenge 2014, the WPE-based processing with eight channels reduced the
   WER by 20\% for the real-condition data using CNN acoustic models with
   10 layers.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Park, S (Corresponding Author), Pusan Natl Univ, Dept Elect Engn, Busan, South Korea.
   Park, Sunchan; Jeong, Yongwon; Kim, Min Sik; Kim, Hyung Soon, Pusan Natl Univ, Dept Elect Engn, Busan, South Korea.}},
ISSN = {{2377-8431}},
ISBN = {{978-1-5386-4754-7}},
Keywords = {{convolutional neural network; dereverberation; reverberant speech
   recognition; weighted prediction error}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{sunchanpark@pusan.ac.kr
   jeongy@pusan.ac.kr
   fire9945@pusan.ac.kr
   kimhs@pusan.ac.kr}},
ResearcherID-Numbers = {{Kim, Hyung Soon/AAH-5292-2020}},
Funding-Acknowledgement = {{Ministry of Trade, Industry \& Energy (MOTIE, Korea) {[}10063424]}},
Funding-Text = {{This material is based upon work supported by the Ministry of Trade,
   Industry \& Energy (MOTIE, Korea) under Industrial Technology Innovation
   Program (No. 10063424, Development of distant speech recognition and
   multi-task dialog processing technologies for in-door conversational
   robots).}},
Cited-References = {{Delcroix M., 2014, P 2014 REVERB WORKSH.
   Kinoshita K, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0306-6.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884.}},
Number-of-Cited-References = {{4}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL3XN}},
Unique-ID = {{ISI:000450093300095}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000446384600019,
Author = {Korzeniowski, Filip and Sears, David R. W. and Widmer, Gerhard},
Book-Group-Author = {{IEEE}},
Title = {{A LARGE-SCALE STUDY OF LANGUAGE MODELS FOR CHORD PREDICTION}},
Booktitle = {{2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Year = {{2018}},
Pages = {{91-95}},
Note = {{IEEE International Conference on Acoustics, Speech and Signal Processing
   (ICASSP), Calgary, CANADA, APR 15-20, 2018}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{We conduct a large-scale study of language models for chord prediction.
   Specifically, we compare N-gram models to various flavours of recurrent
   neural networks on a comprehensive dataset comprising all publicly
   available datasets of annotated chords known to us. This large amount of
   data allows us to systematically explore hyper-parameter settings for
   the recurrent neural networks-a crucial step in achieving good results
   with this model class. Our results show not only a quantitative
   difference between the models, but also a qualitative one: in contrast
   to static N-gram models, certain RNN configurations adapt to the songs
   at test time. This finding constitutes a further step towards the
   development of chord recognition systems that are more aware of local
   musical context than what was previously possible.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Korzeniowski, F (Corresponding Author), Johannes Kepler Univ Linz, Dept Computat Percept, Linz, Austria.
   Korzeniowski, Filip; Widmer, Gerhard, Johannes Kepler Univ Linz, Dept Computat Percept, Linz, Austria.
   Sears, David R. W., Texas Tech Univ, Coll Visual \& Performing Arts, Lubbock, TX 79409 USA.}},
ISBN = {{978-1-5386-4658-8}},
Keywords = {{Language Modelling; Chord Prediction; Recurrent Neural Networks}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
ResearcherID-Numbers = {{Sears, David/ABB-4661-2020
   Widmer, Gerhard/B-8218-2017}},
ORCID-Numbers = {{Widmer, Gerhard/0000-0003-3531-1282}},
Funding-Acknowledgement = {{European Research Council (ERC) under the EU (ERC) {[}670035]}},
Funding-Text = {{This work is supported by the European Research Council (ERC) under the
   EU's Horizon 2020 Framework Programme (ERC Grant Agreement number
   670035, project ``Con Espressione{''}).}},
Cited-References = {{Boulanger-Lewandowski Nicolas, 2013, P 14 INT SOC MUS INF.
   BURGOYNE J., 2011, P 12 INT SOC MUS INF.
   Chen Ruofeng, 2012, P 13 INT SOC MUS INF.
   Cho Kyunghyun, 2014, ARXIV14091259.
   Cho T, 2014, IEEE-ACM T AUDIO SPE, V22, P477, DOI 10.1109/TASLP.2013.2295926.
   De Clercq T, 2011, POP MUSIC, V30, P47, DOI 10.1017/S026114301000067X.
   Deng Junqi, 2016, INT C AC SPEECH SIGN.
   Di Giorgi B., 2013, P 8 INT WORKSH MULT.
   ELLIS DPW, 2003, USPOP2002 POP MUSIC.
   Goto Masataka, 2002, P 3 INT C MUS INF RE.
   Harte C., 2010, THESIS.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Humphrey E. J., 2012, 11 INT C MACH LEARN.
   Humphrey Eric J., 2015, P 16 INT SOC MUS INF.
   Kingma Diederik P, 2014, ARXIV14126980.
   Korzeniowski F., 2016, P 17 INT SOC MUS INF.
   Korzeniowski F., 2017, P AES INT C SEM AUD.
   Li L., 2016, ARXIV160306560.
   Mauch Matthias, 2010, P 11 INT SOC MUS INF.
   Mauch Matthias, 2009, 10 INT C MUS INF RET.
   Mikolov T., 2010, INTERSPEECH.
   Mikolov Tomas, 2013, ARXIV13013781.
   Pascanu R., 2014, P 2 INT C LEARN REPR.
   Pauwels J, 2014, J NEW MUSIC RES, V43, P318, DOI 10.1080/09298215.2014.917684.
   The Jazzomat Research Project, 2016, WEIM JAZZ DAT WJAZZD.
   Ueda Yushi, 2010, INT C AC SPEECH SIGN.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL0QY}},
Unique-ID = {{ISI:000446384600019}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000446384605113,
Author = {Lotfidereshgi, Reza and Gournay, Philippe},
Book-Group-Author = {{IEEE}},
Title = {{SPEECH PREDICTION USING AN ADAPTIVE RECURRENT NEURAL NETWORK WITH
   APPLICATION TO PACKET LOSS CONCEALMENT}},
Booktitle = {{2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Year = {{2018}},
Pages = {{5394-5398}},
Note = {{IEEE International Conference on Acoustics, Speech and Signal Processing
   (ICASSP), Calgary, CANADA, APR 15-20, 2018}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{This paper proposes a novel approach for speech signal prediction based
   on a recurrent neural network (RNN). Unlike existing RNN-based
   predictors, which operate on parametric features and are trained offline
   on a large collection of such features, the proposed predictor operates
   directly on speech samples and is trained online on the recent past of
   the speech signal. Optionally, the network can be pre-trained offline to
   speed-up convergence at start-up. The proposed predictor is a single
   end-to-end network that captures all sorts of dependencies between
   samples, and therefore has the potential to outperform classical
   linear/non-linear and short-term/long-term speech predictor structures.
   We apply it to the packet loss concealment (PLC) problem and show that
   it outperforms the standard ITU G.711 Appendix I PLC technique.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Lotfidereshgi, R (Corresponding Author), Univ Sherbrooke, Speech \& Audio Res Grp, Sherbrooke, PQ J1K 2R1, Canada.
   Lotfidereshgi, Reza; Gournay, Philippe, Univ Sherbrooke, Speech \& Audio Res Grp, Sherbrooke, PQ J1K 2R1, Canada.}},
ISBN = {{978-1-5386-4658-8}},
Keywords = {{Speech prediction; recurrent neural network; long short-term memory;
   packet loss concealment}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Cited-References = {{Cho Kyunghyun, 2014, ARXIV14061078.
   Clark John, 2008, INTRO PHONETICS PHON.
   Garofolo J.S., 1993, NASA STI RECON TECHN, V93.
   Gers F.A., 1999, LEARNING FORGET CONT.
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302.
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042.
   Graves A., 2014, P 31 INT C MACH LEAR, P1764, DOI DOI 10.1145/1143844.1143891.
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947.
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924.
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   ITU-T Recommendation G. 711 Appendix I, 1999, HIGH QUAL LOW COMPL.
   Kingma Diederik P, 2014, ARXIV14126980.
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539.
   Lee BK, 2016, IEEE-ACM T AUDIO SPE, V24, P378, DOI 10.1109/TASLP.2015.2509780.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Perkins C, 1998, IEEE NETWORK, V12, P40, DOI 10.1109/65.730750.
   Rodbro CA, 2006, IEEE T AUDIO SPEECH, V14, P1609, DOI 10.1109/TSA.2005.858561.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL0QY}},
Unique-ID = {{ISI:000446384605113}},
DA = {{2020-12-06}},
}

@article{ ISI:000441936300001,
Author = {Halai, Ajay D. and Woollams, Anna M. and Ralph, Matthew A. Lambon},
Title = {{Predicting the pattern and severity of chronic post-stroke language
   deficits from functionally-partitioned structural lesions}},
Journal = {{NEUROIMAGE-CLINICAL}},
Year = {{2018}},
Volume = {{19}},
Pages = {{1-13}},
Abstract = {{There is an ever-increasing wealth of knowledge arising from basic
   cognitive and clinical neuroscience on how speech and language
   capabilities are organised in the brain. It is, therefore, timely to use
   this accumulated knowledge and expertise to address critical research
   challenges, including the ability to predict the pattern and level of
   language deficits found in aphasic patients (a third of all stroke
   cases). Previous studies have mainly focused on discriminating between
   broad aphasia dichotomies from purely anatomically-defined lesion
   information. In the current study, we developed and assessed a novel
   approach in which core language areas were mapped using principal
   component analysis in combination with correlational lesion mapping and
   the resultant `functionally-partitioned(lesion maps were used to predict
   a battery of 21 individual test scores as well as aphasia subtype for 70
   patients with chronic post-stroke aphasia. Specifically, we used lesion
   information to predict behavioural scores in regression models
   (cross-validated using 5-folds). The winning model was identified
   through the adjusted R-2 (model fit to data) and performance in
   predicting holdout folds (generalisation to new cases). We also used
   logistic regression to predict fluent/non-fluent status and aphasia
   subtype. Functionally-partitioned models generally outperformed other
   models at predicting individual tests, fluency status and aphasia
   subtype.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Halai, AD; Ralph, MAL (Corresponding Author), Univ Manchester, Fac Biol Med \& Hlth, Div Neurosci \& Expt Psychol, Neurosci \& Aphasia Res Unit, 3-19 Zochonis Bldg,Brunswick St, Manchester M13 9PL, Lancs, England.
   Halai, Ajay D.; Woollams, Anna M.; Ralph, Matthew A. Lambon, Univ Manchester, Fac Biol Med \& Hlth, Div Neurosci \& Expt Psychol, Neurosci \& Aphasia Res Unit, 3-19 Zochonis Bldg,Brunswick St, Manchester M13 9PL, Lancs, England.}},
DOI = {{10.1016/j.nicl.2018.03.011}},
ISSN = {{2213-1582}},
Keywords = {{Aphasia; Prediction; Principal component analysis; Regression; Stroke}},
Keywords-Plus = {{READING ALOUD; NEUROCOMPUTATIONAL MODEL; INDIVIDUAL-DIFFERENCES; UNIFIED
   SEGMENTATION; SEMANTIC DEMENTIA; ISCHEMIC-STROKE; RECOVERY; APHASIA;
   BRAIN; VARIABILITY}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neuroimaging}},
Author-Email = {{ajay.halai@manchester.ac.uk
   matt.lambon-ralph@manchester.ac.uk}},
ORCID-Numbers = {{Halai, Ajay/0000-0003-1725-7948}},
Funding-Acknowledgement = {{Rosetrees TrustRosetrees Trust {[}A1699]; MRCMedical Research Council UK
   (MRC) {[}MR/J004146/1]; ERCEuropean Research Council (ERC) {[}GAP:
   670428 - BRAIN2MIND\_NEUROCOMP]; Medical Research CouncilMedical
   Research Council UK (MRC) {[}MR/J004146/1] Funding Source: researchfish;
   Rosetrees TrustRosetrees Trust {[}M354-F1, M354] Funding Source:
   researchfish}},
Funding-Text = {{We are especially grateful to all the patients, families, carers and
   community support groups for their continued, enthusiastic support of
   our research programme. This research was supported by grants from The
   Rosetrees Trust (A1699), the MRC (MR/J004146/1) and ERC (GAP: 670428 -
   BRAIN2MIND\_NEUROCOMP).}},
Cited-References = {{Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018.
   Bates E, 2003, NAT NEUROSCI, V6, P448, DOI 10.1038/nn1050.
   Bozeat S, 2000, NEUROPSYCHOLOGIA, V38, P1207, DOI 10.1016/S0028-3932(00)00034-8.
   Brownsett SLE, 2014, BRAIN, V137, P242, DOI 10.1093/brain/awt289.
   Burgess P. W., 1997, HAYLING BRIXTON TEST.
   Butler RA, 2014, BRAIN, V137, P3248, DOI 10.1093/brain/awu286.
   Calhoun Vince D, 2016, Biol Psychiatry Cogn Neurosci Neuroimaging, V1, P230.
   Catani M, 2005, BRAIN, V128, P2224, DOI 10.1093/brain/awh622.
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319.
   Chase Alex, 2014, Nat Rev Neurol, V10, P674, DOI 10.1038/nrneurol.2014.217.
   Corbetta M, 2015, NEURON, V85, P927, DOI 10.1016/j.neuron.2015.02.027.
   Fillingham JK, 2005, INT J LANG COMM DIS, V40, P505, DOI 10.1080/13682820500138572.
   Griffis JC, 2017, NEUROIMAGE-CLIN, V14, P552, DOI 10.1016/j.nicl.2017.02.019.
   Halai AD, 2017, CORTEX, V86, P275, DOI 10.1016/j.cortex.2016.04.016.
   Hand PJ, 2006, NEUROLOGY, V66, P1159, DOI 10.1212/01.wnl.0000202524.43850.81.
   Hoffman P, 2015, P NATL ACAD SCI USA, V112, pE3719, DOI 10.1073/pnas.1502032112.
   Hope TMH, 2015, BRAIN, V138, P1070, DOI 10.1093/brain/awv020.
   Hope TMH, 2013, NEUROIMAGE-CLIN, V2, P424, DOI 10.1016/j.nicl.2013.03.005.
   Horn SD, 2005, ARCH PHYS MED REHAB, V86, pS101, DOI 10.1016/j.apmr.2005.09.016.
   Jefferies E, 2009, NEUROPSYCHOLOGY, V23, P492, DOI 10.1037/a0015452.
   Johnston KC, 2007, STROKE, V38, P1820, DOI 10.1161/STROKEAHA.106.479154.
   Johnston KC, 2002, STROKE, V33, P466, DOI 10.1161/hs0202.102881.
   Kaplan E., 1983, BOSTON NAMING TEST.
   Karnath HO, 2017, BRAIN STRUCT FUNCT, V222, P2059, DOI 10.1007/s00429-016-1325-7.
   Kay J., 1992, PSYCHOLINGUISTIC ASS.
   Keidel JL, 2010, NEUROPSYCHOLOGIA, V48, P1716, DOI 10.1016/j.neuropsychologia.2010.02.019.
   Kherif F, 2009, J COGNITIVE NEUROSCI, V21, P654, DOI 10.1162/jocn.2009.21084.
   Kummerer D., 2013, DAMAGE VENTRAL DORSA, V136.
   Lacey EH, 2017, NEUROREHAB NEURAL RE, V31, P442, DOI 10.1177/1545968316688797.
   Lazar RM, 2008, J NEUROL NEUROSUR PS, V79, P530, DOI 10.1136/jnnp.2007.122457.
   Mirman D., 2015, NEUROPSYCHOLOGIA, DOI {[}10.1016./j.ncuropsychologia.2015.02.014, DOI 10.1016/J.NCUROPSYCHOLOGIA.2015.02.014].
   Mirman D, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7762.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Patterson K, 1999, CURR OPIN NEUROBIOL, V9, P235, DOI 10.1016/S0959-4388(99)80033-6.
   Phan TG, 2005, STROKE, V36, P986, DOI 10.1161/01.STR.0000163087.66828.e9.
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062.
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x.
   Price CJ, 2002, TRENDS COGN SCI, V6, P416, DOI 10.1016/S1364-6613(02)01976-9.
   Ralph MAL, 2003, BRAIN, V126, P2350, DOI 10.1093/brain/awg236.
   Ralph MAL, 2002, APHASIOLOGY, V16, P56, DOI 10.1080/02687040143000448.
   Raven IC., 1962, ADV PROGR MATRICES.
   Saur D, 2010, BRAIN, V133, P1252, DOI 10.1093/brain/awq021.
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105.
   Schiemanck SK, 2006, NEUROREHAB NEURAL RE, V20, P492, DOI 10.1177/1545968306289298.
   Schwartz M. P., 2009, ANTERIOR TEMPORAL IN, V132.
   Schwartz MF, 2012, BRAIN, V135, P3799, DOI 10.1093/brain/aws300.
   Seghier ML, 2008, NEUROIMAGE, V42, P1226, DOI 10.1016/j.neuroimage.2008.05.029.
   Seghier ML, 2008, NEUROIMAGE, V41, P1253, DOI 10.1016/j.neuroimage.2008.03.028.
   SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523.
   Swinburn K., 2005, COMPREHENSIVE APHASI.
   Thijs VN, 2000, STROKE, V31, P2597, DOI 10.1161/01.STR.31.11.2597.
   Ueno T, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00422.
   Ueno T, 2011, NEURON, V72, P385, DOI 10.1016/j.neuron.2011.09.013.
   Wechsler DA, 1987, WECHSLER MEMORY SCAL.
   Welbourne SR, 2007, J COGNITIVE NEUROSCI, V19, P1125, DOI 10.1162/jocn.2007.19.7.1125.
   Welbourne SR, 2011, COGN NEUROPSYCHOL, V28, P65, DOI 10.1080/02643294.2011.621937.
   Wilke M, 2011, NEUROIMAGE, V56, P2038, DOI 10.1016/j.neuroimage.2011.04.014.
   WILLMES K, 1993, BRAIN, V116, P1527, DOI 10.1093/brain/116.6.1527.
   Woollams AM, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01757.
   Yourganov G, 2015, CORTEX, V73, P203, DOI 10.1016/j.cortex.2015.09.005.}},
Number-of-Cited-References = {{60}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{NeuroImage-Clin.}},
Doc-Delivery-Number = {{GQ7PL}},
Unique-ID = {{ISI:000441936300001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000433225200023,
Author = {Kurada, Ramachandra Rao and Kanadam, Karteeka Pavan},
Title = {{An Epitomized Approach to Possess Promising Predictions by using
   Time-Series Analysis and Forecasting in R language}},
Journal = {{HELIX}},
Year = {{2018}},
Volume = {{8}},
Number = {{3}},
Pages = {{3467-3477}},
Abstract = {{The aim of this work is to exertion a plug-in, formerly named as Time
   Series Analysis and Forecasting (TSAF) and incorporates this plug-in
   into R language. The intent behind materializing this plug-in is to
   establish a first-rated approach to forecast in-advance extrapolations
   in time series data and to make accurate decisions methodically. The
   plug-in provides a computationally intelligent environment by accepting
   a preprocessed time series datasets as input and sense the direction of
   outputs that will transpire over the coming ages. The internal code
   structure and implementation details in between the input and output
   precincts are factorized with the general machine learning, statistical
   calculation, and visualization packages. The preeminence of this
   incarnated viewpoint is scientifically verified over time-series
   datasets archived in UCI repositories. The results enabled from these
   datasets pertain to revive qualitative nature of forecasting, which
   helps the users to predict or foresee changing domain trends and thereby
   make strategic decisions and hopefully gain lifelong encroachments in
   this process.}},
Publisher = {{BIOAXIS DNA RESEARCH CENTRE PRIVATE LIMITED}},
Address = {{13-51, SRI LAKSHMI NAGAR COLONY, BESIDES BLG BAZAR, NEAR KAMINENI
   HOSPITALS, GSI POST BANDAGUDA, HYDERBAD, 500068, INDIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kurada, RR (Corresponding Author), Shri Vishnu Engn Coll Women, Dept CSE, Bhimavaram, Andhra Prades, India.
   Kurada, Ramachandra Rao, Shri Vishnu Engn Coll Women, Dept CSE, Bhimavaram, Andhra Prades, India.
   Kanadam, Karteeka Pavan, RVR \& JC Coll Engn, Dept Comp Applicat, Guntur, Andhra Prades, India.}},
DOI = {{10.29042/2018-3467-3477}},
ISSN = {{2277-3495}},
EISSN = {{2319-5592}},
Keywords = {{Time series analysis; Forecasting's; Predictions; Machine Learning;
   Statistical study; Computational Intelligence}},
Keywords-Plus = {{ACCURACY}},
Research-Areas = {{Biotechnology \& Applied Microbiology}},
Web-of-Science-Categories  = {{Biotechnology \& Applied Microbiology}},
Author-Email = {{ramachandrarao.kurada@gmail.com
   karteeka@yahoo.com}},
ResearcherID-Numbers = {{Kurada, Ramachandra Rao/AAR-2769-2020
   Kanadam, Karteeka Pavan/AAQ-5501-2020}},
ORCID-Numbers = {{Kurada, Ramachandra Rao/0000-0002-7014-8313
   }},
Cited-References = {{{[}Anonymous], TIM SER FOR SYST.
   Booth, 2006, SAN FRANCISCO ESTUAR, V4.
   Box G. E. P., 1994, TIME SERIES ANAL FOR.
   Box G.E.P., 1970, J AM STAT ASSOC, V65, P1509, DOI {[}10.1080/01621459.1970.10481180, DOI 10.1080/01621459.1970.10481180].
   Box G. E. P., 2008, TIME SERIES ANAL FOR.
   Brockwell Peter J., 2016, INTRO TIME SERIES FO.
   Brown Robert G., 1956, EXPONENTIAL SMOOTHIN, P15.
   Chatfield C, 2016, ANAL TIME SERIES INT.
   CLEMENT EP, 2014, AM J MATH STAT, V4, P214, DOI DOI 10.5923/J.AJMS.20140405.02.
   Coghlan A, 2017, LITTLE BOOK R TIME S.
   De Gooijer JG, 2006, INT J FORECASTING, V22, P443, DOI 10.1016/j.ijforecast.2006.01.001.
   De Livera AM, 2011, J AM STAT ASSOC, V106, P1513, DOI 10.1198/jasa.2011.tm09771.
   Fanaee-T H, 2014, PROG ARTIF INTELL, V2, P113, DOI 10.1007/s13748-013-0040-3.
   GARDNER ES, 1985, J FORECASTING, V4, P1, DOI 10.1002/for.3980040103.
   Goodwin P, 2010, FORESIGHT INT J APPL, V19, P30.
   Holt C. C., 1960, PLANNING PRODUCTION.
   Holt Charles C., 1957, PITTSBURGH OFFICE NA.
   Hyndman R.J., 2007, AUTOMATIC TIME SERIE.
   Hyndman R.J., FORECASTING PRINCIPL.
   Kalekar P. S., 2004, KANWAL REKHI SCH INF, V4329008, P1.
   Liang X, 2015, P ROY SOC A-MATH PHY, V471, DOI 10.1098/rspa.2015.0257.
   Lichman M., 2013, UCI MACHINE LEARNING.
   LJUNG GM, 1978, BIOMETRIKA, V65, P297, DOI 10.2307/2335207.
   MAKRIDAKIS S, 1979, J ROY STAT SOC A STA, V142, P97, DOI 10.2307/2345077.
   MAKRIDAKIS S, 1982, J FORECASTING, V1, P111, DOI 10.1002/for.3980010202.
   Makridakis S, 2008, FORECASTING METHODS.
   NIST/SEMATECH, NIST SEMATECH E HDB.
   Oppenheim A. V., 1975, DIGIT SIGNAL PROCESS, P5.
   Osarumwense Osabuohien-Irabor, 2014, OPEN SCI J STAT APPL, V2, P24.
   Zhang J., 2017, HDB MED STAT, V269.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Helix}},
Doc-Delivery-Number = {{GH2II}},
Unique-ID = {{ISI:000433225200023}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000433158600004,
Author = {Luke, Steven G. and Asplund, Anna},
Title = {{Prereaders' eye movements during shared storybook reading are
   language-mediated but not predictive}},
Journal = {{VISUAL COGNITION}},
Year = {{2018}},
Volume = {{26}},
Number = {{5}},
Pages = {{351-365}},
Abstract = {{When viewing a visual scene, eye movements are often language-mediated:
   people look at objects as those objects are named. Eye movements can
   even reflect predictive language processing, moving to an object before
   it is named. Children are also capable of making language-mediated eye
   movements, even predictive ones, and prediction may be involved in
   language learning. The present study explored whether eye movements are
   language-mediated in a more naturalistic task - shared storybook
   reading. Research has shown that children fixate illustrations during
   shared storybook reading, ignoring text. The present study used
   high-precision eye-tracking to replicate this finding. Further,
   prereader participants showed increased likelihood of fixating relevant
   storybook illustrations as words were read aloud, indicating that their
   eye movements were language mediated like the adult participants.
   Language-mediated eye movements to illustrations were reactive, not
   predictive, in both participant groups.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Luke, SG (Corresponding Author), Brigham Young Univ, Dept Psychol, 1062 SWKT, Provo, UT 84602 USA.
   Luke, Steven G.; Asplund, Anna, Brigham Young Univ, Dept Psychol, 1062 SWKT, Provo, UT 84602 USA.}},
DOI = {{10.1080/13506285.2018.1452323}},
ISSN = {{1350-6285}},
EISSN = {{1464-0716}},
Keywords = {{Eye movements; visual world paradigm; shared storybook reading;
   prediction; prereaders}},
Keywords-Plus = {{INDIVIDUAL-DIFFERENCES; VISUAL-ATTENTION; SPOKEN LANGUAGE;
   PRESCHOOL-CHILDREN; EXECUTIVE FUNCTION; LITERACY; PRINT; VOCABULARY;
   HOME; COMPREHENSION}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{steven\_luke@byu.edu}},
Cited-References = {{Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arnold JE, 2007, LANG COGNITIVE PROC, V22, P527, DOI 10.1080/01690960600845950.
   Ashby J, 2012, ATTEN PERCEPT PSYCHO, V74, P634, DOI 10.3758/s13414-012-0277-0.
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01.
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005.
   BUS AG, 1995, REV EDUC RES, V65, P1, DOI 10.3102/00346543065001001.
   Choi Y, 2010, J EXP CHILD PSYCHOL, V106, P41, DOI 10.1016/j.jecp.2010.01.003.
   Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X.
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2014, LANG LINGUIST COMPAS, V8, P631, DOI 10.1111/lnc3.12093.
   Evans MA, 2005, PSYCHOL SCI, V16, P913, DOI 10.1111/j.1467-9280.2005.01636.x.
   Evans MA, 2000, CAN J EXP PSYCHOL, V54, P65, DOI 10.1037/h0087330.
   Evans MA, 2008, SCI STUD READ, V12, P106, DOI 10.1080/10888430701773884.
   Evans MA, 2011, FIRST LANG, V31, P195, DOI 10.1177/0142723710393795.
   Evans MA, 2013, J EDUC PSYCHOL, V105, P596, DOI 10.1037/a0032465.
   Evans MA, 2009, CHILD DEV, V80, P1824, DOI 10.1111/j.1467-8624.2009.01370.x.
   Evans MA, 2008, CAN PSYCHOL, V49, P89, DOI 10.1037/0708-5591.49.2.89.
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044.
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98.
   Fletcher KL, 2005, DEV REV, V25, P64, DOI 10.1016/j.dr.2004.08.009.
   Fukushima J, 2000, BRAIN DEV-JPN, V22, P173, DOI 10.1016/S0387-7604(00)00101-7.
   Garon N, 2008, PSYCHOL BULL, V134, P31, DOI 10.1037/0033-2909.134.1.31.
   Hallett P. E., 1986, HDB PERCEPTION HUMAN, P101.
   Hargrave AC, 2000, EARLY CHILD RES Q, V15, P75, DOI 10.1016/S0885-2006(99)00038-1.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Johnson MA, 2013, BEHAV BRAIN SCI, V36, P360, DOI 10.1017/S0140525X12002609.
   Justice LM, 2008, DEV PSYCHOL, V44, P855, DOI 10.1037/0012-1649.44.3.855.
   Justice LM, 2009, LANG SPEECH HEAR SER, V40, P67, DOI 10.1044/0161-1461(2008/07-0098).
   Justice LM, 2005, J RES READ, V28, P229, DOI 10.1111/j.1467-9817.2005.00267.x.
   Kaefer T, 2017, INFANT CHILD DEV, V26, DOI 10.1002/icd.2018.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kuznetsova A, 2014, LMERTEST TESTS RANDO.
   Levy BA, 2006, J EXP CHILD PSYCHOL, V93, P63, DOI 10.1016/j.jecp.2005.07.003.
   Lonigan CJ, 1998, EARLY CHILD RES Q, V13, P263, DOI 10.1016/S0885-2006(99)80038-6.
   Luke SG, 2017, BEHAV RES METHODS, V49, P1494, DOI 10.3758/s13428-016-0809-y.
   Luke SG, 2016, COGNITIVE PSYCHOL, V88, P22, DOI 10.1016/j.cogpsych.2016.06.002.
   Luke SG, 2015, J EXP PSYCHOL LEARN, V41, P1675, DOI 10.1037/xlm0000133.
   Luna B, 2008, BRAIN COGNITION, V68, P293, DOI 10.1016/j.bandc.2008.08.019.
   Mani N, 2016, Q J EXP PSYCHOL, V69, P2189, DOI 10.1080/17470218.2015.1111395.
   Mani N, 2014, J EXP CHILD PSYCHOL, V126, P264, DOI 10.1016/j.jecp.2014.05.004.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Midgett C., 2007, FIRST LANG, V27, P175, DOI {[}10.1177/0142723706075784, DOI 10.1177/0142723706075784].
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006.
   Miryam, 2005, HAPP MAN HIS DUMP TR.
   Mol SE, 2011, PSYCHOL BULL, V137, P267, DOI 10.1037/a0021890.
   Mol SE, 2009, REV EDUC RES, V79, P979, DOI 10.3102/0034654309332561.
   Morgan PL, 2015, CHILD DEV, V86, P1351, DOI 10.1111/cdev.12398.
   Nadig AS, 2002, PSYCHOL SCI, V13, P329, DOI 10.1111/j.0956-7976.2002.00460.x.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Perfetti C, 2007, SCI STUD READ, V11, P357, DOI 10.1080/10888430701530730.
   Piasta SB, 2012, CHILD DEV, V83, P810, DOI 10.1111/j.1467-8624.2012.01754.x.
   R Core Team, 2015, R LANG ENV STAT COMP.
   Rabagliati H, 2016, LANG COGN NEUROSCI, V31, P94, DOI 10.1080/23273798.2015.1077979.
   Reese E, 1999, DEV PSYCHOL, V35, P20, DOI 10.1037/0012-1649.35.1.20.
   Roy-Charland A, 2007, READ WRIT, V20, P909, DOI 10.1007/s11145-007-9059-9.
   Roy-Charland A, 2016, READ WRIT, V29, P731, DOI 10.1007/s11145-016-9624-1.
   Salman MS, 2006, VISION RES, V46, P1432, DOI 10.1016/j.visres.2005.06.011.
   SCARBOROUGH HS, 1994, DEV REV, V14, P245, DOI 10.1006/drev.1994.1010.
   Sekerina IA, 2004, J CHILD LANG, V31, P123, DOI 10.1017/S0305000903005890.
   Sekerina IA, 2007, J EXP CHILD PSYCHOL, V98, P20, DOI 10.1016/j.jecp.2007.04.005.
   Senechal M, 2002, CHILD DEV, V73, P445, DOI 10.1111/1467-8624.00417.
   Senechal M, 1998, READ RES QUART, V33, P96, DOI 10.1598/RRQ.33.1.5.
   Senechal M, 2008, EARLY EDUC DEV, V19, P27, DOI 10.1080/10409280701838710.
   SHARE DL, 1995, COGNITION, V55, P151, DOI 10.1016/0010-0277(94)00645-2.
   Smith LB, 2002, PSYCHOL SCI, V13, P13, DOI 10.1111/1467-9280.00403.
   Smith LB, 2013, LANG LEARN DEV, V9, P25, DOI 10.1080/15475441.2012.707104.
   Snedeker J, 2004, COGNITIVE PSYCHOL, V49, P238, DOI 10.1016/j.cogpsych.2004.03.001.
   Staub A, 2012, VIS COGN, V20, P922, DOI 10.1080/13506285.2012.715599.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Treiman R, 2015, CHILD DEV, V86, P1406, DOI 10.1111/cdev.12385.
   Trueswell JC, 1999, COGNITION, V73, P89, DOI 10.1016/S0010-0277(99)00032-3.
   van Steensel R, 2011, REV EDUC RES, V81, P69, DOI 10.3102/0034654310388819.
   WELSH MC, 1988, DEV NEUROPSYCHOL, V4, P199, DOI 10.1080/87565648809540405.
   WELSH MC, 1991, DEV NEUROPSYCHOL, V7, P131, DOI 10.1080/87565649109540483.
   WHITEHURST GJ, 1994, DEV PSYCHOL, V30, P679, DOI 10.1037/0012-1649.30.5.679.
   Yu C, 2011, DEVELOPMENTAL SCI, V14, P165, DOI 10.1111/j.1467-7687.2010.00958.x.
   Yurovsky D, 2013, DEVELOPMENTAL SCI, V16, P959, DOI 10.1111/desc.12036.}},
Number-of-Cited-References = {{79}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{Vis. Cogn.}},
Doc-Delivery-Number = {{GH1JG}},
Unique-ID = {{ISI:000433158600004}},
DA = {{2020-12-06}},
}

@article{ ISI:000431587000001,
Author = {Szewczyk, Jakub M. and Schriefers, Herbert},
Title = {{The N400 as an index of lexical preactivation and its implications for
   prediction in language comprehension}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2018}},
Volume = {{33}},
Number = {{6}},
Pages = {{665-686}},
Abstract = {{The N400 component's amplitude is standardly reduced for predictable
   words. But it is not clear whether this reduction truly reflects
   preactivation of the critical word or whether it just indexes the
   difficulty of integrating the word with the sentence. To adjudicate
   between these two accounts, event-related potentials were recorded while
   participants read short stories. In half of the stories, just before the
   story-final sentence, we induced an explicit prediction of a congruent
   or an incongruent target word, thereby preactivating this word. Inducing
   prediction for the incongruent target word eliminated the N400, fully
   supporting the preactivation theory. This implies that the N400 is a
   marker of prediction and that prediction is an essential aspect of
   sentence comprehension. In addition, an analysis of the ERPs on the
   words preceding the critical target word provides evidence on how the
   target word becomes preactivated by the context.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Szewczyk, JM (Corresponding Author), Jagiellonian Univ, Inst Psychol, Krakow, Poland.
   Szewczyk, Jakub M., Jagiellonian Univ, Inst Psychol, Krakow, Poland.
   Schriefers, Herbert, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, Nijmegen, Netherlands.}},
DOI = {{10.1080/23273798.2017.1401101}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{N400; late N400; sentence processing; prediction}},
Keywords-Plus = {{EVENT-RELATED POTENTIALS; WORD REPETITION; BRAIN POTENTIALS;
   WORKING-MEMORY; ELECTROPHYSIOLOGICAL EVIDENCE; SENTENCE COMPREHENSION;
   UPCOMING WORDS; RECOGNITION MEMORY; SEMANTIC CONGRUITY; NEURAL
   MECHANISMS}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{jakub.szewczyk@gmail.com}},
ResearcherID-Numbers = {{Schriefers, Herbert/D-8532-2012
   }},
ORCID-Numbers = {{Szewczyk, Jakub/0000-0003-4464-082X}},
Cited-References = {{Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   BENTIN S, 1990, MEM COGNITION, V18, P359, DOI 10.3758/BF03197125.
   BESSON M, 1992, J COGNITIVE NEUROSCI, V4, P132, DOI 10.1162/jocn.1992.4.2.132.
   BESSON M, 1993, J EXP PSYCHOL LEARN, V19, P1115, DOI 10.1037/0278-7393.19.5.1115.
   Brothers T, 2015, COGNITION, V136, P135, DOI 10.1016/j.cognition.2014.10.017.
   BROWN C, 1993, J COGNITIVE NEUROSCI, V5, P34, DOI 10.1162/jocn.1993.5.1.34.
   Callahan SM, 2008, J NEUROLINGUIST, V21, P231, DOI 10.1016/j.jneuroling.2007.10.002.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Choudhary KK, 2009, NEUROPSYCHOLOGIA, V47, P3012, DOI 10.1016/j.neuropsychologia.2009.05.009.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong K. A., 2009, ELECTROPHYSIOLOGICAL.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DeLong KA, 2014, NEUROPSYCHOLOGIA, V61, P150, DOI 10.1016/j.neuropsychologia.2014.06.016.
   DeLong KA, 2012, BRAIN LANG, V121, P226, DOI 10.1016/j.bandl.2012.02.006.
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004.
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Fiebach CJ, 2001, J PSYCHOLINGUIST RES, V30, P321, DOI 10.1023/A:1010447102554.
   Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006.
   Frank Stefan L., 2013, PROCEEDINGS OF THE 5, V2, P878.
   Friederici AD, 1996, J EXP PSYCHOL LEARN, V22, P1219, DOI 10.1037/0278-7393.22.5.1219.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   GARNSEY SM, 1989, J PSYCHOLINGUIST RES, V18, P51, DOI 10.1007/BF01069046.
   Greenwald AG, 1996, SCIENCE, V273, P1699, DOI 10.1126/science.273.5282.1699.
   Hagoort P, 2008, PHILOS T R SOC B, V363, P1055, DOI 10.1098/rstb.2007.2159.
   Hahne A, 1999, J COGNITIVE NEUROSCI, V11, P194, DOI 10.1162/089892999563328.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1111/1469-8986.3720163.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   KARAYANIDIS F, 1991, PSYCHOPHYSIOLOGY, V28, P307, DOI 10.1111/j.1469-8986.1991.tb02200.x.
   Kim MS, 2001, COGNITIVE BRAIN RES, V11, P387, DOI 10.1016/S0926-6410(01)00011-8.
   KING JW, 1995, J COGNITIVE NEUROSCI, V7, P376, DOI 10.1162/jocn.1995.7.3.376.
   Kuperberg GR, 2007, BRAIN RES, V1146, P23, DOI 10.1016/j.brainres.2006.12.063.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6.
   KUTAS M, 1993, LANG COGNITIVE PROC, V8, P533, DOI 10.1080/01690969308407587.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Laszlo S, 2011, PSYCHOPHYSIOLOGY, V48, P176, DOI 10.1111/j.1469-8986.2010.01058.x.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Lewis AG, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00085.
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9.
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   Matzke M, 2002, CLIN NEUROPHYSIOL, V113, P844, DOI 10.1016/S1388-2457(02)00059-7.
   MITCHELL PF, 1993, PSYCHOPHYSIOLOGY, V30, P496, DOI 10.1111/j.1469-8986.1993.tb02073.x.
   NAGY ME, 1989, PSYCHOPHYSIOLOGY, V26, P431, DOI 10.1111/j.1469-8986.1989.tb01946.x.
   NEVILLE HJ, 1986, J MEM LANG, V25, P75, DOI 10.1016/0749-596X(86)90022-7.
   Nieuwland M, 2017, BIORXIV, P111807, DOI {[}10.1101/111807, DOI 10.1101/111807].
   O'Rourke PL, 2011, BRAIN RES, V1392, P62, DOI 10.1016/j.brainres.2011.03.071.
   Olichney JM, 2000, BRAIN, V123, P1948, DOI 10.1093/brain/123.9.1948.
   Otten M, 2009, BRAIN RES, V1291, P92, DOI 10.1016/j.brainres.2009.07.042.
   Phillips C, 2005, COGNITIVE BRAIN RES, V22, P407, DOI 10.1016/j.cogbrainres.2004.09.012.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Rabovsky M, 2014, COGNITION, V132, P68, DOI 10.1016/j.cognition.2014.03.010.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   RUGG MD, 1992, J COGNITIVE NEUROSCI, V4, P69, DOI 10.1162/jocn.1992.4.1.69.
   RUGG MD, 1990, MEM COGNITION, V18, P367, DOI 10.3758/BF03197126.
   Rugg MD, 1997, PSYCHOPHYSIOLOGY, V34, P572, DOI 10.1111/j.1469-8986.1997.tb01744.x.
   RUGG MD, 1985, PSYCHOPHYSIOLOGY, V22, P642, DOI 10.1111/j.1469-8986.1985.tb01661.x.
   RUGG MD, 1988, PSYCHOPHYSIOLOGY, V25, P55, DOI 10.1111/j.1469-8986.1988.tb00958.x.
   Sassenhagen J, 2014, BRAIN LANG, V137, P29, DOI 10.1016/j.bandl.2014.07.010.
   Sereno SC, 1998, NEUROREPORT, V9, P2195, DOI 10.1097/00001756-199807130-00009.
   Szewczyk J. M., 2017, ARCH MECH LANG PROC.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Szewczyk JM, 2011, BRAIN RES, V1368, P208, DOI 10.1016/j.brainres.2010.10.070.
   Van Berkum J. J. A., 2009, SEMANTICS PRAGMATICS, P276.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Berkum JJA, 2008, CURR DIR PSYCHOL SCI, V17, P376, DOI 10.1111/j.1467-8721.2008.00609.x.
   van de Meerendonk N, 2011, NEUROIMAGE, V54, P2350, DOI 10.1016/j.neuroimage.2010.10.022.
   van Herten M, 2006, J COGNITIVE NEUROSCI, V18, P1181, DOI 10.1162/jocn.2006.18.7.1181.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   VanPetten C, 1996, PSYCHOPHYSIOLOGY, V33, P491.
   VANPETTEN C, 1990, MEM COGNITION, V18, P380, DOI 10.3758/BF03197127.
   VANPETTEN C, 1991, J COGNITIVE NEUROSCI, V3, P131, DOI 10.1162/jocn.1991.3.2.131.
   Vos SH, 2001, PSYCHOPHYSIOLOGY, V38, P41, DOI 10.1111/1469-8986.3810041.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8.
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0.
   Wlotko EW, 2012, PSYCHOL AGING, V27, P975, DOI 10.1037/a0029206.
   Wolff S, 2008, BRAIN LANG, V107, P133, DOI 10.1016/j.bandl.2008.06.003.}},
Number-of-Cited-References = {{82}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{GE9YL}},
Unique-ID = {{ISI:000431587000001}},
DA = {{2020-12-06}},
}

@article{ ISI:000430284100004,
Author = {Kim, D. and Lin, Y. and Lee, S. and Kang, B. H. and Han, S. C.},
Title = {{A Hybrid Failure Diagnosis and Prediction using Natural Language-based
   Process Map and Rule-based Expert System}},
Journal = {{INTERNATIONAL JOURNAL OF COMPUTERS COMMUNICATIONS \& CONTROL}},
Year = {{2018}},
Volume = {{13}},
Number = {{2}},
Pages = {{175-191}},
Abstract = {{Preventive maintenance is required in large scale industries to
   facilitate highly efficient performance. The efficiency of production
   can be maximized by preventing the failure of facilities in advance.
   Typically, regular maintenance is conducted manually in which case, it
   is hard to prevent repeated failures. Also, since measures to prevent
   failure depend on proactive problem-solving by the facility expert, they
   have limitations when the expert is absent, or any error in diagnosis is
   made by an unskilled expert. In many cases, an alarm system is used to
   aid manual facility diagnosis and early detection. However, it is not
   efficient in practice, since it is designed to simply collect
   information and is activated even with small problems. In this paper, we
   designed and developed an automated preventive maintenance system using
   experts' experience in detecting failure, determining the cause, and
   predicting future system failure. There are two main functions in order
   to acquire and analyze domain expertise. First, we proposed the
   network-based process map that can extract the expert's knowledge of the
   written failure report. Secondly, we designed and implemented an
   incremental learning rule-based expert system with alarm data and
   failure case. The evaluation results shows that the combination of two
   main functions works better than another failure diagnosis and
   prediction frameworks.}},
Publisher = {{CCC PUBL-AGORA UNIV}},
Address = {{PIATA TINERETULUI 8, ORADEA, JUD, BIHOR, 410526, ROMANIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Han, SC (Corresponding Author), Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
   Kim, D.; Lee, S., Kyung Hee Univ, Dept Comp Sci \& Engn, 1732 Deogyeong Daero, Yongin 17104, Gyeonggi Do, South Korea.
   Lin, Y.; Kang, B. H., Univ Tasmania, Sch Engn, Private Bag 87, Hobart, Tas 7001, Australia.
   Lin, Y.; Kang, B. H., Univ Tasmania, ICT, Private Bag 87, Hobart, Tas 7001, Australia.
   Han, S. C., Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.}},
ISSN = {{1841-9836}},
EISSN = {{1841-9844}},
Keywords = {{expert's knowledge; preventive maintenance; failure prediction; alarm
   management; knowledge reuse}},
Research-Areas = {{Automation \& Control Systems; Computer Science}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Information Systems}},
Author-Email = {{dhkim@oslab.khu.ac.kr
   Yingru.Lin@utas.edu.au
   sylee@oslab.khu.ac.kr
   Byeong.Kang@utas.edu.au
   Caren.Han@sydney.edu.au}},
ResearcherID-Numbers = {{Kang, Byeong Ho/J-7907-2014}},
ORCID-Numbers = {{Kang, Byeong Ho/0000-0003-3476-8838}},
Funding-Acknowledgement = {{MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program {[}IITP-2017-0-01629];
   Industrial Core Technology Development Program - Ministry of Trade,
   Industry and Energy (MOTIE, Korea) {[}10049079]; US Office of Naval
   Research grantOffice of Naval Research {[}GRANT12154887]}},
Funding-Text = {{This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program (IITP-2017-0-01629) supervised by the IITP(Institute for
   Information \& communications Technology Promotion). This work was
   supported by the Industrial Core Technology Development Program
   (10049079, Develop of mining core technology exploiting personal big
   data) funded by the Ministry of Trade, Industry and Energy (MOTIE,
   Korea). This work was also funded by the US Office of Naval Research
   grant, \#GRANT12154887.}},
Cited-References = {{Ahmed K, 2013, IEEE T AUTOM SCI ENG, V10, P452, DOI 10.1109/TASE.2012.2230627.
   Chen BD, 2015, IET RENEW POWER GEN, V9, P503, DOI 10.1049/iet-rpg.2014.0181.
   Cheng Y, 2013, IEEE T AUTOM SCI ENG, V10, P446, DOI 10.1109/TASE.2012.2233472.
   Foong O., 2009, P WORLD C ENG COMP S, V2.
   Izadi I., 2009, P 7 IFAC S FAULT DET, P651, DOI DOI 10.3182/20090630-4-ES-2003.00108.
   Ju Z., 2011, 5 INT C BIOINF BIOM, P1.
   Kang B. H., 2013, IEEE RAD C MAY, P1.
   Langone R, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING (CIDM), P359, DOI 10.1109/CIDM.2014.7008690.
   Liu YT, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P1491, DOI 10.1109/ICAL.2008.4636389.
   Mohapatra H., 2013, EMNLP, P436.
   Morwal S., 2012, INT J NATURAL LANGUA, V1, P15, DOI DOI 10.5121/ijnlc.2012.1402.
   Orair GH, 2010, PROC VLDB ENDOW, V3, P1469, DOI 10.14778/1920841.1921021.
   Santos I., 2010, WORLD AUT C WAC 2010, P1.
   Sawsaa A., 2011, WORLDCOMP 11 2011 WO, P18.
   Zhao W., 2005, IEEE PES INT C TRANS, P1.
   Zhu JF, 2014, J LOSS PREVENT PROC, V30, P207, DOI 10.1016/j.jlp.2013.07.008.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Int. J. Comput. Commun. Control}},
Doc-Delivery-Number = {{GD1TL}},
Unique-ID = {{ISI:000430284100004}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000427737900001,
Author = {Lieberman, Amy M. and Borovsky, Arielle and Mayberry, Rachel I.},
Title = {{Prediction in a visual language: real-time sentence processing in
   American Sign Language across development}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2018}},
Volume = {{33}},
Number = {{4}},
Pages = {{387-401}},
Abstract = {{Prediction during sign language comprehension may enable signers to
   integrate linguistic and non-linguistic information within the visual
   modality. In two eye-tracking experiments, we investigated American Sign
   language (ASL) semantic prediction in deaf adults and children (aged 4-8
   years). Participants viewed ASL sentences in a visual world paradigm in
   which the sentence-initial verb was either neutral or constrained
   relative to the sentence-final target noun. Adults and children made
   anticipatory looks to the target picture before the onset of the target
   noun in the constrained condition only, showing evidence for semantic
   prediction. Crucially, signers alternated gaze between the stimulus sign
   and the target picture only when the sentential object could be
   predicted from the verb. Signers therefore engage in prediction by
   optimising visual attention between divided linguistic and referential
   signals. These patterns suggest that prediction is a
   modality-independent process, and theoretical implications are
   discussed.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lieberman, AM (Corresponding Author), Boston Univ, Sch Educ, Boston, MA 02215 USA.
   Lieberman, Amy M., Boston Univ, Sch Educ, Boston, MA 02215 USA.
   Borovsky, Arielle, Purdue Univ, Speech Language \& Hearing Sci, W Lafayette, IN 47907 USA.
   Mayberry, Rachel I., Univ Calif San Diego, Dept Linguist, La Jolla, CA 92093 USA.}},
DOI = {{10.1080/23273798.2017.1411961}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{American sign language; deaf; semantic processing; prediction;
   eye-tracking}},
Keywords-Plus = {{ANTICIPATORY EYE-MOVEMENTS; WORLD PARADIGM; DEAF-CHILDREN;
   COMPREHENSION; ASL; ORGANIZATION; RECOGNITION; INFORMATION; ICONICITY;
   ADULTS}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{alieber@bu.edu}},
Funding-Acknowledgement = {{National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health \& Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness \& Other
   Communication Disorders (NIDCD) {[}R01DC015272, R03DC013638,
   R01DC012797]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness \&
   Other Communication Disorders (NIDCD) {[}R03DC013638, R01DC015272,
   R01DC012797, R01DC012797, R01DC015272, R01DC015272, R01DC012797,
   R01DC015272, R01DC012797, R03DC013638, R01DC012797, R01DC015272,
   R01DC012797, R03DC013638] Funding Source: NIH RePORTER}},
Funding-Text = {{This work was supported by National Institute on Deafness and Other
   Communication Disorders {[}grant numbers R01DC015272 (AL), R03DC013638
   (AB), and R01DC012797 (RM)].}},
Cited-References = {{Allen TE, 2013, SIGN LANG STUD, V14, P58, DOI 10.1353/sls.2013.0027.
   Altmann GTM, 2004, COGNITION, V93, pB79, DOI 10.1016/j.cognition.2004.02.005.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Anderson D., 2002, J DEAF STUD DEAF EDU, V7, P83, DOI DOI 10.1093/DEAFED/7.2.83.
   Andreu L, 2013, APPL PSYCHOLINGUIST, V34, P5, DOI 10.1017/S0142716411000592.
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005.
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002.
   Borovsky A, 2014, DEV PSYCHOL, V50, P1600, DOI 10.1037/a0035591.
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005.
   Bosworth RG, 2010, J EXP PSYCHOL LEARN, V36, P1573, DOI 10.1037/a0020934.
   Carreiras M, 2008, J MEM LANG, V58, P100, DOI 10.1016/j.jml.2007.05.004.
   Dink J. W., 2015, EYETRACKINGR R LIB E.
   EMMOREY K, 1990, PERCEPT MOTOR SKILL, V71, P1227, DOI 10.2466/PMS.71.8.1227-1252.
   Emmorey K, 2009, J DEAF STUD DEAF EDU, V14, P237, DOI 10.1093/deafed/enn037.
   Fernald A., 2008, DEV PSYCHOLINGUISTIC, P113.
   Harris M., 1989, FIRST LANG, V9, P81, DOI {[}10.1177/014272378900902507, DOI 10.1177/014272378900902507].
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Huettig F, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00394.
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Knoeferle P, 2007, J MEM LANG, V57, P519, DOI 10.1016/j.jml.2007.01.003.
   KUHL PK, 1984, INFANT BEHAV DEV, V7, P361, DOI 10.1016/S0163-6383(84)80050-8.
   Kukona A, 2011, COGNITIVE SCI, V35, P1009, DOI 10.1111/j.1551-6709.2011.01180.x.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Lieberman AM, 2015, J EXP PSYCHOL LEARN, V41, P1130, DOI 10.1037/xlm0000088.
   Lieberman AM, 2014, LANG LEARN DEV, V10, P19, DOI 10.1080/15475441.2012.760381.
   MacSweeney M, 2006, HUM BRAIN MAPP, V27, P63, DOI 10.1002/hbm.20167.
   Mani N, 2014, J EXP CHILD PSYCHOL, V126, P264, DOI 10.1016/j.jecp.2014.05.004.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Mayberry MR, 2009, COGNITIVE SCI, V33, P449, DOI 10.1111/j.1551-6709.2009.01019.x.
   Mayberry RI, 2011, BRAIN LANG, V119, P16, DOI 10.1016/j.bandl.2011.05.007.
   Mishra RK, 2012, J EYE MOVEMENT RES, V5.
   Mitchell Ross, 2004, SIGN LANGUAGE STUDIE, V4, P138, DOI DOI 10.1353/SLS.2004.0005.
   Morford JP, 2011, LANG LEARN DEV, V7, P149, DOI 10.1080/15475441.2011.543393.
   Nappa R, 2009, LANG LEARN DEV, V5, P203, DOI 10.1080/15475440903167528.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Ormel E, 2009, J DEAF STUD DEAF EDU, V14, P436, DOI 10.1093/deafed/enp021.
   Rommers J, 2015, ATTEN PERCEPT PSYCHO, V77, P720, DOI 10.3758/s13414-015-0873-x.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Waxman R, 1997, J Deaf Stud Deaf Educ, V2, P104.
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686.
   WILBUR RB, 1996, INT REV SIGN LING, V1, P209.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{FZ6VM}},
Unique-ID = {{ISI:000427737900001}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000521636500013,
Author = {Bao, Siya and Yanagisawa, Masao and Togawa, Nozomu},
Editor = {{Hussain, DMA and Tomar, GS}},
Title = {{Personalized Landmark Recommendation Algorithm Based on
   Language-specific Satisfaction Prediction Using Heterogeneous Open Data
   Sources}},
Booktitle = {{2018 10TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND
   COMMUNICATION NETWORKS (CICN 2018)}},
Series = {{International Confernce on Computational Intelligence and Communication
   Networks}},
Year = {{2018}},
Pages = {{70-76}},
Note = {{10th International Conference on Computational Intelligence and
   Communication Networks (CICN), Aalborg Univ, Esbjerg, DENMARK, AUG
   17-19, 2018}},
Organization = {{IEEE Denmark Sect; MIR Labs}},
Abstract = {{This paper proposes a personalized landmark recommendation algorithm
   based on the prediction of users' satisfaction on landmarks. We have
   accumulated 270,239 user-generated comments from travel websites of
   Ctrip, Jaran and TripAdvisor for 196 landmarks in Tokyo, Japan. We find
   that users do have different satisfaction on landmarks depending on
   their commonly used languages and travel websites. Then we establish a
   database for landmarks with abundant and accurate landmark type and
   landmark satisfaction information. Finally, we propose an effective
   personalized landmark satisfaction prediction algorithm based on users'
   landmark type, language and travel website preferences. After that,
   landmarks with the top-6 highest satisfaction are provided to the user
   for a one- day visit plan in Tokyo. Experimental results demonstrate
   that the proposed algorithm can recommend landmarks that fit the user's
   preferences and our algorithm also successfully predicts the user's
   landmark satisfaction with a low error rate less than 7\%, which is
   superior to other previous studies.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bao, SY (Corresponding Author), Waseda Univ, Dept Comp Sci \& Commun Engn, Tokyo, Japan.
   Bao, Siya; Yanagisawa, Masao; Togawa, Nozomu, Waseda Univ, Dept Comp Sci \& Commun Engn, Tokyo, Japan.}},
DOI = {{10.1109/CICN.2018.015}},
ISSN = {{2375-8244}},
ISBN = {{978-1-5386-2577-4}},
Keywords = {{user-generated comment; landmark satisfaction prediction; personalized
   landmark recommendation}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{siya.bao@togawa.cs.waseda.ac.jp
   togawa@togawa.cs.waseda.ac.jp}},
ORCID-Numbers = {{Togawa, Nozomu/0000-0003-3400-3587}},
Funding-Acknowledgement = {{{[}17K19986]; Grants-in-Aid for Scientific ResearchMinistry of
   Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan
   Society for the Promotion of ScienceGrants-in-Aid for Scientific
   Research (KAKENHI) {[}17K19986] Funding Source: KAKEN}},
Funding-Text = {{This paper was supported in part by Grant-in-Aid for Scientific Research
   (No. 17K19986).}},
Cited-References = {{Agarwal A, 2017, EXPERT SYST APPL, V82, P115, DOI 10.1016/j.eswa.2017.03.069.
   Amoretti M, 2017, PERVASIVE MOB COMPUT, V38, P474, DOI 10.1016/j.pmcj.2016.08.008.
   Colomo-Palacios R, 2017, PERVASIVE MOB COMPUT, V38, P505, DOI 10.1016/j.pmcj.2016.03.001.
   Darlington R. B., 2016, REGRESSION ANAL LINE.
   Dolnicar S, 2007, INT J CULT TOUR HOSP, V1, P140, DOI 10.1108/17506180710751687.
   Frees E. W., 2014, PREDICTIVE MODELING, V1.
   Khopkar SS, 2017, ELECTRON COMMER R A, V21, P38, DOI 10.1016/j.elerap.2016.12.002.
   Kotiloglu S, 2017, TOURISM MANAGE, V62, P76, DOI 10.1016/j.tourman.2017.03.005.
   Pantano E, 2017, TOURISM MANAGE, V60, P430, DOI 10.1016/j.tourman.2016.12.020.
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3\_1.
   Sun C., 2017, DECISION SUPPORT SYS.
   Weaver DB, 2017, TOURISM MANAGE, V63, P302, DOI 10.1016/j.tourman.2017.06.028.
   Ying YK, 2017, NEUROCOMPUTING, V242, P195, DOI 10.1016/j.neucom.2017.02.067.
   Yu ZW, 2016, IEEE T HUM-MACH SYST, V46, P151, DOI 10.1109/THMS.2015.2446953.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BO6PU}},
Unique-ID = {{ISI:000521636500013}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000511427500035,
Author = {Budhwar, Aditya and Kuboi, Toshihiro and Dekhtyar, Alex and Khosmood,
   Foaad},
Editor = {{Zuiderwijk, A and Hinnant, CC}},
Book-Group-Author = {{ACM}},
Title = {{Predicting the Vote Using Legislative Speech}},
Booktitle = {{PROCEEDINGS OF THE 19TH ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL
   GOVERNMENT RESEARCH (DGO 2018): GOVERNANCE IN THE DATA AGE}},
Year = {{2018}},
Pages = {{305-314}},
Note = {{19th Annual International Conference on Digital Government Research
   (Dgo) - Governance in the Data Age, Delft Univ Technol, Delft,
   NETHERLANDS, MAY 30-JUN 01, 2018}},
Organization = {{Digital Govt Soc; Emerald Publishing; IOS Press; 4TU, Ctr Res Data}},
Abstract = {{As most dedicated observers of voting bodies like the U.S. Supreme Court
   can attest, it is possible to guess vote outcomes based on statements
   made during deliberations or questioning by the voting members. We show
   this is also possible to do automatically using machine learning,
   potentially providing a powerful tool to ordinary citizens. Our working
   hypothesis is that verbal utterances made during the legislative process
   by elected representatives can indicate their intent on a future vote,
   and therefore can be used to automatically predict said vote to a
   significant degree.
   In this paper, we examine thousands of hours of legislative
   deliberations from the California state legislature's 2015-2016 session
   to form models of voting behavior for each legislator and use them to
   train classifiers and predict the votes that occur subsequent to the
   discussions. We can achieve average legislator vote prediction
   accuracies as high as 83\%. For bill vote prediction, our model can
   achieve 76\% accuracy with an F1 score of 0.83 using a balanced dataset.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Budhwar, A (Corresponding Author), Calif Polytech State Univ San Luis Obispo, San Luis Obispo, CA 93407 USA.
   Budhwar, Aditya; Dekhtyar, Alex; Khosmood, Foaad, Calif Polytech State Univ San Luis Obispo, San Luis Obispo, CA 93407 USA.
   Kuboi, Toshihiro, Inst Adv Technol \& Publ Policy, San Luis Obispo, CA USA.}},
DOI = {{10.1145/3209281.3209374}},
ISBN = {{978-1-4503-6526-0}},
Keywords = {{Sentiment Analysis; Predictive Analytics; Machine Learning; Digital
   Democracy; Vote Prediction}},
Research-Areas = {{Computer Science; Public Administration}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Public Administration}},
Author-Email = {{abudhwar@calpoly.edu
   tkuboi@calpoly.edu
   dekhtyar@calpoly.edu
   foaad@calpoly.edu}},
Funding-Acknowledgement = {{Institute for Advanced Technology and Public Policy}},
Funding-Text = {{The authors thank the Institute for Advanced Technology and Public
   Policy for their generous support and for providing the data necessary
   to conduct this work.}},
Cited-References = {{Bird E. L. Steven, 2009, NATURAL LANGUAGE PRO.
   Blei David, 2010, TECHNICAL REPORT.
   Cain Kristian Gampong Zach, 2012, TECHNICAL REPORT.
   Calabrese Stephen, 2015, THESIS.
   Farhi P, 2015, WASHINGTON POST.
   Gerrish Blei, 2011, INT C MACH LEARN.
   Herlocker Jonathan L., 2004, THESIS.
   Hunt Albert R., 2009, INT HERALD TRIBUNE.
   Izzatdust Z., 2012, LNCS, V7553.
   Jackman S., 2004, AM POLITICAL SCI REV.
   Jean Y., 2013, EMPIRICAL METHODS NA.
   Latner Michael, 2017, CALIFORNIA J POLITIC, V9, P3.
   McElroy Jonathan David, 2012, THESIS.
   Mishne G., 2006, AAAI SPRING S COMP A.
   ONeil Tyler, 2012, TECHNICAL REPORT.
   Paltoglou G., 2010, J AM SOC INF SCI TEC.
   Pang B., 2007, OPINION MINING SENTI.
   Sandner P. G., 2010, INT AAAI C WEBL SOC.
   Wiebe J., 2005, HUMAN LANGUAGE TECHN.
   Wilkerson John D., 2012, ASS COMPUTATIONAL LI.
   Wu Chengyi Coral, 2016, THESIS.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BO3SF}},
Unique-ID = {{ISI:000511427500035}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000414187000017,
Author = {Kiss, Gabor and Vicsi, Klara},
Title = {{Mono- and multi-lingual depression prediction based on speech processing}},
Journal = {{INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY}},
Year = {{2017}},
Volume = {{20}},
Number = {{4}},
Pages = {{919-935}},
Month = {{DEC}},
Abstract = {{In this paper a mono- and multi-lingual study is presented about the
   depressed speech detection possibilities. Beck Depression Inventory
   questionnaires were used for the description of severity of depression
   of speakers for all languages. In the mono-lingual experiment a detailed
   speech parameter selection is shown, and the analysis of the connection
   between the severity of the depression and the calculated parameters is
   presented. The goal was to select the most relevant input feature
   vectors from a preselected set of vectors for the detection and
   prediction methods of depression. A detailed examination was carried out
   where and how to measure these features in continuous speech. After
   parameter selection, classification experiments were conducted on a
   Hungarian speech database. The overall accuracies of the classification
   experiments were 86\%. The second part of this study concerns a
   multi-lingual automatic depression detection and prediction method,
   where three European languages were tested: German, Hungarian and
   Italian. With the selected quasi language-independent parameters,
   Support Vector Regression experiments were conducted on German,
   Hungarian and Italian speech databases, separately for both sexes. It
   was found that depression prediction based on speech signals can be
   achieved in a multi-lingual way. Our method is even capable of
   predicting the severity of depression in the case of a language not used
   during the training of the automatic prediction model. The experiments
   clearly show that multi-lingual depression recognition can be achieved,
   and it should be possible to construct an automated diagnostic tool for
   detecting depression, or for patient monitoring, in a multi-lingual way.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kiss, G (Corresponding Author), Budapest Univ Technol \& Econ, Fac Elect Engn \& Informat, Dept Telecommun \& Media Informat, Budapest, Hungary.
   Kiss, Gabor; Vicsi, Klara, Budapest Univ Technol \& Econ, Fac Elect Engn \& Informat, Dept Telecommun \& Media Informat, Budapest, Hungary.}},
DOI = {{10.1007/s10772-017-9455-8}},
ISSN = {{1381-2416}},
EISSN = {{1572-8110}},
Keywords = {{Depression; Classification; Regression; Multi-lingual; Automatic
   prediction; Paralinguistic}},
Keywords-Plus = {{SEVERITY; SUICIDE}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{kiss.gabor@tmit.bme.hu}},
Funding-Acknowledgement = {{European Space Agency COALA project: Psychological Status Monitoring by
   Computerised Analysis of Language phenomena (COALA)}},
Funding-Text = {{We would like to thank Bjorn Schuller and his co-workers Jarek Krajewski
   and Sonja-Dana Roelena for sharing with us the database of AVEC 2013 for
   research purposes. They gave us the possibility to extend our
   multi-lingual research. We also thank Anna Esposito for the Italian
   depressed speech database. The research was supported by European Space
   Agency COALA project: Psychological Status Monitoring by Computerised
   Analysis of Language phenomena (COALA) (AO-11- Concordia).}},
Cited-References = {{Abela JRZ, 2002, BRIT J CLIN PSYCHOL, V41, P111, DOI 10.1348/014466502163912.
   Alghowinem S, 2016, INTERSPEECH, P1943, DOI 10.21437/Interspeech.2016-1339.
   Alghowinem S, 2013, INT CONF ACOUST SPEE, P7547, DOI 10.1109/ICASSP.2013.6639130.
   Boersma, 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Cummins N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P110.
   Cummins N, 2015, SPEECH COMMUN, V75, P27, DOI 10.1016/j.specom.2015.09.003.
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004.
   Drucker H, 1997, ADV NEUR IN, V9, P155.
   France DJ, 2000, IEEE T BIO-MED ENG, V47, P829, DOI 10.1109/10.846676.
   Hawton K, 2013, J AFFECT DISORDERS, V147, P17, DOI 10.1016/j.jad.2013.01.004.
   Helfer BS, 2013, INTERSPEECH, P2171.
   Jiang HH, 2017, SPEECH COMMUN, V90, P39, DOI 10.1016/j.specom.2017.04.001.
   Kiss G., 2015, ACTA U SAPIENTIAE EL, V7, P62.
   Kiss G, 2016, SMART INNOV SYST TEC, V48, P103, DOI 10.1007/978-3-319-28109-4\_11.
   Kiss G, 2014, LECT NOTES COMPUT SC, V8791, P120, DOI 10.1007/978-3-319-11397-5\_9.
   Kiss G, 2013, INT CONF COGN INFO, P579, DOI 10.1109/CogInfoCom.2013.6719169.
   Kotti M, 2012, INT J SPEECH TECHNOL, V15, P131, DOI 10.1007/s10772-012-9127-7.
   Kraepelin E., 1921, J NERV MENT DIS, V53, P350, DOI {[}DOI 10.1097/00005053-192104000-00057, 10.1097/00005053-192104000-00057].
   Lepine Jean-Pierre, 2011, Neuropsychiatr Dis Treat, V7, P3, DOI 10.2147/NDT.S19617.
   Liu ZY, 2015, INT CONF AFFECT, P743, DOI 10.1109/ACII.2015.7344652.
   Low LSA, 2011, IEEE T BIO-MED ENG, V58, P574, DOI 10.1109/TBME.2010.2091640.
   MARCUS M, 2012, WHO DEP MENTAL HLTH, V1, P6, DOI DOI 10.1037/E517532013-004.
   Mathers CD, 2006, PLOS MED, V3, DOI 10.1371/journal.pmed.0030442.
   Mundt JC, 2007, J NEUROLINGUIST, V20, P50, DOI 10.1016/j.jneuroling.2006.04.001.
   Mundt JC, 2012, BIOL PSYCHIAT, V72, P580, DOI 10.1016/j.biopsych.2012.03.015.
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143.
   Sztaho D., 2014, WOCCI 2014 SAT WORKS.
   SZTAHO D, 2011, AUT CLASS EM SPONT, V6800, P229.
   Valstar M., 2013, P 3 ACM INT WORKSH A, P3, DOI DOI 10.1145/2512530.2512533.
   Williamson J. R., 2013, P 3 ACM INT WORKSH A, P41, DOI DOI 10.1145/2512530.2512531.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{Int. J. Speech Technol.}},
Doc-Delivery-Number = {{FL4GN}},
Unique-ID = {{ISI:000414187000017}},
DA = {{2020-12-06}},
}

@article{ ISI:000418476900004,
Author = {Dijkgraaf, Aster and Hartsuiker, Robert J. and Duyck, Wouter},
Title = {{Predicting upcoming information in native-language and
   non-native-language auditory word recognition}},
Journal = {{BILINGUALISM-LANGUAGE AND COGNITION}},
Year = {{2017}},
Volume = {{20}},
Number = {{5}},
Pages = {{917-930}},
Month = {{NOV}},
Abstract = {{Monolingual listeners continuously predict upcoming information. Here,
   we tested whether predictive language processing occurs to the same
   extent when bilinguals listen to their native language vs. a non-native
   language. Additionally, we tested whether bilinguals use prediction to
   the same extent as monolinguals. Dutch-English bilinguals and English
   monolinguals listened to constraining and neutral sentences in Dutch
   (bilinguals only) and in English, and viewed target and distractor
   pictures on a display while their eye movements were measured. There was
   a bias of fixations towards the target object in the constraining
   condition, relative to the neutral condition, before information from
   the target word could affect fixations. This prediction effect occurred
   to the same extent in native processing by bilinguals and monolinguals,
   but also in non-native processing. This indicates that unbalanced,
   proficient bilinguals can quickly use semantic information during
   listening to predict upcoming referents to the same extent in both of
   their languages.}},
Publisher = {{CAMBRIDGE UNIV PRESS}},
Address = {{32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dijkgraaf, A (Corresponding Author), Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.
   Dijkgraaf, Aster; Hartsuiker, Robert J.; Duyck, Wouter, Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.}},
DOI = {{10.1017/S1366728916000547}},
ISSN = {{1366-7289}},
EISSN = {{1469-1841}},
Keywords = {{bilingualism; prediction; speech perception; visual world paradigm}},
Keywords-Plus = {{LEXICAL COMPETITION; SENTENCE CONTEXT; BILINGUALS; 2ND-LANGUAGE; BRAIN;
   COMPREHENSION; PROFICIENCY; ACCENTS; NORMS}},
Research-Areas = {{Linguistics; Psychology}},
Web-of-Science-Categories  = {{Linguistics; Psychology, Experimental}},
Author-Email = {{aster.dijkgraaf@ugent.be}},
ResearcherID-Numbers = {{Hartsuiker, Robert J./N-1668-2019
   }},
ORCID-Numbers = {{Duyck, Wouter/0000-0003-2114-6212}},
Funding-Acknowledgement = {{Concerted Research Action (GOA) from the Special Research Fund, Ghent
   University}},
Funding-Text = {{This research was supported by a Concerted Research Action (GOA) from
   the Special Research Fund, Ghent University.}},
Cited-References = {{Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552.
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Baayen H. R., 1995, CELEX LEXICAL DATABA.
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005.
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002.
   Boland JE, 2005, COGNITION, V95, P237, DOI 10.1016/j.cognition.2004.01.008.
   Broersma P., 2014, PRAAT DOING PHONETIC.
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977.
   Chambers CG, 2009, J EXP PSYCHOL LEARN, V35, P1029, DOI 10.1037/a0015901.
   Cook V., 1997, TUTORIALS BILINGUALI, P279.
   De Deyne S, 2013, BEHAV RES METHODS, V45, P480, DOI 10.3758/s13428-012-0260-7.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Dussias PE, 2013, STUD SECOND LANG ACQ, V35, P353, DOI 10.1017/S0272263112000915.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   FitzPatrick I., 2007, P COGNITIVE NEUROSCI, P43.
   Foucart A., 2015, BILING-LANG COGN, P1.
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756.
   Gollan TH, 2008, J MEM LANG, V58, P787, DOI 10.1016/j.jml.2007.07.001.
   Hahne A, 2001, J PSYCHOLINGUIST RES, V30, P251, DOI 10.1023/A:1010490917575.
   Hopp H., 2015, INT REV APPL LINGUIS.
   Hopp H, 2013, SECOND LANG RES, V29, P33, DOI 10.1177/0267658312461803.
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643.
   Koehne J, 2015, COGNITIVE SCI, V39, P849, DOI 10.1111/cogs.12178.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Lagrou E, 2013, PSYCHON B REV, V20, P963, DOI 10.3758/s13423-013-0405-4.
   Lagrou E, 2013, BILING-LANG COGN, V16, P508, DOI 10.1017/S1366728912000508.
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   MacDonald M. C, 2013, FRONTIERS PSYCHOL, V4.
   MacWhinney B., 2015, BILING-LANG COGN, V19, P19.
   Mandera P., J MEMORY LA IN PRESS.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067).
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   MATIN E, 1993, PERCEPT PSYCHOPHYS, V53, P372, DOI 10.3758/BF03206780.
   McQueen JM, 2012, J ACOUST SOC AM, V131, P509, DOI 10.1121/1.3664087.
   Misra M, 2012, J MEM LANG, V67, P224, DOI 10.1016/j.jml.2012.05.001.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   R Core Team, 2013, R LANG ENV STAT COMP.
   Rommers J, 2015, ATTEN PERCEPT PSYCHO, V77, P720, DOI 10.3758/s13414-015-0873-x.
   SASLOW MG, 1967, J OPT SOC AM, V57, P1030, DOI 10.1364/JOSA.57.001030.
   Schepens J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063006.
   Severens E, 2005, ACTA PSYCHOL, V119, P159, DOI 10.1016/j.actpsy.2005.01.002.
   Van Berkum JJA, 2010, ITAL J LINGUIST, V22, P181.
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521.
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0.
   Weber A., 2012, ENCY APPL LINGUISTIC.
   Weber A, 2014, J PHONETICS, V46, P34, DOI 10.1016/j.wocn.2014.05.002.
   Woumans E, 2015, J EXP PSYCHOL LEARN, V41, P1579, DOI 10.1037/xlm0000107.
   Zirnstein M., 2015, INT S BIL.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{Biling.-Lang. Cogn.}},
Doc-Delivery-Number = {{FQ6LV}},
Unique-ID = {{ISI:000418476900004}},
DA = {{2020-12-06}},
}

@article{ ISI:000406461900015,
Author = {Nematollahi, Mohammad Ali and Vorakulpipat, Chalee and Gamboa-Rosales,
   Hamurabi and Martinez-Ruiz, Francisco J. and De la Rosa-Vargas, Jose I.},
Title = {{Digital Speech Watermarking Based on Linear Predictive Analysis and
   Singular Value Decomposition}},
Journal = {{PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES INDIA SECTION A-PHYSICAL
   SCIENCES}},
Year = {{2017}},
Volume = {{87}},
Number = {{3}},
Pages = {{433-446}},
Month = {{SEP}},
Abstract = {{In this paper different digital audio watermarking techniques have been
   proposed. Currently, more attention is given to combination of Discrete
   Wavelet Transform (DWT) and Singular Value Decomposition (SVD)
   techniques for watermarking purpose. Available DWT-SVD audio
   watermarking techniques cannot be applied to speech signals efficiently.
   However, Linear Predictive Analysis (LPA) technique can model digital
   speech signals (20-30 ms) in more flexible and efficient ways than DWT.
   In this paper, a novel digital speech watermarking technique is proposed
   by applying both LPA and SVD. Quantization Index Modulation (QIM) is
   further applied to embed the watermark bits. The experimental results
   show that not only time and memory were reduced significantly as
   compared to different DWT-SVD audio watermarking techniques, but also
   the proposed technique was more robust and imperceptible for speech
   watermarking than other DWT-SVD audio watermarking techniques.}},
Publisher = {{NATL ACAD SCIENCES INDIA}},
Address = {{5 LAJPATRAI RD, ALLAHABAD 211002, INDIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Nematollahi, MA (Corresponding Author), Islamic Azad Univ, Safadasht Branch, Dept Comp Engn, Tehran, Iran.
   Nematollahi, Mohammad Ali, Islamic Azad Univ, Safadasht Branch, Dept Comp Engn, Tehran, Iran.
   Vorakulpipat, Chalee, Natl Elect \& Comp Technol Ctr NECTEC, Cybersecur Lab, Wireless Innovat \& Secur Res Unit, 112 Phahonyothin Rd, Khlong Luang Dist 12120, Pathumthani, Thailand.
   Gamboa-Rosales, Hamurabi; Martinez-Ruiz, Francisco J.; De la Rosa-Vargas, Jose I., Autonomous Univ Zacatecas, Dept Elect Engn, Zacatecas 98000, Zac, Mexico.}},
DOI = {{10.1007/s40010-017-0371-8}},
ISSN = {{0369-8203}},
EISSN = {{2250-1762}},
Keywords = {{Digital speech watermarking; Digital audio watermarking; Linear
   predictive analysis; Singular value decomposition; Quantization index
   modulation}},
Keywords-Plus = {{AUDIO WATERMARKING}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{Greencomputinguae@gmail.com}},
ResearcherID-Numbers = {{De la Rosa, Jose Ismael/N-7394-2019
   De la Rosa, Jose/R-3971-2019}},
ORCID-Numbers = {{De la Rosa, Jose Ismael/0000-0002-7337-8974
   }},
Cited-References = {{Al-Haj A, 2011, INT ARAB J INF TECHN, V8, P326.
   Al-Haj Ali, 2010, EUR J SCI RES, V39, P6.
   Al-Shoshan AI, 2006, J KING SAUD U, V19, P95, DOI DOI 10.1016/S1018-3639(18)30850-X.
   Al-Yaman MS, 2012, SYST SIGN DEV SSD 9.
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1.
   Bhat KV, 2011, CIRC SYST SIGNAL PR, V30, P915, DOI 10.1007/s00034-010-9255-8.
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006.
   BIGLIERI E, 1989, SIGNAL PROCESS, V18, P277, DOI 10.1016/0165-1684(89)90039-X.
   Dhar P., 2013, J SIGNAL PROCESS, V17, P69.
   Djebbar F, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-25.
   Ebu S., 2006, SOUND QUALITY ASSESS.
   Flanagan J. L., 2013, SPEECH ANAL SYNTHESI, V3.
   Hofbauer K., 2008, LREC.
   Hofbauer K, 2009, IEEE T AUDIO SPEECH, V17, P1624, DOI 10.1109/TASL.2009.2021543.
   Johnson D.H., 2006, SCHOLARPEDIA, V1, P2088.
   Katzenbeisser S., 2000, INFORM HIDING TECHNI.
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001.
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021.
   Mishra J, 2013, INT J COMPUT APPL, V70, P6.
   Nematollahi M. A., 2015, INT J HUM ROBOT.
   Nematollahi MA, 2013, INT J SPEECH TECHNOL, V16, P471, DOI 10.1007/s10772-013-9192-6.
   Nematollahi MA, 2016, NATL ACAD SCI LETT, V39, P197, DOI 10.1007/s40009-016-0430-8.
   Nematollahi MA, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0074-5.
   Nematollahi MA, 2015, J KING SAUD UNIV-COM, V27, P58, DOI 10.1016/j.jksuci.2014.03.012.
   Orovic I, 2010, EURASIP J ADV SIG PR, P4.
   Ozer Hamza, 2005, P 7 WORKSH MULT SEC.
   Picovici D, 2001, 1 JOINT IEI IEE S TE.
   Rabiner L. R., 1978, DIGITAL PROCESSING S.
   Servan-Schreiber D, 1990, SCIENCE, V24, P9.
   Vallabha GK, 2002, SPEECH COMMUN, V38, P141, DOI 10.1016/S0167-6393(01)00049-8.
   VERDU S, 1994, IEEE T INFORM THEORY, V40, P1147, DOI 10.1109/18.335960.
   Verma A, 2012, ENG NUICONE NIRM U I.
   Wang J, 2011, SIGNAL PROCESS, V91, P1693, DOI 10.1016/j.sigpro.2011.01.014.
   Waters G., 1988, SOUND QUALITY ASSESS.
   Wei-zhen J, 2010, INT COMP INT SYST IC.
   Zheng N, 2006, SPEAKER RECOGNITION.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{Proc. Nat. Acad. Sci. India A}},
Doc-Delivery-Number = {{FB9LZ}},
Unique-ID = {{ISI:000406461900015}},
DA = {{2020-12-06}},
}

@article{ ISI:000407659100004,
Author = {Najnin, Shamima and Banerjee, Bonny},
Title = {{A predictive coding framework for a developmental agent: Speech motor
   skill acquisition and speech production}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2017}},
Volume = {{92}},
Pages = {{24-41}},
Month = {{SEP}},
Abstract = {{Predictive coding has been hypothesized as a universal principle guiding
   the operation in different brain areas. In this paper, a predictive
   coding framework for a developmental agent with perception (audio),
   action (vocalization), and learning capabilities is proposed. The agent
   learns concurrently to plan optimally and the associations between
   sensory and motor parameters, by minimizing the sensory prediction error
   in an unsupervised manner. The proposed agent is solely driven by
   sensory prediction error and does not require reinforcement. It learns
   initially by self-exploration and later by imitation from the ambient
   environment.
   Our goal is to investigate the process of speech motor skill acquisition
   and speech production in such an agent. Standard vocal exploration
   experiments show that it learns to generate speech-like sounds (acoustic
   babbling followed by proto-syllables and vowels) as well as the timing
   for motor command execution. Random goal exploration leads to the
   self-organization of developmental stages of vocal sequences in the
   agent due to increase in complexity of vocalization. The
   self-organization is invariant to certain acoustic feature
   representations. Self-exploration allows the agent to learn to imitate
   environmental sounds quickly. It learns to vocalize differently in
   different environments. (C) 2017 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Najnin, S (Corresponding Author), Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   Najnin, Shamima, Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   Univ Memphis, Dept Elect \& Comp Engn, Memphis, TN 38152 USA.}},
DOI = {{10.1016/j.specom.2017.05.002}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Prediction error minimization; Self-organization of developmental
   stages; Recurrent network; Auditory sensory; Proprioception;
   Actor-critic network; Active inference}},
Keywords-Plus = {{VOCAL DEVELOPMENT; MODEL; RECONSTRUCTION}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{snajnin@memphis.edu
   bbnerjee@memphis.edu}},
ORCID-Numbers = {{Banerjee, Bonny/0000-0002-0428-1044}},
Funding-Acknowledgement = {{NSFNational Science Foundation (NSF) {[}IIS-1231620]}},
Funding-Text = {{This research was partially supported by NSF Grant IIS-1231620.}},
Cited-References = {{Aliu SO, 2009, J COGNITIVE NEUROSCI, V21, P791, DOI 10.1162/jocn.2009.21055.
   Asada M, 2016, IEEE T COGN DEV SYST, V8, P128, DOI 10.1109/TCDS.2016.2552493.
   Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702.
   Banerjee B, 2014, NEUROCOMPUTING, V138, P41, DOI 10.1016/j.neucom.2013.02.044.
   Banerjee B, 2013, INT CONF DAT MIN WOR, P497, DOI 10.1109/ICDMW.2013.134.
   Baranes A, 2013, ROBOT AUTON SYST, V61, P49, DOI 10.1016/j.robot.2012.05.008.
   Benureau FCY, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00008.
   Bishop CM, 2006, MACH LEARN, V128, P225.
   Boulanger-Lewandowski N, 2012, P 29 INT C MACH LEAR, P1159.
   Brown H, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00218.
   Bruineberg J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00599.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889.
   De Meyer K., 2009, COMPUT INTEL NEUROSC.
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005.
   Doupe AJ, 1999, ANNU REV NEUROSCI, V22, P567, DOI 10.1146/annurev.neuro.22.1.567.
   Erhan D, 2010, J MACH LEARN RES, V11, P625.
   Fang Q, 2009, ACOUST SCI TECHNOL, V30, P277, DOI 10.1250/ast.30.277.
   Friston Karl, 2013, ANATOMY CHOICE ACTIV.
   Friston KJ, 2013, BEHAV BRAIN SCI, V36, P212, DOI 10.1017/S0140525X12002142.
   Friston KJ, 2011, BIOL CYBERN, V104, P137, DOI 10.1007/s00422-011-0424-z.
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005.
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300.
   Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000081.
   Friston KJ, 2011, IMPLICATIONS EMBODIM, P89.
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001.
   GUENTHER FH, 1995, PSYCHOL REV, V102, P594, DOI 10.1037/0033-295X.102.3.594.
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006.
   Haken H., 2010, MIND MATTER, V8, P7.
   Heintz I., 2009, P INTERSPEECH, V9, P688.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Howard IS, 2011, MOTOR CONTROL, V15, P85, DOI 10.1123/mcj.15.1.85.
   Howard IS., 2014, PLOSONE.
   Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142.
   Jakobson Roman, 1968, CHILD LANGUAGE APHAS.
   Kanda H, 2009, IEEE INT CONF ROBOT, P4036.
   Kelso JAS, 2012, PHILOS T R SOC B, V367, P906, DOI 10.1098/rstb.2011.0351.
   Kok P., 2015, INTRO MODEL BASED CO, V221, P221, DOI {[}DOI 10.1007/978-1-4939-2236-9\_11, 10.1007/978-1-4939-2236-9\_11].
   Koopmans-van Beinum F. J., 1986, PRECURSORS EARLY SPE, P37, DOI DOI 10.1007/978-1-349-08023-6\_4.
   Kroger BJ, 2009, SPEECH COMMUN, V51, P793, DOI 10.1016/j.specom.2008.08.002.
   Kuhl PK, 2014, COLD SH Q B, V79, P211, DOI 10.1101/sqb.2014.79.024802.
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533.
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011.
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539.
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370.
   Lillicrap T. P., 2015, ARXIV150902971.
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005.
   Maassen B., 2010, SPEECH MOTOR CONTROL.
   MAEDA S, 1990, NATO ADV SCI I D-BEH, V55, P131.
   Messum P, 2015, J PHONETICS, V53, P125, DOI 10.1016/j.wocn.2015.08.005.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Miura K, 2012, ADV ROBOTICS, V26, P23, DOI 10.1163/016918611X607347.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Mordatch Igor, 2014, P ROB SCI SYST.
   Moulin-Frier C., 2013, P INT.
   Moulin-Frier C., 2012, P 2012 IEEE INT C DE, P1.
   Moulin-Frier C., 2013, IEEE 3 JOINT INT C D, P1, DOI DOI 10.1109/DEVLRN.2013.6652535.
   Moulin-Frier C, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01006.
   Muhammad W, 2015, ADAPT BEHAV, V23, P265, DOI 10.1177/1059712315607363.
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477.
   Murakamli M, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P208, DOI 10.1109/DEVLRN.2015.7346142.
   Mustafa K, 2006, IEEE T AUDIO SPEECH, V14, P435, DOI 10.1109/TSA.2005.855840.
   Najnin S, 2016, INTERSPEECH, P1113, DOI 10.21437/Interspeech.2016-1126.
   Nathani S, 2006, CLIN LINGUIST PHONET, V20, P351, DOI 10.1080/02699200500211451.
   OZBEK IY, 2009, P INTERSPEECH, P2807.
   Pasa L., 2014, ADV NEURAL INFORM PR, P3572.
   Patel A. D., 1999, P 14 INT C PHON SCI, P405.
   PEARCE JM, 1980, PSYCHOL REV, V87, P532, DOI 10.1037/0033-295X.87.6.532.
   Philippsen AK, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P195, DOI 10.1109/DEVLRN.2014.6982981.
   PISONI DB, 1980, PHONETICA, V37, P285, DOI 10.1159/000259999.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Ren ZX, 2013, IEEE T IMAGE PROCESS, V22, P3120, DOI 10.1109/TIP.2013.2259837.
   Rolf M, 2010, IEEE T AUTON MENT DE, V2, P216, DOI 10.1109/TAMD.2010.2062511.
   Settles B., 2010, ACTIVE LEARNING LIT, V52, P11, DOI DOI 10.1111/J.1467-7687.2012.01135.X.
   Sigismund B., 1971, CHILD LANGUAGE BOOK.
   Spratling KW., 2015, ENCY COMPUTATIONAL N.
   Spratling MW, 2008, VISION RES, V48, P1391, DOI 10.1016/j.visres.2008.03.009.
   Spratling MW, 2012, NEURAL NETWORKS, V26, P7, DOI 10.1016/j.neunet.2011.10.002.
   Spratling M. W., 2016, BRAIN COGNITION, P92.
   Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008.
   Stuart A., 1993, ORIGINS ORDER SELF O.
   Sutskever I., 2011, P 28 ANN INT C MACH, V11, P1017.
   Taine H., 1971, CHILD LANGUAGE BOOK.
   Tassa Y, 2014, IEEE INT CONF ROBOT, P1168, DOI 10.1109/ICRA.2014.6907001.
   Tognoli E, 2014, NEURON, V81, P35, DOI 10.1016/j.neuron.2013.12.022.
   Tschacher W, 2007, NEW IDEAS PSYCHOL, V25, P1, DOI 10.1016/j.newideapsych.2006.09.002.
   Valle J. M. A., 2017, IEEE T COGN DEV SYST, V1.
   Vihman M. M., 1996, PHONOLOGICAL DEV ORI.
   Warlaumont AS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145096.
   Warlaumont AS, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P262, DOI 10.1109/DEVLRN.2014.6982991.
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337.
   Westermann G, 2004, BRAIN LANG, V89, P393, DOI 10.1016/S0093-934X(03)00345-6.
   Xia C, 2016, IEEE T NEUR NET LEAR, V27, P1227, DOI 10.1109/TNNLS.2015.2512898.
   Xia C, 2015, PATTERN RECOGN, V48, P1337, DOI 10.1016/j.patcog.2014.10.007.}},
Number-of-Cited-References = {{98}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{FD6SV}},
Unique-ID = {{ISI:000407659100004}},
DA = {{2020-12-06}},
}

@article{ ISI:000406184200010,
Author = {Ullberg, Johan and Johnson, Pontus},
Title = {{Empirical assessment of the accuracy of an interoperability prediction
   language}},
Journal = {{INFORMATION SYSTEMS FRONTIERS}},
Year = {{2017}},
Volume = {{19}},
Number = {{4}},
Pages = {{819-833}},
Month = {{AUG}},
Abstract = {{Interoperability, defined as the satisfaction of a communication need
   between two or more actors, is an important aspect in many phases of an
   enterprise's development. Mastering the field of interoperability is a
   daunting task so aid in predicting interoperability can be of great
   benefit. Formalisms capable of such predictions of future information
   system architectures are however sparse, and when employed, it is
   essential that the prediction is accurate. In this paper, a previously
   proposed interoperability modelling and prediction language is subjected
   to case testing and evaluated toward interoperability predictions made
   by practitioners and experts in the field. The results show that
   although there are some areas not currently covered by the framework, in
   general, it performs better than the intended users, and would thereby
   provide additional support in various development and design contexts.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ullberg, J (Corresponding Author), KTH Royal Inst Technol, Sch Elect Engn, Dept Ind Informat \& Control Syst, Stockholm, Sweden.
   Ullberg, Johan; Johnson, Pontus, KTH Royal Inst Technol, Sch Elect Engn, Dept Ind Informat \& Control Syst, Stockholm, Sweden.}},
DOI = {{10.1007/s10796-016-9630-5}},
ISSN = {{1387-3326}},
EISSN = {{1572-9419}},
Keywords = {{Interoperability; Architecture prediction; Modeling and description
   languages; Interoperability assessment}},
Keywords-Plus = {{HEURISTICS; BIASES}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{johanu@ics.kth.se
   pj101@ics.kth.se}},
ResearcherID-Numbers = {{Johnson, Pontus/C-5796-2014}},
ORCID-Numbers = {{Johnson, Pontus/0000-0002-3293-1681}},
Cited-References = {{Agarwal R., 1993, EXPERT SYSTEMS APPL, V6, P2.
   Alberola J.M., 2014, INFORM SYSTEMS FRONT, V16.
   {[}Anonymous], 2009, OMG UN MOD LANG OMG.
   {[}Anonymous], 2008, GRIDWISE INT CONT SE.
   Baddeley M.C., 2004, SPECIAL PUBLICATIONS, V239, P15, DOI DOI 10.1144/GSL.SP.2004.239.01.02.
   Berre A.J., 2007, P INT ENT SOFTW APPL.
   Blanc S., 2007, INTEROPERABILITY ENT.
   Booch G., 2005, UNIFIED MODELING LAN.
   Chandrasekaran B, 1983, AI MAG, V4, P34.
   Chen D., 2006, 2 INT WORKSH ENT INT.
   Chen D, 2008, COMPUT IND, V59, P647, DOI 10.1016/j.compind.2007.12.016.
   Daclin N., 2014, 7 INT C INT ENT SYST.
   Department of Defense (DoD), 2004, DOD ARCH FRAM VERS 1.
   IDABC, 2004, ENT IND DG EUR INT F.
   Johnson P, 2014, INF SYST E-BUS MANAG, V12, P595, DOI 10.1007/s10257-014-0241-8.
   Kasunic M., 2004, CMUSEI2004TN003.
   Kynn M, 2008, J ROY STAT SOC A STA, V171, P239.
   Lankhorst M., 2013, ENTERPRISE ARCHITECT.
   Lauras M, 2015, INFORM SYST FRONT, V17, P857, DOI 10.1007/s10796-013-9475-0.
   Mallek S, 2012, COMPUT IND, V63, P643, DOI 10.1016/j.compind.2012.03.002.
   Matthes F. C, 2008, TECHNICAL REPORT.
   Meyer MA, 2001, ELICITING ANAL EXPER.
   Ministry of Defence (MOD), 2008, TECHNICAL REPORT.
   Morgan MG, 1992, UNCERTAINTY GUIDE DE.
   MORRIS E, 2004, CMUSEI2004TR004.
   OKEEFE RM, 1993, ARTIF INTELL REV, V7, P3, DOI 10.1007/BF00849196.
   OMG, 2006, MET FAC MOF COR SPEC.
   OMG, 2014, OBJ CONSTR LANG SPEC.
   Pencheva E, 2016, INFORM SYST FRONT, V18, P277, DOI 10.1007/s10796-014-9532-3.
   Ruokolainen T., 2007, INTEROPERABILITY ENT.
   Rushby J., 1988, QUALITY MEASURES ASS, V4187.
   Saleem A., 2010, INN SMART GRID TECHN.
   Solhstrom J., 2013, THESIS.
   Sommestad T., 2012, THESIS.
   The Institute of Electrical and Electronics Engineers: Standard Glossary of Software Engineering Terminology, 1990, 61012 I EL EL ENG.
   Tolk A., 2003, 2003 FALL SIM INT WO.
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124.
   Ullberg J., 2009, 5 CHIN EUR INT S SOF.
   Ullberg J., 2012, TECHNICAL REPORT.
   Ullberg J., 2010, P INT C INT ENT SOFT.
   Ullberg J., 2014, SCADA SPECIFIC UNPUB.
   Ullberg J., 2009, 2 IFIP WG5 8 WORKSH, P13.
   Ullberg J., 2012, TECHNICAL REPORT.
   Ullberg J, 2012, COMPUT IND, V63, P766, DOI 10.1016/j.compind.2012.08.009.
   Verdanat F. B., 2007, ANNU REV CONTROL, V31, P137, DOI {[}10.1016/j.arcontrol.2007.03.004, DOI 10.1016/J.ARCONTROL.2007.03.004].
   ZACHMAN JA, 1987, IBM SYST J, V26, P276, DOI 10.1147/sj.263.0276.}},
Number-of-Cited-References = {{46}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Inf. Syst. Front.}},
Doc-Delivery-Number = {{FB5LV}},
Unique-ID = {{ISI:000406184200010}},
DA = {{2020-12-06}},
}

@article{ ISI:000403817500004,
Author = {Alku, Paavo and Saeidi, Rahim},
Title = {{The Linear Predictive Modeling of Speech From Higher-Lag Autocorrelation
   Coefficients Applied to Noise-Robust Speaker Recognition}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2017}},
Volume = {{25}},
Number = {{8}},
Pages = {{1606-1617}},
Month = {{AUG}},
Abstract = {{A linear predictive spectral estimation method based on higher-lag
   autocorrelation coefficients is proposed for the noiserobust feature
   extraction from speech. The method, called higherlag linear prediction,
   is derived from a signal prediction model that is optimized in the mean
   square sense using a cost function that has two prediction error terms,
   the first of which is similar to that of conventional linear prediction
   and the second of which is a delayed version introducing an integer
   delay of M samples. This basic form is developed further into the
   combined higher-lag linear prediction (CHLLP) model by simultaneously
   taking advantage of the zero-lag and higher-lag predictions. The CHLLP
   model was used in the computation of mel-frequency cepstral coefficients
   and compared with several reference feature extraction methods in
   speaker recognition. The experiments were conducted by using a modern
   i-vector-based system. Noise-corruption was done using both additive
   car, babble, and factory noise in different signal-tonoise ratio
   conditions as well as speech recordings from real noisy conditions. The
   results indicate that CHLLP outperformed the reference feature
   extraction methods in almost all the comparisons in the noise-corrupted
   conditions and the performance of CHLLP was only slightly inferior to
   the nonparametric FFT-based spectral modeling in the clean condition.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Alku, P (Corresponding Author), Aalto Univ, Dept Signal Proc \& Acoust, Espoo 02150, Finland.
   Alku, Paavo; Saeidi, Rahim, Aalto Univ, Dept Signal Proc \& Acoust, Espoo 02150, Finland.}},
DOI = {{10.1109/TASLP.2017.2703165}},
ISSN = {{2329-9290}},
Keywords = {{Linear prediction; mismatch; robust feature extraction; speaker
   recognition}},
Keywords-Plus = {{FEATURE-EXTRACTION; FRONT-END; SPECTRAL ESTIMATION; MULTITAPER MFCC;
   VERIFICATION; FEATURES; SIGNALS}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{paavo.alku@aalto.fi
   rahim.saeidi@aalto.fi}},
ResearcherID-Numbers = {{Alku, Paavo/E-2400-2012
   Saeidi, Rahim/J-5963-2014}},
ORCID-Numbers = {{Alku, Paavo/0000-0002-8173-9418
   Saeidi, Rahim/0000-0002-9084-0091}},
Funding-Acknowledgement = {{Academy of FinlandAcademy of Finland {[}284671]}},
Funding-Text = {{This work was supported by the Academy of Finland under Project 284671.}},
Cited-References = {{Alam MJ, 2013, SPEECH COMMUN, V55, P237, DOI 10.1016/j.specom.2012.08.007.
   Alku P, 2013, J ACOUST SOC AM, V134, P1295, DOI 10.1121/1.4812756.
   {[}Anonymous], 2010, NIST 2010 SRE.
   {[}Anonymous], 2012, NIST 2012 SRE.
   Boril H, 2010, IEEE T AUDIO SPEECH, V18, P1379, DOI 10.1109/TASL.2009.2034770.
   Bou-Ghazale SE, 2000, IEEE T SPEECH AUDI P, V8, P429, DOI 10.1109/89.848224.
   CHAN YT, 1982, IEEE T ACOUST SPEECH, V30, P689, DOI 10.1109/TASSP.1982.1163946.
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307.
   Ekman LA, 2008, IEEE T AUDIO SPEECH, V16, P65, DOI 10.1109/TASL.2007.909448.
   Fant G., 1960, ACOUSTIC THEORY SPEE.
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530.
   Ganapathy S, 2014, IEEE-ACM T AUDIO SPE, V22, P1285, DOI 10.1109/TASLP.2014.2329190.
   Garcia-Romero D., 2011, INTERSPEECH, P249.
   Garcia-Romero D, 2012, INT CONF ACOUST SPEE, P4257, DOI 10.1109/ICASSP.2012.6288859.
   Godin KW, 2013, INTERSPEECH, P3623.
   Gowda D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1166.
   Hanilci C, 2012, IEEE SIGNAL PROC LET, V19, P163, DOI 10.1109/LSP.2012.2184284.
   Hansen J. H., 2015, AFRLRIRSTR2015234 DE.
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851.
   Hasan T, 2014, IEEE-ACM T AUDIO SPE, V22, P381, DOI 10.1109/TASLP.2013.2292356.
   Hatch AO, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1471.
   Hernando J, 1997, IEEE T SPEECH AUDI P, V5, P80, DOI 10.1109/89.554273.
   Hirsch H.G., 2000, P ICSLP, p29 .
   Hu HT, 1998, ELECTRON LETT, V34, P1385, DOI 10.1049/el:19981003.
   Hu HT, 1998, IEE P-VIS IMAGE SIGN, V145, P303, DOI 10.1049/ip-vis:19982014.
   KAY SM, 1979, IEEE T ACOUST SPEECH, V27, P478, DOI 10.1109/TASSP.1979.1163275.
   KAY SM, 1980, IEEE T ACOUST SPEECH, V28, P292, DOI 10.1109/TASSP.1980.1163406.
   KAY SM, 1981, P IEEE, V69, P1380, DOI 10.1109/PROC.1981.12184.
   Kinnunen T, 2013, INT CONF ACOUST SPEE, P7229, DOI 10.1109/ICASSP.2013.6639066.
   Kinnunen T, 2012, IEEE T AUDIO SPEECH, V20, P1990, DOI 10.1109/TASL.2012.2191960.
   KROON P, 1991, IEEE T SIGNAL PROCES, V39, P733, DOI 10.1109/78.80859.
   LEE CH, 1988, IEEE T ACOUST SPEECH, V36, P642, DOI 10.1109/29.1574.
   Lei Y, 2013, INT CONF ACOUST SPEE, P6788, DOI 10.1109/ICASSP.2013.6638976.
   Liu G, 2014, IEEE-ACM T AUDIO SPE, V22, P1978, DOI 10.1109/TASLP.2014.2352154.
   Liu G, 2012, INT CONF ACOUST SPEE, P4233, DOI 10.1109/ICASSP.2012.6288853.
   MA CX, 1993, SPEECH COMMUN, V12, P69, DOI 10.1016/0167-6393(93)90019-H.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Mandasari MI, 2015, SPEECH COMMUN, V72, P126, DOI 10.1016/j.specom.2015.05.009.
   MANSOUR D, 1989, IEEE T ACOUST SPEECH, V37, P795, DOI 10.1109/ASSP.1989.28053.
   Markel JD, 1976, LINEAR PREDICTION SP.
   Martinez David, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4042, DOI 10.1109/ICASSP.2014.6854361.
   Nautsch A, 2016, P OD, P358.
   Padmanabhan R., 2009, P INTERSPEECH, P2355.
   PALIWAL KK, 1988, SIGNAL PROCESS, V15, P437, DOI 10.1016/0165-1684(88)90062-X.
   Pelecanos J., 2001, P SPEAK OD SPEAK REC, P213.
   Pohjalainen J., 2013, P INTERSPEECH, P1931.
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751.
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2231, DOI 10.1109/TASLP.2016.2598308.
   Rabiner L., 1993, FUNDAMENTALS SPEECH.
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361.
   Saeidi R., 2013, P INTERSPEECH, P1986.
   Saeidi R, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481420.
   Saeidi R, 2016, IEEE-ACM T AUDIO SPE, V24, P42, DOI 10.1109/TASLP.2015.2493366.
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649.
   Shannon BJ, 2006, SPEECH COMMUN, V48, P1458, DOI 10.1016/j.specom.2006.08.003.
   STOICA P, 1987, IEEE T ACOUST SPEECH, V35, P582, DOI 10.1109/TASSP.1987.1165162.
   Thomas S, 2008, IEEE SIGNAL PROC LET, V15, P681, DOI 10.1109/LSP.2008.2002708.
   Yan FR, 2016, IEEE ACCESS, V4, P5258, DOI 10.1109/ACCESS.2016.2607778.
   Yapanel UH, 2008, SPEECH COMMUN, V50, P142, DOI 10.1016/j.specom.2007.07.006.
   Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398.}},
Number-of-Cited-References = {{61}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{13}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{EY2RQ}},
Unique-ID = {{ISI:000403817500004}},
DA = {{2020-12-06}},
}

@article{ ISI:000407250100001,
Author = {Kryvonos, Iu. G. and Krak, Iu. V. and Barmak, O. V. and Bagriy, R. O.},
Title = {{PREDICTIVE TEXT TYPING SYSTEM FOR THE UKRAINIAN LANGUAGE}},
Journal = {{CYBERNETICS AND SYSTEMS ANALYSIS}},
Year = {{2017}},
Volume = {{53}},
Number = {{4}},
Pages = {{495-502}},
Month = {{JUL}},
Abstract = {{This paper investigates the intellectualization of text input using a
   system for accelerated input of texts into digital devices with a view
   to constructing a model of a corpus of the Ukrainian spoken language and
   a text typing system based on this model. Such a system uses a smaller
   number of commands to input letters and predicts variants of words on
   the basis of the corpus of words and word combinations for
   communication. It is experimentally shown that the input of texts using
   four and six command keys is rather efficient for the constructed
   corpus.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Krak, IV (Corresponding Author), Natl Acad Sci Ukraine, VM Glushkov Inst Cybernet, Kiev, Ukraine.
   Kryvonos, Iu. G.; Krak, Iu. V., Natl Acad Sci Ukraine, VM Glushkov Inst Cybernet, Kiev, Ukraine.
   Krak, Iu. V., Taras Shevchenko Natl Univ, Kiev, Ukraine.
   Barmak, O. V.; Bagriy, R. O., Khmelnytsky Natl Univ, Khmelnytsky, Ukraine.}},
DOI = {{10.1007/s10559-017-9951-5}},
ISSN = {{1060-0396}},
EISSN = {{1573-8337}},
Keywords = {{alternative communication; formation of a corpus of words; N-gram;
   prediction}},
Research-Areas = {{Computer Science; Mathematics}},
Web-of-Science-Categories  = {{Computer Science, Cybernetics; Mathematics, Interdisciplinary
   Applications}},
Author-Email = {{yuri.krak@gmail.com
   alexander.barmak@gmail.com
   gcardinal2009@gmail.com}},
ResearcherID-Numbers = {{Barmak, Alexander/I-2925-2018
   Bahrii, Ruslan О/I-2340-2018}},
ORCID-Numbers = {{Barmak, Alexander/0000-0003-0739-9678
   Bahrii, Ruslan О/0000-0001-5219-1185}},
Cited-References = {{Bird S, 2009, NATURAL LANGUAGE PRO.
   Darchuk N., 2010, B TARAS SHEVCHENKO U, P45.
   Demska-Kulchytska O., 2006, LEXICOGRAPHIC NEWSLE, P5.
   Jurafsky D., 2008, SPEECH LANGUAGE PROC.
   Krak Iu. V., 2017, J AUTOMATION INFORM, V49, P65.
   Kryvonos Iu. G., 2016, CYBERNET SYST, V52, P3.
   Sidorchuk N. M., 2006, MATH MACHINES SYSTEM, P126.}},
Number-of-Cited-References = {{7}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Cybern. Syst. Anal.}},
Doc-Delivery-Number = {{FD0SX}},
Unique-ID = {{ISI:000407250100001}},
DA = {{2020-12-06}},
}

@article{ ISI:000402212900006,
Author = {Molinaro, Nicola and Giannelli, Francesco and Caffarra, Sendy and
   Martin, Clara D.},
Title = {{Hierarchical levels of representation in language prediction: The
   influence of first language acquisition in highly proficient bilinguals}},
Journal = {{COGNITION}},
Year = {{2017}},
Volume = {{164}},
Pages = {{61-73}},
Month = {{JUL}},
Abstract = {{Language comprehension is largely supported by predictive mechanisms
   that account for the ease and speed with which communication unfolds.
   Both native and proficient non-native speakers can efficiently handle
   contextual cues to generate reliable linguistic expectations. However,
   the link between the variability of the linguistic background of the
   speaker and the hierarchical format of the representations predicted is
   still not clear. We here investigate whether native language exposure to
   typologically highly diverse languages (Spanish and Basque) affects the
   way early balanced bilingual speakers carry out language predictions.
   During Spanish sentence comprehension, participants developed
   predictions of words the form of which (noun ending) could be either
   diagnostic of grammatical gender values (transparent) or totally
   ambiguous (opaque). We measured electrophysiological prediction effects
   time-locked both to the target word and to its determiner, with the
   former being expected or unexpected. Event-related (N200-N400) and
   oscillatory activity in the low beta-band (15-17 Hz) frequency channel
   showed that both Spanish and Basque natives optimally carry out lexical
   predictions independently of word transparency. Crucially, in contrast
   to Spanish natives, Basque natives displayed visual word form
   predictions for transparent words, in consistency with the relevance
   that noun endings (post-nominal suffixes) play in their native language.
   We conclude that early language exposure largely shapes prediction
   mechanisms, so that bilinguals reading in their second language rely on
   the distributional regularities that are highly relevant in their first
   language. More importantly, we show that individual linguistic
   experience hierarchically modulates the format of the predicted
   representation. (C) 2017 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Molinaro, N (Corresponding Author), Basque Ctr Cognit Brain \& Language, BCBL, Paseo Mikeletegi 69,2, San Sebastian 20009, Spain.
   Molinaro, Nicola; Caffarra, Sendy; Martin, Clara D., Basque Ctr Cognit Brain \& Language, BCBL, Donostia San Sebastian, Spain.
   Molinaro, Nicola; Martin, Clara D., Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
   Giannelli, Francesco, Univ Milano Bicocca, Dipartimento Psicol, Milan, Italy.}},
DOI = {{10.1016/j.cognition.2017.03.012}},
ISSN = {{0010-0277}},
EISSN = {{1873-7838}},
Keywords = {{Prediction; Multilingualism; N200; Beta-band activity; Reading}},
Keywords-Plus = {{VISUAL WORD RECOGNITION; SEMANTIC INTEGRATION; GENDER AGREEMENT;
   TIME-COURSE; 2 ROUTES; COMPREHENSION; BRAIN; SPANISH; SPEECH;
   2ND-LANGUAGE}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{n.molinaro@bcbl.eu}},
ResearcherID-Numbers = {{Martin, Clara/B-4563-2012
   Caffarra, Sendy/P-5057-2015
   Molinaro, Nicola/D-2208-2014
   Caffarra, Sendy/P-9126-2019
   }},
ORCID-Numbers = {{Martin, Clara/0000-0003-2701-5045
   Caffarra, Sendy/0000-0003-3667-5061
   Molinaro, Nicola/0000-0002-7549-6042
   Caffarra, Sendy/0000-0003-3667-5061
   Giannelli, Francesco/0000-0003-3468-2567
   Basque Center on Cognition, Brain and Language, BCBL./0000-0002-8345-6892}},
Funding-Acknowledgement = {{Spanish Ministry of Economy and Competitiveness {[}PSI2012-32350,
   PSI2015-65694-P, PSI2014-54500-P]; Basque GovernmentBasque Government
   {[}PI\_2015\_1\_25]; Ikerbasque Research Fellowships; European
   Commission 7th Framework ProgrammeEuropean Union (EU); European Research
   CouncilEuropean Research Council (ERC) {[}ERC-2011-ADG-295362]; ``Centro
   de Excelencia Severo Ochoa{''} {[}SEV-2015-0490]}},
Funding-Text = {{This work was partially supported by the Spanish Ministry of Economy and
   Competitiveness (grants PSI2012-32350 and PSI2015-65694-P to N.M. and
   grant PSI2014-54500-P to C.M. and S.C.), by the Basque Government (grant
   PI\_2015\_1\_25 to C.M. and S.C.) and by the Ikerbasque Research
   Fellowships to N.M and C.M.; Further support derived from the AThEME
   project funded by the European Commission 7th Framework Programme, the
   ERC-2011-ADG-295362 from the European Research Council and the award
   ``Centro de Excelencia Severo Ochoa SEV-2015-0490{''}.}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103.
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Bastos AM, 2015, NEURON, V85, P390, DOI 10.1016/j.neuron.2014.12.018.
   Brothers T, 2015, COGNITION, V136, P135, DOI 10.1016/j.cognition.2014.10.017.
   Caffarra S, 2015, BRAIN RES, V1605, P83, DOI 10.1016/j.brainres.2015.02.018.
   Caffarra S, 2014, NEUROPSYCHOLOGIA, V63, P124, DOI 10.1016/j.neuropsychologia.2014.08.016.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Clahsen H, 2006, APPL PSYCHOLINGUIST, V27, P3, DOI 10.1017/S0142716406060024.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DeRijk RPG, 2007, CURR STUD LINGUIST, P1.
   Duchon A, 2013, BEHAV RES METHODS, V45, P1246, DOI 10.3758/s13428-013-0326-1.
   Dussias PE, 2010, SECOND LANG RES, V26, P443, DOI 10.1177/0267658310373326.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 2005, MEM COGNITION, V33, P871, DOI 10.3758/BF03193082.
   Ferreira F, 2013, J MEM LANG, V69, P165, DOI 10.1016/j.jml.2013.06.001.
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Gervain J, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00689.
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408.
   Gollan TH, 2001, J PSYCHOLINGUIST RES, V30, P627, DOI 10.1023/A:1014235223566.
   GUTHRIE D, 1991, PSYCHOPHYSIOLOGY, V28, P240, DOI 10.1111/j.1469-8986.1991.tb00417.x.
   HARRIS JW, 1991, LINGUIST INQ, V22, P27.
   Holcomb PJ, 2006, J COGNITIVE NEUROSCI, V18, P1631, DOI 10.1162/jocn.2006.18.10.1631.
   Hopp H, 2013, SECOND LANG RES, V29, P33, DOI 10.1177/0267658312461803.
   Izura C, 2014, PSICOLOGICA, V35, P49.
   Janssen N, 2015, CEREB CORTEX, V25, P2960, DOI 10.1093/cercor/bhu092.
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa.
   Kim A, 2012, J COGNITIVE NEUROSCI, V24, P1104, DOI 10.1162/jocn\_a\_00148.
   King JW, 1998, NEUROSCI LETT, V244, P61, DOI 10.1016/S0304-3940(98)00140-2.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   Laka I, 1996, BRIEF GRAMMAR EUSKAR.
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0.
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014.
   MacWhinney B., 2015, BILING-LANG COGN, V19, P19.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024.
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   Michalareas G, 2016, NEURON, V89, P384, DOI 10.1016/j.neuron.2015.12.018.
   Molinaro N, 2008, PSYCHOPHYSIOLOGY, V45, P1008, DOI 10.1111/j.1469-8986.2008.00694.x.
   Molinaro N, 2016, LANG COGN NEUROSCI, V31, P145, DOI 10.1080/23273798.2015.1077978.
   Molinaro N, 2013, NEUROIMAGE, V78, P339, DOI 10.1016/j.neuroimage.2013.04.025.
   Molinaro N, 2013, NEUROIMAGE, V72, P120, DOI 10.1016/j.neuroimage.2013.01.031.
   Molinaro N, 2012, NEUROIMAGE, V59, P3488, DOI 10.1016/j.neuroimage.2011.11.009.
   Molinaro N, 2010, COGN NEUROSCI, V1, P1, DOI 10.1080/17588920903373952.
   Molnar M, 2014, LANG LEARN, V64, P45, DOI 10.1111/lang.12069.
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/156869.
   Osterhout L, 1997, BIOL PSYCHOL, V46, P143, DOI 10.1016/S0301-0511(97)05250-2.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   R Core Team, 2015, R LANG ENV STAT COMP.
   Rescorla R. A., 1972, CLASSICAL CONDITION, V2, P64, DOI DOI 10.1101/GR.110528.110.
   Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593.
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113.
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{24}},
Journal-ISO = {{Cognition}},
Doc-Delivery-Number = {{EW0WW}},
Unique-ID = {{ISI:000402212900006}},
DA = {{2020-12-06}},
}

@article{ ISI:000407397100006,
Author = {Liu, Peng and Li, Songbin and Wang, Haiqiang},
Title = {{Steganography in vector quantization process of linear predictive coding
   for low-bit-rate speech codec}},
Journal = {{MULTIMEDIA SYSTEMS}},
Year = {{2017}},
Volume = {{23}},
Number = {{4}},
Pages = {{485-497}},
Month = {{JUL}},
Abstract = {{In this paper, we focus on quantization-indexmodulation (QIM)
   steganography in low-bit-rate speech codec and contribute to improve its
   steganalysis resistance. A novel QIM steganography is proposed based on
   the replacement of quantization index set in linear predictive coding
   (LPC). In this method, each quantization index set is seen as a point in
   quantization index space. Steganography is conducted in such space.
   Comparing with other methods, our algorithm significantly improves the
   embedding efficiency. One quantization index needs to be changed at most
   when three binary bits are hidden. The number of alterations introduced
   by the proposed approach is much lower than that of the current methods
   with the same embedding rate. Due to the fewer cover changes, the
   proposed steganography is less detectable. Moreover, a division strategy
   based on the genetic algorithm is proposed to reduce the additional
   distortion introduced by replacements. In our experiment, ITU-T G.723.1
   is selected as the codec, and the experimental results show that the
   proposed approach outperforms the state-of-the-art LPC-based approach in
   low-bit-rate speech codec with respect to both stegano-graphic capacity
   and steganalysis resistance.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Li, SB (Corresponding Author), Chinese Acad Sci, Inst Acoust, Haikou Lab, Haikou 570105, Hainan, Peoples R China.
   Liu, Peng; Li, Songbin, Chinese Acad Sci, Inst Acoust, Haikou Lab, Haikou 570105, Hainan, Peoples R China.
   Wang, Haiqiang, Univ Southern Calif, Los Angeles, CA USA.}},
DOI = {{10.1007/s00530-015-0500-7}},
ISSN = {{0942-4962}},
EISSN = {{1432-1882}},
Keywords = {{Information hiding; Linear predictive coding; Low bit-rate speech; Voice
   over Internet Protocol; Quantization index modulation; Steganalysis}},
Keywords-Plus = {{CODEBOOK PARTITION; INDEX MODULATION; WATERMARKING}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{lisb@dsp.ac.cn
   haiqianw@usc.edu}},
Funding-Acknowledgement = {{Natural Science Foundation of Nation and Hainan Province of China
   {[}61303249, 614236]; Important Science and Technology Project of Hainan
   Province of China {[}JDJS2013006]; Preferred Foundation of Director of
   Institute of Acoustics, Chinese Academy of Sciences; Young Talent
   Frontier Project of Institute of Acoustics, Chinese Academy of Sciences}},
Funding-Text = {{This work is supported partly by Natural Science Foundation of Nation
   and Hainan Province of China under Grant 61303249 and 614236, partly by
   Important Science and Technology Project of Hainan Province of China
   under Grant JDJS2013006, partly by Preferred Foundation of Director of
   Institute of Acoustics, Chinese Academy of Sciences, and partly by the
   Young Talent Frontier Project of Institute of Acoustics, Chinese Academy
   of Sciences.}},
Cited-References = {{{[}Anonymous], 2001, P862 ITUT.
   {[}Anonymous], 2015, INT CALL VOLUMES GRO.
   {[}Anonymous], 2007, P501 ITUT.
   Bierbrauer J, 2008, LECT NOTES COMPUT SC, V4920, P1, DOI 10.1007/978-3-540-69019-1\_1.
   Bo XA, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.375.
   Bohme R, 2010, ADV STAT STEGANALYSI.
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306.
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725.
   Chiang YK, 2008, FUND INFORM, V82, P15.
   Crandall R., 1998, SOME NOTES STEGANOGR.
   Fridrich J., 2006, P 8 INT WORKSH INF H, P282.
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281.
   Huang YF, 2011, IEEE T INF FOREN SEC, V6, P296, DOI 10.1109/TIFS.2011.2108649.
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599.
   Jin Liu, 2012, IEEE International Conference on Communications (ICC 2012), P1133, DOI 10.1109/ICC.2012.6363997.
   Kratzer C., 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C), DOI 10.1109/ISCAS.2006.1693105.
   Li SB, 2012, J ZHEJIANG U-SCI C, V13, P624, DOI 10.1631/jzus.C1100374.
   Lin C, 2006, IEEE SYS MAN CYBERN, P2380, DOI 10.1109/ICSMC.2006.385219.
   Liu LH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P406, DOI 10.1109/IIH-MSP.2008.297.
   Lu ZM, 2005, IEICE T INF SYST, VE88D, P330, DOI 10.1093/ietisy/E88-D.2.330.
   Mazurczyk W, 2008, LECT NOTES COMPUT SC, V5332, P1001.
   Tian H., 2011, COMPUT J.
   Tian H, 2009, P 44 IEEE INT C COMM, P1.
   Tian H, 2014, MULTIMEDIA SYST, V20, P143, DOI 10.1007/s00530-013-0302-8.
   Tian H, 2009, ISCAS: 2009 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-5, P2922, DOI 10.1109/ISCAS.2009.5118414.
   Tutte W.T., 2001, GRAPH THEORY, P233.
   Wang FH, 2007, J NETW COMPUT APPL, V30, P4, DOI 10.1016/j.jnca.2005.08.002.
   Westfeld A., 2001, 4 INF HID WORKSH.
   Wu Zhi-jun, 2009, Journal of China Universities of Posts and Telecommunications, V16, P103, DOI 10.1016/S1005-8885(08)60295-2.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{Multimedia Syst.}},
Doc-Delivery-Number = {{FD2XC}},
Unique-ID = {{ISI:000407397100006}},
DA = {{2020-12-06}},
}

@article{ ISI:000402671200016,
Author = {Li, Yaxing and Kang, Sangwon},
Title = {{Deep neural network-based linear predictive parameter estimations for
   speech enhancement}},
Journal = {{IET SIGNAL PROCESSING}},
Year = {{2017}},
Volume = {{11}},
Number = {{4}},
Pages = {{469-476}},
Month = {{JUN}},
Abstract = {{This study presents a speech enhancement technique to improve noise
   corrupted speech via deep neural network (DNN)-based linear predictive
   (LP) parameter estimations of speech and noise. With regard to the LP
   coefficient estimation, an enhanced estimation method using a DNN with
   multiple layers was proposed. Excitation variances were then estimated
   via a maximum-likelihood scheme using observed noisy speech and
   estimated LP coefficients. A time-smoothed Wiener filter was further
   introduced to improve the enhanced speech quality. Performance was
   evaluated via log spectral distance, a composite multivariate adaptive
   regression splines modelling-based measure, and a segmental
   signal-to-noise ratio. The experimental results revealed that the
   proposed scheme outperformed competing methods.}},
Publisher = {{INST ENGINEERING TECHNOLOGY-IET}},
Address = {{MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kang, S (Corresponding Author), Hanyang Univ, Dept Elect \& Commun Engn, Ansan 426791, South Korea.
   Li, Yaxing; Kang, Sangwon, Hanyang Univ, Dept Elect \& Commun Engn, Ansan 426791, South Korea.}},
DOI = {{10.1049/iet-spr.2016.0477}},
ISSN = {{1751-9675}},
EISSN = {{1751-9683}},
Keywords = {{speech enhancement; parameter estimation; neural nets; maximum
   likelihood estimation; Wiener filters; regression analysis; splines
   (mathematics); deep neural network; linear predictive parameter
   estimation; speech enhancement technique; LP parameter estimation
   method; DNN; maximum-likelihood scheme; time-smoothed Wiener filter;
   performance evaluation; log spectral distance evaluation; composite
   multivariate adaptive regression spline modelling; signal-to-noise ratio}},
Keywords-Plus = {{DIVERGENCE; NOISE}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{swkang@hanyang.ac.kr}},
Funding-Acknowledgement = {{research fund of the Signal Intelligence Research Center}},
Funding-Text = {{This work was supported by a research fund of the Signal Intelligence
   Research Center supervised by the Defense Acquisition Program
   Administration and Agency for Defense Development of Korea.}},
Cited-References = {{{[}Anonymous], 1994, MULT SPEECH DAT TEL.
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   CARLSON BA, 1991, IEEE T PATTERN ANAL, V13, P1255, DOI 10.1109/34.106999.
   Deng F, 2016, SPEECH COMMUN, V79, P30, DOI 10.1016/j.specom.2016.02.006.
   Eguchi S, 2006, J MULTIVARIATE ANAL, V97, P2034, DOI 10.1016/j.jmva.2006.03.007.
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550.
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453.
   Erhan D, 2010, J MACH LEARN RES, V11, P625.
   GAROFOLO JS, 1988, GETTING STARTED DARP.
   GRAY RM, 1980, IEEE T ACOUST SPEECH, V28, P367, DOI 10.1109/TASSP.1980.1163421.
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647.
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   ITU-R, 2001, PERC EV SPEECH QUAL, P862.
   ITU-T Recommendation, 2012, TEST SIGN US TEL, P501.
   Jacobsen A. P., 2015, THESIS AALBORG U.
   Kay S. M., 1993, FUNDAMENTALS STAT SI, V1.
   Kondoz A. M., 2004, DIGITAL SPEECH CODIN.
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694.
   Li Y, 2016, IET SIGNAL PROCESS, V10, P422, DOI 10.1049/iet-spr.2015.0375.
   Ling ZH, 2015, IEEE SIGNAL PROC MAG, V32, P35, DOI 10.1109/MSP.2014.2359987.
   Liu D., 2014, INTERSPEECH, P2685.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Sameti H, 1998, IEEE T SPEECH AUDI P, V6, P445, DOI 10.1109/89.709670.
   Srinivasan S, 2006, IEEE T AUDIO SPEECH, V14, P163, DOI 10.1109/TSA.2005.854113.
   Srinivasan S, 2007, IEEE T AUDIO SPEECH, V15, P441, DOI 10.1109/TASL.2006.881696.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.
   Veisi H, 2013, SPEECH COMMUN, V55, P205, DOI 10.1016/j.specom.2012.08.005.
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961.
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240.
   Yamashita T, 2014, INT C PATT RECOG, P1520, DOI 10.1109/ICPR.2014.270.
   Yegnanarayana B, 2000, IEEE T SPEECH AUDI P, V8, P267, DOI 10.1109/89.841209.
   Zhang XL, 2016, IEEE-ACM T AUDIO SPE, V24, P967, DOI 10.1109/TASLP.2016.2536478.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{IET Signal Process.}},
Doc-Delivery-Number = {{EW7DY}},
Unique-ID = {{ISI:000402671200016}},
DA = {{2020-12-06}},
}

@article{ ISI:000402191500001,
Author = {Jaeger, T. Florian and Weatherholtz, Kodi},
Title = {{What the Heck Is Salience? How Predictive Language Processing
   Contributes to Sociolinguistic Perception (vol 7, 1115, 2016)}},
Journal = {{FRONTIERS IN PSYCHOLOGY}},
Year = {{2017}},
Volume = {{8}},
Month = {{MAY 29}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND}},
Type = {{Correction}},
Language = {{English}},
Affiliation = {{Jaeger, TF (Corresponding Author), Univ Rochester, Dept Brain \& Cognit Sci, Human Language Proc Lab, Rochester, NY 14627 USA.
   Jaeger, TF (Corresponding Author), Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
   Jaeger, TF (Corresponding Author), Univ Rochester, Dept Linguist, Rochester, NY 14627 USA.
   Jaeger, T. Florian; Weatherholtz, Kodi, Univ Rochester, Dept Brain \& Cognit Sci, Human Language Proc Lab, Rochester, NY 14627 USA.
   Jaeger, T. Florian, Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
   Jaeger, T. Florian, Univ Rochester, Dept Linguist, Rochester, NY 14627 USA.}},
DOI = {{10.3389/fpsyg.2017.00902}},
Article-Number = {{902}},
ISSN = {{1664-1078}},
Keywords = {{accent; dialect; idiolect; salience; surprisal; prediction; expectation;
   learning}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{fjaeger@ur.rochester.edu}},
ResearcherID-Numbers = {{Jaeger, T. Florian/O-8224-2019}},
ORCID-Numbers = {{Jaeger, T. Florian/0000-0002-1158-7308}},
Cited-References = {{Jaeger TF, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01115.}},
Number-of-Cited-References = {{1}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Front. Psychol.}},
Doc-Delivery-Number = {{EW0OR}},
Unique-ID = {{ISI:000402191500001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000399169600012,
Author = {Johari, Karim and Behroozmand, Roozbeh},
Title = {{Premotor neural correlates of predictive motor timing for speech
   production and hand movement: evidence for a temporal predictive code in
   the motor system}},
Journal = {{EXPERIMENTAL BRAIN RESEARCH}},
Year = {{2017}},
Volume = {{235}},
Number = {{5}},
Pages = {{1439-1453}},
Month = {{MAY}},
Abstract = {{The predictive coding model suggests that neural processing of sensory
   information is facilitated for temporally-predictable stimuli. This
   study investigated how temporal processing of visually-presented sensory
   cues modulates movement reaction time and neural activities in speech
   and hand motor systems. Event-related potentials (ERPs) were recorded in
   13 subjects while they were visually-cued to prepare to produce a steady
   vocalization of a vowel sound or press a button in a randomized order,
   and to initiate the cued movement following the onset of a go signal on
   the screen. Experiment was conducted in two counterbalanced blocks in
   which the time interval between visual cue and go signal was
   temporally-predictable (fixed delay at 1000 ms) or unpredictable
   (variable between 1000 and 2000 ms). Results of the behavioral response
   analysis indicated that movement reaction time was significantly
   decreased for temporally-predictable stimuli in both speech and hand
   modalities. We identified premotor ERP activities with a
   left-lateralized parietal distribution for hand and a frontocentral
   distribution for speech that were significantly suppressed in response
   to temporally-predictable compared with unpredictable stimuli. The
   premotor ERPs were elicited approximately -100 ms before movement and
   were significantly correlated with speech and hand motor reaction times
   only in response to temporally-predictable stimuli. These findings
   suggest that the motor system establishes a predictive code to
   facilitate movement in response to temporally-predictable sensory
   stimuli. Our data suggest that the premotor ERP activities are robust
   neurophysiological biomarkers of such predictive coding mechanisms.
   These findings provide novel insights into the temporal processing
   mechanisms of speech and hand motor systems.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Behroozmand, R (Corresponding Author), Univ South Carolina, Speech Neurosci Lab, Dept Commun Sci \& Disorders, 1224 Sumter St, Columbia, SC 29208 USA.
   Johari, Karim; Behroozmand, Roozbeh, Univ South Carolina, Speech Neurosci Lab, Dept Commun Sci \& Disorders, 1224 Sumter St, Columbia, SC 29208 USA.}},
DOI = {{10.1007/s00221-017-4900-0}},
ISSN = {{0014-4819}},
EISSN = {{1432-1106}},
Keywords = {{Predictive code; Temporal processing; Internal forward model; Speech
   production; Hand movement; ERP}},
Keywords-Plus = {{SIMPLE REACTION-TIME; MISMATCH NEGATIVITY; PARKINSONS-DISEASE;
   AUDITORY-CORTEX; FEEDBACK-CONTROL; TASK COMPLEXITY; UNCERTAINTY;
   FOREPERIOD; PREDICTABILITY; PITCH}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{r-behroozmand@sc.edu}},
ResearcherID-Numbers = {{Johari, Karim/C-7552-2013
   Johari, Karim/N-5396-2019}},
ORCID-Numbers = {{Johari, Karim/0000-0002-0295-7397}},
Cited-References = {{Alegre M, 2003, NEUROREPORT, V14, P381, DOI 10.1097/01.wnr.0000059624.96928.c0.
   Aliu SO, 2009, J COGNITIVE NEUROSCI, V21, P791, DOI 10.1162/jocn.2009.21055.
   Baker KS, 2012, NEUROPSYCHOLOGIA, V50, P715, DOI 10.1016/j.neuropsychologia.2011.12.026.
   BARD C, 1992, NEUROPSYCHOLOGIA, V30, P201, DOI 10.1016/0028-3932(92)90028-K.
   Behroozmand R, 2016, BRAIN RES, V1636, P1, DOI 10.1016/j.brainres.2016.01.040.
   Behroozmand R, 2016, J NEUROSCI, V36, P2302, DOI 10.1523/JNEUROSCI.3305-14.2016.
   Behroozmand R, 2011, BMC NEUROSCI, V12, DOI 10.1186/1471-2202-12-54.
   Behroozmand R, 2011, J COGNITIVE NEUROSCI, V23, P1205, DOI 10.1162/jocn.2010.21447.
   BERTELSON P, 1960, NATURE, V187, P531, DOI 10.1038/187531a0.
   BEVAN W, 1965, PERCEPT MOTOR SKILL, V20, P969, DOI 10.2466/pms.1965.20.3.969.
   Blakemore SJ, 1998, NAT NEUROSCI, V1, P635, DOI 10.1038/2870.
   Blakemore SJ, 2003, EXP BRAIN RES, V153, P239, DOI 10.1007/s00221-003-1597-z.
   Blakemore SJ, 2000, NEUROREPORT, V11, pR11, DOI 10.1097/00001756-200008030-00002.
   BLOXHAM CA, 1984, BRAIN, V107, P371, DOI 10.1093/brain/107.2.371.
   BLOXHAM CA, 1987, J NEUROL NEUROSUR PS, V50, P1178, DOI 10.1136/jnnp.50.9.1178.
   Chang EF, 2013, P NATL ACAD SCI USA, V110, P2653, DOI 10.1073/pnas.1216827110.
   Chen ZC, 2012, BMC NEUROSCI, V13, DOI 10.1186/1471-2202-13-55.
   Conradi N, 2016, NEUROIMAGE, V139, P211, DOI 10.1016/j.neuroimage.2016.06.033.
   Cornella M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043604.
   Coull JT, 2016, NEUROIMAGE, V141, P40, DOI 10.1016/j.neuroimage.2016.07.036.
   Crowe DA, 2014, J NEUROSCI, V34, P11972, DOI 10.1523/JNEUROSCI.2177-14.2014.
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009.
   Dieterich R, 2016, COGN AFFECT BEHAV NE, V16, P447, DOI 10.3758/s13415-016-0405-8.
   DRAZIN DH, 1961, J EXP PSYCHOL, V62, P43, DOI 10.1037/h0046860.
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630.
   Faul F., 1992, GPOWER PRIORI POSTHO.
   Flanagan JR, 2003, CURR BIOL, V13, P146, DOI 10.1016/S0960-9822(03)00007-1.
   Gajewski PD, 2013, INT J PSYCHOPHYSIOL, V87, P273, DOI 10.1016/j.ijpsycho.2012.08.007.
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001.
   Heinks-Maldonado TH, 2005, PSYCHOPHYSIOLOGY, V42, P180, DOI 10.1111/j.1469-8986.2005.00272.x.
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140.
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082.
   Hsu M, 2005, SCIENCE, V310, P1680, DOI 10.1126/science.1115327.
   Ivry R B, 1989, J Cogn Neurosci, V1, P136, DOI 10.1162/jocn.1989.1.2.136.
   Jahanshahi M, 2006, J NEUROSCI, V26, P12266, DOI 10.1523/JNEUROSCI.2540-06.2006.
   JOHANSSON RS, 1988, EXP BRAIN RES, V71, P59.
   KARLIN L, 1959, J EXP PSYCHOL, V58, P185, DOI 10.1037/h0049152.
   KLEMMER ET, 1956, J EXP PSYCHOL, V51, P179, DOI 10.1037/h0042317.
   Kotz SA, 2015, CORTEX, V68, P48, DOI 10.1016/j.cortex.2015.02.021.
   Kuhn AA, 2004, BRAIN, V127, P735, DOI 10.1093/brain/awh106.
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863.
   Ma H, 2004, AM J OCCUP THER, V58, P150, DOI 10.5014/ajot.58.2.150.
   Mattes S, 1997, PERCEPT PSYCHOPHYS, V59, P1089, DOI 10.3758/BF03205523.
   Mendoza G, 2014, PROG NEUROBIOL, V122, P73, DOI 10.1016/j.pneurobio.2014.09.001.
   Merchant H, 2015, EUR J NEUROSCI, V41, P586, DOI 10.1111/ejn.12811.
   Merchant H, 2013, J NEUROSCI, V33, P9082, DOI 10.1523/JNEUROSCI.5513-12.2013.
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4.
   Mifsud NG, 2016, PSYCHOPHYSIOLOGY, V53, P723, DOI 10.1111/psyp.12605.
   Moberget T, 2008, NEUROPSYCHOLOGIA, V46, P2569, DOI 10.1016/j.neuropsychologia.2008.03.016.
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026.
   NIEMI P, 1981, PSYCHOL BULL, V89, P133, DOI 10.1037/0033-2909.89.1.133.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   PASTOR MA, 1992, BRAIN, V115, P211, DOI 10.1093/brain/115.1.211.
   Praamstra P, 2007, J NEUROPHYSIOL, V98, P2848, DOI 10.1152/jn.00224.2007.
   Roux S, 2006, BEHAV BRAIN RES, V169, P335, DOI 10.1016/j.bbr.2006.02.004.
   Schwartze M, 2011, BIOL PSYCHOL, V87, P146, DOI 10.1016/j.biopsycho.2011.02.021.
   Symonds RM, 2017, BRAIN TOPOGR, V30, P136, DOI 10.1007/s10548-016-0529-8.
   Thickbroom GW, 2000, BRAIN RES, V874, P233, DOI 10.1016/S0006-8993(00)02588-9.
   Timm J, 2016, CORTEX, V80, P5, DOI 10.1016/j.cortex.2016.03.018.
   Toyomaki A, 2008, PROG NEURO-PSYCHOPH, V32, P95, DOI 10.1016/j.pnpbp.2007.07.020.
   Vallesi A, 2007, CEREB CORTEX, V17, P466, DOI 10.1093/cercor/bhj163.
   Vallesi A, 2009, J COGNITIVE NEUROSCI, V21, P1116, DOI 10.1162/jocn.2009.21098.
   van Zuijen TL, 2005, COGNITIVE BRAIN RES, V23, P270, DOI 10.1016/j.cogbrainres.2004.10.007.
   Ventura MI, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-58.
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012.
   Witney AG, 1999, J NEUROPHYSIOL, V82, P2039.
   Wolpert DM, 2011, NAT REV NEUROSCI, V12, P739, DOI 10.1038/nrn3112.
   Wolpert DM, 1997, TRENDS COGN SCI, V1, P209, DOI 10.1016/S1364-6613(97)01070-X.
   Wolpert DM, 2001, CURR BIOL, V11, pR729, DOI 10.1016/S0960-9822(01)00432-8.
   Wolpert DM, 2001, TRENDS COGN SCI, V5, P487, DOI 10.1016/S1364-6613(00)01773-3.}},
Number-of-Cited-References = {{72}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Exp. Brain Res.}},
Doc-Delivery-Number = {{ER9TL}},
Unique-ID = {{ISI:000399169600012}},
DA = {{2020-12-06}},
}

@article{ ISI:000398941500012,
Author = {Ito, Aine and Martin, Andrea E. and Nieuwland, Mante S.},
Title = {{On Predicting Form and Meaning in a Second Language}},
Journal = {{JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION}},
Year = {{2017}},
Volume = {{43}},
Number = {{4}},
Pages = {{635-652}},
Month = {{APR}},
Abstract = {{We used event-related potentials (ERP) to investigate whether
   Spanish-English bilinguals preactivate form and meaning of predictable
   words. Participants read high-cloze sentence contexts (e.g., ``The
   student is going to the library to borrow a...{''}), followed by the
   predictable word (book), a word that was form-related (hook) or
   semantically related (page) to the predictable word, or an unrelated
   word (sofa). Word stimulus onset synchrony (SOA) was 500 ms (Experiment
   1) or 700 ms (Experiment 2). In both experiments, all nonpredictable
   words elicited classic N400 effects. Form-related and unrelated words
   elicited similar N400 effects. Semantically related words elicited
   smaller N400s than unrelated words, which however, did not depend on
   cloze value of the predictable word. Thus, we found no N400 evidence for
   preactivation of form or meaning at either SOA, unlike native-speaker
   results (Ito, Corley et al., 2016). However, non-native speakers did
   show the post-N400 posterior positivity (LPC effect) for form-related
   words like native speakers, but only at the slower SOA. This LPC effect
   increased gradually with cloze value of the predictable word. We do not
   interpret this effect as necessarily demonstrating prediction, but
   rather as evincing combined effects of top-down activation (contextual
   meaning) and bottom-up activation (form similarity) that result in
   activation of unseen words that fit the context well, thereby leading to
   an interpretation conflict reflected in the LPC. Although there was no
   evidence that non-native speakers preactivate form or meaning,
   non-native speakers nonetheless appear to use bottom-up and top-down
   information to constrain incremental interpretation much like native
   speakers do.}},
Publisher = {{AMER PSYCHOLOGICAL ASSOC}},
Address = {{750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ito, A (Corresponding Author), Univ Edinburgh, Dept Psychol, Sch Philosophy Psychol \& Language Sci, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.
   Ito, Aine; Martin, Andrea E.; Nieuwland, Mante S., Univ Edinburgh, Dept Psychol, Sch Philosophy Psychol \& Language Sci, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.}},
DOI = {{10.1037/xlm0000315}},
ISSN = {{0278-7393}},
EISSN = {{1939-1285}},
Keywords = {{non-native language comprehension; prediction; N400; LPC; SOA}},
Keywords-Plus = {{WORD ANTICIPATION; L2; COMPREHENSION; POTENTIALS; TIME; ERP;
   PLAUSIBILITY; PROFICIENCY; REANALYSIS; QUESTIONS}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology; Psychology, Experimental}},
Author-Email = {{aine.ito@ed.ac.uk}},
ResearcherID-Numbers = {{Ito, Aine/I-6828-2019}},
ORCID-Numbers = {{Ito, Aine/0000-0003-4408-8801}},
Funding-Acknowledgement = {{Economic and Social Research CouncilEconomic \& Social Research Council
   (ESRC) {[}ES/K009095/1] Funding Source: researchfish}},
Cited-References = {{Baayen HR, 2008, J MEM LANG, V59, P390, DOI DOI 10.1016/J.JML.2007.12.005.
   Bates E, 1989, CROSSLINGUISTIC STUD, P3.
   Blumenfeld Henrike, 2007, LANG COGNITIVE PROC, V22, P633, DOI {[}10.1080/01690960601000746, DOI 10.1080/01690960601000746].
   Chambers CG, 2009, J EXP PSYCHOL LEARN, V35, P1029, DOI 10.1037/a0015901.
   Clahsen H, 2006, APPL PSYCHOLINGUIST, V27, P3, DOI 10.1017/S0142716406060024.
   Dambacher M, 2012, NEUROPSYCHOLOGIA, V50, P1852, DOI 10.1016/j.neuropsychologia.2012.04.011.
   DUSSIAS PE, 2010, SECOND LANG RES, V26, P443, DOI DOI 10.1177/0267658310373326.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756.
   Hopp H, 2006, SECOND LANG RES, V22, P369, DOI 10.1191/0267658306sr272oa.
   Hopp H, 2013, SECOND LANG RES, V29, P33, DOI 10.1177/0267658312461803.
   Hopp H, 2009, BILING-LANG COGN, V12, P463, DOI 10.1017/S1366728909990253.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Ito A., 2016, ROBUST ARE PREDICTIO.
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007.
   Ivanova I, 2008, ACTA PSYCHOL, V127, P277, DOI 10.1016/j.actpsy.2007.06.003.
   Jackson CN, 2009, APPL PSYCHOLINGUIST, V30, P603, DOI 10.1017/S014271640999004X.
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084.
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa.
   Kotz SA, 2004, J NEUROLINGUIST, V17, P215, DOI 10.1016/S0911-6044(03)00058-7.
   Kotz SA, 2009, BRAIN LANG, V109, P68, DOI 10.1016/j.bandl.2008.06.002.
   Kroll J. F., 2005, HDB BILINGUALISM PSY.
   Kroll JF, 2013, ANNU REV APPL LINGUI, V33, P102, DOI 10.1017/S0267190513000111.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   Lew-Williams C, 2010, J MEM LANG, V63, P447, DOI 10.1016/j.jml.2010.07.003.
   Marinis T, 2005, STUD SECOND LANG ACQ, V27, P53, DOI 10.1017/S0272263105050035.
   Martin A. E., 2016, LANGUAGE SPEECH.
   Martin AE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00120.
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   Mitsugi S, 2016, BILING-LANG COGN, V19, P19, DOI 10.1017/S1366728914000881.
   Nieuwland MS, 2015, J COGNITIVE NEUROSCI, V27, P2215, DOI 10.1162/jocn\_a\_00856.
   Nieuwland MS, 2014, J MEM LANG, V76, P1, DOI 10.1016/j.jml.2014.06.002.
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463.
   Pullum G. K., 1988, LINGUISTICS CAMBRIDG, P255.
   Roberts L, 2011, APPL PSYCHOLINGUIST, V32, P299, DOI 10.1017/S0142716410000421.
   Shook A, 2013, BILING-LANG COGN, V16, P304, DOI 10.1017/S1366728912000466.
   Staub A, 2015, J MEM LANG, V82, P1, DOI 10.1016/j.jml.2015.02.004.
   Tanner D, 2013, BILING-LANG COGN, V16, P367, DOI 10.1017/S1366728912000302.
   Tokowicz N, 2005, STUD SECOND LANG ACQ, V27, P173, DOI 10.1017/S0272263105050102.
   Townsend D. J., 2001, COMPUTATIONAL LINGUI, V28, P238.
   Trenkic D, 2014, BILING-LANG COGN, V17, P237, DOI 10.1017/S1366728913000321.
   de Meerendonk N, 2009, LANG LINGUIST COMPAS, V3, DOI 10.1111/j.1749-818x.2009.00163.x.
   WeberFox CM, 1996, J COGNITIVE NEUROSCI, V8, P231, DOI 10.1162/jocn.1996.8.3.231.
   Williams JN, 2006, BILING-LANG COGN, V9, P71, DOI 10.1017/S1366728905002385.
   Wlotko EW, 2015, CORTEX, V68, P20, DOI 10.1016/j.cortex.2015.03.014.}},
Number-of-Cited-References = {{46}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{J. Exp. Psychol.-Learn. Mem. Cogn.}},
Doc-Delivery-Number = {{ER6TP}},
Unique-ID = {{ISI:000398941500012}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000401931700003,
Author = {Mussavi, Aghassi and Gorjian, Bahman},
Title = {{THE USE OF REFERRING AND PREDICTING ACTIVITIES ON LEARNING LANGUAGE
   FUNCTIONS AMONG SENIOR HIGH SCHOOL STUDENTS}},
Journal = {{MODERN JOURNAL OF LANGUAGE TEACHING METHODS}},
Year = {{2017}},
Volume = {{7}},
Number = {{3}},
Pages = {{35-45}},
Month = {{MAR}},
Abstract = {{This study investigated the use of referring and predicting activities
   in learning language functions among senior high school students. For
   the purpose of this study, 70 senior high school students who were
   studying English in Anzan high school in Izeh were selected
   non-randomly. They took Oxford Quick Placement Test (OQPT) to determine
   their level of proficiency as the pre-intermediate (i.e., 18 to 39 band
   score). Then they were non-randomly divided into two experimental groups
   of referring and predicting. i.e., each included 25 participants through
   non-random convenience sampling method. They met for two hours, once a
   week in 10 sessions. Then both groups were given a pre-test of language
   functions before treatment to determine how well the participants knew
   language those functions. During the ten sessions, they covered
   ten-dialogue texts of their text book. The referring group received
   instructions on referring activities (i.e., point to persons and objects
   directly or indirectly in a conversation) while the predicting group
   received predictive instructions (i.e., guessing on possible future
   events and opportunities based on available data). After the treatment
   sessions, the participants took the language function post-test. Data
   were analyzed through Independent and Paired Samples t-test and findings
   showed that the referring group outperformed the predicting group
   significantly. Implications of the study suggest that using predicting
   activities could be more effective than predicting functional activities
   in teaching language functions to senior high school students.}},
Publisher = {{MODERN JOURNAL LANGUAGE TEACHING METHODS}},
Address = {{NO 300, AHMADABAD ST, MASHHAD, 00000, IRAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gorjian, B (Corresponding Author), Islamic Azad Univ, Dept ELT, Abadan Branch, Abadan, Iran.
   Mussavi, Aghassi, Islamic Azad Univ, Dept ELT, Ahvaz Branch, Ahwaz, Iran.
   Gorjian, Bahman, Islamic Azad Univ, Dept ELT, Abadan Branch, Abadan, Iran.}},
EISSN = {{2251-6204}},
Keywords = {{Referring and predicting activities; language functions; senior high
   school students}},
Research-Areas = {{Education \& Educational Research}},
Web-of-Science-Categories  = {{Education \& Educational Research}},
Author-Email = {{bahgorji@yahoo.com}},
Cited-References = {{Akmajian A., 2010, INTRO LANGUAGE COMMU.
   Alcon E., 2005, SYSTEM, V33, P417, DOI DOI 10.1016/J.SYSTEM.2005.06.005.
   Soler EA, 2010, INT J ENGL STUD, V10, P65.
   Soler EA, 2008, SECOND LANG ACQUIS, V30, P3.
   Austin J.L., 1962, DO THINGS WORDS.
   Bach K., 1994, MIND LANG, V9, P124, DOI {[}DOI 10.1111/J.1468-0017.1994.TB00220.X, 10.1111/j.1468-0017.1994.tb00220.x].
   Barsalou L. W., 2009, SIMULATION SITUATED.
   Batjargal D., 2010, THESIS.
   Bayat N, 2013, PROCD SOC BEHV, V70, P213, DOI 10.1016/j.sbspro.2013.01.057.
   Chen H., 1996, SYSTEM, V33, P481.
   Friston KJ, 2009, NEURAL NETWORKS, V22, P1093, DOI 10.1016/j.neunet.2009.07.023.
   Gilbert DT, 2007, SCIENCE, V317, P1351, DOI 10.1126/science.1144161.
   Hudson Richard Anthony, 1996, SOCIOLINGUISTICS.
   Kasper Gabriele, 2002, PRAGMATIC DEV 2 LANG.
   Koike D. A., 2005, SYSTEM, V33, P481, DOI DOI 10.1016/J.SYSTEM.2005.06.008.
   Koosha B., 2012, ASIAN SOCIAL SCI, V8, P54.
   Kronfeld A., 1998, PRAGMAT COGN, V6, P189.
   PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295.
   Schultz W, 2000, ANNU REV NEUROSCI, V23, P473, DOI 10.1146/annurev.neuro.23.1.473.
   Searle John R., 1969, SPEECH ACTS ESSAY PH.
   SEARLE JR, 1976, LANG SOC, V5, P1, DOI 10.1017/S0047404500006837.
   Soozandehfar M., 2011, THEORY PRACTICE LANG, V1, P1831.
   Stevenson H., 1998, DO LUNCH OR BE LUNCH.
   Takahashi S., 1996, STUDIES 2 LANGUAGE A, V18, P189, DOI DOI 10.1017/S0272263100014881.
   Williams JMG, 1996, MEM COGNITION, V24, P116, DOI 10.3758/BF03197278.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Mod. J. Lang. Teach. Methods}},
Doc-Delivery-Number = {{EV7CK}},
Unique-ID = {{ISI:000401931700003}},
DA = {{2020-12-06}},
}

@article{ ISI:000401258700007,
Author = {Patel, Aniruddh D. and Morgan, Emily},
Title = {{Exploring Cognitive Relations Between Prediction in Language and Music}},
Journal = {{COGNITIVE SCIENCE}},
Year = {{2017}},
Volume = {{41}},
Number = {{2, SI}},
Pages = {{303-320}},
Month = {{MAR}},
Abstract = {{The online processing of both music and language involves making
   predictions about upcoming material, but the relationship between
   prediction in these two domains is not well understood.
   Electrophysiological methods for studying individual differences in
   prediction in language processing have opened the door to new questions.
   Specifically, we ask whether individuals with musical training predict
   upcoming linguistic material more strongly and/or more accurately than
   non-musicians. We propose two reasons why prediction in these two
   domains might be linked: (a) Musicians may have greater verbal
   short-term/working memory; (b) music may specifically reward predictions
   based on hierarchical structure. We provide suggestions as to how to
   expand upon recent work on individual differences in language processing
   to test these hypotheses.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Patel, AD (Corresponding Author), Tufts Univ, Dept Psychol, 490 Boston Ave, Medford, MA 02155 USA.
   Patel, Aniruddh D.; Morgan, Emily, Tufts Univ, Dept Psychol, 490 Boston Ave, Medford, MA 02155 USA.
   Patel, Aniruddh D., Canadian Inst Adv Res CIFAR, Azrieli Program Brain Mind \& Consciousness, Toronto, ON, Canada.}},
DOI = {{10.1111/cogs.12411}},
ISSN = {{0364-0213}},
EISSN = {{1551-6709}},
Keywords = {{Music; Language; Prediction; ERP; Individual differences}},
Keywords-Plus = {{WORKING-MEMORY; INDIVIDUAL-DIFFERENCES; PROCESSING MUSIC; NEURAL
   OVERLAP; BRAIN; SYNTAX; SPEECH; COMPREHENSION; EXPECTATIONS; PERCEPTION}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{a.patel@tufts.edu}},
ORCID-Numbers = {{Morgan, Emily/0000-0002-8891-3175}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arbib M. A., 2013, LANGUAGE MUSIC BRAIN, DOI {[}10.7551/mitpress/9780262018104.001.0001, DOI 10.7551/MITPRESS/9780262018104.001.0001].
   Arnon I, 2013, LANG SPEECH, V56, P349, DOI 10.1177/0023830913484891.
   Arnon I, 2010, J MEM LANG, V62, P67, DOI 10.1016/j.jml.2009.09.005.
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628.
   Benassi-Werke ME, 2012, Q J EXP PSYCHOL, V65, P1161, DOI 10.1080/17470218.2011.644799.
   Bigand E, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00094.
   Bod R., 2003, DATA ORIENTED PARSIN.
   Boudewyn MA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00060.
   Bregman MR, 2016, P NATL ACAD SCI USA, V113, P1666, DOI 10.1073/pnas.1515380113.
   Brown M, 2015, J EXP PSYCHOL HUMAN, V41, P306, DOI 10.1037/a0038689.
   Brown M, 2011, PSYCHON B REV, V18, P1189, DOI 10.3758/s13423-011-0167-9.
   Bybee J, 2006, LANGUAGE, V82, P711, DOI 10.1353/lan.2006.0186.
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Clayton KK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157638.
   Collins T, 2014, PSYCHOL REV, V121, P33, DOI 10.1037/a0034695.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DeLong KA, 2014, LANG LINGUIST COMPAS, V8, P631, DOI 10.1111/lnc3.12093.
   Egermann H, 2013, COGN AFFECT BEHAV NE, V13, P533, DOI 10.3758/s13415-013-0161-y.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Ferreira F, 2007, LANG LINGUIST COMPAS, V1, P71, DOI 10.1111/j.1749-818x.2007.00007.x.
   Fitch WT, 2014, PHYS LIFE REV, V11, P329, DOI 10.1016/j.plrev.2014.04.005.
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715.
   Fogel AR, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01718.
   Forgeard M, 2008, MUSIC PERCEPT, V25, P383, DOI 10.1525/MP.2008.25.4.383.
   Francois C, 2014, HEARING RES, V308, P122, DOI 10.1016/j.heares.2013.08.018.
   Franklin MS, 2008, PSYCHOL MUSIC, V36, P353, DOI 10.1177/0305735607086044.
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005.
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029.
   Gibson E, 2013, P NATL ACAD SCI USA, V110, P8051, DOI 10.1073/pnas.1216438110.
   Goldberg AE, 2003, TRENDS COGN SCI, V7, P219, DOI 10.1016/S1364-6613(03)00080-9.
   Hansen M, 2013, PSYCHOL MUSIC, V41, P779, DOI 10.1177/0305735612452186.
   Huron DB, 2006, SWEET ANTICIPATION M.
   Jackendoff R. S., 1992, LANGUAGES MIND ESSAY.
   Jackendoff R, 2006, COGNITION, V100, P33, DOI 10.1016/j.cognition.2005.11.005.
   Jackendoff R, 2017, COGNITIVE SCI, V41, P185, DOI 10.1111/cogs.12324.
   Jackendoff R, 2009, MUSIC PERCEPT, V26, P195, DOI 10.1525/MP.2009.26.3.195.
   Jentschke S, 2009, NEUROIMAGE, V47, P735, DOI 10.1016/j.neuroimage.2009.04.090.
   Johnson M., 2007, ADV NEURAL INFORM PR, V19, P641.
   JUST MA, 1992, PSYCHOL REV, V99, P122, DOI 10.1037/0033-295X.99.1.122.
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa.
   Koelsch S, 2005, J COGNITIVE NEUROSCI, V17, P1565, DOI 10.1162/089892905774597290.
   Koelsch S, 2002, PSYCHOPHYSIOLOGY, V39, P657, DOI 10.1017/S0048577202010508.
   Koelsch S., 2012, BRAIN AND MUSIC.
   Koelsch S, 2007, PSYCHOPHYSIOLOGY, V44, P476, DOI 10.1111/j.1469-8986.2007.00517.x.
   Koelsch S, 2013, P NATL ACAD SCI USA, V110, P15443, DOI 10.1073/pnas.1300272110.
   Koelsch S, 2009, PSYCHOPHYSIOLOGY, V46, P179, DOI 10.1111/j.1469-8986.2008.00752.x.
   Krumhans C., 1997, Music, Gestalt, and Computing. Studies in Cognitive and Systematic Musicology, P294.
   Krumhansl CL, 2015, MUSIC PERCEPT, V33, P20, DOI 10.1525/MP.2015.33.1.20.
   Kunert R, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.150685.
   Kunert R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141069.
   Kunert R, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00330.
   Kuperberg G. R., 2013, UNRAVELING BEHAV NEU, P176.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   LaCroix AN, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01138.
   Lamb SJ, 1993, ED PSYCHOL, V13, P13, DOI DOI 10.1080/0144341930130103.
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003.
   Lerdahl F., 1983, GENERATIVE THEORY TO.
   Lerdahl F, 2007, MUSIC PERCEPT, V24, P329, DOI 10.1525/MP.2007.24.4.329.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Maess B, 2001, NAT NEUROSCI, V4, P540.
   Magne C, 2016, BRAIN LANG, V153, P13, DOI 10.1016/j.bandl.2016.01.001.
   MARGULIS E. H., 2014, REPEAT MUSIC PLAYS M.
   Margulis EH, 2012, MUSIC PERCEPT, V29, P377, DOI 10.1525/MP.2012.29.4.377.
   Meyer L. B., 1956, EMOTION MEANING MUSI.
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120.
   Morgan E., 2016, THESIS.
   Nakano H, 2010, J COGNITIVE NEUROSCI, V22, P2886, DOI 10.1162/jocn.2009.21400.
   Narmour E., 1990, ANAL COGNITION BASIC.
   O'Donnell T., 2015, PRODUCTIVITY REUSE L.
   Omigie D, 2013, NEUROPSYCHOLOGIA, V51, P1749, DOI 10.1016/j.neuropsychologia.2013.05.010.
   Patel A.D., 2008, MUSIC LANGUAGE BRAIN.
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082.
   Patel AD, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00057.
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011.
   Patel AD, 2013, STRUNGMANN FORUM REP, P329.
   Pearce MT, 2006, MUSIC PERCEPT, V23, P377, DOI 10.1525/mp.2006.23.5.377.
   Pearce MT, 2010, NEUROIMAGE, V50, P302, DOI 10.1016/j.neuroimage.2009.12.019.
   Pearce MT, 2005, THESIS.
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090.
   Pierrehumbert J., 2000, FREQUENCY EFFECTS EM, P1.
   Post M, 2013, LANG SPEECH, V56, P291, DOI 10.1177/0023830913484901.
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011.
   Rohrmeier M, 2011, J MATH MUSIC, V5, P35, DOI 10.1080/17459737.2011.573676.
   Salimpoor VN, 2015, TRENDS COGN SCI, V19, P86, DOI 10.1016/j.tics.2014.12.001.
   Schellenberg EG, 1996, COGNITION, V58, P75, DOI 10.1016/0010-0277(95)00665-6.
   Schmidt-Kassow M, 2009, J COGNITIVE NEUROSCI, V21, P1693, DOI 10.1162/jocn.2008.21153.
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060.
   Seth AK, 2013, TRENDS COGN SCI, V17, P565, DOI 10.1016/j.tics.2013.09.007.
   Steinbeis N, 2006, J COGNITIVE NEUROSCI, V18, P1380, DOI 10.1162/jocn.2006.18.8.1380.
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628.
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46.
   Tillmann B, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00491.
   Tillmann B, 2012, TOP COGN SCI, V4, P568, DOI 10.1111/j.1756-8765.2012.01209.x.
   Traxler MJ, 2005, J MEM LANG, V53, P204, DOI 10.1016/j.jml.2005.02.010.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van de Cavey J, 2016, COGNITION, V146, P172, DOI 10.1016/j.cognition.2015.09.013.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   VanPetten C, 1997, PSYCHOL SCI, V8, P238, DOI 10.1111/j.1467-9280.1997.tb00418.x.
   Vuust P, 2009, CORTEX, V45, P80, DOI 10.1016/j.cortex.2008.05.014.
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004.
   Wan CY, 2014, BRAIN LANG, V136, P1, DOI 10.1016/j.bandl.2014.03.011.
   Wlotko EW, 2012, PSYCHOL AGING, V27, P975, DOI 10.1037/a0029206.
   Zuk J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099868.}},
Number-of-Cited-References = {{105}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{20}},
Journal-ISO = {{Cogn. Sci.}},
Doc-Delivery-Number = {{EU8AK}},
Unique-ID = {{ISI:000401258700007}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000394506700009,
Author = {Greenwald, Jeffrey L. and Cronin, Patrick R. and Carballo, Victoria and
   Danaei, Goodarz and Choy, Garry},
Title = {{A Novel Model for Predicting Rehospitalization Risk Incorporating
   Physical Function, Cognitive Status, and Psychosocial Support Using
   Natural Language Processing}},
Journal = {{MEDICAL CARE}},
Year = {{2017}},
Volume = {{55}},
Number = {{3}},
Pages = {{261-266}},
Month = {{MAR}},
Abstract = {{Background: With the increasing focus on reducing hospital readmissions
   in the United States, numerous readmissions risk prediction models have
   been proposed, mostly developed through analyses of structured data
   fields in electronic medical records and administrative databases. Three
   areas that may have an impact on readmission but are poorly captured
   using structured data sources are patients' physical function, cognitive
   status, and psychosocial environment and support.
   Objective of the Study: The objective of the study was to build a
   discriminative model using information germane to these 3 areas to
   identify hospitalized patients' risk for 30-day all cause readmissions.
   Research Design: We conducted clinician focus groups to identify
   language used in the clinical record regarding these 3 areas. We then
   created a dataset including 30,000 inpatients, 10,000 from each of 3
   hospitals, and searched those records for the focus groupderived
   language using natural language processing. A 30-day readmission
   prediction model was developed on 75\% of the dataset and validated on
   the other 25\% and also on hospital specific subsets.
   Results: Focus group language was aggregated into 35 variables. The
   final model had 16 variables, a validated C-statistic of 0.74, and was
   well calibrated. Subset validation of the model by hospital yielded
   C-statistics of 0.70-0.75.
   Conclusions: Deriving a 30-day readmission risk prediction model through
   identification of physical, cognitive, and psychosocial issues using
   natural language processing yielded a model that per-forms similarly to
   the better performing models previously published with the added
   advantage of being based on clinically relevant factors and also
   automated and scalable. Because of the clinical relevance of the
   variables in the model, future research may be able to test if targeting
   interventions to identified risks results in reductions in readmissions.}},
Publisher = {{LIPPINCOTT WILLIAMS \& WILKINS}},
Address = {{TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Greenwald, JL (Corresponding Author), Massachusetts Gen Hosp, Core Educator Fac, Dept Med, 50 Staniford St,Suite 503b, Boston, MA 02114 USA.
   Greenwald, Jeffrey L., Massachusetts Gen Hosp, Core Educator Fac, Dept Med, 50 Staniford St,Suite 503b, Boston, MA 02114 USA.
   Cronin, Patrick R., Massachusetts Gen Hosp, Lab Comp Sci, Boston, MA 02114 USA.
   Carballo, Victoria, Partners HealthCare, Needham, MA USA.
   Danaei, Goodarz, Harvard TH Chan Sch Publ Hlth, Dept Global Hlth \& Populat, Boston, MA USA.
   Danaei, Goodarz, Harvard TH Chan Sch Publ Hlth, Dept Epidemiol, Boston, MA USA.
   Choy, Garry, Massachusetts Gen Hosp, QPID Informat, Boston, MA 02114 USA.
   Choy, Garry, Massachusetts Gen Hosp, Massachusetts Gen Phys Org, Boston, MA 02114 USA.}},
DOI = {{10.1097/MLR.0000000000000651}},
ISSN = {{0025-7079}},
EISSN = {{1537-1948}},
Keywords = {{natural language processing; readmission; risk prediction; hospitalized
   patients; care transitions; hospital discharge}},
Keywords-Plus = {{HOSPITAL READMISSION; MEDICAL PATIENTS; HEART-FAILURE; RATES; CARE}},
Research-Areas = {{Health Care Sciences \& Services; Public, Environmental \& Occupational
   Health}},
Web-of-Science-Categories  = {{Health Care Sciences \& Services; Health Policy \& Services; Public,
   Environmental \& Occupational Health}},
Author-Email = {{jlgreenwald@partners.org}},
ResearcherID-Numbers = {{Danaei, Goodarz/B-6085-2008}},
Funding-Acknowledgement = {{Partners HealthCare High Performance Team IV Readmissions Committee}},
Funding-Text = {{Supported by the Partners HealthCare High Performance Team IV
   Readmissions Committee.}},
Cited-References = {{Barnett ML, 2015, JAMA INTERN MED, V175, P1803, DOI 10.1001/jamainternmed.2015.4660.
   Bohannon RW, 2004, AM J PHYS MED REHAB, V83, P434, DOI 10.1097/00002060-200406000-00005.
   Calvillo-King L, 2013, J GEN INTERN MED, V28, P269, DOI 10.1007/s11606-012-2235-x.
   Chu LW, 1999, GERONTOLOGY, V45, P220, DOI 10.1159/000022091.
   Coleman EA, 2004, HEALTH SERV RES, V39, P1449, DOI 10.1111/j.1475-6773.2004.00298.x.
   DePalma G, 2013, GERONTOLOGIST, V53, P454, DOI 10.1093/geront/gns103.
   Doan S, 2014, METHODS MOL BIOL, V1168, P275, DOI 10.1007/978-1-4939-0847-9\_16.
   Donze J, 2013, JAMA INTERN MED, V173, P632, DOI 10.1001/jamainternmed.2013.3023.
   Garcia-Aymerich J, 2003, THORAX, V58, P100, DOI 10.1136/thorax.58.2.100.
   Greysen SR, 2015, JAMA INTERN MED, V175, P559, DOI 10.1001/jamainternmed.2014.7756.
   Halfon P, 2002, J CLIN EPIDEMIOL, V55, P573, DOI 10.1016/S0895-4356(01)00521-2.
   Herrin J, 2015, HEALTH SERV RES, V50, P20, DOI 10.1111/1475-6773.12177.
   Joynt KE, 2011, JAMA-J AM MED ASSOC, V305, P675, DOI 10.1001/jama.2011.123.
   Kansagara D, 2011, JAMA-J AM MED ASSOC, V306, P1688, DOI 10.1001/jama.2011.1515.
   Krumholz HM, 2016, JACC-HEART FAIL, V4, P12, DOI 10.1016/j.jchf.2015.07.017.
   McCoy TH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136341.
   Morrissey EFR, 2003, CLIN DRUG INVEST, V23, P119, DOI 10.2165/00044011-200323020-00005.
   Okhmatovskaia A, 2014, STUD HEALTH TECHNOL, V205, P1125, DOI 10.3233/978-1-61499-432-9-1125.
   Smith DM, 2000, J CLIN EPIDEMIOL, V53, P1113, DOI 10.1016/S0895-4356(00)00236-5.
   van Walraven C, 2013, J HOSP MED, V8, P261, DOI 10.1002/jhm.2025.
   van Walraven C, 2011, CAN MED ASSOC J, V183, pE391, DOI 10.1503/cmaj.101860.
   Watson AJ, 2011, PSYCHOSOMATICS, V52, P319, DOI 10.1016/j.psym.2011.02.007.
   Wou F, 2013, AGE AGEING, V42, P776, DOI 10.1093/ageing/aft055.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{Med. Care}},
Doc-Delivery-Number = {{EL3GD}},
Unique-ID = {{ISI:000394506700009}},
DA = {{2020-12-06}},
}

@article{ ISI:000393722100005,
Author = {Parchami, Mandi and Zhu, Wei-Ping and Champagne, Benoit},
Title = {{Speech dereverberation using weighted prediction error with correlated
   inter-frame speech components}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2017}},
Volume = {{87}},
Pages = {{49-57}},
Month = {{MAR}},
Abstract = {{In this paper, we propose a new dereverberation approach based on the
   weighted prediction error (WPE) method implemented in the short-time
   Fourier transform (SIFT) domain. Our main contribution is to model the
   temporal correlation of the STFT coefficients across analysis frames,
   referred to as inter-frame correlation (IFC), and exploit it in the
   dereverberation process. Since accurate modeling of the IFC is not
   tractable, we consider an approximate model wherein only a finite number
   of consecutive speech frames are considered correlated. It is shown
   that, given an estimate of the IFC matrix, the proposed approach results
   in a convex quadratic optimization problem with respect to the
   reverberation prediction weights, and a closed-form solution can be
   accordingly derived. Furthermore, an efficient method for the estimation
   of the underlying IFC matrix is developed based on the extension of a
   recently proposed speech variance estimator. We evaluate the performance
   of our approach incorporating the estimated IFC matrix and compare it to
   the original and several variants of the WPE method. The results reveal
   lower residual reverberation and higher overall quality of the enhanced
   speech when the proposed method is employed. (C) 2017 Elsevier B.V. All
   rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Parchami, M (Corresponding Author), Concordia Univ, Dept Elect \& Comp Engn, Montreal, PQ, Canada.
   Parchami, Mandi; Zhu, Wei-Ping, Concordia Univ, Dept Elect \& Comp Engn, Montreal, PQ, Canada.
   Champagne, Benoit, McGill Univ, Dept Elect \& Comp Engn, Montreal, PQ, Canada.}},
DOI = {{10.1016/j.specom.2017.01.004}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Inter-frame correlation; Multi-channel linear prediction (MCLP); Speech
   dereverberation; Speech enhancement}},
Keywords-Plus = {{REVERBERANT; SUPPRESSION; NOISE; ENHANCEMENT; QUALITY; MODEL}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{m\_parch@ece.concordia.ca
   weiping@ece.concordia.ca
   benoit.champagne@mcgill.ca}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council (NSERC) of
   CanadaNatural Sciences and Engineering Research Council of Canada}},
Funding-Text = {{This work was supported in part by the Natural Sciences and Engineering
   Research Council (NSERC) of Canada.}},
Cited-References = {{{[}Anonymous], 2013, SIMDATA DEV EV SETS.
   Attias H, 2001, ADV NEUR IN, V13, P758.
   Brookes M, 2009, VOICEBOX SPEECH PROC.
   Cohen I, 2005, IEEE T SPEECH AUDI P, V13, P870, DOI 10.1109/TSA.2005.851940.
   CVXResearch I., 2012, CVX MATLAB SOFTWARE.
   Erkelens JS, 2010, IEEE T AUDIO SPEECH, V18, P1746, DOI 10.1109/TASL.2010.2051271.
   Esch T., 2012, THESIS.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Habets E. A. P., 2007, THESIS.
   Habets EAP, 2012, INT CONF ACOUST SPEE, P305, DOI 10.1109/ICASSP.2012.6287877.
   Habets EAP, 2009, IEEE SIGNAL PROC LET, V16, P770, DOI 10.1109/LSP.2009.2024791.
   HAGER WW, 1989, SIAM REV, V31, P221, DOI 10.1137/1031049.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   I.-T. Recommendation, PERC EV SPEECH QUAL.
   ITU-T, 2011, OBJ MEAS ACT SPEECH.
   Jukic Ante, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5172, DOI 10.1109/ICASSP.2014.6854589.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Kinoshita T, 2013, 2013 9TH INTERNATIONAL WORKSHOP ON ELECTROMAGNETIC COMPATIBILITY OF INTEGRATED CIRCUITS (EMC COMPO 2013), P1, DOI 10.1109/EMCCompo.2013.6735162.
   Lehmann E. A., IMAGE SOURCE METHOD.
   Lollmann H., 2010, P INT WORKSH AC ECH, P1.
   Lu Y, 2008, SPEECH COMMUN, V50, P453, DOI 10.1016/j.specom.2008.01.003.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Parchami M., 2016, P IEEE INT C AC SPEE.
   Press W. H., 2007, NUMERICAL RECIPES AR.
   Schmid D, 2012, INT CONF ACOUST SPEE, P17, DOI 10.1109/ICASSP.2012.6287806.
   Togami M, 2013, INT CONF ACOUST SPEE, P7447, DOI 10.1109/ICASSP.2013.6639110.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.
   Vaseghi SV, 2006, ADV DIGITAL SIGNAL P.
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029.
   Yoshioka T, 2009, IEEE T AUDIO SPEECH, V17, P231, DOI 10.1109/TASL.2008.2008042.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{EK1XW}},
Unique-ID = {{ISI:000393722100005}},
DA = {{2020-12-06}},
}

@article{ ISI:000394560700058,
Author = {Yang, Ying and Wang, Jing and Bailer, Cyntia and Cherkassky, Vladimir
   and Just, Marcel Adam},
Title = {{Commonality of neural representations of sentences across languages:
   Predicting brain activation during Portuguese sentence comprehension
   using an English-based model of brain function}},
Journal = {{NEUROIMAGE}},
Year = {{2017}},
Volume = {{146}},
Pages = {{658-666}},
Month = {{FEB 1}},
Abstract = {{The aim of the study was to test the cross-language generative
   capability of a model that predicts neural activation patterns evoked by
   sentence reading, based on a semantic characterization of the sentence.
   In a previous study on English monolingual speakers (Wang et al.,
   submitted), a computational model performed a mapping from a set of 42
   concept-level semantic features (Neurally Plausible Semantic Features,
   NPSFs) as well as 6 thematic role markers to neural activation patterns
   (assessed with fMRI), to predict activation levels in a network of brain
   locations. The model used two types of information gained from the
   English-based fMRI data to predict the activation for individual
   sentences in Portuguese. First, it used the mapping weights from NPSFs
   to voxel activation levels derived from the model for English reading.
   Second, the brain locations for which the activation levels were
   predicted were derived from a factor analysis of the brain activation
   patterns during English reading. These meta-language locations were
   defined by the clusters of voxels with high loadings on each of the four
   main dimensions (factors), namely people, places, actions and feelings,
   underlying the neural representations of the stimulus sentences. This
   cross-language model succeeded in predicting the brain activation
   patterns associated with the reading of 60 individual Portuguese
   sentences that were entirely new to the model, attaining accuracies
   reliably above chance level. The prediction accuracy was not affected by
   whether the Portuguese speaker was monolingual or Portuguese-English
   bilingual. The model's confusion errors indicated an accurate capture of
   the events or states described in the sentence at a conceptual level.
   Overall, the cross-language predictive capability of the model
   demonstrates the neural commonality between speakers of different
   languages in the representations of everyday events and states, and
   provides an initial characterization of the common meta-language neural
   basis.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Just, MA (Corresponding Author), Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
   Yang, Ying; Wang, Jing; Cherkassky, Vladimir; Just, Marcel Adam, Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
   Bailer, Cyntia, Univ Fed Santa Catarina, Dept Foreign Language \& Literature, BR-88040900 Florianopolis, SC, Brazil.}},
DOI = {{10.1016/j.neuroimage.2016.10.029}},
ISSN = {{1053-8119}},
EISSN = {{1095-9572}},
Keywords = {{Cross-language commonality; Sentence representations in bilinguals;
   Predictive modeling of sentence; representations; Meta-language brain
   locations in sentence; processing}},
Keywords-Plus = {{CORTEX; BILINGUALS; CATEGORIES; FMRI; ARCHITECTURE; KNOWLEDGE; REVEALS;
   NOUNS}},
Research-Areas = {{Neurosciences \& Neurology; Radiology, Nuclear Medicine \& Medical
   Imaging}},
Web-of-Science-Categories  = {{Neurosciences; Neuroimaging; Radiology, Nuclear Medicine \& Medical
   Imaging}},
Author-Email = {{just@cmu.edu}},
ResearcherID-Numbers = {{Bailer, Cyntia/ABG-1574-2020
   }},
ORCID-Numbers = {{Wang, Jing/0000-0001-6022-8240
   Bailer, Cyntia/0000-0002-9049-8003}},
Funding-Acknowledgement = {{Office of the Director of National Intelligence (ODNI); Intelligence
   Advanced Research Projects Activity (IARPA); via Air Force Research
   Laboratory (AFRL) {[}FA8650-13-C-7360]; Brazilian Ministry of Education,
   CAPES BEX {[}1463613-1]}},
Funding-Text = {{This research is based upon work supported in part by the Office of the
   Director of National Intelligence (ODNI), Intelligence Advanced Research
   Projects Activity (IARPA), via Air Force Research Laboratory (AFRL)
   contract number FA8650-13-C-7360. The views and conclusions contained
   herein are those of the authors and should not be interpreted as
   necessarily representing the official policies or endorsements, either
   expressed or implied, of ODNI, IARPA, AFRL, or the U.S. Government. The
   U.S. Government is authorized to reproduce and distribute reprints for
   Governmental purposes notwithstanding any copyright annotation thereon.
   During data collection Cyntia Bailer was supported by the Brazilian
   Ministry of Education, CAPES BEX 1463613-1. We thank Nick Diana, Robert
   Vargas, and Zachary Anderson for their help in data collection, stimulus
   preparation and coding, and Leda Tomitch for guidance on bilingual
   issues.}},
Cited-References = {{Aflalo T, 2015, SCIENCE, V348, P906, DOI 10.1126/science.aaa5417.
   Bloch C, 2009, NEUROPSYCHOLOGIA, V47, P625, DOI 10.1016/j.neuropsychologia.2008.11.009.
   Buchweitz A, 2013, PHYS LIFE REV, V10, P428, DOI 10.1016/j.plrev.2013.07.020.
   Buchweitz A, 2012, BRAIN LANG, V120, P282, DOI 10.1016/j.bandl.2011.09.003.
   Collinger JL, 2013, LANCET, V381, P557, DOI 10.1016/S0140-6736(12)61816-9.
   Correia J, 2014, J NEUROSCI, V34, P332, DOI 10.1523/JNEUROSCI.1302-13.2014.
   Costa A, 2014, NAT REV NEUROSCI, V15, P336, DOI 10.1038/nrn3709.
   Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189.
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5.
   Frankland SM, 2015, P NATL ACAD SCI USA, V112, P11732, DOI 10.1073/pnas.1421236112.
   Giuliani NR, 2014, J COGNITIVE NEUROSCI, V26, P1390, DOI 10.1162/jocn\_a\_00563.
   Glasgow K, 2016, ARXIV160307253.
   Hastie T., 2005, MATH INTELL, V27, P83, DOI {[}10.1007/BF02985802, DOI 10.1007/BF02985802].
   Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637.
   Huth AG, 2012, NEURON, V76, P1210, DOI 10.1016/j.neuron.2012.10.014.
   Isel F, 2010, BRAIN COGNITION, V72, P169, DOI 10.1016/j.bandc.2009.07.008.
   Johnson-Frey SH, 2004, TRENDS COGN SCI, V8, P71, DOI 10.1016/j.tics.2003.12.002.
   Jones OP, 2012, CEREB CORTEX, V22, P892, DOI 10.1093/cercor/bhr161.
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329.
   Just MA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113879.
   Just MA, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008622.
   Kassam KS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066032.
   Koehn Philipp, 2009, STAT MACHINE TRANSLA.
   Kovelman I, 2008, J COGNITIVE NEUROSCI, V20, P153, DOI 10.1162/jocn.2008.20011.
   Marcus G, 2014, SCIENCE, V346, P551, DOI 10.1126/science.1261661.
   Martin A, 1996, NATURE, V379, P649, DOI 10.1038/379649a0.
   Mason RA, 2016, PSYCHOL SCI, V27, P904, DOI 10.1177/0956797616641941.
   Mitchell TM, 2008, SCIENCE, V320, P1191, DOI 10.1126/science.1152876.
   Moseley RL, 2014, BRAIN LANG, V132, P28, DOI 10.1016/j.bandl.2014.03.001.
   Murphy B., 2012, P 1 JOINT C LEX COMP, V2, P114.
   Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073.
   Palomar-Garcia MA, 2015, BRAIN LANG, V142, P36, DOI 10.1016/j.bandl.2015.01.004.
   Parker Jones O., 2011, CEREB CORTEX.
   Price AR, 2016, J NEUROSCI, V36, P3829, DOI 10.1523/JNEUROSCI.3120-15.2016.
   Proverbio AM, 2002, J COGNITIVE NEUROSCI, V14, P994, DOI 10.1162/089892902320474463.
   Rilling JK, 2004, NEUROIMAGE, V22, P1694, DOI 10.1016/j.neuroimage.2004.04.015.
   Rustandi I., 2009, P MICCAI 2009 WORKSH.
   Schilbach L, 2006, NEUROPSYCHOLOGIA, V44, P718, DOI 10.1016/j.neuropsychologia.2005.07.017.
   Schilbach L., 2015, BRAIN MAPPING ENCY R, V3, P159.
   Schloss B, 2016, BEHAV RES METHODS, P1.
   Schuster S, 2016, CEREB CORTEX.
   Tranel D, 2003, COGN NEUROPSYCHOL, V20, P409, DOI 10.1080/02643290244000248.
   Van der Cruyssen L, 2015, NEUROIMAGE, V104, P336, DOI 10.1016/j.neuroimage.2014.09.022.
   van der Laan LN, 2011, NEUROIMAGE, V55, P296, DOI 10.1016/j.neuroimage.2010.11.055.
   Wang J, NATURE UNPUB.
   Zhu Y, 2007, NEUROIMAGE, V34, P1310, DOI 10.1016/j.neuroimage.2006.08.047.
   Zinszer B. D, 2016, J COGN NEUROSCI.}},
Number-of-Cited-References = {{47}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{Neuroimage}},
Doc-Delivery-Number = {{EL3ZX}},
Unique-ID = {{ISI:000394560700058}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000452163400008,
Author = {Ikegami, Yukino and Sakurai, Yoshitaka and Damiani, Ernesto and Knauf,
   Rainer and Tsuruta, Setsuo},
Editor = {{Yetongnon, K and Dipanda, A and Chbeir, R and Gallo, L and Nain, N}},
Title = {{Flick: Japanese Input Method Editor using N-gram and Recurrent Neural
   Network Language Model based Predictive Text Input}},
Booktitle = {{2017 13TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND
   INTERNET-BASED SYSTEMS (SITIS)}},
Year = {{2017}},
Pages = {{50-55}},
Note = {{13th International Conference on Signal-Image Technology and
   Internet-Based Systems (SITIS), Jaipur, INDIA, DEC 04-07, 2017}},
Organization = {{IEEE Comp Soc; Malaviya Natl Inst Technol; Univ Bourgogne; Univ Milan;
   Univ Bourgogne, Lab Electronique Image Informatique Res Grp; Natl Res
   Ctr Italy, Inst High Performance Comp \& Networking; Govt Rajasthan,
   Dept Sci \& Technol; IEEE Comp Soc, Special Interest Grp Semant
   Multimedia Management; ACM Special Interest Grp Appl Comp, French
   Chapter; IFIP; ACM}},
Abstract = {{Smartphone is prevalent among many people. Smartphone is used not only
   by personal use but also by business. However, inputting Japanese text
   to smartphone requires longer time than PC. For this reason, predictive
   input, which suggesting next words, is important to type word
   efficiently. On the other hands, Recurrent Neural Networks (RNNs) are
   very powerful sequence models. Thus, we developed the input method
   editor (IME), which using n-gram and a recurrent neural networks
   language model based predictive text input. This IME is aimed at
   decreasing actions of inputting text. The evaluation experiments show
   our method outperforms conventional Japanese IME in terms of amount of
   time.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ikegami, Y (Corresponding Author), IO Inc, Tokyo, Japan.
   Ikegami, Yukino, IO Inc, Tokyo, Japan.
   Sakurai, Yoshitaka, Meiji Univ, Sch Interdisciplinary Math Sci, Nakano, Japan.
   Damiani, Ernesto, Univ Milan, Dept Comp Sci, Milan, Italy.
   Knauf, Rainer, Tech Univ Ilmenau, Dept Comp Sci \& Automat, Ilmenau, Germany.
   Tsuruta, Setsuo, Tokyo Denki Univ, Sch Informat Environent, Inzai, Japan.}},
DOI = {{10.1109/SITIS.2017.19}},
ISBN = {{978-1-5386-4283-2}},
Keywords = {{predictive inmut; n-gram; recurrent neuronal network; input method
   editor}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{yknikgm@gmail.com
   sakuraiy@meiji.ac.jp
   ernesto.damiani@unimi.it
   Rainer.knauf@tu-ilmenau.de
   tsuruta@mail.dendai.ac.jp}},
ResearcherID-Numbers = {{damiani, ernesto/AAI-5709-2020}},
ORCID-Numbers = {{damiani, ernesto/0000-0002-9557-6496}},
Funding-Acknowledgement = {{JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) {[}15K00349];
   Grants-in-Aid for Scientific ResearchMinistry of Education, Culture,
   Sports, Science and Technology, Japan (MEXT)Japan Society for the
   Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)
   {[}15K00382] Funding Source: KAKEN}},
Funding-Text = {{This work was supported by JSPS KAKENHI Grant Number 15K00349. We thank
   Mr. Mitsuaki Ishimoto, a president of IO Inc., for supporting the
   research development of FLICK. In addition, we thank participants of
   user test.{''}}},
Cited-References = {{Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223.
   Ehara Y., 2008, P INT JOINT C NAT LA, P441.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   Elumeze N., 2006, 5832 CSCI NAT LANG P.
   Gao JF, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P579.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Komachi M., 2011, P NLP 2011, P1095.
   Komatsu H, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P75, DOI 10.1109/AMT.2005.1505271.
   Kudo T., 2011, P NLP 2011, P948.
   Kudo Taku, 2004, P 2004 C EMP METH NA, P230.
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193.
   Maekawa K, 2014, LANG RESOUR EVAL, V48, P345, DOI 10.1007/s10579-013-9261-0.
   Masui T, 1999, LECT NOTES COMPUT SC, V1707, P289.
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045.
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL5MK}},
Unique-ID = {{ISI:000452163400008}},
DA = {{2020-12-06}},
}

@article{ ISI:000415913500005,
Author = {Zhang, Xingyu and Kim, Joyce and Patzer, Rachel E. and Pitts, Stephen R.
   and Patzer, Aaron and Schrager, Justin D.},
Title = {{Prediction of Emergency Department Hospital Admission Based on Natural
   Language Processing and Neural Networks}},
Journal = {{METHODS OF INFORMATION IN MEDICINE}},
Year = {{2017}},
Volume = {{56}},
Number = {{5}},
Pages = {{377-389}},
Abstract = {{Objective: To describe and compare logistic regression and neural
   network modeling strategies to predict hospital admission or transfer
   following initial presentation to Emergency Department (ED) triage with
   and without the addition of natural language processing elements.
   Methods: Using data from the National Hospital Ambulatory Medical Care
   Survey (NHAMCS), a cross-sectional probability sample of United States
   EDs from 2012 and 2013 survey years, we developed several predictive
   models with the outcome being admission to the hospital or transfer vs.
   discharge home. We included patient characteristics immediately
   available after the patient has presented to the ED and undergone a
   triage process. We used this information to construct logistic
   regression (LR) and multi layer neural network models (MLNN) which
   included natural language processing (NLP) and principal component
   analysis from the patient's reason for visit. Ten-fold cross validation
   was used to test the predictive capacity of each model and receiver
   operating curves (AUC) were then calculated for each model.
   Results: Of the 47,200 ED visits from 642 hospitals, 6,335 (13.42\%)
   resulted in hospital admission (or transfer). A total of 48 principal
   components were extracted by NLP from the reason for visit fields, which
   explained 75\% of the overall variance for hospitalization. In the model
   including only structured variables, the AUC was 0.824 (95\% CI
   0.818-0.830) for logistic regression and 0.823 (95\% CI 0.817-0.829) for
   MLNN. Models including only free-text information generated AUC of 0.742
   (95\% CI 0.7310.753) for logistic regression and 0.753 (95\% CI
   0.742-0.764) for MLNN. When both structured variables and free text
   variables were included, the AUC reached 0.846 (95\% CI 0.839-0.853) for
   logistic regression and 0.844 (95\% CI 0.836-0.852) for MLNN.
   Conclusions: The predictive accuracy of hospital admission or transfer
   for patients who presented to ED triage overall was good, and was
   improved with the inclusion of free text data from a patient's reason
   for visit regardless of modeling approach. Natural language processing
   and neural networks that incorporate patient-reported outcome free text
   may increase predictive accuracy for hospital admission.}},
Publisher = {{GEORG THIEME VERLAG KG}},
Address = {{RUDIGERSTR 14, D-70469 STUTTGART, GERMANY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Schrager, JD (Corresponding Author), Emory Univ, Sch Med, Dept Emergency Med, 531 Asbury Circle,Annex Bldg N340, Atlanta, GA 30322 USA.
   Zhang, Xingyu; Patzer, Rachel E., Emory Univ, Sch Med, Dept Surg, Atlanta, GA 30322 USA.
   Kim, Joyce, Emory Univ, Sch Med, Atlanta, GA 30322 USA.
   Patzer, Rachel E., Rollins Sch Publ Hlth, Dept Epidemiol, Atlanta, GA USA.
   Pitts, Stephen R.; Schrager, Justin D., Emory Sch Med, Dept Emergency Med, Atlanta, GA USA.
   Patzer, Aaron, Vital Software Inc, Auckland, New Zealand.}},
DOI = {{10.3414/ME17-01-0024}},
ISSN = {{0026-1270}},
EISSN = {{2511-705X}},
Keywords = {{Natural language processing; neural networks; logistic regression;
   prediction; emergency department}},
Keywords-Plus = {{ACUTE CORONARY SYNDROME; LOGISTIC-REGRESSION; SEVERITY INDEX; SYSTEM;
   MODEL; COMPLAINTS; LENGTH; STAY; RISK}},
Research-Areas = {{Computer Science; Health Care Sciences \& Services; Medical Informatics}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Health Care Sciences \& Services;
   Medical Informatics}},
Author-Email = {{jschrag@emory.edu}},
ORCID-Numbers = {{Zhang, Xingyu/0000-0001-8108-1997}},
Cited-References = {{{[}Anonymous], 2006, FUT EM CAR HOSP BAS.
   Bar Y, 2015, SPIE MED IMAGING.
   Bartfay E, 2006, EUR J CANCER CARE, V15, P115, DOI 10.1111/j.1365-2354.2005.00638.x.
   Becalick DC, 2001, J TRAUMA, V51, P123, DOI 10.1097/00005373-200107000-00020.
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061.
   Botsis T, 2011, J AM MED INFORM ASSN, V18, P631, DOI 10.1136/amiajnl-2010-000022.
   Carlos J. S., 2016, PREHOSP EMERG CARE, P1.
   Centers for Disease Control and Prevention, 2013, NHAMCS MICR FIL DOC.
   Chalfin DB, 2007, CRIT CARE MED, V35, P1477, DOI 10.1097/01.CCM.0000266585.74905.5A.
   Claster W, 2008, J COMPUT, V3, P1, DOI 10.4304/jcp.3.1.1-6.
   Cohen AM, 2005, BRIEF BIOINFORM, V6, P57, DOI 10.1093/bib/6.1.57.
   Day FC, 2004, ANN EMERG MED, V43, P401, DOI 10.1016/S0196-0644(03)00748-0.
   Demner-Fushman D, 2009, J BIOMED INFORM, V42, P760, DOI 10.1016/j.jbi.2009.08.007.
   Dexheimer Judith W, 2007, AMIA Annu Symp Proc, P937.
   Dybowski R, 2001, CLIN APPL ARTIFICIAL.
   Forberg JL, 2009, J ELECTROCARDIOL, V42, P58, DOI 10.1016/j.jelectrocard.2008.07.010.
   Forero R, 2011, CRIT CARE, V15, DOI 10.1186/cc9998.
   Gholipour C, 2015, J CLIN DIAGN RES, V9, pOC19, DOI 10.7860/JCDR/2015/9467.5828.
   Golmohammadi D, 2016, INT J PROD ECON, V182, P535, DOI 10.1016/j.ijpe.2016.09.020.
   Green M, 2006, ARTIF INTELL MED, V38, P305, DOI 10.1016/j.artmed.2006.07.006.
   Gurulingappa H, 2012, J BIOMED INFORM, V45, P885, DOI 10.1016/j.jbi.2012.04.008.
   Handly N, 2015, EUR J EMERG MED, V22, P87, DOI 10.1097/MEJ.0000000000000126.
   Heckerling PS, 2003, MED DECIS MAKING, V23, P112, DOI 10.1177/0272989X03251247.
   Hess EP, 2008, BMC EMERG MED, V8, DOI 10.1186/1471-227X-8-3.
   Hirshon JM, 2009, ACAD EMERG MED, V16, P1103, DOI 10.1111/j.1553-2712.2009.00554.x.
   Hsich E, 2011, CIRC-CARDIOVASC QUAL, V4, P39, DOI 10.1161/CIRCOUTCOMES.110.939371.
   Husk G, 2007, ACAD EMERG MED, V14, P69, DOI 10.1197/j.aem.2006.07.012.
   Jaimes F, 2005, CRITICAL CARE, V9, P1.
   Lammers RL, 2003, AM J EMERG MED, V21, P1, DOI 10.1053/ajem.2003.50026.
   Launay CP, 2015, EUR J INTERN MED, V26, P478, DOI 10.1016/j.ejim.2015.06.002.
   Leegon J, 2005, AMIA ANN S P, V2005, P1022.
   Leegon Jeffrey, 2006, AMIA Annu Symp Proc, P1004.
   Lin C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069932.
   Lo-Ciganic WH, 2015, MED CARE, V53, P720, DOI 10.1097/MLR.0000000000000394.
   Lum HD, 2012, J GEN INTERN MED, V27, P1467, DOI 10.1007/s11606-012-2116-3.
   McCaig LF, 2012, ANN EMERG MED, V60, P716, DOI 10.1016/j.annemergmed.2012.07.010.
   McCallum A., 2005, ACM Queue, V3, P48, DOI 10.1145/1105664.1105679.
   McHugh M, 2012, ACAD EMERG MED, V19, P106, DOI 10.1111/j.1553-2712.2011.01240.x.
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464.
   Newman D, 2009, LECT NOTES ARTIF INT, V5866, P270, DOI 10.1007/978-3-642-10439-8\_28.
   Ozcift A, 2011, COMPUT BIOL MED, V41, P265, DOI 10.1016/j.compbiomed.2011.03.001.
   Parsaeian M, 2012, IRAN J PUBLIC HEALTH, V41, P86.
   Peck JS, 2012, ACAD EMERG MED, V19, pE1045, DOI 10.1111/j.1553-2712.2012.01435.x.
   Penny W, 1996, MED DECIS MAKING, V16, P386, DOI 10.1177/0272989X9601600409.
   Pines JM, 2011, ACAD EMERG MED, V18, P1358, DOI 10.1111/j.1553-2712.2011.01235.x.
   Rabin E, 2012, HEALTH AFFAIR, V31, P1757, DOI 10.1377/hlthaff.2011.0786.
   Roberts Angus, 2007, AMIA Annu Symp Proc, P625.
   Sadat-Hashemi SM, 2005, NEURAL COMPUT APPL, V14, P198, DOI 10.1007/s00521-004-0454-8.
   Sinha M, 2014, PEDIATR EMERG CARE, V30, P63, DOI 10.1097/PEC.0000000000000037.
   Song JH, 2005, ACAD RADIOL, V12, P487, DOI 10.1016/j.acra.2004.12.016.
   Stoltzfus JC, 2011, ACAD EMERG MED, V18, P1099, DOI 10.1111/j.1553-2712.2011.01185.x.
   Subasi A, 2005, EXPERT SYST APPL, V28, P701, DOI 10.1016/j.eswa.2004.12.027.
   Sun BC, 2013, ANN EMERG MED, V61, P605, DOI 10.1016/j.annemergmed.2012.10.026.
   Sun Y, 2011, ACAD EMERG MED, V18, P844, DOI 10.1111/j.1553-2712.2011.01125.x.
   Tanabe Paula, 2004, J Emerg Nurs, V30, P22, DOI 10.1016/j.jen.2003.11.004.
   Thompson DA, 1996, ANN EMERG MED, V28, P657, DOI 10.1016/S0196-0644(96)70090-2.
   Tsai PF, 2016, J HEALTHC ENG, V2016, DOI 10.1155/2016/7035463.
   Vijayarani S., 2015, INT J COMPUT SCI COM, V5, P7, DOI DOI 10.1016/J.PR0CS.2013.05.286.
   Wallach H. M, 2006, P 23 INT C MACH LEAR.
   Wuerz R, 2001, ACAD EMERG MED, V8, P61.
   Wuerz RC, 2000, ACAD EMERG MED, V7, P236, DOI 10.1111/j.1553-2712.2000.tb01066.x.
   Yu W, 2010, BMC MED INFORM DECIS, V10, DOI 10.1186/1472-6947-10-16.
   Zhang P, 2015, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2015/11/P11006.
   Zhang XC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085241.
   Zhang XY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063116.
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0.
   Zhao Z., 2010, INT C MEAS TECHN MEC.}},
Number-of-Cited-References = {{67}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Methods Inf. Med.}},
Doc-Delivery-Number = {{FN3QI}},
Unique-ID = {{ISI:000415913500005}},
DA = {{2020-12-06}},
}

@article{ ISI:000392305000055,
Author = {Liu, Peng and Li, Songbin and wang, Haiqiang},
Title = {{Steganography integrated into linear predictive coding for low bit-rate
   speech codec}},
Journal = {{MULTIMEDIA TOOLS AND APPLICATIONS}},
Year = {{2017}},
Volume = {{76}},
Number = {{2}},
Pages = {{2837-2859}},
Month = {{JAN}},
Abstract = {{The extensive use of Voice over IP (VoIP) applications makes low
   bit-rate speech stream a very suitable steganographic cover media. To
   incorporate steganography into low bit-rate speech codec, we propose a
   novel approach to embed information during linear predictive coding
   (LPC) process based on Matrix Embedding (ME). In the proposed method, a
   mapping table is constructed based on the criterion of minimum distance
   of Linear-Predictive-Coefficient-Vectors, and embedding position and
   template are selected according to a private key so as to choose the
   cover frames. The original speech data of the chosen frames are
   partially encoded to get the codewords for embedding and then the
   codewords that need to be modified for embedding are selected according
   to the secret bits and ME algorithm. The selected codeword will be
   changed into its best replacement codeword according to the mapping
   table. When embedding k (k > 1) bits into 2 (k) -1 codewords, the
   embedding efficiency of our method is k times as that of LPC-based
   Quantization Index Modulation method. The performance of the proposed
   approach is evaluated in two aspects: distortion in speech quality
   introduced by embedding and security under steganalysis. The
   experimental results demonstrate that the proposed approach leads to a
   better performance with less speech distortion and better security.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Li, SB (Corresponding Author), Chinese Acad Sci, Inst Acoust, Haikou Lab, Haikou 570105, Peoples R China.
   Li, SB (Corresponding Author), Natl Network New Media Engn Res Ctr, Beijing 100190, Peoples R China.
   Liu, Peng; Li, Songbin, Chinese Acad Sci, Inst Acoust, Haikou Lab, Haikou 570105, Peoples R China.
   Liu, Peng; Li, Songbin, Natl Network New Media Engn Res Ctr, Beijing 100190, Peoples R China.
   wang, Haiqiang, Univ Southern Calif, Los Angeles, CA USA.}},
DOI = {{10.1007/s11042-016-3257-x}},
ISSN = {{1380-7501}},
EISSN = {{1573-7721}},
Keywords = {{Information hiding; Linear predictive coding; Matrix embedding;
   Quantization index modulation}},
Keywords-Plus = {{WATERMARKING}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic}},
Author-Email = {{liup@dsp.ac.cn
   lisb@dsp.ac.cn
   haiqianw@usc.edu}},
Funding-Acknowledgement = {{Natural Science Foundation of Nation and Hainan Province of China
   {[}61303249, 614236]; Important Science \& Technology Project of Hainan
   Province of China {[}JDJS2013006, ZDXM2015103]; Preferred Foundation of
   Director of Institute of Acoustics, Chinese Academy of Sciences; Young
   Talent Frontier Project of Institute of Acoustics, Chinese Academy of
   Sciences}},
Funding-Text = {{This work is supported partly by Natural Science Foundation of Nation
   and Hainan Province of China under grant 61303249 and 614236, and partly
   by Important Science \& Technology Project of Hainan Province of China
   under grant JDJS2013006 and ZDXM2015103, and partly by Preferred
   Foundation of Director of Institute of Acoustics, Chinese Academy of
   Sciences, and partly by the Young Talent Frontier Project of Institute
   of Acoustics, Chinese Academy of Sciences.}},
Cited-References = {{{[}Anonymous], 2007, RECOMMENDATION P 563.
   {[}Anonymous], 1996, RECOMMENDATION P 800.
   {[}Anonymous], 2001, RECOMMENDATION P 862.
   Bo XA, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.375.
   Chang YT, 2015, MULTIMED TOOLS APPL, V74, P1645, DOI 10.1007/s11042-014-2019-x.
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725.
   Chiang YK, 2008, FUND INFORM, V82, P15.
   Crandall R, 1998, SOME NOTES STEGANOGR.
   Huang YF, 2011, IEEE T INF FOREN SEC, V6, P296, DOI 10.1109/TIFS.2011.2108649.
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599.
   Ito A, 2009, INT CONF ACOUST SPEE, P1409, DOI 10.1109/ICASSP.2009.4959857.
   {*}ITU, 1996, G729 ITUT.
   Ji S., 2012, ADV DIFFER EQU, V2012, P1, DOI DOI 10.1016/J.CAGE0.2012.01.004.
   Jin Liu, 2012, IEEE International Conference on Communications (ICC 2012), P1133, DOI 10.1109/ICC.2012.6363997.
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020.
   Lin C, 2006, IEEE SYS MAN CYBERN, P2380, DOI 10.1109/ICSMC.2006.385219.
   Liu LH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P406, DOI 10.1109/IIH-MSP.2008.297.
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718.
   Lu ZM, 2005, IEICE T INF SYST, VE88D, P330, DOI 10.1093/ietisy/E88-D.2.330.
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036.
   Rahmani P, 2014, MULTIMED TOOLS APPL, P1.
   Roselinkiruba R, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P491.
   Simmons G. J., 1984, Advances in Cryptology. Proceedings of Crypto 83, P51.
   SIMMONS GJ, 1985, LECT NOTES COMPUT SC, V209, P364.
   SIMMONS GJ, 1994, EUR T TELECOMMUN, V5, P459.
   TeleGeography Report \& Database, 2014, TELEGEOGRAPHY REPORT.
   Tian H, 2009, P 44 IEEE INT C COMM, P1.
   Tutte W.T., 2001, GRAPH THEORY, P233.
   Wang FH, 2007, J NETW COMPUT APPL, V30, P4, DOI 10.1016/j.jnca.2005.08.002.
   Westfeld A., 2001, P 4 INF HID WORKSH, P289, DOI {[}DOI 10.1007/3-540-45496-9\_21, 10.1007/3-540-].
   Xu TT, 2009, INT CONF WIRE COMMUN, P752.
   Yan S, 2014, MATH PROBL ENG, V2014, P1, DOI DOI 10.1007/S11042-014-2265-Y.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{15}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{Multimed. Tools Appl.}},
Doc-Delivery-Number = {{EI2GN}},
Unique-ID = {{ISI:000392305000055}},
DA = {{2020-12-06}},
}

@article{ ISI:000425149100006,
Author = {Park, J. and Lechevalier, D. and Ak, R. and Ferguson, M. and Law, K. H.
   and Lee, Y. -T. T. and Rachuri, S.},
Title = {{Gaussian Process Regression (GPR) Representation in Predictive Model
   Markup Language (PMML)}},
Journal = {{SMART AND SUSTAINABLE MANUFACTURING SYSTEMS}},
Year = {{2017}},
Volume = {{1}},
Number = {{1}},
Pages = {{121-141}},
Abstract = {{This paper describes Gaussian process regression (GPR) models presented
   in predictive model markup language (PMML). PMML is an
   extensible-markup-language (XML) -based standard language used to
   represent data-mining and predictive analytic models, as well as pre-
   and post-processed data. The previous PMML version, PMML 4.2, did not
   provide capabilities for representing probabilistic (stochastic)
   machine-learning algorithms that are widely used for constructing
   predictive models taking the associated uncertainties into
   consideration. The newly released PMML version 4.3, which includes the
   GPR model, provides new features: confidence bounds and distribution for
   the predictive estimations. Both features are needed to establish the
   foundation for uncertainty quantification analysis. Among various
   probabilistic machinelearning algorithms, GPR has been widely used for
   approximating a target function because of its capability of
   representing complex input and output relationships without predefining
   a set of basis functions, and predicting a target output with
   uncertainty quantification. GPR is being employed to various
   manufacturing data-analytics applications, which necessitates
   representing this model in a standardized form for easy and rapid
   employment. In this paper, we present a GPR model and its representation
   in PMML. Furthermore, we demonstrate a prototype using a real data set
   in the manufacturing domain.}},
Publisher = {{AMER SOC TESTING MATERIALS}},
Address = {{100 BARR HARBOR DR, W CONSHOHOCKEN, PA 19428-2959 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Park, J (Corresponding Author), Korea Adv Inst Sci \& Technol, Dept Ind \& Syst Engn, Daejeon 34141, South Korea.
   Park, J., Korea Adv Inst Sci \& Technol, Dept Ind \& Syst Engn, Daejeon 34141, South Korea.
   Lechevalier, D., Univ Bourgogne, Lab Elect Informat \& Image, F-21000 Dijon, France.
   Ak, R.; Lee, Y. -T. T., NIST, Engn Lab, Gaithersburg, MD 20899 USA.
   Ferguson, M.; Law, K. H., Stanford Univ, Dept Civil \& Environm Engn, Stanford, CA 94305 USA.
   Rachuri, S., Dept Energy, Adv Mfg Off, Washington, DC 20585 USA.}},
DOI = {{10.1520/SSMS20160008}},
ISSN = {{2520-6478}},
EISSN = {{2572-3928}},
Keywords = {{predictive model markup language (PMML); Gaussian process regression;
   predictive analytics; data mining; standards; XML}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Manufacturing}},
Author-Email = {{jinkyoo.park@gmail.com}},
Funding-Acknowledgement = {{National Institute of Standards and Technology (NIST)National Institute
   of Standards \& Technology (NIST) - USA {[}70NANB12H273]; National
   Institute of Standards and Technology's Foreign Guest Researcher Program}},
Funding-Text = {{The work described in this paper is funded in part by the National
   Institute of Standards and Technology (NIST) cooperative agreement with
   Stanford University, Grant No. 70NANB12H273, and is supported by
   National Institute of Standards and Technology's Foreign Guest
   Researcher Program. The writers acknowledge the support of the late
   Prof. David Dornfeld and Mr. Raunak Bhinge of the Laboratory for
   Manufacturing and Sustainability at UC Berkeley, United States, in
   collecting, preparing, and providing machine operation data. Certain
   commercial systems are identified in this paper. Such identification
   does not imply recommendation or endorsement by NIST; nor does it imply
   that the products identified are necessarily the best available for the
   purpose.}},
Cited-References = {{Ak R, 2015, ASME 2015 INT DES EN.
   Bhinge R., LMAS DATABASE.
   Bhinge R, 2014, IEEE INT CONF BIG DA, P978, DOI 10.1109/BigData.2014.7004331.
   Carbonneau R, 2008, EUR J OPER RES, V184, P1140, DOI 10.1016/j.ejor.2006.12.004.
   Cohen M., 2015, GOOGLE COMPUTE ENGIN.
   Ferguson M., 2016, IEEE INT C BIG DAT D, P1.
   Ferguson M., GAUSSIAN PROCESS REG.
   Ghosh N, 2007, MECH SYST SIGNAL PR, V21, P466, DOI 10.1016/j.ymssp.2005.10.010.
   Guazzelli A., 2009, ACM SIGKDD EXPLORATI, V11, P32, DOI DOI 10.1145/1656274.1656281.
   Guazzelli A., 2010, WHAT IS PMML EXPLORE, P1.
   Guazzelli A, 2012, PMML ACTION UNLEASHI.
   Guazzelli A, 2009, R J, V1, P60.
   Hensman James, 2013, UNCERTAINTY ARTIFICI.
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415.
   Lyons K., 2016, 2016 WINT SIM C ARL.
   Mitchell T.M., 1997, MACH LEARN, P154.
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1.
   Nannapaneni S, 2016, J CLEAN PROD, V113, P947, DOI 10.1016/j.jclepro.2015.12.003.
   Nguyen-Tuong D., 2008, ADV NEURAL INFORM PR, P1193.
   Orbanz P., 2011, ENCY MACHINE LEARNIN, P81.
   Park Jinkyoo, 2015, ASME 2015 INT MAN SC.
   Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939.
   Ranganathan A, 2011, IEEE T IMAGE PROCESS, V20, P391, DOI 10.1109/TIP.2010.2066984.
   Rasmussen CE, 2010, J MACH LEARN RES, V11, P3011.
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9\_4.
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1.
   Shi JQ, 2005, STAT COMPUT, V15, P31, DOI 10.1007/s11222-005-4787-7.
   Snelson E., 2005, ADV NEURAL INFORM PR, V18, P1257, DOI DOI 10.5555/2976248.2976406.
   Snelson E., 2007, 11 INT C ART INT STA, V11, P524.
   Stegle O., PYTHON PACKAGE GAUSS.
   Suresh PVS, 2002, INT J MACH TOOL MANU, V42, P675, DOI 10.1016/S0890-6955(02)00005-6.
   Suttor J., 2004, TECHNICAL REPORT, P1.
   Teramura K, 2008, P INT C MUS PERC COG, P167.
   Titsias M., 2009, J MACHINE LEARNING R, P567.
   Wuest T, 2016, PROD MANUF RES, V4, P23, DOI 10.1080/21693277.2016.1192517.
   Yan JH, 2005, J MANUF SCI E-T ASME, V127, P912, DOI 10.1115/1.1962019.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Smart Sustain. Manuf. Syst.}},
Doc-Delivery-Number = {{FW2QL}},
Unique-ID = {{ISI:000425149100006}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@incollection{ ISI:000443326600003,
Author = {Guillan, Amanda},
Book-Author = {{Guillan, A}},
Title = {{Analysis of Scientific Prediction from Language}},
Booktitle = {{PRAGMATIC IDEALISM AND SCIENTIFIC PREDICTION: A PHILOSOPHICAL SYSTEM AND
   ITS APPROACH TO PREDICTION IN SCIENCE}},
Series = {{European Studies in Philosophy of Science}},
Year = {{2017}},
Volume = {{8}},
Pages = {{37-65}},
Abstract = {{Within the system of pragmatic idealism, the viewpoint of language is
   used for the analysis of prediction, in general, and scientific
   prediction, in particular. This chapter initially offers the general
   coordinates of a pragmatic idealist approach to language. Thereafter, it
   seeks to shed light on the semantic features of scientific prediction.
   First, Rescher's characterization of prediction is analyzed. This leads
   to us to consider the distinction between ``scientific{''} and
   ``non-scientific{''} prediction, as well as the differences between
   ``prediction{''} and ``retrodiction.{''} Secondly, his contribution to
   the analysis of scientific prediction as a statement is made explicit.
   In this regard, the distinction between ``qualitative prediction{''} and
   ``quantitative prediction{''} is relevant, but we also need the
   distinction between ``prediction,{''} ``foresight,{''}
   ``forecasting,{''} and ``planning.{''} Finally, the limits of language
   are seen with regard to prediction, where the distinction between ``non
   predictability{''} and ``unpredictability{''} is highlighted.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Article; Book Chapter}},
Language = {{English}},
Affiliation = {{Guillan, A (Corresponding Author), Univ A Coruna, Fac Humanities, Ferrol, Spain.
   Guillan, Amanda, Univ A Coruna, Fac Humanities, Ferrol, Spain.}},
DOI = {{10.1007/978-3-319-63043-4\_2}},
ISSN = {{2365-4228}},
ISBN = {{978-3-319-63043-4; 978-3-319-63042-7}},
Keywords = {{Pragmatic idealism; Semantics; Scientific prediction; Retrodiction;
   Qualitative prediction; Quantitative prediction; Non predictability;
   Unpredictability}},
Keywords-Plus = {{EXPLANATION}},
Research-Areas = {{History \& Philosophy of Science}},
Web-of-Science-Categories  = {{History \& Philosophy Of Science}},
Cited-References = {{DUMMETT M, 1982, SYNTHESE, V52, P55, DOI 10.1007/BF00485255.
   Dummett M., 1963, COMMUNICATION   0308, P145.
   Dummett M., 1985, ANALES FILOSOFIA, V3, P27.
   Dummett M, 1981, FREGE PHILOS LANGUAG.
   Fernandez Valbuena S., 1990, ASPECTOS METODOLOGIC, P385.
   Friedman M., 1953, ESSAYS POSITIVE EC, P3.
   Gonzalez W. J, 2002, DIVERSIDAD EXPLICACI.
   Gonzalez W. J., 1986, TEORIA REFERENCIA ST.
   Gonzalez W. J., 2010, PREDICCION CIENTIFIA.
   Gonzalez W. J., 2003, RACIONALIDAD HIST PR, P65.
   Gonzalez W. J., 2015, PHILOS METHODOLOGICA.
   Gonzalez WJ, 2014, HOPOS, V4, P1.
   Gonzalez WJ, 2001, THEORIA-SPAIN, V16, P499.
   GRUNBAUM A, 1962, PHILOS SCI, V29, P146, DOI 10.1086/287858.
   Guillan A, 2016, POZNAN STUD PHILOS S, V109, P134, DOI 10.1163/9789004325401\_008.
   HELMER O, 1959, MANAGE SCI, V6, P25, DOI 10.1287/mnsc.6.1.25.
   Kuhn T. S., 1970, STRUCTURE SCI REVOLU, P174.
   Lakatos I., 1978, METHODOLOGY SCI RES, V1.
   Malkiel B., 1973, RANDOM WALK WALL STR.
   Mellor D. H., 1975, P BRIT ACAD, V65, P207.
   RESCHER N, 1958, BRIT J PHILOS SCI, V8, P281.
   Rescher N, 1989, COGNITIVE EC EC DIME.
   Rescher N., 1992, SYSTEM PRAGMATIC IDE, VI, P243.
   Rescher N., 1998, COMMUNICATIVE PRAGMA.
   Rescher N., 2006, COMPANION PRAGMATISM, P386.
   Rescher N, 1998, PREDICTING FUTURE IN.
   Rescher N., 2012, MIND SOC, V11, P149, DOI DOI 10.1007/S11299-012-0099-8.
   Rescher N, 1999, LIMITS SCI.
   Rescher N., 1967, P3593 RAND, P3593.
   Rescher N., 1983, PHYS PHILOS PSYCHOAN, V76, P153.
   Rescher N., 2008, EPISTEMIC PRAGMATISM, P13.
   Rescher N, 1988, RATIONALITY PHILOS I.
   RESCHER Nicholas, 1999, RAZON VALORES ERA CI.
   Salmon Wesley C, 1990, 4 DECADES SCI EXPLAN.
   Strawson P. F., 1950, P ARISTOTELIAN SOC, VV, P129.
   Toulmin S. E., 1961, FORESIGHT UNDERSTAND.
   Werndl C, 2009, BRIT J PHILOS SCI, V60, P195, DOI 10.1093/bjps/axn053.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BK8PM}},
Unique-ID = {{ISI:000443326600003}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000431848700081,
Author = {Sanchez, Byron and Zhao, Xiumin and Mitsuishi, Takashi and Aoki,
   Terumasa},
Editor = {{Chen, W and Yang, JC and Ayub, AFM and Wong, SL and Mitrovic, A}},
Title = {{A Study on Prediction of Academic Performance based on Current Learning
   Records of a Language Class using Blended Learning}},
Booktitle = {{25TH INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION (ICCE 2017):
   TECHNOLOGY AND INNOVATION: COMPUTER-BASED EDUCATIONAL SYSTEMS FOR THE
   21ST CENTURY}},
Year = {{2017}},
Pages = {{493-495}},
Note = {{25th International Conference on Computers in Education (ICCE) -
   Technology and Innovation - Computer-Based Educational Systems for the
   21st Century, Christchurch, NEW ZEALAND, DEC 04-08, 2017}},
Abstract = {{In this paper, we describe a classification method that does not rely on
   historic data to predict changes in student academic performance, and
   therefore predict if a student will fail a class or not. By classifying
   students into groups given their grades, and extracting the common
   features in between them, it is possible to use those common features to
   predict if other students that share common characteristics will fall
   into the same classification groups. As well, those same common features
   can be used to help students improve their academic performance.}},
Publisher = {{ASIA PACIFIC SOC COMPUTERS IN EDUCATION}},
Address = {{NO 300, JUNGDA RD, JHONGLI DISTRICT, TAOYUAN CITY, 320, TAIWAN}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sanchez, B (Corresponding Author), Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
   Sanchez, Byron; Aoki, Terumasa, Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
   Zhao, Xiumin, Tohoku Univ, Ctr Educ Informat, Sendai, Miyagi, Japan.
   Mitsuishi, Takashi, Tohoku Univ, Inst Excellence Higher Educ, Sendai, Miyagi, Japan.}},
ISBN = {{978-986-94012-6-5}},
Keywords = {{K-Means clustering; feature selection; student performance prediction;
   unsupervised learning; learning analytics}},
Research-Areas = {{Computer Science; Education \& Educational Research}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods;
   Education \& Educational Research}},
Author-Email = {{byronism@riec.tohoku.ac.jp}},
Funding-Acknowledgement = {{JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) {[}JP15K02709,
   JP15K01012]; Grants-in-Aid for Scientific ResearchMinistry of Education,
   Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for
   the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)
   {[}15K01012] Funding Source: KAKEN}},
Funding-Text = {{This work was supported by the JSPS KAKENHI grant, numbers JP15K02709
   and JP15K01012. We would also like to thank the members of both
   Mitsuishi Lab and Aoki Lab at Tohoku University for their insight and
   input into the topic since the beginning.}},
Cited-References = {{Ade R., 2014, P 3 INT C REL INF TE, P1.
   Bote-Lorenzo M.L., 2017, P 7 INT LEARN AN KNO.
   Hlosta M., 2017, P 7 INT LEARN AN KNO.
   Pardo A, 2016, LAK `16 CONFERENCE PROCEEDINGS: THE SIXTH INTERNATIONAL LEARNING ANALYTICS \& KNOWLEDGE CONFERENCE,, P474, DOI 10.1145/2883851.2883870.
   Ueno M., 2003, P WORLD C ED MULT HY, V2003, P227.}},
Number-of-Cited-References = {{5}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BK1KC}},
Unique-ID = {{ISI:000431848700081}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000428073701009,
Author = {Zhang, Daniel (Yue) and Wang, Dong and Zheng, Hao and Mu, Xin and Li, Qi
   and Zhang, Yang},
Editor = {{Nie, JY and Obradovic, Z and Suzumura, T and Ghosh, R and Nambiar, R and Wang, C and Zang, H and BaezaYates, R and Hu, X and Kepner, J and Cuzzocrea, A and Tang, J and Toyoda, M}},
Title = {{Large-scale Point-of-Interest Category Prediction Using Natural Language
   Processing Models}},
Booktitle = {{2017 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)}},
Series = {{IEEE International Conference on Big Data}},
Year = {{2017}},
Pages = {{1027-1032}},
Note = {{IEEE International Conference on Big Data (IEEE Big Data), Boston, MA,
   DEC 11-14, 2017}},
Organization = {{IEEE; IEEE Comp Soc; ELSEVIER; CISCO}},
Abstract = {{Point-of-Interest (POI) recommendation is an important application in
   Location-based Social Networks (LBSN). The category prediction problem
   is to predict the next POI category that users may visit. The predicted
   category information is critical in large-scale POI recommendation
   because it can significantly reduce the prediction space and improve the
   recommendation accuracy. While efforts have been made to address the POI
   category prediction problem, several important challenges still exist.
   First, existing solutions did not fully explore the temporal dependency
   (e.g., ``long range dependency{''}) of users' check-in traces. Second,
   the hidden contextual information associated with each check-in point
   has been underutilized. In this work, we propose a Context-Aware POI
   Category Prediction (CAP-CP) scheme using Natural Language Processing
   (NLP) models. In particular, to address temporal dependency challenge,
   we develop a novel Temporal Adaptive Ngram (TA-Ngram) model to capture
   the dynamic dependency between check-in points. To address the challenge
   of hidden context incorporation, CAP-CP leverages the Probabilistic
   Latent Semantic Analysis (PLSA) model to infer the semantic implications
   of the context variables in the prediction model. Empirical results on a
   real world dataset show that our scheme can effectively improve the
   performance of the state-of-the-art POI recommendation solutions.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, D (Corresponding Author), Univ Notre Dame, Dept Comp Sci \& Engn, Notre Dame, IN 46556 USA.
   Zhang, Daniel (Yue); Wang, Dong; Zheng, Hao; Li, Qi; Zhang, Yang, Univ Notre Dame, Dept Comp Sci \& Engn, Notre Dame, IN 46556 USA.
   Mu, Xin, Univ Notre Dame, Dept Aerosp \& Mech Engn, Notre Dame, IN 46556 USA.}},
ISSN = {{2639-1589}},
ISBN = {{978-1-5386-2715-0}},
Keywords = {{POI Recommendation; Context-Aware Prediction; Natural Language
   Processing; Location-based Social Networks}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems}},
Author-Email = {{yzhang40@nd.edu
   dwang5@nd.edu
   hzheng3@nd.edu
   xmu@nd.edu
   qli8@nd.edu
   yzhang42@nd.edu}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}CBET-1637251, CNS-1566465, IIS-1447795]; Army Research Office
   {[}W911NF-17-1-0409]}},
Funding-Text = {{This research is supported in part by the National Science Foundation
   under Grant No. CBET-1637251, CNS-1566465 and IIS-1447795 and Army
   Research Office under Grant W911NF-17-1-0409. The views and conclusions
   contained in this document are those of the authors and should not be
   interpreted as representing the official policies, either expressed or
   implied, of the Army Research Office or the U.S. Government. The U.S.
   Government is authorized to reproduce and distribute reprints for
   Government purposes not with standing any copyright notation here on.}},
Cited-References = {{Cheng C., 2013, P 23 INT JOINT C ART, V13, P2605.
   Feng SS, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2069.
   Gao Huiji, 2013, P 7 ACM C REC SYST, P93, DOI DOI 10.1145/2507157.2507182.
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649.
   Huang C, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P676, DOI 10.1109/BigData.2016.7840660.
   Huang C, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P13, DOI 10.1109/SmartCity.2015.40.
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797.
   Liu X., 2013, P 22 ACM INT C INF K, P733, DOI DOI 10.1145/2505515.2505639.
   Liu YC, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1015, DOI 10.1145/2939672.2939773.
   Wang D., 2015, SOCIAL SENSING BUILD.
   Wang XR, 2007, IEEE DATA MINING, P697, DOI 10.1109/ICDM.2007.86.
   Witten I. H., 1999, MANAGING GIGABYTES C.
   Wu J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PLASMA SCIENCE (ICOPS).
   Yang D., 2015, ACM T INTEL SYST TEC, V7, P467.
   Yao ZJ, 2016, IEEE DATA MINING, P549, DOI {[}10.1109/ICDM.2016.137, 10.1109/ICDM.2016.0066].
   Ye J., 2013, P 2013 SIAM INT C DA, P171, DOI DOI 10.1137/1.9781611972832.19.
   Ye M., 2011, P 34 INT ACM SIGIR C, P325, DOI DOI 10.1145/2009916.2009962.
   Yin HZ, 2016, IEEE T KNOWL DATA EN, V28, P2566, DOI 10.1109/TKDE.2016.2580511.
   Yuan Q, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH \& DEVELOPMENT IN INFORMATION RETRIEVAL, P363.
   Zhang D, 2017, INT CON DISTR COMP S, P966, DOI 10.1109/ICDCS.2017.196.
   Zhang D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1076, DOI 10.1109/BigData.2016.7840710.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BJ8DN}},
Unique-ID = {{ISI:000428073701009}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000426992400069,
Author = {Yusnita, M. A. and Hafiz, A. M. and Fadzilah, Nor M. and Zulhanip, Aida
   Zulia and Idris, Mohaiyedin},
Book-Group-Author = {{IEEE}},
Title = {{Automatic Gender Recognition using Linear Prediction Coefficients and
   Artificial Neural Network on Speech Signal}},
Booktitle = {{2017 7TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND
   ENGINEERING (ICCSCE)}},
Year = {{2017}},
Pages = {{372-377}},
Note = {{7th IEEE International Conference on Control System Computing and
   Engineering (ICCSCE), MALAYSIA, NOV 24-26, 2017}},
Organization = {{IEEE Control System Soc, Chapter Malaysia; Univ Teknologi MARA; IEEE
   Malaysia Sect}},
Abstract = {{Automatic Gender Recognition (AGR) system is an intelligent machine
   inspired by the highly advanced skills of human cognitive and developed
   through adequate training to recognize the gender of a speaker as male
   or female. In this paper, speech from 93 speakers were extracted using
   Linear Prediction Coefficients (LPC). Pre-processing steps such as
   normalization, pre-emphasis, frame blocking and windowing were carried
   out prior to feature extraction. The LPC coefficients of different order
   was investigated to produce the optimum parameters for the developed
   AGR. Artificial Neural Network (ANN) was used as the recognition engine
   and Multi-Layer Perceptron (MLP) was adopted to train the ANN. The
   experimental results show the highest overall recognition rate that can
   be achieved by the proposed system was 93.3\% in average and the results
   also indicate almost equal performance for the detection of male and
   female throughout the experiments.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Yusnita, MA (Corresponding Author), Univ Teknol MARA, Fac Elect Engn, Permatang Pauh 13500, Penang, Malaysia.
   Yusnita, M. A.; Hafiz, A. M.; Fadzilah, Nor M.; Zulhanip, Aida Zulia; Idris, Mohaiyedin, Univ Teknol MARA, Fac Elect Engn, Permatang Pauh 13500, Penang, Malaysia.}},
ISBN = {{978-1-5386-3897-2}},
Keywords = {{Automatic gender recognition; linear prediction coefficients; artificial
   neural network; multi-layer perceptron; speech recognition system}},
Keywords-Plus = {{CLASSIFICATION; EMOTION; AGE}},
Research-Areas = {{Automation \& Control Systems; Computer Science; Engineering}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic}},
Author-Email = {{yusnita082@ppinang.uitm.edu.my}},
Funding-Acknowledgement = {{Universiti Teknologi MARA Pulau Pinang, Malaysia}},
Funding-Text = {{The authors would like to acknowledge the financial support and
   encouragement given by the Universiti Teknologi MARA Pulau Pinang,
   Malaysia and Professor James M. Hillenbrand from Western Michigan
   University, United States for his courtesy of speech raw database.}},
Cited-References = {{DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   Firoz Shah A, 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, \& Telecommunication Technologies (ACT 2009), P162, DOI 10.1109/ACT.2009.49.
   Furui S., 2001, DIGITAL SPEECH PROCE, V7.
   GUPTA M, 2016, 4 INT C PAR DISTR GR, P737.
   Harila MJ, 2011, J PEDIAT HEMATOL ONC, V33, P194, DOI 10.1097/MPH.0b013e3181ff0e2e.
   Jang J.-S. R., AUDIO SIGNAL PROCESS.
   Kaya H, 2017, COMPUT SPEECH LANG, V46, P268, DOI 10.1016/j.csl.2017.06.002.
   Keyvanrad Mohammad Ali, 2009, 2009 14th International CSI Computer Conference (CSICC 2009) (Postponed from July 2009), P613, DOI 10.1109/CSICC.2009.5349647.
   Ladde PP, 2015, INT CONF COMPUT INTE, P713, DOI 10.1109/CICN.2015.145.
   Lim S., 2009, CLUST COMP WORKSH 20, P1, DOI DOI 10.1109/CLUSTR.2009.5289159.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   McLoughlin I., 2009, APPL SPEECH AUDIO PR.
   Qawaqneh Z, 2017, EXPERT SYST APPL, V85, P76, DOI 10.1016/j.eswa.2017.05.037.
   Rabiner L., 1993, FUNDAMENTALS SPEECH, V103.
   Sivanandam S. N., 2005, INTRO ARTIFICIAL NEU.
   Thasleema TM, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL II, PROCEEDINGS, P361, DOI 10.1109/ICCIMA.2007.372.
   Trabelsi A, 2007, 2007 International IEEE Northeast Workshop on Circuits and Systems (NEWCAS `07), P93, DOI 10.1109/NEWCAS.2007.4487956.
   Vallabha G., 2004, CHOICE FILTER ORDER, pC203.
   Yuan Yujin, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P765, DOI 10.1109/ICICISYS.2010.5658337.
   Yusnita MA, 2013, PROCEDIA ENGINEER, V64, P385, DOI 10.1016/j.proeng.2013.09.111.
   Yusnita M. A., 2012, 2012 IEEE Symposium on Computer Applications and Industrial Electronics (ISCAIE), P179, DOI 10.1109/ISCAIE.2012.6482092.
   Yusnita M. A., 2011, Proceedings of the 2011 IEEE International Conference on Control System, Computing and Engineering (ICCSCE), P472, DOI 10.1109/ICCSCE.2011.6190572.
   Yusnita M. A., 2016, LECT NOTES ELECT ENG, V362, P161.
   Zourmand A., 2012, 2012 Fourth International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM 2012), P282, DOI 10.1109/CIMSim.2012.95.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJ7BG}},
Unique-ID = {{ISI:000426992400069}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000426939000058,
Author = {Dietzen, Thomas and Doclo, Simon and Spriet, Ann and Tirry, Wouter and
   Moonen, Marc and van Waterschoot, Toon},
Book-Group-Author = {{IEEE}},
Title = {{LOW-COMPLEXITY KALMAN FILTER FOR MULTI-CHANNEL LINEAR-PREDICTION-BASED
   BLIND SPEECH DEREVERBERATION}},
Booktitle = {{2017 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND
   ACOUSTICS (WASPAA)}},
Series = {{IEEE Workshop on Applications of Signal Processing to Audio and
   Acoustics}},
Year = {{2017}},
Pages = {{284-288}},
Note = {{IEEE Workshop on Applications of Signal Processing to Audio and
   Acoustics (WASPAA), New Paltz, NY, OCT 15-18, 2017}},
Abstract = {{Multi-channel linear prediction (MCLP) has been shown to be a suitable
   framework for tackling the problem of blind speech dereverberation. In
   recent years, a number of adaptive MCLP algorithms have been proposed,
   whereby the majority operates in the short-time Fourier transform (STFT)
   domain. In this paper, we focus on the STFT-based Kalman filter solution
   to the adaptive MCLP task. Similarly to all other available adaptive
   STFT-based MCLP algorithms, the Kalman filter exhibits a quadratic
   computational cost in the number of filter coefficients per frequency
   bin. Aiming at a reduced complexity, we propose to simplify to the
   Kalman filter solution by enforcing the state error correlation matrix
   to be block-diagonal, leading to a linear cost instead. Further, we
   apply a Wiener-gain spectral post-processor subsequent to MCLP, which is
   designed from readily available power spectral density (PSD) estimates.
   The convergence behavior of the standard and the simplified algorithm is
   evaluated by means of two objective measures, i.e. perceptual evaluation
   of speech quality (PESQ) and short-time objective intelligibility
   (STOI), showing only a minor performance degradation for the simplified
   algorithm.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Dietzen, T (Corresponding Author), Katholieke Univ Leuven, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, Dept Elect Engn ESAT, Leuven, Belgium.
   Dietzen, T (Corresponding Author), NXP Semicond Belgium NV, Leuven, Belgium.
   Dietzen, Thomas; Moonen, Marc; van Waterschoot, Toon, Katholieke Univ Leuven, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, Dept Elect Engn ESAT, Leuven, Belgium.
   Dietzen, Thomas; Spriet, Ann; Tirry, Wouter, NXP Semicond Belgium NV, Leuven, Belgium.
   Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust \& Cluster Excellence Heari, Oldenburg, Germany.
   van Waterschoot, Toon, Katholieke Univ Leuven, Dept Elect Engn ESAT ETC, Geel, Belgium.}},
ISSN = {{1931-1168}},
ISBN = {{978-1-5386-1632-1}},
Keywords = {{Speech dereverberation; Kalman filter; multi-channel linear prediction;
   low complexity}},
Keywords-Plus = {{REVERBERATION; ENHANCEMENT}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Funding-Acknowledgement = {{KU Leuven Internal Funds {[}C2-16-00449]; KU Leuven Impulse Fund
   {[}IMP/14/037]; European CommissionEuropean CommissionEuropean
   Commission Joint Research Centre {[}316969]; KU Leuven Research Council
   CoE {[}PFV/10/002]}},
Funding-Text = {{This research work was carried out in the frame of KU Leuven Research
   Council CoE PFV/10/002 (OPTEC), KU Leuven Impulse Fund IMP/14/037, KU
   Leuven Internal Funds C2-16-00449 `Distributed Digital Signal Processing
   for Ad-hoc Wireless Local Area Audio Networking', and the FP7-PEOPLE
   Marie Curie Initial Training Network `Dereverberation and Reverberation
   of Audio, Music, and Speech (DREAMS)', funded by the European Commission
   under Grant Agreement no. 316969. The scientific responsibility is
   assumed by its authors.}},
Cited-References = {{{[}Anonymous], 1992, MUS ARCH.
   Avargel Y, 2007, IEEE T AUDIO SPEECH, V15, P1305, DOI 10.1109/TASL.2006.889720.
   Braun S, 2016, IEEE SIGNAL PROC LET, V23, P1741, DOI 10.1109/LSP.2016.2616888.
   Braun S, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0077-2.
   Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698.
   Dietzen T., 2017, AUDIO EXAMPLES WASPA.
   Dietzen T., 2016, P INT WORKSH AC SIGN, P1.
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453.
   Hadad E, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P313, DOI 10.1109/IWAENC.2014.6954309.
   Haykin S., 2002, ADAPTIVE FILTER THEO.
   ITU-T, 2001, ITU T RECPMMENDATION.
   Jukic A, 2017, IEEE SIGNAL PROC LET, V24, P101, DOI 10.1109/LSP.2016.2640939.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Kodrasi I, 2017, INT CONF ACOUST SPEE, P611, DOI 10.1109/ICASSP.2017.7952228.
   Kuech Fabian, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1295, DOI 10.1109/ICASSP.2014.6853806.
   Kuklasinski A, 2016, IEEE-ACM T AUDIO SPE, V24, P1599, DOI 10.1109/TASLP.2016.2573591.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Triki M., 2005, P 2005 INT WORKSH AC, P173.
   Valero ML, 2015, INT CONF ACOUST SPEE, P599, DOI 10.1109/ICASSP.2015.7178039.
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2009, INT CONF ACOUST SPEE, P3733, DOI 10.1109/ICASSP.2009.4960438.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJ6SM}},
Unique-ID = {{ISI:000426939000058}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000426939000066,
Author = {Villemoes, Lars and Klejsa, Janusz and Hedelin, Per},
Book-Group-Author = {{IEEE}},
Title = {{SPEECH CODING WITH TRANSFORM DOMAIN PREDICTION}},
Booktitle = {{2017 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND
   ACOUSTICS (WASPAA)}},
Series = {{IEEE Workshop on Applications of Signal Processing to Audio and
   Acoustics}},
Year = {{2017}},
Pages = {{324-328}},
Note = {{IEEE Workshop on Applications of Signal Processing to Audio and
   Acoustics (WASPAA), New Paltz, NY, OCT 15-18, 2017}},
Abstract = {{We show how model based prediction can be employed in the construction
   of a speech codec which operates entirely in the frequency domain of a
   Modified Discrete Cosine Transform (MDCT). The codec tools described in
   this paper are part of the Dolby AC-4 system standardized by ETSI and
   included in ATSC 3.0.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Villemoes, L (Corresponding Author), Dolby Sweden AB, Stockholm, Sweden.
   Villemoes, Lars; Klejsa, Janusz; Hedelin, Per, Dolby Sweden AB, Stockholm, Sweden.}},
ISSN = {{1931-1168}},
ISBN = {{978-1-5386-1632-1}},
Keywords = {{Speech coding; long term prediction; MDCT; audio coding}},
Keywords-Plus = {{HIGH-QUALITY; CODEC; RATES}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Cited-References = {{{[}Anonymous], 2005, LOW COMPLEXITY CODIN.
   {[}Anonymous], 2015, METH SUBJ ASS INT QU.
   {[}Anonymous], 2015, 1031901V121 ETSI TS.
   Bessette B, 2002, IEEE T SPEECH AUDI P, V10, P620, DOI 10.1109/TSA.2002.804299.
   Burg JP, 1968, MODERN SPECTRUM ANAL.
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541.
   ITU, 2011, PERC OBJ LIST QUAL A.
   Nanjundaswamy T, 2014, IEEE-ACM T AUDIO SPE, V22, P697, DOI 10.1109/TASLP.2014.2303292.
   Neuendorf M, 2013, J AUDIO ENG SOC, V61, P956.
   Ojanpera J., 1999, AUDIO ENG SOC CONVEN.
   Ramprashad SA, 2003, IEEE T SPEECH AUDI P, V11, P117, DOI 10.1109/TSA.2003.809195.
   Riedmiller Jeffrey, 2017, IEEE Transactions on Broadcasting, V63, P179, DOI 10.1109/TBC.2017.2659623.
   Valin JM, 2010, IEEE T AUDIO SPEECH, V18, P58, DOI 10.1109/TASL.2009.2023186.
   Zamir R, 1996, IEEE T INFORM THEORY, V42, P1340, DOI 10.1109/18.532876.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJ6SM}},
Unique-ID = {{ISI:000426939000066}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000426458000030,
Author = {Zhang, Jianxin and Xu, Weifeng and Zhang, Qiang and Jin, Bo and Wei,
   Xiaopeng},
Book-Group-Author = {{IEEE}},
Title = {{Exploring Risk Factors and Predicting UPDRS Score Based on Parkinson's
   Speech Signals}},
Booktitle = {{2017 IEEE 19TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING,
   APPLICATIONS AND SERVICES (HEALTHCOM)}},
Year = {{2017}},
Note = {{19th Annual IEEE International Conference on e-Health Networking,
   Applications and Services (Healthcom), Dalian, PEOPLES R CHINA, OCT
   12-15, 2017}},
Organization = {{IEEE; IEEE Commun Soc}},
Abstract = {{The unified Parkinson's disease rating scale (UPDRS) is the most widely
   employed scale for tracking Parkinson's disease (PD) symptom
   progression. However, conventional way to achieve UPDRS, mainly based on
   the physical examinations of clinic patients performed by the trained
   medical staffs, involves the disadvantages of inconvenience and high
   medical expense. Hence, in this study, we try to explore some risk
   factors and accurately predict the UPDRS for PD, using the speech
   signals of PD patients published on UCI machine-learning archive. More
   specifically, inspired by the idea of ensemble learning, we firstly
   construct a framework of ensemble feature selection (EFS) to select a
   suitable subset of features among numerous speech signals. Subsequently,
   a personalized predictive model, trained by adopting information from
   similar patients, is developed to be customized for an individual PD
   patient. Finally, we employ the personalized predictive model to predict
   UPDRS score combined with various classical regression algorithms.
   Compared to conventional models, our study has a potential to capture
   more relevant risk factors and produces more accurate UPDRS score for
   individual patient. Experimental results on real-world dataset from UCI
   machine-learning archive show that our personalized predictive model
   gets a promising performance.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, JX; Zhang, Q (Corresponding Author), Dalian Univ, Minist Educ, Key Lab Adv Design \& Intelligent Comp, Dalian, Peoples R China.
   Zhang, Jianxin; Xu, Weifeng; Zhang, Qiang; Wei, Xiaopeng, Dalian Univ, Minist Educ, Key Lab Adv Design \& Intelligent Comp, Dalian, Peoples R China.
   Jin, Bo, Dalian Univ Technol, Sch Comp Sci, Dalian, Peoples R China.}},
ISBN = {{978-1-5090-6704-6}},
Keywords = {{UPDRS; speech signals; framework of ensemble feature selection;
   personalized predictive model}},
Research-Areas = {{Computer Science; Engineering; Medical Informatics}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Medical Informatics}},
Author-Email = {{jxzhang0411@163.com
   zhangq26@126.com}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}91546123, 61202251]; Program for
   Changjiang Scholars and Innovative Research Team in UniversityProgram
   for Changjiang Scholars \& Innovative Research Team in University
   (PCSIRT) {[}IRT 15R07]; Program for Liaoning Innovative Research Team in
   University {[}LT2015002]; Liaoning Provincial Natural Science Foundation
   {[}201602035]; High-level Talent Innovation Support Program of Dalian
   City {[}2016RQ078]}},
Funding-Text = {{We acknowledge the support from the National Natural Science Foundation
   of China (No. 91546123, 61202251), Program for Changjiang Scholars and
   Innovative Research Team in University (No. IRT 15R07), Program for
   Liaoning Innovative Research Team in University (No. LT2015002), the
   Liaoning Provincial Natural Science Foundation (No. 201602035), and from
   the High-level Talent Innovation Support Program of Dalian City (No.
   2016RQ078).}},
Cited-References = {{Ayuk-Egbe B. Patricia, 2001, AM J PHARM EDUC, V65.3, P998.
   Brabenec L., 1996, J NEURAL TRANSMISSIO.
   Canturk I, 2016, ARAB J SCI ENG, V41, P5049, DOI 10.1007/s13369-016-2206-3.
   Castelli M, 2014, EXPERT SYST APPL, V41, P4608, DOI 10.1016/j.eswa.2014.01.018.
   Galaz Z, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P503, DOI 10.1109/TSP.2016.7760930.
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616.
   Hamon J., 2013, OPTIMISATION COMBINA.
   Jain S, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMPUTER ENGINEERING AND THEIR APPLICATIONS (EECEA), P104, DOI 10.1109/EECEA.2016.7470774.
   Lasierra N, 2012, INT J MED INFORM, V81, P332, DOI 10.1016/j.ijmedinf.2012.02.008.
   Lesage S, 2009, HUM MOL GENET, V18, pR48, DOI 10.1093/hmg/ddp012.
   Lisak P. Robert, 2016, INT NEUROLOGY, P188.
   Liu Y, 2015, IEEE T CYBERNETICS, V45, P1209, DOI 10.1109/TCYB.2014.2347372.
   Ng Kenney, 2015, AMIA Jt Summits Transl Sci Proc, V2015, P132.
   Nicolas G., 2015, 16 ANN C INT SPEECH.
   Overby CL, 2013, J AM MED INFORM ASSN, V20, pE243, DOI 10.1136/amiajnl-2013-001930.
   Phuong T. M., 2005, COMP SYST BIOINF C P.
   Ramaker C, 2002, MOVEMENT DISORD, V17, P867, DOI 10.1002/mds.10248.
   Rusz J, 2011, J ACOUST SOC AM, V129, P350, DOI 10.1121/1.3514381.
   Sakar B. Erdogdu, 2015, BIOINF BIOENG BIBE 2.
   Sakar CO, 2010, J MED SYST, V34, P591, DOI 10.1007/s10916-009-9272-y.
   Samii A, 2004, LANCET, V363, P1783, DOI 10.1016/S0140-6736(04)16305-8.
   Sveinbjornsdottir S., 2016, J NEUROCHEM, V139.
   Sveinbjornsdottir S, 2016, J NEUROCHEM, V139, P318, DOI 10.1111/jnc.13691.
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x.
   Tsanas A, 2010, IEEE T BIO-MED ENG, V57, P884, DOI 10.1109/TBME.2009.2036000.
   Vadovsk M., 2017, APPL MACH INT INF SA.
   Van Maele-Fabry G., 2013, ENVIRON INT, V46, P3043.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BJ6CB}},
Unique-ID = {{ISI:000426458000030}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000424192700180,
Author = {Alghamdi, Ahmed and Chan, Wai-Yip},
Book-Group-Author = {{IEEE}},
Title = {{Single-ended Intelligibility Prediction of Noisy Speech Based on
   Auditory Features}},
Booktitle = {{2017 IEEE 30TH CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER
   ENGINEERING (CCECE)}},
Series = {{Canadian Conference on Electrical and Computer Engineering}},
Year = {{2017}},
Note = {{30th IEEE Canadian Conference on Electrical and Computer Engineering
   (CCECE), Windsor, CANADA, APR 30-MAY 03, 2017}},
Organization = {{IEEE}},
Abstract = {{In this work, we present a low-complexity single-ended objective
   intelligibility measure for noisy speech based on statistics computed
   from auditory modulation features. The proposed measure is obtained in
   two steps. First, we compute several statistics of auditory
   representation of corrupted speech. Next, a support vector regressor
   (SVR) is used to map these statistics to an overall intelligibility
   score. The SVR is trained using subjective intelligibility data. The
   proposed measure shows high performance in predicting intelligibility of
   speech corrupted with additive noise.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Alghamdi, A (Corresponding Author), Queens Univ, Dept Elect \& Comp Engn, Kingston, ON, Canada.
   Alghamdi, Ahmed; Chan, Wai-Yip, Queens Univ, Dept Elect \& Comp Engn, Kingston, ON, Canada.}},
ISSN = {{0840-7789}},
ISBN = {{978-1-5090-5538-8}},
Keywords = {{Single-ended intelligibility measure; intelligibility prediction}},
Keywords-Plus = {{REVERBERANT; QUALITY}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{12aa89@queensu.ca
   chan@queensu.ca}},
Cited-References = {{American National Standards Institute, 1997, METH CALC SPEECH INT.
   {[}Anonymous], 1993, P56 ITUT.
   Chen F., 2013, P SAS GLOB FOR 2013, P1.
   Chen F, 2013, BIOMED SIGNAL PROCES, V8, P311, DOI 10.1016/j.bspc.2012.11.007.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673.
   PUDIL P, 1994, INT C PATT RECOG, P279, DOI 10.1109/ICPR.1994.576920.
   Ravindran S, 2006, P ISCA SAPA PITTSB P, P48.
   Santos JF, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P55, DOI 10.1109/IWAENC.2014.6953337.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEIGER JH, 1980, PSYCHOL BULL, V87, P245, DOI 10.1037/0033-2909.87.2.245.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BJ3QA}},
Unique-ID = {{ISI:000424192700180}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000426330001155,
Author = {Juin, Chin Char and Wei, Richard Xiong Jun and D'Haro, Luis Fernando and
   Banchs, Rafael E.},
Book-Group-Author = {{IEEE}},
Title = {{Punctuation Prediction using a Bidirectional Recurrent Neural Network
   with Part-of-Speech Tagging}},
Booktitle = {{TENCON 2017 - 2017 IEEE REGION 10 CONFERENCE}},
Series = {{TENCON IEEE Region 10 Conference Proceedings}},
Year = {{2017}},
Pages = {{1806-1811}},
Note = {{IEEE Region 10 Conference (TENCON), MALAYSIA, NOV 05-08, 2017}},
Organization = {{IEEE; IEEE Region 10}},
Abstract = {{Most automatic speech recognition (ASR) systems are incapable of
   generating punctuation, making it difficult to read the transcribed
   output and less appropriate for tasks such as dictation. This paper
   introduces a procedure to automatically insert punctuation into
   unpunctuated sentences by using a bidirectional recurrent neural network
   with attention mechanism and Part-of-Speech (POS) Tags. Using the
   WikiText Long Term Dependency Language Modelling Dataset and handling 11
   different punctuation symbols, the model managed to achieve a
   punctuation error rate of 31.4\% and an F1 score of 785\%. When the
   system was trained on consecutive sentences and a smaller dataset using
   the Europarl v7 corpus, the model still managed to achieve a punctuation
   error rate of 48.1\% and an F1 score of 64.7\%. In both cases, our
   proposed system outperforms previous state-of-the-art systems trained on
   the same datasets, showing the advantage of using POS tags information
   and an encoder decoder network.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Juin, CC (Corresponding Author), Anglochinese Sch, Singapore 139650, Singapore.
   Juin, Chin Char, Anglochinese Sch, Singapore 139650, Singapore.
   Wei, Richard Xiong Jun, Hwa Chong Inst, 661 Bukit Timah Rd, Singapore 269734, Singapore.
   D'Haro, Luis Fernando; Banchs, Rafael E., ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.}},
ISSN = {{2159-3442}},
ISBN = {{978-1-5090-1134-6}},
Keywords = {{deep neural networks; punctuation prediction; sequence-to-sequence
   approach}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{chincharjuin@gmail.com
   junweixiong@hotmail.com
   luisdhe@i2r.a-star.edu.sg
   rembanchs@i2r.a-star.edu.sg}},
ResearcherID-Numbers = {{DHaro, Luis Fernando/Q-6664-2019
   D'Haro, Luis Fernando L.F/B-8194-2011}},
ORCID-Numbers = {{DHaro, Luis Fernando/0000-0002-3411-7384
   D'Haro, Luis Fernando L.F/0000-0002-3411-7384}},
Cited-References = {{Bahdanau D., 2014, ARXIV14090473.
   Cho Kyunghyun, 2014, ARXIV14061078.
   Chopra S., 2015, ARXIV150900685.
   Christensen Heidi, 2001, ISCA TUT RES WORKSH.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Kim Y, SEQUENCE TO SEQUENCE.
   Klein G, 2017, ARXIV170102810.
   Koehn P, 2005, MT SUMMIT, V5, P79, DOI DOI 10.3115/1626355.1626380.
   Lu Wei, 2010, P 2010 C EMP METH NA, P177.
   Luong M.-T., 2015, ARXIV150804025.
   Matusov E., 2006, IWSLT, P158.
   Merity S., 2016, ARXIV160907843.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Peitz Stephan, 2011, IWSLT, P238.
   Salimbajevs A, 2016, FRONT ARTIF INTEL AP, V289, P59, DOI 10.3233/978-1-61499-701-6-59.
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093.
   Schwartz R., 1990, AC SPEECH SIGN PROC, P81.
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.1007/S10107-014-0839-0.
   Svec Jan, 2004, SPECOM 2004.
   Tiedemann J, 2012, LREC, V2012, P2214.
   Tilk O., 2015, INTERSPEECH 2015.
   Tilk O, 2016, INTERSPEECH, P3047, DOI 10.21437/Interspeech.2016-1517.
   Vinyals Oriol, 2015, ARXIV150605869.
   Waibel A, 2011, INT WORKSH SPOK LANG.
   Yao K, 2016, INT S CHIN SPOK LANG.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJ5UT}},
Unique-ID = {{ISI:000426330001155}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000426116300088,
Author = {Bonifaco, Herbert and Guzman, Kris Roy and Jara, John Neil and Jasareno,
   Alberto Dominic and Zabala, Arthur Christian and Prado, Seigfred V. and
   San Buenaventura, Charlene},
Book-Group-Author = {{IEEE}},
Title = {{Comparative Analysis of Filipino-Based Rhinolalia Aperta Speech Using
   Mel Frequency Cepstral Analysis and Perceptual Linear Prediction}},
Booktitle = {{2017 IEEE 9TH INTERNATIONAL CONFERENCE ON HUMANOID, NANOTECHNOLOGY,
   INFORMATION TECHNOLOGY, COMMUNICATION AND CONTROL, ENVIRONMENT AND
   MANAGEMENT (IEEE HNICEM)}},
Series = {{IEEE International Conference on Humanoid Nanotechnology Information
   Technology Communication and Control Environment and Management}},
Year = {{2017}},
Note = {{9th IEEE International Conference on Humanoid, Nanotechnology,
   Information Technology, Communication and Control, Environment and
   Management (IEEE HNICEM), Pasay, PHILIPPINES, NOV 29-DEC 03, 2017}},
Organization = {{IEEE; IEEE Philippines}},
Abstract = {{In this work, a database collected from two different Filipino Cleft
   Palate patients was used to identify the discriminative features for
   hypernasal speech. Data from the Filipino Speech Corpus (FSC) were used
   as normal speech samples. The features identified were based from three
   feature extraction algorithms, Mel Frequency Cepstrum Coefficient
   (MFCC), Perceptual Linear Prediction (PLP), along with a MFCC-PLP hybrid
   feature extraction method, which was introduced in this study.
   Intraclass and interclass correlation among the speech samples,
   separating the two hypernasal speech samples and along with the normal
   speech samples were computed to determine the correlation of the speech
   samples to each other. This paper will also compare the differences
   between the extracted MFCC features, PLP features and a hybrid of MFCC
   and PLP features to determine the most discriminative features from
   hypernasal speech compared with normal speech and the most
   discriminative features from hypernasal speech obtained from different
   study volunteers through Analysis of Variance (ANOVA) statistical
   analysis. The p-values obtained from the ANOVA test will be the basis to
   determine which features provide a certain degree of significant
   difference between speech samples. The paper will also present and
   determine the most optimal and conclusive feature extraction method in
   analyzing speech samples using MATLAB and through correlation analysis.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bonifaco, H (Corresponding Author), Univ Santo Tomas, Dept Elect Engn, Manila, Philippines.
   Bonifaco, Herbert; Guzman, Kris Roy; Jara, John Neil; Jasareno, Alberto Dominic; Zabala, Arthur Christian; Prado, Seigfred V.; San Buenaventura, Charlene, Univ Santo Tomas, Dept Elect Engn, Manila, Philippines.}},
ISSN = {{2475-7152}},
ISBN = {{978-1-5386-0912-5}},
Keywords = {{automatic speech recognition; Mel Frequency Cesptral Coefficient;
   Perceptual Linear Prediction}},
Research-Areas = {{Engineering; Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Engineering, Multidisciplinary; Engineering, Environmental; Nanoscience
   \& Nanotechnology}},
Author-Email = {{hf.bonii@gmail.com
   royguz66@yahoo.com
   neiljara21@gmail.com
   dominic.jasareno@gmail.com
   ac.zabala@yahoo.com.ph
   svprado@ust.edu.ph
   cvsanbuenaventura@ust.edu.ph}},
Cited-References = {{Abd El-Fattah MA, 2008, PROG ELECTROMA RES M, V4, P167, DOI 10.2528/PIERM08061206.
   Abundo Nerrizza Ann D., 2014, SPEAKER DEPENDENT RH.
   Chelali F., 2011, P WORLD C ENG, V2, P1.
   Dave N., 2013, INT J ADV RES ENG TE, V1.
   Dubey A., 2016, ZERO TIME WINDOWING, P1.
   Farjardo A., 2015, IJARCCE, P1.
   Guevara R., DEV FILIPINO SPEECH.
   Joshi Siddhant C., 2014, INT J SCI ENG TECHNO, V3, P1820.
   Meseguer N., 2009, SPEECH ANAL AUTOMATI, P14.
   Muda L., 2010, J COMP, V2, P138, DOI DOI 10.5815/IJIGSP.2016.09.03.
   Paal Sonja, 2005, J Orofac Orthop, V66, P270, DOI 10.1007/s00056-005-0427-2.
   Shannon BJ, 2003, MICR ENG RES C, P1.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BJ5OG}},
Unique-ID = {{ISI:000426116300088}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000414286205061,
Author = {Huang, Zhaocheng and Epps, Julien},
Book-Group-Author = {{IEEE}},
Title = {{A PLLR AND MULTI-STAGE STAIRCASE REGRESSION FRAMEWORK FOR SPEECH-BASED
   EMOTION PREDICTION}},
Booktitle = {{2017 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2017}},
Pages = {{5145-5149}},
Note = {{IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), New Orleans, LA, MAR 05-09, 2017}},
Organization = {{IEEE; Inst Elect \& Elect Engineers, Signal Proc Soc}},
Abstract = {{Continuous prediction of dimensional emotions (e.g. arousal and valence)
   has attracted increasing research interest recently. When processing
   emotional speech signals, phonetic features have been rarely used due to
   the assumption that phonetic variability is a confounding factor that
   degrades emotion recognition/prediction performance. In this paper,
   instead of eliminating phonetic variability, we investigated whether
   Phone Log-Likelihood Ratio (PLLR) features could be used to index
   arousal and valence in a pairwise low/high framework. A multi-stage
   staircase regression (SR) framework which enables fusion at three
   different stages is also investigated. Results on the RECOLA database
   show that PLLR outperforms EGEMAPS features for arousal and valence.
   Interestingly, long-term averaged PLLR proved to be more robust and
   emotionally informative than local frame-level PLLR, which contains more
   phoneme-specific information. Within the multistage SR framework, PLLR
   yielded an 8.2\% and 11.6\% relative improvement in CCC for arousal and
   valence respectively, showing great promise for including phonetic
   features in emotion prediction systems.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Huang, ZC (Corresponding Author), UNSW Australia, Sch Elect Engn \& Telecommun, Sydney, NSW, Australia.
   Huang, ZC (Corresponding Author), CSIRO, Data61, Canberra, ACT, Australia.
   Huang, Zhaocheng; Epps, Julien, UNSW Australia, Sch Elect Engn \& Telecommun, Sydney, NSW, Australia.
   Huang, Zhaocheng; Epps, Julien, CSIRO, Data61, Canberra, ACT, Australia.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-5090-4117-6}},
Keywords = {{Phone log-likelihood ratio; staircase regression; relevance vector
   machine; emotion prediction}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{zhaocheng.huang@unsw.edu.au
   j.epps@unsw.edu.au}},
ResearcherID-Numbers = {{Huang, Zhaocheng/R-2904-2019
   }},
ORCID-Numbers = {{Epps, Julien/0000-0001-6624-5551}},
Funding-Acknowledgement = {{Data61, CSIRO}},
Funding-Text = {{This work is partly funded by Data61, CSIRO. The authors would like to
   thank their colleagues Mr. Sarith Fernando and Mr. Saad Irtza for their
   help with the PLLR features and helpful discussions.}},
Cited-References = {{Bitouk D, 2010, SPEECH COMMUN, V52, P613, DOI 10.1016/j.specom.2010.02.010.
   Caballero-Morales S. O., 2013, SCI WORLD J, V2013, P13.
   Cowie R., 2012, INT J SYNTHETIC EMOT, V3, P1, DOI DOI 10.4018/jse.2012010101.
   Cummins N., 2016, THESIS.
   Diez M., 2012, SLT 2012 IEEE.
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI {[}DOI 10.1145/2502081.2502224, 10.1145/2502081.2502224].
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417.
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016.
   Huang Z., 2016, P 6 INT WORKSH AVEC.
   Huang Z, 2015, P 5 INT WORKSH AVEC.
   Lee C. M., 2004, 8 INT C SPOK LANG PR, P889.
   Mariooryad S, 2014, SPEECH COMMUN, V57, P1, DOI 10.1016/j.specom.2013.07.011.
   Mporas I, 2010, INT J PATTERN RECOGN, V24, P1159, DOI 10.1142/S0218001410008329.
   Origlia A, 2014, SPEECH COMMUN, V57, P155, DOI 10.1016/j.specom.2013.09.012.
   Ringeval F., 2015, P 5 INT WORKSH AUD V, P3, DOI DOI 10.1145/2808196.2811642.
   Ringeval F., 2013, AUT FAC GEST REC FG, P1, DOI {[}DOI 10.1109/FG.2013.6553805, 10.1109/FG.2013.6553805].
   Ringeval F, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2763.
   Roach P., 2000, ISCA WORKSH SPEECH E, P53, DOI DOI 10.1051/0004-6361/201220577.
   Sanchez Marcelo, 2015, THESIS.
   Schmitt M, 2016, INTERSPEECH, P495, DOI 10.21437/Interspeech.2016-1124.
   Schuller B, 2012, ICMI `12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449.
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336.
   Schwarz Petr, 2008, THESIS.
   Sethu V., 2015, SPEECH AUDIO PROCESS, P197.
   Sethu V, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P617.
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236.
   Valstar M, 2016, P 6 INT WORKSH AVEC.
   Vlasenko B, 2008, LECT NOTES ARTIF INT, V5078, P217, DOI 10.1007/978-3-540-69369-7\_24.
   Vlasenko B, 2014, COMPUT SPEECH LANG, V28, P483, DOI 10.1016/j.csl.2012.11.003.
   WILLIAMS J, 2014, NY TIMES BK REV, V119, P4.
   Williamson J. R., 2013, P 3 ACM INT WORKSH A, P41, DOI DOI 10.1145/2512530.2512531.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI7JW}},
Unique-ID = {{ISI:000414286205061}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000414286205098,
Author = {Meyer, Bernd T. and Mallidi, Harish and Kayser, Hendrik and Hermansky,
   Hynek},
Book-Group-Author = {{IEEE}},
Title = {{PREDICTING ERROR RATES FOR UNKNOWN DATA IN AUTOMATIC SPEECH RECOGNITION}},
Booktitle = {{2017 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2017}},
Pages = {{5330-5334}},
Note = {{IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), New Orleans, LA, MAR 05-09, 2017}},
Organization = {{IEEE; Inst Elect \& Elect Engineers, Signal Proc Soc}},
Abstract = {{In this paper we investigate methods to predict word error rates in
   automatic speech recognition in the presence of unknown noise types,
   which have not been seen during training. The performance measures
   operate on phoneme posteriorgrams that are obtained from neural nets. We
   compare average frame-wise entropy as a baseline measure to the mean
   temporal distance (M-Measure) and to the number of phonetic events. The
   latter is obtained by learning typical phoneme activations from clean
   training data, which are later applied as phoneme-specific matched
   filters to posteriorgrams (MaP). When exceeding a threshold after
   filtering, we register this as phonetic event. For test sets using 10
   unknown noise types and a wide range of signal-to-noise ratios, we find
   M-Measure and MaP to produce predictions twice as accurate as the
   baseline measure. When excluding noise types that contain speech
   segments, a prediction error of 3.1\% is achieved, compared to 15.0\%
   for the baseline measure.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Meyer, BT (Corresponding Author), Johns Hopkins Univ, Ctr Language \& Speech Proc, Baltimore, MD 21218 USA.
   Meyer, Bernd T.; Mallidi, Harish; Hermansky, Hynek, Johns Hopkins Univ, Ctr Language \& Speech Proc, Baltimore, MD 21218 USA.
   Kayser, Hendrik, Carl von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   Kayser, Hendrik, Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-5090-4117-6}},
Keywords = {{performance measure; error prediction; automatic speech recognition}},
Keywords-Plus = {{NOISE}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
ORCID-Numbers = {{Kayser, Hendrik/0000-0001-8200-992X}},
Funding-Acknowledgement = {{Google; Cluster of Excellence 1077/1' ``Hearing4all{''}}},
Funding-Text = {{This work was funded by Google via a Google faculty award to Hynek
   Hermansky and by the Cluster of Excellence 1077/1' ``Hearing4all{''}.}},
Cited-References = {{Bourlard H., 1996, Signal Processing VIII, Theories and Applications. Proceedings of EUSIPCO-96, Eighth European Signal Processing Conference, P1579.
   Dreschler WA, 2001, AUDIOLOGY, V40, P148.
   Hermansky H, 2013, P IEEE, V101, P1076, DOI 10.1109/JPROC.2012.2236871.
   Hirsch H.G., 2000, P ICSLP, p29 .
   Kintzley Keith, 2011, P INTERSPEECH, P1905.
   Lehtonen M., 2005, 0541 IDIAP.
   Mallidi S. H., 2016, IEEE WORK AUT SPEECH, P283.
   Meyer B. T., 2016, IEEE WORKSH SP UNPUB.
   MISRA H, 2003, P IEEE INT C AC SPEE, V2, P741.
   OKAWA S, 1998, ACOUST SPEECH SIG PR, P641.
   Parihar N., 2003, P EUR, P10.
   Peddinti V., 2013, ICASSP IEEE INT C AC.
   Povey D., 2011, P ASRU, P1, DOI DOI 10.1017/CBO9781107415324.004.
   Ravuri S., 2010, P INTERSPEECH.
   Spille C., 2016, P INTERSPEECH.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI7JW}},
Unique-ID = {{ISI:000414286205098}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000414286205131,
Author = {Moungsri, Decha and Koriyama, Tomoki and Kobayashi, Takao},
Book-Group-Author = {{IEEE}},
Title = {{DURATION PREDICTION USING MULTIPLE GAUSSIAN PROCESS EXPERTS FOR
   GPR-BASED SPEECH SYNTHESIS}},
Booktitle = {{2017 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2017}},
Pages = {{5495-5499}},
Note = {{IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), New Orleans, LA, MAR 05-09, 2017}},
Organization = {{IEEE; Inst Elect \& Elect Engineers, Signal Proc Soc}},
Abstract = {{This paper proposes an alternative multi-level approach to duration
   prediction for improving prosody generation in statistical parametric
   speech synthesis using multiple Gaussian process experts. We use two
   duration models at different levels, specifically, syllable and phone.
   First, we individually train syllable-and phone-level duration models.
   Then, the predictive distributions of syllable and phone duration models
   are combined by product of Gaussians. The means of combined predictive
   distributions are used as predicted durations for synthetic speech. We
   show objective and subjective evaluation results for the proposed
   technique by comparing with the conventional ones when the techniques
   are applied to Gaussian process regression (GPR)-based speech synthesis.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Moungsri, D (Corresponding Author), Tokyo Inst Technol, Interdisciplinary Grad Sch Sci \& Engn, Tokyo, Japan.
   Moungsri, Decha, Tokyo Inst Technol, Interdisciplinary Grad Sch Sci \& Engn, Tokyo, Japan.
   Koriyama, Tomoki; Kobayashi, Takao, Tokyo Inst Technol, Sch Engn, Tokyo, Japan.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-5090-4117-6}},
Keywords = {{Multi-level model; Duration prediction; GPR-based speech synthesis;
   Product of Guassians; Multiple Gaussian process experts}},
Keywords-Plus = {{THAI}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{moungsri.d.aa@m.titech.ac.jp
   koriyama@ip.titech.ac.jp
   takao.kobayashi@ip.titech.ac.jp}},
Funding-Acknowledgement = {{JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) {[}JP15H02724]}},
Funding-Text = {{We would like to thank Dr. Vataya Chunwijitra of NECTEC, Thailand, for
   providing the T-Sync-1 speech database. A part of this work was
   supported by JSPS KAKENHI Grant Number JP15H02724.}},
Cited-References = {{Chen SH, 2014, IEEE-ACM T AUDIO SPE, V22, P1158, DOI 10.1109/TASLP.2014.2321482.
   Hansakunbuntheung C., 2005, P SNLP, P127.
   Hiranburana Samang, 1972, TAI PHONETICS PHONOL, P23.
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5.
   Koriyama Tomoki, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3834, DOI 10.1109/ICASSP.2014.6854319.
   Koriyama T., 2013, P INTERSPEECH, P1072.
   Koriyama T, 2015, INT CONF ACOUST SPEE, P4929, DOI 10.1109/ICASSP.2015.7178908.
   Koriyama T, 2014, IEEE J-STSP, V8, P173, DOI 10.1109/JSTSP.2013.2283461.
   Koriyama T, 2013, INT CONF ACOUST SPEE, P8007, DOI 10.1109/ICASSP.2013.6639224.
   Luksaneeyanawin S, 1983, INTONATION IN THAI.
   Moungsri D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1591.
   Pilkington NCV, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2772.
   Potisuk S, 1996, PHONETICA, V53, P200, DOI 10.1159/000262201.
   POTISUK S, 1998, ACTA LINGUIST HAF, V30, P39.
   Qian Y, 2011, IEEE T AUDIO SPEECH, V19, P1702, DOI 10.1109/TASL.2010.2097248.
   Wutiwiwatchsi C, 2007, SPEECH COMMUN, V49, P8, DOI 10.1016/j.specom.2006.10.004.
   Yoshimura T, 1999, P EUR, P2347, DOI DOI 10.1093/IETISY/E90-D.3.692.
   Zen H, 2007, COMPUT SPEECH LANG, V21, P153, DOI 10.1016/j.csl.2006.01.002.
   Zen H, 2012, IEEE T AUDIO SPEECH, V20, P794, DOI 10.1109/TASL.2011.2165280.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI7JW}},
Unique-ID = {{ISI:000414286205131}},
DA = {{2020-12-06}},
}

@article{ ISI:000418681600019,
Author = {Mitchener, W. Garrett},
Title = {{A STOCHASTIC MODEL OF LANGUAGE CHANGE THROUGH SOCIAL STRUCTURE AND
   PREDICTION-DRIVEN INSTABILITY}},
Journal = {{SIAM JOURNAL ON APPLIED MATHEMATICS}},
Year = {{2017}},
Volume = {{77}},
Number = {{6}},
Pages = {{2272-2293}},
Abstract = {{Children reliably learn their community's language; consequently human
   languages are relatively stable on short time scales. However, languages
   can change dramatically over the course of centuries, and once begun,
   such changes generally run monotonically to completion. We consider a
   stochastic model that reproduces this pattern of fluctuations via large
   deviations. We begin with a Markov chain that represents an
   age-structured population in which children learn which of two grammars
   their community prefers but are aware of age-correlated usage patterns
   and will use the dispreferred grammar more often if they infer that its
   use is spreading. The Markov chain is shown to converge in the limit of
   an infinite population to a stochastic differential equation that
   generalizes the Wright-Fisher SDE for population genetics. This proof is
   not routine because the dynamics are only defined in a Cartesian product
   of simplexes, and it must be verified that trajectories of the SDE
   cannot escape. Results are proved by changing variables in a way that
   expands each simplex to an entire plane, yielding reasonable constraints
   on the dynamics that ensure that a standard but sophisticated theorem
   for well-posedness of SDEs can be applied. The SDE yields a phase
   portrait that reveals the mechanism that causes these models to produce
   sporadic, monotone, population wide transitions between grammars. A
   further simplification results in a stochastic functional-delay
   differential equation that shows how population-level memory effects and
   the attempt by learners to avoid sounding outdated results in
   prediction-driven instability.}},
Publisher = {{SIAM PUBLICATIONS}},
Address = {{3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Mitchener, WG (Corresponding Author), Coll Charleston, Dept Math, Charleston, SC 29424 USA.
   Mitchener, W. Garrett, Coll Charleston, Dept Math, Charleston, SC 29424 USA.}},
DOI = {{10.1137/16M1074990}},
ISSN = {{0036-1399}},
EISSN = {{1095-712X}},
Keywords = {{language change; prediction-driven instability; population dynamics;
   stochastic differential equation; noise-activated transitions}},
Keywords-Plus = {{EVOLUTIONARY DYNAMICS; UNIVERSAL GRAMMAR; POPULATION-SIZE;
   LEARNING-MODEL; ESCAPE PROBLEM; ACQUISITION; GAME; LEARNERS; EQUATION;
   TRIGGERS}},
Research-Areas = {{Mathematics}},
Web-of-Science-Categories  = {{Mathematics, Applied}},
Author-Email = {{MitchenerG@cofc.edu}},
Cited-References = {{Adger David, 2003, CORE SYNTAX MINIMALI.
   Alishahi A, 2008, COGNITIVE SCI, V32, P789, DOI 10.1080/03640210801929287.
   Baxter GJ, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.73.046118.
   Becker M, 2006, LINGUIST INQ, V37, P441, DOI 10.1162/ling.2006.37.3.441.
   Berwick RC, 1996, LINGUIST INQ, V27, P605.
   Briscoe T, 2000, LANGUAGE, V76, P245, DOI 10.2307/417657.
   Briscoe Ted, 2002, LINGUISTIC EVOLUTION, P255.
   Chomsky N., 1965, ASPECTS THEORY SYNTA.
   Cucker F, 2004, FOUND COMPUT MATH, V4, P315, DOI 10.1007/s10208-003-0101-2.
   DURRETT R, 1994, THEOR POPUL BIOL, V46, P363, DOI 10.1006/tpbi.1994.1032.
   Durrett R., 1996, PROBAB STOCH SER.
   Fagyal Z, 2010, LINGUA, V120, P2061, DOI 10.1016/j.lingua.2010.02.001.
   Freidlin M.I., 1998, RANDOM PERTURBATIONS.
   GIBSON E, 1994, LINGUIST INQ, V25, P407.
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5.
   Gureckis TM, 2009, TOP COGN SCI, V1, P651, DOI 10.1111/j.1756-8765.2009.01046.x.
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569.
   Hofbauer J, 1998, EVOLUTIONARY GAMES P.
   Kam CLH, 2005, LANG LEARN DEV, V1, P151, DOI 10.1207/s15473341lld0102\_3.
   Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x.
   Kirby S, 2002, SIMULATING THE EVOLUTION OF LANGUAGE, P121.
   Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430.
   Komarova NL, 2001, B MATH BIOL, V63, P451, DOI 10.1006/bulm.2000.0222.
   Kroch A, 1989, LANG VAR CHANGE, V1, P199, DOI DOI 10.1017/S0954394500000168.
   Labov W., 2001, PRINCIPLES LINGUISTI, V2.
   Labov W, 2007, LANGUAGE, V83, P344, DOI 10.1353/lan.2007.0082.
   Labov William, 1994, PRINCIPLES LINGUISTI, V1.
   Lightfoot D., 1991, SET PARAMETERS ARGUM.
   Lightfoot David, 1999, DEV LANGUAGE ACQUISI.
   Lindner B, 1999, PHYS REV E, V60, P7270, DOI 10.1103/PhysRevE.60.7270.
   Maier RS, 1996, J STAT PHYS, V83, P291, DOI 10.1007/BF02183736.
   MAIER RS, 1993, PHYS REV E, V48, P931, DOI 10.1103/PhysRevE.48.931.
   Mitchener W. Garrett, 2011, Journal of Logic, Language and Information, V20, P385, DOI 10.1007/s10849-011-9136-y.
   MITCHENER W. G., FRONT MATH LINGUISTI.
   MITCHENER W. G., 2006, STUDIES ENGLISH MEDI, V16, P189.
   Mitchener WG, 2007, B MATH BIOL, V69, P1093, DOI 10.1007/s11538-006-9165-x.
   Mitchener WG, 2010, SIAM J MATH ANAL, V42, P1899, DOI 10.1137/07069955X.
   Mitchener WG, 2004, P ROY SOC B-BIOL SCI, V271, P701, DOI 10.1098/rspb.2003.2643.
   Mitchener WG, 2003, J MATH BIOL, V46, P265, DOI 10.1007/s00285-002-0172-8.
   Mitchener WG, 2003, B MATH BIOL, V65, P67.
   Mitchener William Garrett, 2011, RES LANGUAGE COMPUTA, V8, P169.
   Murray J D, 2002, MATH BIOL.
   Niyogi P, 2006, CURR STUD LINGUIST, V43, P1.
   Niyogi P, 1996, COGNITION, V61, P161, DOI 10.1016/S0010-0277(96)00718-4.
   Nowak M.A., 2006, EVOLUTIONARY DYNAMIC.
   Nowak MA, 2000, NATURE, V404, P495, DOI 10.1038/35006635.
   Nowak MA, 1999, P ROY SOC B-BIOL SCI, V266, P2131, DOI 10.1098/rspb.1999.0898.
   Nowak MA, 1999, J THEOR BIOL, V200, P147, DOI 10.1006/jtbi.1999.0981.
   Nowak MA, 2002, NATURE, V417, P611, DOI 10.1038/nature00771.
   Nowak MA, 2001, TRENDS COGN SCI, V5, P288, DOI 10.1016/S1364-6613(00)01683-1.
   Nowak MA, 2001, SCIENCE, V291, P114, DOI 10.1126/science.291.5501.114.
   Oksendal B., 1985, STOCHASTIC DIFFERENT.
   Page KM, 2002, J THEOR BIOL, V219, P93, DOI 10.1006/yjtbi.3112.
   Pearl L, 2007, LANG LEARN DEV, V3, P43, DOI 10.1207/s15473341lld0301\_2.
   Perfors A, 2010, J CHILD LANG, V37, P607, DOI 10.1017/S0305000910000012.
   Plotkin JB, 2000, J THEOR BIOL, V205, P147, DOI 10.1006/jtbi.2000.2053.
   Radford Andrew, 2004, MINIMALIST SYNTAX EX.
   Reali F, 2010, P ROY SOC B-BIOL SCI, V277, P429, DOI 10.1098/rspb.2009.1513.
   Smolensky P., 2000, LEARNABILITY OPTIMAL.
   Swarup S, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.066114.
   Trapa PE, 2000, J MATH BIOL, V41, P172, DOI 10.1007/s002850070004.
   Warner Anthony, 2005, LANG VAR CHANGE, V17, P257.
   Wichmann S, 2008, ADV COMPLEX SYST, V11, P357, DOI 10.1142/S0219525908001684.
   Wichmann S, 2009, HUM BIOL, V81, P259, DOI 10.3378/027.081.0308.
   Yang Charles., 2002, KNOWLEDGE LEARNING N.
   Zuidema W, 2009, J PHONETICS, V37, P125, DOI 10.1016/j.wocn.2008.10.003.}},
Number-of-Cited-References = {{66}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{SIAM J. Appl. Math.}},
Doc-Delivery-Number = {{FQ9KS}},
Unique-ID = {{ISI:000418681600019}},
DA = {{2020-12-06}},
}

@article{ ISI:000416585500001,
Author = {Fowler, Courtney Johnson and Jackson, Carrie N.},
Title = {{Facilitating morphosyntactic and semantic prediction among second
   language speakers of German}},
Journal = {{JOURNAL OF COGNITIVE PSYCHOLOGY}},
Year = {{2017}},
Volume = {{29}},
Number = {{8}},
Pages = {{883-901}},
Abstract = {{Using two visual priming experiments, the present study investigates
   whether presenting facilitative semantic (i.e. colour) and
   morphosyntactic (i.e. grammatical gender) information in a prime image
   prior to reading a target sentence facilitates naming of a
   sentence-final target image among L1 German and L1 English-L2 German
   speakers. In Experiment 1, L1 and L2 German speakers used both semantic
   and gender cues to predict the sentence-final target image. In
   Experiment 2, a new group of L2 German speakers used gender cues to
   predict, but this effect was stronger when gender information was
   provided via a gender-marked indefinite article and adjective in the
   prime, than when the prime contained only the gender-marked article.
   These results suggest that if L2 speakers are able to overcome unstable
   and often inaccurate L2 gender assignment, they can use gender cues in a
   native-like manner for prediction, but that multiple gender-marked cues
   may be necessary for such prediction to occur.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Fowler, CJ (Corresponding Author), Penn State Univ, Dept German \& Slav Languages \& Literatures, University Pk, PA 16802 USA.
   Fowler, Courtney Johnson; Jackson, Carrie N., Penn State Univ, Dept German \& Slav Languages \& Literatures, University Pk, PA 16802 USA.}},
DOI = {{10.1080/20445911.2017.1353517}},
ISSN = {{2044-5911}},
EISSN = {{2044-592X}},
Keywords = {{Predictive processing; grammatical gender; processing resources; German;
   second-language acquisition}},
Keywords-Plus = {{GRAMMATICAL GENDER; LANGUAGE PRODUCTION; L2; COMPREHENSION; ACQUISITION;
   MARKING; BILINGUALS; L1}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{cej136@psu.edu}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}OISE-0968369]; Humboldt FoundationAlexander von Humboldt Foundation;
   Office Of The DirectorNational Science Foundation (NSF)NSF - Office of
   the Director (OD) {[}0968369] Funding Source: National Science
   Foundation}},
Funding-Text = {{This research was funded in part by the National Science Foundation
   under grant OISE-0968369 (PI: J. F. Kroll; co-PIs: P. E. Dussias and J.
   G. van Hell) and a grant to Dr Carrie Jackson from the Humboldt
   Foundation.}},
Cited-References = {{Baayen Harald R, 2008, ANAL LINGUISTIC DATA.
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001.
   Bauch H. J., 1971, WISSENSCHAFTLICHE Z, V20, P411.
   Bergmann C, 2015, NEUROREPORT, V26, P1065, DOI 10.1097/WNR.0000000000000469.
   Bianchi G, 2013, BILING-LANG COGN, V16, P538, DOI 10.1017/S1366728911000745.
   Corbett Greville G., 1991, GENDER.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   Dijkgraaf A, 2017, BILING-LANG COGN, V20, P917, DOI 10.1017/S1366728916000547.
   Dussias PE, 2013, STUD SECOND LANG ACQ, V35, P353, DOI 10.1017/S0272263112000915.
   Friederici AD, 1999, J PSYCHOLINGUIST RES, V28, P467, DOI 10.1023/A:1023264209610.
   Goethe Institut, 2004, EINST.
   Gruter T, 2012, SECOND LANG RES, V28, P191, DOI 10.1177/0267658312437990.
   Gruter T, 2017, LINGUIST APPROACH BI, V7, P199, DOI 10.1075/lab.15011.gru.
   Guillelmon D, 2001, MEM COGNITION, V29, P503, DOI 10.3758/BF03196401.
   Hopp H, 2016, SECOND LANG RES, V32, P277, DOI 10.1177/0267658315624960.
   Hopp H, 2015, IRAL-INT REV APPL LI, V53, P277, DOI 10.1515/iral-2015-0014.
   Hopp H, 2013, SECOND LANG RES, V29, P33, DOI 10.1177/0267658312461803.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   KOPCKE KLAUS-MICHAEL, 1984, LINGUISTISCHE BERICH, V93, P26.
   KOPCKE KM, 1983, Z GER LINGUISTIK, V11, P166, DOI 10.1515/zfgl.1983.11.2.166.
   Lemhofer K, 2014, J COGNITIVE NEUROSCI, V26, P1428, DOI 10.1162/jocn\_a\_00609.
   Lew-Williams C, 2010, J MEM LANG, V63, P447, DOI 10.1016/j.jml.2010.07.003.
   MacDonald MC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00226.
   MILLS AE, 1986, ACQUISITION GENDER S.
   Mitsugi S, 2016, BILING-LANG COGN, V19, P19, DOI 10.1017/S1366728914000881.
   Phillips C, 2015, LINGUIST APPROACH BI, V5, P409, DOI 10.1075/lab.5.4.01phi.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   R Development Core Team, 2016, R LANG ENV STAT COMP.
   Sabourin L, 2006, SECOND LANG RES, V22, P1, DOI 10.1191/0267658306sr259oa.
   Scherag A, 2004, COGNITION, V93, pB97, DOI 10.1016/j.cognition.2004.02.003.
   Schmid Monika S., 2009, EUROSLA YB, V9, P212, DOI DOI 10.1075/EUROSLA.9.11SCH.
   Szagun G, 2007, J CHILD LANG, V34, P445, DOI 10.1017/S0305000906007951.
   Tokowicz N, 2005, STUD SECOND LANG ACQ, V27, P173, DOI 10.1017/S0272263105050102.
   TURNER ML, 1989, J MEM LANG, V28, P127, DOI 10.1016/0749-596X(89)90040-5.
   Universitat Leipzig Institut fur Informatik, 2012, DTSCH WORTSCH.}},
Number-of-Cited-References = {{38}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{J. Cogn. Psychol.}},
Doc-Delivery-Number = {{FO2DZ}},
Unique-ID = {{ISI:000416585500001}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000414478200105,
Author = {Shi, Zejian and Shi, Minyong and Li, Chunfang},
Editor = {{Zhu, G and Yao, S and Cui, X and Xu, S}},
Title = {{The Prediction of Character Based on Recurrent Neural Network Language
   Model}},
Booktitle = {{2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION
   SCIENCE (ICIS 2017)}},
Year = {{2017}},
Pages = {{613-616}},
Note = {{16th IEEE/ACIS International Conference on Computer and Information
   Science (ICIS), Wuhan Univ, Wuhan, PEOPLES R CHINA, MAY 24-26, 2017}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Comp Soc; Int Assoc Comp \& Informat
   Sci; Wuhan Univ, Int Sch Software}},
Abstract = {{This paper mainly talks about the Recurrent Neural Network and
   introduces a more effective neural network model named LSTM. Then, the
   paper recommends a special language model based on Recurrent Neural
   Network. With the help of LSTM and RNN language models, program can
   predict the next character after a certain character. The main purpose
   of this paper is to compare the LSTM model with the standard RNN model
   and see their results in character prediction. So we can see the huge
   potential of Recurrent Neural Network Language Model in the field of
   character prediction.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Shi, ZJ (Corresponding Author), Commun Univ China, Sch Comp Sci, Beijing, Peoples R China.
   Shi, Zejian; Shi, Minyong; Li, Chunfang, Commun Univ China, Sch Comp Sci, Beijing, Peoples R China.}},
ISBN = {{978-1-5090-5507-4}},
Keywords = {{RNN; LSTM; language model; character prediction}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{541838623@qq.com
   myshi@cuc.edu.cn}},
Funding-Acknowledgement = {{Excellent Young Teachers Training Project {[}YXJS201508]; Key
   Cultivation Engineering Project of Communication University of China
   {[}3132016XNG1606, 3132016XNG1608]; Cultural technological innovation
   project of Ministry of Culture of P. R. China {[}2014-12]; comprehensive
   reform project of computer science and technology, department of science
   and Engineering; Chaoyang District Science and Technology Project
   {[}CYXC1504]}},
Funding-Text = {{This paper is partly supported by ``the Excellent Young Teachers
   Training Project (the second level, Project number: YXJS201508){''},
   ``Key Cultivation Engineering Project of Communication University of
   China (Project number: 3132016XNG1606 and 3132016XNG1608){''},
   ``Cultural technological innovation project of Ministry of Culture of P.
   R. China (Project number: 2014-12){''}, and partly supported by ``The
   comprehensive reform project of computer science and technology,
   department of science and Engineering{''}. The research work was also
   supported by ``Chaoyang District Science and Technology Project
   (CYXC1504){''}.}},
Cited-References = {{Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223.
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006.
   He K., 2015, ARXIV151203385.
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045.
   Srivastava R. K., 2015, ARXIV150500387.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BI7NS}},
Unique-ID = {{ISI:000414478200105}},
DA = {{2020-12-06}},
}

@article{ ISI:000393813700007,
Author = {Jukic, Ante and van Waterschoot, Toon and Doclo, Simon},
Title = {{Adaptive Speech Dereverberation Using Constrained Sparse Multichannel
   Linear Prediction}},
Journal = {{IEEE SIGNAL PROCESSING LETTERS}},
Year = {{2017}},
Volume = {{24}},
Number = {{1}},
Pages = {{101-105}},
Month = {{JAN}},
Abstract = {{In this letter, we present an adaptive speech dereverberation method
   based on constrained sparse multichannel linear prediction (MCLP),
   minimizing the mixed l(2),p norm of the desired component. In order to
   prevent overestimation of the undesired reverberant component, possibly
   leading to severe distortions of the output, we propose to use a
   statistical model for late reverberation to limit the power of the
   MCLP-based estimate. The resulting constrained optimization problem is
   solved by using the alternating direction method of multipliers,
   resulting in two variants of the dereverberation algorithm. Simulation
   results show that the proposed constraint increases the robustness with
   respect to parameter selection and improves the usability for dynamic
   scenarios in comparison to the unconstrained method.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jukic, A (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.
   Jukic, Ante; Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.
   van Waterschoot, Toon, Katholieke Univ Leuven, Dept Elect Engn, B-3001 Leuven, Belgium.}},
DOI = {{10.1109/LSP.2016.2640939}},
ISSN = {{1070-9908}},
EISSN = {{1558-2361}},
Keywords = {{Adaptive filtering; constrained linear prediction; sparsity; speech
   dereverberation}},
Keywords-Plus = {{REVERBERATION; NOISE}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{ante.jukic@uni-oldenburg.de
   toon.vanwaterschoot@esat.kuleuven.be
   simon.doclo@uni-oldenburg.de}},
ORCID-Numbers = {{Doclo, Simon/0000-0002-3392-2381}},
Funding-Acknowledgement = {{Marie Curie ITN DREAMS {[}ITN-GA-2012-316969]; Cluster of Excellence
   ``Hearing4All.{''} {[}1077]}},
Funding-Text = {{This research was supported in part by the Marie Curie ITN DREAMS Grant
   ITN-GA-2012-316969, and in part by the Cluster of Excellence 1077
   ``Hearing4All.{''} The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Balazs Bank.}},
Cited-References = {{Akino TK, 2008, IEEE T WIREL COMMUN, V7, P4248, DOI 10.1109/T-WC.2008.070497.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016.
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498.
   Dietzen T., 2016, P INT WORKSH AC SIGN, P1.
   Habets EAP, 2009, IEEE SIGNAL PROC LET, V16, P770, DOI 10.1109/LSP.2009.2024791.
   Haykin S.O., 2013, ADAPTIVE FILTER THEO.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Juki A., 2016, P AES 60 INT C LEUV, P1.
   Jukic Ante, 2015, 2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). Proceedings, P1, DOI 10.1109/WASPAA.2015.7336927.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita K, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0306-6.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Lebart K, 2001, ACUSTICA, V87, P359.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003.
   Polack J., 1988, THESIS.
   ROBINSON T, 1995, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1995.479278.
   Schmid D, 2014, IEEE-ACM T AUDIO SPE, V22, P1320, DOI 10.1109/TASLP.2014.2329732.
   Schwartz B, 2015, IEEE-ACM T AUDIO SPE, V23, P394, DOI 10.1109/TASLP.2014.2372342.
   TRIKI M, 2006, INT CONF ACOUST SPEE, P97.
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2009, INT CONF ACOUST SPEE, P3733, DOI 10.1109/ICASSP.2009.4960438.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{16}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{IEEE Signal Process. Lett.}},
Doc-Delivery-Number = {{EK3GE}},
Unique-ID = {{ISI:000393813700007}},
DA = {{2020-12-06}},
}

@article{ ISI:000393288000012,
Author = {Mussavi, Aghassi and Gorjian, Bahman},
Title = {{THE USE OF REFERRING AND PREDICTING ACTIVITIES ON LEARNING LANGUAGE
   FUNCTIONS AMONG SENIOR HIGH SCHOOL STUDENTS}},
Journal = {{MODERN JOURNAL OF LANGUAGE TEACHING METHODS}},
Year = {{2017}},
Volume = {{7}},
Number = {{1}},
Pages = {{121-130}},
Month = {{JAN}},
Abstract = {{This study investigated the uses of the referring and predicting
   language learning activities in learning language functions among senior
   high school students. Fifty laerners were selected through the use of
   oxford quich placement test (oqpt). Then they were divided in two equal
   experimetal groups of referring and predicting. They took a teacher-made
   pre-test of language functions at the beginning of the study to assess
   their prior knowledge on language functions of their text book. Then
   they participated in the 10 treatment sessions. Both groups covered
   tendialogs in the text book and learned the language functions through
   both activities. The referring group received instructions on how to
   point to the people and objects directly or indirectly. The predicting
   group learned how to guess the possible future events and opprtunities
   based on the available data. Finally, the post-test was administered to
   both groups. Data were analyzead through independent and paired samples
   t-test and results revealed that the referring group outperformed the
   predicting one. Implications suggest that language teachers may teach
   language functions through referring activities rather than the
   predicting ones since the learners can learn language functions in the
   real contexts.}},
Publisher = {{MODERN JOURNAL LANGUAGE TEACHING METHODS}},
Address = {{NO 300, AHMADABAD ST, MASHHAD, 00000, IRAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gorjian, B (Corresponding Author), Islamic Azad Univ, Abadan Branch, Dept ELT, Abadan, Iran.
   Mussavi, Aghassi, Islamic Azad Univ, Khouzestan Sci \& Res Branch, Dept ELT, Ahwaz, Iran.
   Mussavi, Aghassi, Islamic Azad Univ, Ahvaz Branch, Dept ELT, Ahwaz, Iran.
   Gorjian, Bahman, Islamic Azad Univ, Abadan Branch, Dept ELT, Abadan, Iran.}},
EISSN = {{2251-6204}},
Keywords = {{referring; predicting; language functions}},
Research-Areas = {{Education \& Educational Research}},
Web-of-Science-Categories  = {{Education \& Educational Research}},
Author-Email = {{bahgorji@yahoo.com}},
Cited-References = {{Akmajian A., 2010, INTRO LANGUAGE COMMU.
   Alcon E., 2005, SYSTEM, V33, P417, DOI DOI 10.1016/J.SYSTEM.2005.06.005.
   Soler EA, 2010, INT J ENGL STUD, V10, P65.
   Soler EA, 2008, SECOND LANG ACQUIS, V30, P3.
   Austin J.L., 1962, DO THINGS WORDS.
   Bach K., 1994, MIND LANG, V9, P124, DOI {[}DOI 10.1111/J.1468-0017.1994.TB00220.X, 10.1111/j.1468-0017.1994.tb00220.x].
   Barsalou L. W., 2009, SIMULATION SITUATED.
   Batjargal D., 2010, THESIS.
   Bayat N, 2013, PROCD SOC BEHV, V70, P213, DOI 10.1016/j.sbspro.2013.01.057.
   Chen H., 1996, SYSTEM, V33, P481.
   Friston KJ, 2009, NEURAL NETWORKS, V22, P1093, DOI 10.1016/j.neunet.2009.07.023.
   Gilbert DT, 2007, SCIENCE, V317, P1351, DOI 10.1126/science.1144161.
   Hudson Richard Anthony, 1996, SOCIOLINGUISTICS.
   Kasper Gabriele, 2002, PRAGMATIC DEV 2 LANG.
   Koike D. A., 2005, SYSTEM, V33, P481, DOI DOI 10.1016/J.SYSTEM.2005.06.008.
   Koosha B., 2012, ASIAN SOCIAL SCI, V8, P54.
   Kronfeld A., 1998, PRAGMAT COGN, V6, P189.
   PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295.
   Schultz W, 2000, ANNU REV NEUROSCI, V23, P473, DOI 10.1146/annurev.neuro.23.1.473.
   Searle John R., 1969, SPEECH ACTS ESSAY PH.
   SEARLE JR, 1976, LANG SOC, V5, P1, DOI 10.1017/S0047404500006837.
   Soozandehfar M., 2011, THEORY PRACTICE LANG, V1, P1831.
   Stevenson H., 1998, DO LUNCH OR BE LUNCH.
   Takahashi S., 1996, STUDIES 2 LANGUAGE A, V18, P189, DOI DOI 10.1017/S0272263100014881.
   Williams JMG, 1996, MEM COGNITION, V24, P116, DOI 10.3758/BF03197278.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Mod. J. Lang. Teach. Methods}},
Doc-Delivery-Number = {{EJ5VX}},
Unique-ID = {{ISI:000393288000012}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000457505000224,
Author = {Tanaka, Kou and Kameoka, Hirokazu and Toda, Tomoki and Nakamura, Satoshi},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Physically Constrained Statistical F-0 Prediction for Electrolaryngeal
   Speech Enhancement}},
Booktitle = {{18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION}},
Series = {{Interspeech}},
Year = {{2017}},
Pages = {{1069-1073}},
Note = {{18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017),
   Stockholm, SWEDEN, AUG 20-24, 2017}},
Organization = {{Int Speech Commun Assoc; Stockholm Univ; KTH Royal Inst Technol;
   Karolinska Inst; Amazon Alexa; DiDi; Furhat Robot; Microsoft; EZ Alibaba
   Grp; CIRRUS LOGIC; CVTE; Google; Baidu; IBM Res; YAHOO Japan; Nuance;
   Voice Provider; ASM Solut Ltd; Mitsubishi Elect Res Lab; Yandex}},
Abstract = {{Electrolaryngeal (EL) speech produced by a laryngectomee using an
   electrolarynx to mechanically generate artificial excitation sounds
   severely suffers from unnatural fundamental frequency (F-0) patterns
   caused by monotonic excitation sounds. To address this issue, we have
   previously proposed EL speech enhancement systems using statistical F-0
   pattern prediction methods based on a Gaussian Mixture Model (GMM),
   making it possible to predict the underlying F-0 pattern of EL speech
   from its spectral feature sequence. Our previous work revealed that the
   naturalness of the predicted F-0 pattern can be improved by
   incorporating a physically based generative model of F-0 patterns into
   the GMM-based statistical F-0 prediction system within a
   Product-of-Expert framework. However. one drawback of this method is
   that it requires an iterative procedure to obtain a predicted F-0
   pattern. making it difficult to realize a real-time system. In this
   paper, we propose yet another approach to physically based statistical
   F-0 pattern prediction by using a HMM-GMM framework. This approach is
   noteworthy in that it allows to generate an F-0 pattern that is both
   statistically likely and physically natural without iterative
   procedures. Experimental results demonstrated that the proposed method
   was capable of generating F-0 patterns more similar to those in normal
   speech than the conventional GMM-based method.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Tanaka, K (Corresponding Author), Nara Inst Sci \& Technol, Grad Sch Informat Sci, Ikoma, Japan.
   Tanaka, Kou; Nakamura, Satoshi, Nara Inst Sci \& Technol, Grad Sch Informat Sci, Ikoma, Japan.
   Kameoka, Hirokazu, NTT Corp, NTT Commun Sci Labs, Tokyo, Japan.
   Toda, Tomoki, Nagoya Univ, Informat Technol Ctr, Nagoya, Aichi, Japan.}},
DOI = {{10.21437/Interspeech.2017-688}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-4876-4}},
Keywords = {{electrolaryngeal speech; statistical F-0 prediction; generative model;
   speech enhancement}},
Keywords-Plus = {{VOICE CONVERSION}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{ko-t@is.naist.jp
   kameoka.hirokazu@lab.ntt.co.jp
   tomoki@icts.nagoya-u.ac.jp
   s-nakamura@is.naist.jp}},
Funding-Acknowledgement = {{JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) {[}26280060];
   JST, PRESTOJapan Science \& Technology Agency (JST) {[}JP-MJPR1657]}},
Funding-Text = {{This work was supported in part by JSPS KAKENHI Grant Number 26280060,
   and by JST, PRESTO Grant Number JP-MJPR1657.}},
Cited-References = {{ABE M, 1990, TRI0166 ATR.
   Doi H, 2014, IEEE-ACM T AUDIO SPE, V22, P172, DOI 10.1109/TASLP.2013.2286917.
   FUJISAKI H, 1998, VOCAL FOLD PHYSL VOI, P347.
   Ishihara T, 2013, INTERSPEECH, P1016.
   Janke M., 2014, P ICASSP, P2598.
   Kameoka H., 2010, P ISCA TUT RES WORKS, P43.
   Kameoka H, 2015, IEEE-ACM T AUDIO SPE, V23, P1042, DOI 10.1109/TASLP.2015.2418576.
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5.
   Li JJ, 2014, ELECTRON LETT, V50, P1781, DOI 10.1049/el.2014.1645.
   Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007.
   Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472.
   Tanaka K, 2016, INT CONF ACOUST SPEE, P5665, DOI 10.1109/ICASSP.2016.7472762.
   Tanaka K, 2014, IEICE T INF SYST, VE97D, P1429, DOI 10.1587/transinf.E97.D.1429.
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344.
   Toda T, 2012, IEEE T AUDIO SPEECH, V20, P2505, DOI 10.1109/TASL.2012.2205241.
   Yoshizato K, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SPEECH PROSODY, VOLS I AND II, P175.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BL9IK}},
Unique-ID = {{ISI:000457505000224}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000457505000244,
Author = {Huber, Rainer and Spille, Constantin and Meyer, Bernd T.},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Single-ended prediction of listening effort based on automatic speech
   recognition}},
Booktitle = {{18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION}},
Series = {{Interspeech}},
Year = {{2017}},
Pages = {{1168-1172}},
Note = {{18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017),
   Stockholm, SWEDEN, AUG 20-24, 2017}},
Organization = {{Int Speech Commun Assoc; Stockholm Univ; KTH Royal Inst Technol;
   Karolinska Inst; Amazon Alexa; DiDi; Furhat Robot; Microsoft; EZ Alibaba
   Grp; CIRRUS LOGIC; CVTE; Google; Baidu; IBM Res; YAHOO Japan; Nuance;
   Voice Provider; ASM Solut Ltd; Mitsubishi Elect Res Lab; Yandex}},
Abstract = {{A new, single-ended. i.e. reference-free measure for the prediction of
   perceived listening effort of noisy speech is presented. It is based on
   phoneme posterior probabilities (or posterior grams) obtained from a
   deep neural network of an automatic speech recognition system. Additive
   noisy or other distortions of speech tend to smear the posteriorgrams.
   The smearing is quantified by a performance measure, which is used as a
   predictor for the perceived listening effort required to understand the
   noisy speech. The proposed measure was evaluated using a database
   obtained from the subjective evaluation of noise reduction algorithms of
   commercial hearing aids. Listening effort ratings of processed noisy
   speech samples were gathered from 20 hearing-impaired subjects. Averaged
   subjective ratings were compared with corresponding predictions computed
   by the proposed new method, the ITU-T standard P.563 for single-ended
   speech quality assessment, the American National Standard ANIQUE+ for
   single-ended speech quality assessment, and a single-ended SNR
   estimator. The proposed method achieved a good correlation with mean
   subjective ratings and clearly outperformed the standard speech quality
   measures and the SNR estimator.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Huber, R (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   Huber, Rainer, Carl von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.}},
DOI = {{10.21437/Interspeech.2017-1360}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-4876-4}},
Keywords = {{automatic speech recognition; deep neural networks; listening effort
   prediction}},
Keywords-Plus = {{INTELLIGIBILITY; NOISE; MODEL}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{rainer.huber@uni-oldenhurg.de
   constantin.spillel@uni-oldenburg.de
   bernd.meyer@uni-oldenburg.de}},
Funding-Acknowledgement = {{Cluster of Excellence ``Hearing4a11{''} {[}1077/1]}},
Funding-Text = {{This work was funded by the Cluster of Excellence 1077/1'
   ``Hearing4a11{''}. The authors would like to thank the Horzentrum
   Oldenburg and Sivantos for kindly providing their data, and four
   anonymous reviewers for helpful comments on an earlier version of this
   paper.}},
Cited-References = {{Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600.
   Denk F., 2014, P 8 INT C SIGN PROC.
   Hermansky H., 2017, ICASSP 2017.
   Holube I., 2015, P 18 ANN C GERM SOC.
   Huber R, 2010, 2 WORKSH SPEECH NOIS.
   Huber R, 2006, IEEE T AUDIO SPEECH, V14, P1902, DOI 10.1109/TASL.2006.883259.
   Huber R, 2018, INT J AUDIOL, V57, pS55, DOI 10.1080/14992027.2017.1279758.
   ITU-T, 2004, SINGL END METH OBJ S, P563.
   Kim DS, 2007, BELL LABS TECH J, V12, P221, DOI 10.1002/bltj.20228.
   Mallidi S. H., 2015, P IEEE WORKSH AUT SP.
   Meyer B. T., 2010, INTERSPEECH 2010.
   Meyer B. T., 2016, IEEE WORKSH SPOK LAN.
   Nagamine T., 2016, INTERSPEECH 2016.
   Peddinti V., 2013, ICASSP IEEE INT C AC.
   Povey D., 2011, P ASRU, P1, DOI DOI 10.1017/CBO9781107415324.004.
   Rennies J, 2014, J ACOUST SOC AM, V136, P2642, DOI 10.1121/1.4897398.
   Schadler MR, 2016, J ACOUST SOC AM, V139, P2708, DOI 10.1121/1.4948772.
   Scharenborg O, 2007, SPEECH COMMUN, V49, P336, DOI 10.1016/j.specom.2007.01.009.
   Schepker H, 2016, INT J AUDIOL, V55, P738, DOI 10.1080/14992027.2016.1219774.
   Wagener K, 1999, Z AUDIOL, V38, P4.
   Xiong W., 2016, ARXIV161005256.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL9IK}},
Unique-ID = {{ISI:000457505000244}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000457505000347,
Author = {Ishimoto, Yuichi and Teraoka, Takehiro and Enomoto, Mika},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{End-of-Utterance Prediction by Prosodic Features and Phrase-Dependency
   Structure in Spontaneous Japanese Speech}},
Booktitle = {{18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION}},
Series = {{Interspeech}},
Year = {{2017}},
Pages = {{1681-1685}},
Note = {{18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017),
   Stockholm, SWEDEN, AUG 20-24, 2017}},
Organization = {{Int Speech Commun Assoc; Stockholm Univ; KTH Royal Inst Technol;
   Karolinska Inst; Amazon Alexa; DiDi; Furhat Robot; Microsoft; EZ Alibaba
   Grp; CIRRUS LOGIC; CVTE; Google; Baidu; IBM Res; YAHOO Japan; Nuance;
   Voice Provider; ASM Solut Ltd; Mitsubishi Elect Res Lab; Yandex}},
Abstract = {{This study is aimed at uncovering a way that participants in
   conversation predict end-of-utterance for spontaneous Japanese speech.
   In spontaneous everyday conversation. the participants must predict the
   ends of utterances of a speaker to perform smooth turn-taking without
   too much gap. We consider that they utilize not only syntactic factors
   but also prosodic factors for the end-of-utterance prediction because of
   the difficulty of prediction of a syntactic completion point in
   spontaneous Japanese. In previous studies, we found that prosodic
   features changed significantly in the final accentual phrase. However,
   it is not clear what prosodic features support the prediction. In this
   paper, we focused on dependency structure among bunsetsuphrases as the
   syntactic factor, and investigated the relation between the
   phrase-dependency and prosodic features. The results showed that the
   average fundamental frequency and the average intensity for accentual
   phrases did not decline until the modified phrase appeared. Next, to
   predict the end of utterance from the syntactic and prosodic features,
   we constructed a generalized linear mixed model. The model provided
   higher accuracy than using the prosodic features only. These suggest the
   possibility that prosodic changes and phrase-dependency relations inform
   the hearer that the utterance is approaching its end.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ishimoto, Y (Corresponding Author), Natl Inst Japanese Language \& Linguist, Ctr Corpus Dev, Tachikawa, Tokyo, Japan.
   Ishimoto, Yuichi, Natl Inst Japanese Language \& Linguist, Ctr Corpus Dev, Tachikawa, Tokyo, Japan.
   Teraoka, Takehiro; Enomoto, Mika, Tokyo Univ Technol, Sch Media Sci, Hachioji, Tokyo, Japan.}},
DOI = {{10.21437/Interspeech.2017-837}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-4876-4}},
Keywords = {{turn-taking; prediction model; prosody; phrase dependency;
   utterance-final element}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{yishi@ninjal.ac.jp
   teraokahr@stf.teu.ac.jp
   menomoto@stf.teu.ac.jp}},
Funding-Acknowledgement = {{JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) {[}15K00390];
   Grants-in-Aid for Scientific ResearchMinistry of Education, Culture,
   Sports, Science and Technology, Japan (MEXT)Japan Society for the
   Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)
   {[}15H02715, 15K16787] Funding Source: KAKEN}},
Funding-Text = {{This work was supported by JSPS KAKENHI Grant Number 15K00390.}},
Cited-References = {{Den Y., 2007, CONVERSATIONAL INFOR, P307.
   Enomoto  M., 2007, JAPANESE J LANGUAGE, P17.
   Ford CE, 1996, INTERACTION GRAMMAR, V13, P134, DOI DOI 10.1017/CBO9780511620874.003.
   Ishimoto  Y., 2014, P OR COCOSDA 2014, P255.
   Ishimoto  Y., 2011, P INTERSPEECH2011, P2061.
   Kudo T., 2002, P 6 C NAT LANG LEARN, P63, DOI DOI 10.3115/1118853.1118869.
   Maekawa  K., 2014, J ACOUST SOC AM, V135, P2194.
   Pierrehumbert Janet, 1988, JAPANESE TONE STRUCT.
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243.
   Takanashi  K., 2007, SENTENCES UTTERANCES, P159.
   Tanaka H., 1999, TURN TAKING JAPANESE.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL9IK}},
Unique-ID = {{ISI:000457505000347}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000457505000681,
Author = {Huang, Zhaocheng and Epps, Julien},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{An Investigation of Emotion Dynamics and Kalman Filtering for
   Speech-based Emotion Prediction}},
Booktitle = {{18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION}},
Series = {{Interspeech}},
Year = {{2017}},
Pages = {{3301-3305}},
Note = {{18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017),
   Stockholm, SWEDEN, AUG 20-24, 2017}},
Organization = {{Int Speech Commun Assoc; Stockholm Univ; KTH Royal Inst Technol;
   Karolinska Inst; Amazon Alexa; DiDi; Furhat Robot; Microsoft; EZ Alibaba
   Grp; CIRRUS LOGIC; CVTE; Google; Baidu; IBM Res; YAHOO Japan; Nuance;
   Voice Provider; ASM Solut Ltd; Mitsubishi Elect Res Lab; Yandex}},
Abstract = {{Despite recent interest in continuous prediction of dimensional
   emotions, the dynamical aspect of emotions has received less attention
   in automated systems. This paper investigates how emotion change can be
   effectively incorporated to improve continuous prediction of arousal and
   valence from speech. Significant correlations were found between emotion
   ratings and their dynamics during investigations on the RECOLA database,
   and here we examine how to best exploit them using a Kalman filter. In
   particular, we investigate the correlation between predicted arousal and
   valence dynamics with arousal and valence ground truth; the Kalman
   filter internal delay for estimating the state transition matrix; the
   use of emotion dynamics as a measurement input to a Kalman filter; and
   how multiple probabilistic Kalman filter outputs can be effectively
   fused. Evaluation results show that correct dynamics estimation and
   internal delay settings allow up to 5\% and 58\% relative improvement in
   arousal and valence prediction respectively over existing Kalman filter
   implementations. Fusion based on probabilistic Kalman filter outputs
   yields further gains.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Huang, ZC (Corresponding Author), UNSW, Sch Elect Engn \& Telecommun, Sydney, NSW, Australia.
   Huang, ZC (Corresponding Author), CSIRO, Data61, Canberra, ACT, Australia.
   Huang, Zhaocheng; Epps, Julien, UNSW, Sch Elect Engn \& Telecommun, Sydney, NSW, Australia.
   Huang, Zhaocheng; Epps, Julien, CSIRO, Data61, Canberra, ACT, Australia.}},
DOI = {{10.21437/Interspeech.2017-1707}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-4876-4}},
Keywords = {{Emotion dynamics; emotion change; Kalman filter; speech-based continuous
   emotion prediction; probabilistic fusion}},
Keywords-Plus = {{TRENDS}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{zhaocheng.huang@unsw.edu.au
   j.epps@unsw.edu.au}},
ResearcherID-Numbers = {{Huang, Zhaocheng/R-2904-2019
   }},
ORCID-Numbers = {{Epps, Julien/0000-0001-6624-5551}},
Cited-References = {{Brady K, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P97, DOI 10.1145/2988257.2988264.
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417.
   Garcia D, 2016, DYNAMICS EMOTIONS ON.
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016.
   Hakim A, 2013, INT CONF AFFECT, P185, DOI 10.1109/ACII.2013.37.
   Huang Z, 2015, P 5 INT WORKSH AVEC.
   Huang Z, 2016, 16 AUSTR INT C SPEEC.
   Kalman R.E., 1960, J BASIC ENG, V82, P35, DOI {[}10.1115/1.3662552, DOI 10.1115/1.3662552].
   Kim Y., 2013, ICASSP.
   Kim Y, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808204.
   Kuppens P, 2015, EMOT REV, V7, P297, DOI 10.1177/1754073915590947.
   Kuppens P, 2010, J PERS SOC PSYCHOL, V99, P1042, DOI 10.1037/a0020962.
   Labbe R, 2014, KALMAN BAYESIAN FILL.
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051.
   Metallinou A, 2013, IMAGE VISION COMPUT, V31, P137, DOI 10.1016/j.imavis.2012.08.018.
   Metallinou A, 2012, IEEE T AFFECT COMPUT, V3, P184, DOI 10.1109/T-AFFC.2011.40.
   Metallinou A, 2011, INT CONF ACOUST SPEE, P2288.
   Oveneke Meshia, 2017, IEEE T AFFECT COMPUT, P1, DOI DOI 10.1109/TAFFC.2016.2643661.
   Provost E. M., 2011, ICASSP.
   Ringeval F., 2013, AUT FAC GEST REC FG, P1, DOI {[}DOI 10.1109/FG.2013.6553805, 10.1109/FG.2013.6553805].
   Scherer KR, 2009, COGNITION EMOTION, V23, P1307, DOI 10.1080/02699930902928969.
   Somandepalli K, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P59, DOI 10.1145/2988257.2988259.
   Valstar M, 2016, P 6 INT WORKSH AVEC.
   Yuan SG, 2015, INT CONF AFFECT, P229, DOI 10.1109/ACII.2015.7344576.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL9IK}},
Unique-ID = {{ISI:000457505000681}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000457505000767,
Author = {Hou, Junfeng and Zhang, Shiliang and Dai, Lirong},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Gaussian Prediction based Attention for Online End-to-End Speech
   Recognition}},
Booktitle = {{18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION}},
Series = {{Interspeech}},
Year = {{2017}},
Pages = {{3692-3696}},
Note = {{18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017),
   Stockholm, SWEDEN, AUG 20-24, 2017}},
Organization = {{Int Speech Commun Assoc; Stockholm Univ; KTH Royal Inst Technol;
   Karolinska Inst; Amazon Alexa; DiDi; Furhat Robot; Microsoft; EZ Alibaba
   Grp; CIRRUS LOGIC; CVTE; Google; Baidu; IBM Res; YAHOO Japan; Nuance;
   Voice Provider; ASM Solut Ltd; Mitsubishi Elect Res Lab; Yandex}},
Abstract = {{Recently end-to-end speech recognition has obtained much attention. One
   of the popular models to achieve end-to-end speech recognition is
   attention based encoder-decoder model, which usually generating output
   sequences iteratively by attending the whole representations of the
   input sequences. However. predicting outputs until receiving the whole
   input sequence is not practical for online or low time latency speech
   recognition. In this paper, we present a simple but effective attention
   mechanism which can make the encoder-decoder model generate outputs
   without attending the entire input sequence and can apply to online
   speech recognition. At each prediction step, the attention is assumed to
   be a time-moving gaussian window with variable size and can be predicted
   by using previous input and output information instead of the content
   based computation on the whole input sequence. To further improve the
   online performance of the model, we employ deep convolutional neural
   networks as encoder. Experiments show that the gaussian prediction based
   attention works well and under the help of deep convolutional neural
   networks the online model achieves 19.5\% phoneme error rate in TIMIT
   ASR task.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hou, JF (Corresponding Author), Univ Sci \& Technol China, Natl Engn Lab Speech \& Language Informat Proc, Hefei, Anhui, Peoples R China.
   Hou, Junfeng; Zhang, Shiliang; Dai, Lirong, Univ Sci \& Technol China, Natl Engn Lab Speech \& Language Informat Proc, Hefei, Anhui, Peoples R China.}},
DOI = {{10.21437/Interspeech.2017-751}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-4876-4}},
Keywords = {{Automatic Speech Recognition; Encoder-Decoder; Online; Gaussian
   Prediction based Attention; Deep Convolutional Encoder}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{hjf176@mail.ustc.edu.cn
   zs12008@mail.ustc.edu.cn
   lrdai@ustc.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}U1613211]}},
Funding-Text = {{The authors would like to acknowledge the support of National Natural
   Science Foundation of China grant No. U1613211.}},
Cited-References = {{Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736.
   Bandanau D., 2014, ARXIV14090473.
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618.
   Bergstra J., 2010, P 9 PYTH SCI C, P1, DOI 10.25080/Majora-92bf1922-003.
   Chan W., 2015, ARXIV150801211.
   Chan W, 2016, INTERSPEECH, P3404, DOI 10.21437/Interspeech.2016-334.
   Chorowski J.K., 2015, ADV NEURAL INFORM PR, P577.
   Gehring J, 2016, ARXIV161102344.
   Glorot X., 2011, AISTATS, V15, P275.
   Graves A., 2011, ADV NEURAL INFORM PR, P2348, DOI DOI 10.5555/2986459.2986721.
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   Jaitly Navdeep, 2016, ADV NEURAL INFORM PR, P5067.
   Kalchbrenner Nal, 2013, EMNLP, V3, P413.
   Luong M.-T., 2015, ARXIV150804025.
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347.
   Sercu T, 2016, INT CONF ACOUST SPEE, P4955, DOI 10.1109/ICASSP.2016.7472620.
   Sutskever I., 2013, INT C MACH LEARN, P1139, DOI DOI 10.1109/ICASSP.2013.6639346.
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935.
   Wu Yonghui, 2016, ARXIV160908144.
   Xu K, 2015, ICML, V2015, P77.
   Zhang Y., 2016, ARXIV161003022.
   Zhang Y, 2016, INTERSPEECH, P410, DOI 10.21437/Interspeech.2016-1446.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL9IK}},
Unique-ID = {{ISI:000457505000767}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000457505000825,
Author = {Adiga, Nagaraj and Prasanna, S. R. M.},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Phase Modeling using Integrated Linear Prediction Residual for
   Statistical Parametric Speech Synthesis}},
Booktitle = {{18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION}},
Series = {{Interspeech}},
Year = {{2017}},
Pages = {{3981-3985}},
Note = {{18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017),
   Stockholm, SWEDEN, AUG 20-24, 2017}},
Organization = {{Int Speech Commun Assoc; Stockholm Univ; KTH Royal Inst Technol;
   Karolinska Inst; Amazon Alexa; DiDi; Furhat Robot; Microsoft; EZ Alibaba
   Grp; CIRRUS LOGIC; CVTE; Google; Baidu; IBM Res; YAHOO Japan; Nuance;
   Voice Provider; ASM Solut Ltd; Mitsubishi Elect Res Lab; Yandex}},
Abstract = {{The conventional statistical parametric speech synthesis (SPSS) focus on
   characteristics of the magnitude spectrum of speech for speech synthesis
   by ignoring phase characteristics of speech. In this work, the role of
   phase information to improve the naturalness of synthetic speech is
   explored. The phase characteristics of excitation signal arc estimated
   from the integrated linear prediction residual (ILPR) using an all-pass
   (AP) filter. The coefficients of the AP filter are estimated by
   minimizing an entropy based objective function from the cosine phase of
   the analytical signal obtained from ILPR signal. The AP filter
   coefficients (APCs) derived from the AP filter are used as features for
   modeling phase in SPSS. During synthesis time. to generate the
   excitation signal, frame wise generated APCs arc used to add the group
   delay to the impulse excitation. The proposed method is compared with
   the group delay based phase excitation used in the STRAIGHT method. The
   experimental results show that proposed phased modeling having a better
   perceptual synthesis quality when compared with the STRAIGHT method.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Adiga, N (Corresponding Author), Indian Inst Technol Guwahati, Dept Elect \& Elect Engn, Gauhati, India.
   Adiga, Nagaraj; Prasanna, S. R. M., Indian Inst Technol Guwahati, Dept Elect \& Elect Engn, Gauhati, India.}},
DOI = {{10.21437/Interspeech.2017-587}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-4876-4}},
Keywords = {{All-pass filter; statistical parametric speech synthesis; integrated
   linear prediction residual; cosine phase}},
Keywords-Plus = {{EPOCH EXTRACTION}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{nagaraj@iitg.ernet.in
   prasanna@iitg.ernet.in}},
ResearcherID-Numbers = {{Prasanna, S R Mahadeva/AAH-8088-2019
   }},
ORCID-Numbers = {{Adiga, Nagaraj/0000-0002-3438-567X}},
Cited-References = {{Adiga  N., 2016, P IEEE INT C AC SPEE.
   Adiga  N., 2013, P INTERSPEECH.
   Cernak M., 2005, P EUR C AC, P2725.
   CHI CY, 1995, SIGNAL PROCESS, V41, P239, DOI 10.1016/0165-1684(93)E0019-H.
   Degottex G, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0038-1.
   Dhananjaya N, 2010, IEEE SIGNAL PROC LET, V17, P273, DOI 10.1109/LSP.2009.2038507.
   Drugman T. D. T., 2009, P INTERSPEECH.
   Imai S., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P93.
   Juvela L., 2016, P IEEE INT C AC SPEE.
   Kawahara H, 1997, INT CONF ACOUST SPEE, P1303, DOI 10.1109/ICASSP.1997.596185.
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5.
   Kominek J., 2004, P 5 ISCA SPEECH SYNT, P223.
   Maia R, 2012, INT CONF ACOUST SPEE, P4581, DOI 10.1109/ICASSP.2012.6288938.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Murphy PJ, 1999, J ACOUST SOC AM, V105, P2866, DOI 10.1121/1.426901.
   Murty KSR, 2008, IEEE T AUDIO SPEECH, V16, P1602, DOI 10.1109/TASL.2008.2004526.
   OShaughnessy D., 1987, SPEECH COMMUNICATION.
   Paliwal K. K., 2003, P INTERSPEECH.
   Prathosh AP, 2013, IEEE T AUDIO SPEECH, V21, P2471, DOI 10.1109/TASL.2013.2273717.
   Quatieri T.F., 2006, DISCRETE TIME SPEECH.
   Raitio  T., 2016, SPEECH COMMUN, P2016.
   Rothenberg M., 1974, GLOTTAL NOISE SPEECH, V15, P1.
   Schluter R, 2001, INT CONF ACOUST SPEE, P133, DOI 10.1109/ICASSP.2001.940785.
   Tokuda K, 1999, INT CONF ACOUST SPEE, P229, DOI 10.1109/ICASSP.1999.758104.
   Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852.
   Vijayan  K., 2016, SPEECH COMMUN, P2016.
   Vijayan Karthika, 2014, P OD 14 SPEAK LANG R, P112.
   WANG SH, 1992, IEEE J SEL AREA COMM, V10, P819, DOI 10.1109/49.138987.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL9IK}},
Unique-ID = {{ISI:000457505000825}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000413813100122,
Author = {Noroozi, Fatemeh and Akrami, Neda and Anbarjafari, Gholamreza},
Book-Group-Author = {{IEEE}},
Title = {{Speech-based Emotion Recognition and Next Reaction Prediction}},
Booktitle = {{2017 25TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE
   (SIU)}},
Series = {{Signal Processing and Communications Applications Conference}},
Year = {{2017}},
Note = {{25th Signal Processing and Communications Applications Conference (SIU),
   Antalya, TURKEY, MAY 15-18, 2017}},
Organization = {{Turk Telekom; Arcelik A S; Aselsan; ARGENIT; HAVELSAN; NETAS;
   Adresgezgini; IEEE Turkey Sect; AVCR Informat Technologies; Cisco; i2i
   Syst; Integrated Syst \& Syst Design; ENOVAS; FiGES Engn; MS Spektral;
   Istanbul Teknik Univ}},
Abstract = {{Communication through voice is one of the main components of affective
   computing in human-computer interaction. In this type of interaction,
   properly comprehending the meanings of the words or the linguistic
   category and recognizing the emotion included in the speech is essential
   for enhancing the performance. In order to model the emotional state,
   the speech waves are utilized, which bear signals standing for emotions
   such as boredom, fear, joy and sadness. In the first step of the
   emotional reaction prediction system proposed in this paper, different
   emotions are recognized by means of different types of classifiers. The
   second step is the prediction of a sequence of the next emotional
   reactions using neural networks. The sequence is extracted based on the
   speech signals being digitized at tenths of a second, after
   concatenating the different speech signals of each subject. The
   prediction problem is solved as a nonlinear auto-regression time-series
   neural network with the assumption that the variables are defined as
   data-feedback time-series. the best average recognition rate is 86.25\%,
   which is achieved by the Random Forest classifier, and the average
   prediction rate of reactions by using neural networks is 60.30\%.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Noroozi, F (Corresponding Author), Univ Tartu, Inst Technol, EE-50411 Tartu, Estonia.
   Noroozi, Fatemeh, Univ Tartu, Inst Technol, EE-50411 Tartu, Estonia.
   Akrami, Neda, Shiraz Univ, Dept Elect \& Comp Engn, Shiraz, Iran.
   Anbarjafari, Gholamreza, Univ Tartu, Inst Technol, ICV Res Grp, EE-50411 Tartu, Estonia.
   Anbarjafari, Gholamreza, Hasan Kalyoncu Univ, Dept Elect \& Elect Engn, Gaziantep, Turkey.}},
ISSN = {{2165-0608}},
ISBN = {{978-1-5090-6494-6}},
Keywords = {{emotion prediction; neural networks; vocal emotion recognition;
   human-computer interaction}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Telecommunications}},
Author-Email = {{fatemeh.noroozi@ut.ee
   neda.akrami@shirazu.ac.ir
   shb@icv.tuit.ut.ee}},
ResearcherID-Numbers = {{Noroozi, Fatemeh/AAD-3695-2019
   Anbarjafari, Gholamreza/A-3845-2010}},
ORCID-Numbers = {{Noroozi, Fatemeh/0000-0002-4618-1375
   Anbarjafari, Gholamreza/0000-0001-8460-5717}},
Funding-Acknowledgement = {{Estonian Research Council GrantEstonian Research Council {[}PUT638];
   European Network on Integrating Vision and Language (iV\&L Net) ICT COST
   Action {[}IC1307]; Estonian Centre of Excellence in IT (EXCITE) -
   European Regional Development Fund}},
Funding-Text = {{This work is supported Estonian Research Council Grant (PUT638), the
   European Network on Integrating Vision and Language (iV\&L Net) ICT COST
   Action IC1307 and the Estonian Centre of Excellence in IT (EXCITE)
   funded by the European Regional Development Fund.}},
Cited-References = {{Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5.
   Bellantonio M., 2016, INT C PATT REC ICPR.
   Bozkurt Elif, 2010, 2010 IEEE 18th Signal Processing and Communications Applications Conference (SIU 2010), P216, DOI 10.1109/SIU.2010.5649919.
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324.
   Cichosz J., 2007, P AFF COMP INT INT.
   Dai WH, 2015, INFORM MANAGE-AMSTER, V52, P777, DOI 10.1016/j.im.2015.02.003.
   Fukunaga K, 2013, INTRO STAT PATTERN R.
   Gamez J. A., 2013, ADV BAYESIAN NETWORK, V146.
   Gharavian D, 2017, MULTIMED TOOLS APPL, V76, P2331, DOI 10.1007/s11042-015-3180-6.
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601.
   Jagdale S., 2016, DIGIT SIGNAL PROCESS, V8, P154.
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381.
   Kaminska D, 2012, INT J ELECTRON TELEC, V58, P165, DOI 10.2478/v10177-012-0024-4.
   Kim S, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P48, DOI 10.1109/MMSP.2007.4412815.
   Knapp ML, 2013, NONVERBAL COMMUNICAT.
   Lin YL, 2016, CORPORA, V11, P63, DOI 10.3366/cor.2016.0085.
   Ma Y., 2014, SUPPORT VECTOR MACHI.
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004.
   Pfahringer B, 2007, LECT NOTES COMPUT SC, V4830, P90.
   Pohjalainen J, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P670, DOI 10.1145/2964284.2967306.
   Powroznik P., 2016, PRZEGLAD ELEKTROTECH, V92.
   Quinlan J.R., 2014, C4 5 PROGRAMS MACHIN.
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642.
   Schuller B., 2016, P INT.
   Schuller B, 2013, COMPUT SPEECH LANG, V27, P1, DOI 10.1016/j.csl.2012.06.002.
   Sethi I. K., 2014, ARTIFICIAL NEURAL NE, V11.
   Sethu V., 2015, SPEECH AUDIO PROCESS, P197.
   Sheguo Wang, 2010, Proceedings of the 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P437, DOI 10.1109/ICMTMA.2010.523.
   Staroniewicz P., 2008, P 55 OP SEM AC WROCL, P373.
   Warren P, 2016, UPTALK: THE PHENOMENON OF RISING INTONATION, P1, DOI 10.1017/CBO9781316403570.
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006.
   Wu CH, 2011, IEEE T AFFECT COMPUT, V2, P10, DOI 10.1109/T-AFFC.2010.16.
   Zhao XM, 2014, NEURAL COMPUT APPL, V24, P1539, DOI 10.1007/s00521-013-1377-z.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI6YK}},
Unique-ID = {{ISI:000413813100122}},
DA = {{2020-12-06}},
}

@article{ ISI:000406238600005,
Author = {Ito, Aine and Martin, Andrea E. and Nieuwland, Mante S.},
Title = {{How robust are prediction effects in language comprehension? Failure to
   replicate article-elicited N400 effects}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2017}},
Volume = {{32}},
Number = {{8}},
Pages = {{954-965}},
Abstract = {{Current psycholinguistic theory proffers prediction as a central,
   explanatory mechanism in language processing. However, widely-replicated
   prediction effects may not mean that prediction is necessary in language
   processing. As a case in point, C. D. Martin et al. {[}2013. Bilinguals
   reading in their second language do not predict upcoming words as native
   readers do. Journal of Memory and Language, 69(4), 574-588.
   doi:10.1016/j.jml.2013.08.001] reported ERP evidence for prediction in
   native- but not in non-native speakers. Articles mismatching an expected
   noun elicited larger negativity in the N400 time window compared to
   articles matching the expected noun in native speakers only. We
   attempted to replicate these findings, but found no evidence for
   prediction irrespective of language nativeness. We argue that
   pre-activation of phonological form of upcoming nouns, as evidenced in
   article-elicited effects, may not be a robust phenomenon. A view of
   prediction as a necessary computation in language comprehension must be
   re-evaluated.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ito, A (Corresponding Author), Univ Edinburgh, Sch Philosophy Psychol \& Language Sci, Dept Psychol, Edinburgh, Midlothian, Scotland.
   Ito, Aine; Martin, Andrea E.; Nieuwland, Mante S., Univ Edinburgh, Sch Philosophy Psychol \& Language Sci, Dept Psychol, Edinburgh, Midlothian, Scotland.}},
DOI = {{10.1080/23273798.2016.1242761}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Prediction; language comprehension; ERP; N400; bilingualism}},
Keywords-Plus = {{WORD ANTICIPATION; UPCOMING WORDS; L2; 2ND-LANGUAGE; DISCOURSE}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{aine.ito@ed.ac.uk}},
ResearcherID-Numbers = {{Ito, Aine/I-6828-2019}},
ORCID-Numbers = {{Ito, Aine/0000-0003-4408-8801}},
Funding-Acknowledgement = {{Economic and Social Research Council of the United KingdomEconomic \&
   Social Research Council (ESRC) {[}ES/K009095/1]; Economic and Social
   Research CouncilEconomic \& Social Research Council (ESRC)
   {[}ES/K009095/1] Funding Source: researchfish}},
Funding-Text = {{AEM was supported by a Future Research Leaders Grant from the Economic
   and Social Research Council of the United Kingdom {[}ES/K009095/1].}},
Cited-References = {{Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Baayen HR, 2008, J MEM LANG, V59, P390, DOI DOI 10.1016/J.JML.2007.12.005.
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01.
   Clahsen H, 2006, TRENDS COGN SCI, V10, P564, DOI 10.1016/j.tics.2006.10.002.
   Cunnings I, 2012, SECOND LANG RES, V28, P369, DOI 10.1177/0267658312443651.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Delong KA, 2011, PSYCHOPHYSIOLOGY, V48, P1203, DOI 10.1111/j.1469-8986.2011.01199.x.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756.
   Gruter T., 2014, P 38 BOST U C LANG D.
   Havik E, 2009, LANG LEARN, V59, P73, DOI 10.1111/j.1467-9922.2009.00501.x.
   Hopp H, 2015, IRAL-INT REV APPL LI, V53, P277, DOI 10.1515/iral-2015-0014.
   Hopp H, 2009, BILING-LANG COGN, V12, P463, DOI 10.1017/S1366728909990253.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Ito A., J EXPT PSYCHOL LEARN.
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007.
   Kaan E, 2016, BILING-LANG COGN, V19, P1, DOI 10.1017/S1366728914000844.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Martin AE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00120.
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   Otten M, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-89.
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463.
   Pashler H, 2012, PERSPECT PSYCHOL SCI, V7, P528, DOI 10.1177/1745691612465253.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   R Development Core Team, 2015, LANG ENV STAT COMP.
   Tanner D, 2013, BILING-LANG COGN, V16, P367, DOI 10.1017/S1366728912000302.
   Thornhill DE, 2012, INT J PSYCHOPHYSIOL, V83, P382, DOI 10.1016/j.ijpsycho.2011.12.007.
   Tokowicz N, 2005, STUD SECOND LANG ACQ, V27, P173, DOI 10.1017/S0272263105050102.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Wlotko EW, 2015, CORTEX, V68, P20, DOI 10.1016/j.cortex.2015.03.014.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{34}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{FB6GC}},
Unique-ID = {{ISI:000406238600005}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000570180700044,
Author = {Crossley, Scott and Liu, Ran and McNamara, Danielle},
Book-Group-Author = {{ACM}},
Title = {{Predicting Math Performance Using Natural Language Processing Tools}},
Booktitle = {{SEVENTH INTERNATIONAL LEARNING ANALYTICS \& KNOWLEDGE CONFERENCE
   (LAK'17)}},
Year = {{2017}},
Pages = {{339-347}},
Note = {{7th International Learning Analytics and Knowledge Conference (LAK),
   Simon Fraser Univ, Vancouver, CANADA, MAR 13-17, 2017}},
Organization = {{Soc Learning Analyt Res}},
Abstract = {{A number of studies have demonstrated links between linguistic knowledge
   and performance in math. Studies examining these links in first language
   speakers of English have traditionally relied on correlational analyses
   between linguistic knowledge tests and standardized math tests. For
   second language (L2) speakers, the majority of studies have compared
   math performance between proficient and non-proficient speakers of
   English. In this study, we take a novel approach and examine the
   linguistic features of student language while they are engaged in
   collaborative problem solving within an on-line math tutoring system. We
   transcribe the students' speech and use natural language processing
   tools to extract linguistic information related to text cohesion,
   lexical sophistication, and sentiment. Our criterion variables are
   individuals' pretest and posttest math performance scores. In addition
   to examining relations between linguistic features of student language
   production and math scores, we also control for a number of
   non-linguistic factors including gender, age, grade, school, and content
   focus (procedural versus conceptual). Linear mixed effect modeling
   indicates that non-linguistic factors are not predictive of math scores.
   However, linguistic features related to cohesion affect and lexical
   proficiency explained approximately 30\% of the variance (R-2 = .303) in
   the math scores.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Crossley, S (Corresponding Author), Georgia State Univ, 25 Pk Pl,Ste 1500, Atlanta, GA 30303 USA.
   Crossley, Scott, Georgia State Univ, 25 Pk Pl,Ste 1500, Atlanta, GA 30303 USA.
   Liu, Ran, Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
   McNamara, Danielle, Arizona State Univ, POB 872111, Tempe, AZ 85287 USA.}},
DOI = {{10.1145/3027385.3027399}},
ISBN = {{978-1-4503-4870-6}},
Keywords = {{On-line tutoring systems; educational data mining; natural language
   processing; sentiment analysis; predictive analytics}},
Keywords-Plus = {{MATHEMATICS; REPRESENTATIONS; ACHIEVEMENT; PROFICIENCY; PATHWAYS;
   LEARNERS; RATINGS; WORDS}},
Research-Areas = {{Computer Science; Education \& Educational Research}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Education \& Educational Research;
   Education, Scientific Disciplines}},
Author-Email = {{scrossley@gsu.edu
   ranliu@cmu.edu
   dsmcnamara1@gmail.com}},
Funding-Acknowledgement = {{Institute for Education Sciences; National Science FoundationNational
   Science Foundation (NSF) {[}IES R305A080589, IES R305G20018-02,
   DRL-1417997]}},
Funding-Text = {{This research was supported in part by the Institute for Education
   Sciences and National Science Foundation (IES R305A080589, IES
   R305G20018-02, and DRL-1417997). Ideas expressed in this material are
   those of the authors and do not necessarily reflect the views of the IES
   or the NSF.}},
Cited-References = {{Adams TL, 2003, READ TEACH, V56, P786.
   Aleven V., 2009, INT J ARTIFICIAL INT, V19, P105, DOI DOI 10.1109/DIGITEL.2010.55.
   Alt M, 2014, LANG SPEECH HEAR SER, V45, P220, DOI 10.1044/2014\_LSHSS-13-0003.
   {[}Anonymous], 2007, BRIT NATL CORPUS VER.
   Ardasheva Y, 2012, LANG LEARN, V62, P769, DOI 10.1111/j.1467-9922.2011.00652.x.
   Bates D., 2015, ARXIV14065823.
   Bird S, 2009, NATURAL LANGUAGE PRO.
   BROWN GD, 1984, BEHAV RES METH INS C, V16, P502, DOI 10.3758/BF03200836.
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5.
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977.
   Cambria E., 2010, AAAI FALL S COMM KNO.
   Cambria E, 2012, MULTIMED TOOLS APPL, V59, P557, DOI 10.1007/s11042-011-0815-0.
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805.
   Coxhead A, 2000, TESOL QUART, V34, P213, DOI 10.2307/3587951.
   Crossley S. A., 1944, BEHAV RES METHODS.
   Crossley S. A., BEHAV RES METHODS.
   CUMMINS J, 1979, REV EDUC RES, V49, P222, DOI 10.3102/00346543049002222.
   Hampden-Thompson G., 2008, MATH ACHIEVEMENT LAN.
   Hernandez F., 2013, THESIS.
   Hutto CJ, 2014, 8 INT AAAI C WEBL SO.
   Kucera H., 1967, COMPUTATIONAL ANAL P.
   Kuperman V, 2012, BEHAV RES METHODS, V44, P978, DOI 10.3758/s13428-012-0210-4.
   Kuznetsova A., 2015, PACKAGE LMERTEST R P.
   Kyle K, 2015, TESOL QUART, V49, P757, DOI 10.1002/tesq.194.
   Lasswell H. D, 1969, LASSWELL VALUE DICT.
   LeFevre JA, 2010, CHILD DEV, V81, P1753, DOI 10.1111/j.1467-8624.2010.01508.x.
   MacGregor M, 1999, J RES MATH EDUC, V30, P449, DOI 10.2307/749709.
   Manning C. D., 2014, 52 ANN M ASS COMP LI.
   Martiniello M, 2009, EDUC ASSESS, V14, P160, DOI 10.1080/10627190903422906.
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748.
   Mohammad S, 2010, P NAACL HLT 2010 WOR.
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x.
   Mosqueda E, 2013, EQUITY EXCELL EDUC, V46, P202, DOI 10.1080/10665684.2013.780647.
   Olsen J. K., P ART INT ED AIED C.
   Polanyi L, 2006, INFORM RETRIEVAL SER, V20, P1.
   R Team, 2014, R LANG ENV STAT COMP.
   Rau Martina A., 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P174, DOI 10.1007/978-3-642-30950-2\_23.
   Rau MA, 2009, FRONT ARTIF INTEL AP, V200, P441, DOI 10.3233/978-1-60750-028-5-441.
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216.
   Simpson-Vlach R, 2010, APPL LINGUIST, V31, P487, DOI 10.1093/applin/amp058.
   Thorndike E. L, 1944, TEACHERS WORDBOOK 30.
   Toutanova K., 2003, P 2003 C N AM ASS CO, V1.
   Vukovic RK, 2013, LEARN INDIVID DIFFER, V23, P87, DOI 10.1016/j.lindif.2012.10.007.
   Wang J, 1999, J EDUC RES, V93, P101, DOI 10.1080/00220679909597634.}},
Number-of-Cited-References = {{44}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP9PA}},
Unique-ID = {{ISI:000570180700044}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000391851700004,
Author = {Kang, Jin Ah and Han, Mikyong and Jang, Jong-Hyun and Kim, Hong Kook},
Title = {{Adaptive Speech Streaming Based on Packet Loss Prediction Using Support
   Vector Machine for Software-Based Multipoint Control Unit over IP
   Networks}},
Journal = {{ETRI JOURNAL}},
Year = {{2016}},
Volume = {{38}},
Number = {{6}},
Pages = {{1064-1073}},
Month = {{DEC}},
Abstract = {{An adaptive speech streaming method to improve the perceived speech
   quality of a software-based multipoint control unit (SW-based MCU) over
   IP networks is proposed. First, the proposed method predicts whether the
   speech packet to be transmitted is lost. To this end, the proposed
   method learns the pattern of packet losses in the IP network, and then
   predicts the loss of the packet to be transmitted over that IP network.
   The proposed method classifies the speech signal into different classes
   of silence, unvoiced, speech onset, or voiced frame. Based on the
   results of packet loss prediction and speech classification, the
   proposed method determines the proper amount and bitrate of redundant
   speech data (RSD) that are sent with primary speech data (PSD) in order
   to assist the speech decoder to restore the speech signals of lost
   packets. Specifically, when a packet is predicted to be lost, the amount
   and bitrate of the RSD must be increased through a reduction in the
   bitrate of the PSD. The effectiveness of the proposed method for
   learning the packet loss pattern and assigning a different speech coding
   rate is then demonstrated using a support vector machine and adaptive
   multirate-narrowband, respectively. The results show that as compared
   with conventional methods that restore lost speech signals, the proposed
   method remarkably improves the perceived speech quality of an SW-based
   MCU under various packet loss conditions in an IP network.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kim, HK (Corresponding Author), Gwangju Inst Sci \& Technol, Sch Elect Engn \& Comp Sci, Gwangju, South Korea.
   Kang, Jin Ah; Han, Mikyong; Jang, Jong-Hyun, ETRI, Giga Commun Res Lab 5G, Daejeon, South Korea.
   Kim, Hong Kook, Gwangju Inst Sci \& Technol, Sch Elect Engn \& Comp Sci, Gwangju, South Korea.}},
DOI = {{10.4218/etrij.16.2716.0013}},
ISSN = {{1225-6463}},
EISSN = {{2233-7326}},
Keywords = {{Software-based multipoint control unit; Adaptive speech streaming;
   Packet loss prediction; Redundant speech transmission; Support vector
   machine; AMR-NB}},
Keywords-Plus = {{REAL-TIME}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{jakang@etri.re.kr
   mkhan@etri.re.kr
   jangjh@etri.re.kr
   hongkook@gist.ac.kr}},
Funding-Acknowledgement = {{``The Cross-Ministry Giga KOREA Project{''} from the Ministry of
   Science, ICT and Future Planning, Korea, Rep. of Korea {[}GK16P0100]}},
Funding-Text = {{This work was supported by the ``The Cross-Ministry Giga KOREA
   Project{''} grant from the Ministry of Science, ICT and Future Planning,
   Korea, Rep. of Korea (GK16P0100, Development of Tele-Experience Service
   SW Platform Based on Giga Media).}},
Cited-References = {{Ameri A, 2014, IEEE T NEUR SYS REH, V22, P1198, DOI 10.1109/TNSRE.2014.2323576.
   {[}Anonymous], 2000, 0311 3GPP TS.
   {[}Anonymous], 2003, 3550 RFC.
   {[}Anonymous], 2010, 26091 3GPP TR.
   {[}Anonymous], 2002, 3267 RFC.
   {[}Anonymous], 2010, 26101 3GPP TS.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Cisco, 2014, TELEPRESENCE PACK LO.
   Cisco, VIS NETW IND FOR MET.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Ellis M., 2011, P 2 ANN ACM C MULT S, P111.
   Ellis M, 2014, COMPUT NETW, V70, P384, DOI 10.1016/j.comnet.2014.05.013.
   Gao Y, 2001, INT CONF ACOUST SPEE, P709, DOI 10.1109/ICASSP.2001.941013.
   Hsu HS, 2012, INT CONF SPEECH DATA, P68, DOI 10.1109/ICSDA.2012.6422452.
   Huang JJ, 2012, ETRI J, V34, P645, DOI 10.4218/etrij.12.0211.0408.
   Juwon Kang, 2012, THESIS.
   Kang J.A., 2015, INT J DISTRIB SENS N, V2015, P1.
   Kang JA, 2011, SENSORS-BASEL, V11, P8469, DOI 10.3390/s110908469.
   Kouvelas I., 1997, P INT WORKSH AUD VIS, P195.
   Malfait L, 2006, IEEE T AUDIO SPEECH, V14, P1924, DOI 10.1109/TASL.2006.883177.
   Merazka F, 2009, IAENG INT J COMPUTER, V36, P1.
   Nagano T., 2014, J INFORM HIDING MULT, V5, P286.
   NTT Adv. Technol. Corp, 1994, MULT SPEECH DAT TEL.
   Park K, 2003, ETRI J, V25, P356, DOI 10.4218/etrij.03.0102.0001.
   Park NI, 2011, SENSORS-BASEL, V11, P5323, DOI 10.3390/s110505323.
   Sun J, 2014, TRANSPORT RES REC, P91, DOI 10.3141/2432-11.
   Tin-Yu Wu, 2013, IEEE Wireless Communications, V20, P146, DOI 10.1109/MWC.2013.6590062.
   Wang Lizhong, 2010, 2010 2nd International Conference on Networking and Digital Society (ICNDS 2010), P186, DOI 10.1109/ICNDS.2010.5479338.
   Yoon H, 2015, ETRI J, V37, P1199, DOI 10.4218/etrij.15.0114.0523.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{ETRI J.}},
Doc-Delivery-Number = {{EH5ZK}},
Unique-ID = {{ISI:000391851700004}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000387595100001,
Author = {Maess, Burkhard and Mamashli, Fahimeh and Obleser, Jonas and Helle,
   Liisa and Friederici, Angela D.},
Title = {{Prediction Signatures in the Brain: Semantic Pre-Activation during
   Language Comprehension}},
Journal = {{FRONTIERS IN HUMAN NEUROSCIENCE}},
Year = {{2016}},
Volume = {{10}},
Month = {{NOV 15}},
Abstract = {{There is broad agreement that context-based predictions facilitate
   lexical-semantic processing. A robust index of semantic prediction
   during language comprehension is an evoked response, known as the N400,
   whose amplitude is modulated as a function of semantic context. However,
   the underlying neural mechanisms that utilize relations of the prior
   context and the embedded word within it are largely unknown. We measured
   magnetoencephalography (MEG) data while participants were listening to
   simple German sentences in which the verbs were either highly predictive
   for the occurrence of a particular noun (i.e., provided context) or not.
   The identical set of nouns was presented in both conditions. Hence,
   differences for the evoked responses of the nouns can only be due to
   differences in the earlier context. We observed a reduction of the N400
   response for highly predicted nouns. Interestingly, the opposite pattern
   was observed for the preceding verbs: highly predictive (that is more
   informative) verbs yielded stronger neural magnitude compared to less
   predictive verbs. A negative correlation between the N400 effect of the
   verb and that of the noun was found in a distributed brain network,
   indicating an integral relation between the predictive power of the verb
   and the processing of the subsequent noun. This network consisted of
   left hemispheric superior and middle temporal areas and a subcortical
   area; the parahippocampus. Enhanced activity for highly predictive
   relative to less predictive verbs, likely reflects establishing semantic
   features associated with the expected nouns, that is a pre-activation of
   the expected nouns.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Maess, B; Mamashli, F (Corresponding Author), Max Planck Inst Human Cognit \& Brain Sci, MEG \& Cort Networks Grp, Leipzig, Germany.
   Mamashli, F (Corresponding Author), Max Planck Inst Human Cognit \& Brain Sci, Dept Neuropsychol, Leipzig, Germany.
   Mamashli, F (Corresponding Author), Harvard Med Sch, Athinoula A Martinos Ctr Biomed Imaging, Massachusetts Gen Hosp, Dept Neurol, Boston, MA 02115 USA.
   Maess, Burkhard; Mamashli, Fahimeh, Max Planck Inst Human Cognit \& Brain Sci, MEG \& Cort Networks Grp, Leipzig, Germany.
   Mamashli, Fahimeh; Friederici, Angela D., Max Planck Inst Human Cognit \& Brain Sci, Dept Neuropsychol, Leipzig, Germany.
   Mamashli, Fahimeh, Harvard Med Sch, Athinoula A Martinos Ctr Biomed Imaging, Massachusetts Gen Hosp, Dept Neurol, Boston, MA 02115 USA.
   Obleser, Jonas, Max Planck Inst Human Cognit \& Brain Sci, Max Planck Res Grp Auditory Cognit, Leipzig, Germany.
   Obleser, Jonas, Univ Lubeck, Dept Psychol, Lubeck, Germany.
   Helle, Liisa, Elekta Oy, Helsinki, Finland.
   Helle, Liisa, Aalto Univ, Sch Sci, Dept Neurosci \& Biomed Engn, Espoo, Finland.}},
DOI = {{10.3389/fnhum.2016.00591}},
Article-Number = {{591}},
ISSN = {{1662-5161}},
Keywords = {{semantics; prediction; language; MEG; N400}},
Keywords-Plus = {{EVENT-RELATED POTENTIALS; TOP-DOWN; TIME-COURSE; MENTAL REPRESENTATION;
   PREFRONTAL CORTEX; WORD RECOGNITION; PRIOR KNOWLEDGE; EYE-TRACKING;
   NEURAL BASIS; EEG-DATA}},
Research-Areas = {{Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Neurosciences; Psychology}},
Author-Email = {{maess@cbs.mpg.de
   fmamashli@mgh.harvard.edu}},
ORCID-Numbers = {{Helle, Liisa/0000-0002-0001-9292
   Maess, Burkhard/0000-0002-7857-291X}},
Funding-Acknowledgement = {{Max Planck Society, Munich, GermanyMax Planck Society; International Max
   Planck Research School on neuroscience of communication, Leipzig,
   Germany; Elekta Oy, Helsinki, Finland}},
Funding-Text = {{This research was supported by the Max Planck Society (ADF, JO, BM, FM),
   Munich, Germany, the International Max Planck Research School on
   neuroscience of communication (FM), Leipzig, Germany, and Elekta Oy,
   Helsinki, Finland. Yvonne Wolff acquired the data. We would like to
   thank Jane Neumann and Helga Smallwood for valuable comments on
   manuscript preparation, Samu Taulu and Antti Ahonen for providing us
   with the advanced sensor noise suppression method for MEG data.
   analysis.}},
Cited-References = {{Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Bar M, 2009, PHILOS T R SOC B, V364, P1181, DOI 10.1098/rstb.2008.0321.
   Bendixen A, 2009, J NEUROSCI, V29, P8447, DOI 10.1523/JNEUROSCI.1493-09.2009.
   Bonhage CE, 2015, CORTEX, V68, P33, DOI 10.1016/j.cortex.2015.04.011.
   Bonte M, 2006, CEREB CORTEX, V16, P115, DOI 10.1093/cercor/bhi091.
   Brusini P, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01841.
   Burgess C, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P61.
   Coutanche MN, 2015, CEREB CORTEX, V25, P2584, DOI 10.1093/cercor/bhu057.
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395.
   Dambacher M, 2006, BRAIN RES, V1084, P89, DOI 10.1016/j.brainres.2006.02.010.
   David O, 2011, J NEUROSCI, V31, P2712, DOI 10.1523/JNEUROSCI.3433-10.2011.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008.
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010.
   Dikker S, 2013, BRAIN LANG, V127, P55, DOI 10.1016/j.bandl.2012.08.004.
   Dikker S, 2011, BRAIN LANG, V118, P23, DOI 10.1016/j.bandl.2011.02.006.
   Duff MC, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00069.
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8.
   Friederici AD, 2000, J MEM LANG, V43, P476, DOI 10.1006/jmla.2000.2709.
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011.
   Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005.
   Fruchter J, 2015, J COGNITIVE NEUROSCI, V27, P1912, DOI 10.1162/jocn\_a\_00822.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267.
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027.
   Griffiths TL, 2011, J EXP PSYCHOL GEN, V140, P725, DOI 10.1037/a0024899.
   Gunter TC, 2000, J COGNITIVE NEUROSCI, V12, P556, DOI 10.1162/089892900562336.
   Hald LA, 2007, BRAIN RES, V1146, P210, DOI 10.1016/j.brainres.2007.02.054.
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159.
   Halgren E, 2006, NEUROIMAGE, V30, P1401, DOI 10.1016/j.neuroimage.2005.10.053.
   Halgren E, 2002, NEUROIMAGE, V17, P1101, DOI 10.1006/nimg.2002.1268.
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476.
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004.
   Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142.
   Jakuszeit M, 2013, CORTEX, V49, P2861, DOI 10.1016/j.cortex.2013.05.014.
   Kiebel Stefan J, 2009, Front Neuroinform, V3, P20, DOI 10.3389/neuro.11.020.2009.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6.
   Kutas M, 1989, J Cogn Neurosci, V1, P38, DOI 10.1162/jocn.1989.1.1.38.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211.
   Lau E, 2009, BRAIN LANG, V111, P161, DOI 10.1016/j.bandl.2009.08.007.
   Lau EF, 2016, CEREB CORTEX, V26, P1377, DOI 10.1093/cercor/bhu219.
   Lau EF, 2013, J NEUROSCI, V 33, P17174, DOI 10.1523/JNEUROSCI.1018-13.2013.
   Lau EF, 2013, J COGNITIVE NEUROSCI, V25, P484, DOI 10.1162/jocn\_a\_00328.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Lewis AG, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00085.
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014.
   Li XS, 2006, J COGNITIVE NEUROSCI, V18, P1774, DOI 10.1162/jocn.2006.18.10.1774.
   Maess B, 2006, BRAIN RES, V1096, P163, DOI 10.1016/j.brainres.2006.04.037.
   Marinkovic K, 2003, NEURON, V38, P487, DOI 10.1016/S0896-6273(03)00197-1.
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024.
   Meyer P, 2005, HIPPOCAMPUS, V15, P451, DOI 10.1002/hipo.20070.
   Obleser J, 2011, NEUROIMAGE, V55, P713, DOI 10.1016/j.neuroimage.2010.12.020.
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049.
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5.
   Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277.
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160.
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x.
   Pulvermuller F, 2005, J COGNITIVE NEUROSCI, V17, P884, DOI 10.1162/0898929054021111.
   Pylkkanen L, 2007, J COGNITIVE NEUROSCI, V19, P1905, DOI 10.1162/jocn.2007.19.11.1905.
   Pylkkanen L, 2003, TRENDS COGN SCI, V7, P187, DOI 10.1016/S1364-6613(03)00092-5.
   Pylkkanen L, 2002, BRAIN LANG, V81, P666, DOI 10.1006/brln.2001.2555.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rauss K, 2011, NEUROSCI BIOBEHAV R, V35, P1237, DOI 10.1016/j.neubiorev.2010.12.011.
   Salmelin R, 2007, CLIN NEUROPHYSIOL, V118, P237, DOI 10.1016/j.clinph.2006.07.316.
   Schiffer AM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036445.
   SHAPIRO LP, 1987, COGNITION, V27, P219, DOI 10.1016/S0010-0277(87)80010-0.
   SHAPIRO LP, 1993, BRAIN LANG, V45, P423, DOI 10.1006/brln.1993.1053.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Strauss A, 2013, J COGNITIVE NEUROSCI, V25, P1383, DOI 10.1162/jocn\_a\_00389.
   Taulu S, 2005, IEEE T SIGNAL PROCES, V53, P3359, DOI 10.1109/TSP.2005.853302.
   Taulu S., 2012, 18 INT C BIOM, P285.
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401.
   Thompson CK, 2007, J COGNITIVE NEUROSCI, V19, P1753, DOI 10.1162/jocn.2007.19.11.1753.
   Thompson-Schill SL, 1999, NEURON, V23, P513, DOI 10.1016/S0896-6273(00)80804-1.
   Thompson-Schill SL, 1997, P NATL ACAD SCI USA, V94, P14792, DOI 10.1073/pnas.94.26.14792.
   Tracy JI, 2008, HANDBOOK OF THE NEUROSCIENCE OF LANGUAGE, P319, DOI 10.1016/B978-008045352-1.00031-8.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Wahl M, 2008, NEURON, V59, P695, DOI 10.1016/j.neuron.2008.07.011.
   Wang L, 2012, FRONT PSYCHOL, V3, DOI {[}10.3389/fpsyg.2012.00187, 10.3389/fpsyg.2012.00438].
   Wlotko EW, 2012, NEUROIMAGE, V62, P356, DOI 10.1016/j.neuroimage.2012.04.054.}},
Number-of-Cited-References = {{92}},
Times-Cited = {{20}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{Front. Hum. Neurosci.}},
Doc-Delivery-Number = {{EB7UC}},
Unique-ID = {{ISI:000387595100001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000382677800011,
Author = {Jensen, Jesper and Taal, Cees H.},
Title = {{An Algorithm for Predicting the Intelligibility of Speech Masked by
   Modulated Noise Maskers}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2016}},
Volume = {{24}},
Number = {{11}},
Pages = {{2009-2022}},
Month = {{NOV}},
Abstract = {{Intelligibility listening tests are necessary during development and
   evaluation of speech processing algorithms, despite the fact that they
   are expensive and time consuming. In this paper, we propose a monaural
   intelligibility prediction algorithm, which has the potential of
   replacing some of these listening tests. The proposed algorithm shows
   similarities to the short-time objective intelligibility (STOI)
   algorithm, but works for a larger range of input signals. In contrast to
   STOI, extended STOI (ESTOI) does not assume mutual independence between
   frequency bands. ESTOI also incorporates spectral correlation by
   comparing complete 400-ms length spectrograms of the noisy/processed
   speech and the clean speech signals. As a consequence, ESTOI is also
   able to accurately predict the intelligibility of speech contaminated by
   temporally highly modulated noise sources in addition to noisy signals
   processed with time-frequency weighting. We show that ESTOI can be
   interpreted in terms of an orthogonal decomposition of short-time
   spectrograms into intelligibility subspaces, i.e., a ranking of
   spectrogram features according to their importance to intelligibility. A
   free MATLAB implementation of the algorithm is available for
   noncommercial use at http://kom.aau.dk/similar to jje/.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jensen, J (Corresponding Author), Aalborg Univ, DK-9100 Aalborg, Denmark.
   Jensen, J (Corresponding Author), Oticon AS, DK-2765 Smorum, Denmark.
   Jensen, Jesper, Aalborg Univ, DK-9100 Aalborg, Denmark.
   Jensen, Jesper, Oticon AS, DK-2765 Smorum, Denmark.
   Taal, Cees H., Quby Labs, NL-1096 CJ Amsterdam, Netherlands.}},
DOI = {{10.1109/TASLP.2016.2585878}},
ISSN = {{2329-9290}},
Keywords = {{Modulated noise sources; noise reduction; objective distortion measures;
   speech enhancement; speech intelligibility prediction}},
Keywords-Plus = {{ENVELOPE POWER RATIO; TEMPORAL ENVELOPE; PERCEPTION; SENTENCES; MASKING}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{jesj@oticon.com
   chtaal@gmail.com}},
Cited-References = {{{[}Anonymous], 1969, S35 ANSI.
   {[}Anonymous], 1995, S35 ANSI.
   {[}Anonymous], 1990, TIM AC PHON CONT SPE.
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32.
   Boldt Jesper B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1849.
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929.
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600.
   Dreschler WA, 2001, AUDIOLOGY, V40, P148.
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112.
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836.
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467.
   Duda R. O., 2001, PATTERN CLASSIFICATI.
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   GUSTAFSSON HA, 1994, J ACOUST SOC AM, V95, P518, DOI 10.1121/1.408346.
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203.
   HOHMANN V, 1995, J ACOUST SOC AM, V97, P1191, DOI 10.1121/1.413092.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   {*}INT EL COMM, 2003, IEC6026816.
   Jensen J, 2014, IEEE-ACM T AUDIO SPE, V22, P430, DOI 10.1109/TASLP.2013.2295914.
   Jensen J, 2012, IEEE T AUDIO SPEECH, V20, P92, DOI 10.1109/TASL.2011.2157685.
   Jorgensen S, 2015, ACTA ACUST UNITED AC, V101, P1016, DOI 10.3813/AAA.918896.
   Jorgensen S, 2015, J ACOUST SOC AM, V137, P1401, DOI 10.1121/1.4908240.
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502.
   Kates JM, 2015, J ACOUST SOC AM, V138, P2470, DOI 10.1121/1.4931899.
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673.
   Koopman J., 2007, 8 EFAS C 10 DGA C HE.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Peters RW, 1998, J ACOUST SOC AM, V103, P577, DOI 10.1121/1.421128.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   Steeneken HJM, 1999, SPEECH COMMUN, V28, P109, DOI 10.1016/S0167-6393(99)00007-2.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEIGER JH, 1980, PSYCHOL BULL, V87, P245, DOI 10.1037/0033-2909.87.2.245.
   Taal C. H., 2009, P INTERSPEECH, P1947.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Taghia J, 2014, IEEE-ACM T AUDIO SPE, V22, P6, DOI 10.1109/TASL.2013.2281574.
   Thiemann J., 2013, P 21 INT C AC MN CAN.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.
   Wilcox RR, 2008, J GEN PSYCHOL, V135, P105, DOI 10.3200/GENP.135.1.105-112.
   WILLIAMS EJ, 1959, J ROY STAT SOC B, V21, P396.
   Xia RS, 2012, INT CONF ACOUST SPEE, P4465, DOI 10.1109/ICASSP.2012.6288911.}},
Number-of-Cited-References = {{46}},
Times-Cited = {{78}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{DV1JS}},
Unique-ID = {{ISI:000382677800011}},
DA = {{2020-12-06}},
}

@article{ ISI:000382677800003,
Author = {Andersen, Asger Heidemann and de Haan, Jan Mark and Tan, Zheng-Hua and
   Jensen, Jesper},
Title = {{Predicting the Intelligibility of Noisy and Nonlinearly Processed
   Binaural Speech}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2016}},
Volume = {{24}},
Number = {{11}},
Pages = {{1908-1920}},
Month = {{NOV}},
Note = {{41st IEEE International Conference on Acoustics, Speech, and Signal
   Processing, Shanghai, PEOPLES R CHINA, MAR, 2016}},
Organization = {{IEEE}},
Abstract = {{Objective speech intelligibility measures are gaining popularity in the
   development of speech enhancement algorithms and speech processing
   devices such as hearing aids. Such devices may process the input signals
   nonlinearly and modify the binaural cues presented to the user. We
   propose a method for predicting the intelligibility of noisy and
   nonlinearly processed binaural speech. This prediction is based on the
   noisy and processed signal as well as a clean speech reference signal.
   The method is obtained by extending a modified version of the short-time
   objective intelligibility (STOI) measure with a modified
   equalization-cancellation (EC) stage. We evaluate the performance of the
   method by comparing the predictions with measured intelligibility from
   four listening experiments. These comparisons indicate that the proposed
   measure can provide accurate predictions of 1) the intelligibility of
   diotic speech with an accuracy similar to that of the original STOI
   measure, 2) speech reception thresholds (SRTs) in conditions with a
   frontal target speaker and a single interferer in the horizontal plane,
   3) SRTs in conditions with a frontal target and a single interferer when
   ideal time frequency segregation (ITFS) is applied to the left and right
   ears separately, and 4) the advantage of two-microphone beamforming as
   applied in state-of-the-art hearing aids. A MATLAB implementation of the
   proposed measure is available online.(1)}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Andersen, AH (Corresponding Author), Oticon AS, DK-2765 Smorum, Denmark.
   Andersen, AH (Corresponding Author), Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.
   Andersen, Asger Heidemann; de Haan, Jan Mark; Jensen, Jesper, Oticon AS, DK-2765 Smorum, Denmark.
   Andersen, Asger Heidemann; Tan, Zheng-Hua; Jensen, Jesper, Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.}},
DOI = {{10.1109/TASLP.2016.2588002}},
ISSN = {{2329-9290}},
Keywords = {{Binaural speech intelligibility prediction; binaural advantage; speech
   enhancement; speech transmission}},
Keywords-Plus = {{RECEPTION THRESHOLD; TRANSMISSION INDEX; OBJECTIVE MEASURES;
   NORMAL-HEARING; REVERBERATION; EQUALIZATION; COMPRESSION; MODEL; TIME}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{aand@oticon.com
   janh@oticon.com
   zt@es.aau.dk
   jesj@oticon.com}},
Cited-References = {{Algazi VR, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P99, DOI 10.1109/ASPAA.2001.969552.
   Allen JB, 2005, AUDITORY SIGNAL PROCESSINGP: PHYSIOLOGY, PSYCHOACOUSTICS, AND MODELS, P314.
   Andersen AH, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2563.
   Andersen AH, 2016, INT CONF ACOUST SPEE, P4995, DOI 10.1109/ICASSP.2016.7472628.
   {[}Anonymous], 2011, 60268162011 IEC.
   {[}Anonymous], 1997, S351997 ANSI.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575.
   Boldt J. B., 2009, P 17 EUR SIGN PROC C.
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152.
   Bronkhorst AW, 2000, ACUSTICA, V86, P117.
   Culling JF, 2005, J ACOUST SOC AM, V118, P552, DOI 10.1121/1.1925967.
   Culling JF, 2004, J ACOUST SOC AM, V116, P1057, DOI 10.1121/1.1772396.
   Dubbelboer F, 2007, J ACOUST SOC AM, V122, P2865, DOI 10.1121/1.2783131.
   Durlach N. I., 1972, F MODERN AUDITORY TH, P371.
   DURLACH NI, 1963, J ACOUST SOC AM, V35, P1206, DOI 10.1121/1.1918675.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   Fletcher H, 1929, BELL SYST TECH J, V8, P806, DOI 10.1002/j.1538-7305.1929.tb01246.x.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   HOHMANN V, 1995, J ACOUST SOC AM, V97, P1191, DOI 10.1121/1.413092.
   Holube I, 2010, INT J AUDIOL, V49, P891, DOI 10.3109/14992027.2010.506889.
   HOUTGAST T, 1971, ACUSTICA, V25, P355.
   Jelfs S, 2011, HEARING RES, V275, P96, DOI 10.1016/j.heares.2010.12.005.
   Jensen J, 2014, IEEE-ACM T AUDIO SPE, V22, P430, DOI 10.1109/TASLP.2013.2295914.
   Jorgensen S, 2015, ACTA ACUST UNITED AC, V101, P1016, DOI 10.3813/AAA.918896.
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502.
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.1093/biomet/30.1-2.81.
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673.
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1689, DOI 10.1121/1.1909094.
   Lavandier M, 2012, J ACOUST SOC AM, V131, P218, DOI 10.1121/1.3662075.
   Lavandier M, 2010, J ACOUST SOC AM, V127, P387, DOI 10.1121/1.3268612.
   Leclere T, 2015, J ACOUST SOC AM, V137, P3335, DOI 10.1121/1.4921028.
   Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617.
   LUDVIGSEN C, 1993, SCAND AUDIOL, V22, P50.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Noordhoek IM, 1997, J ACOUST SOC AM, V101, P498, DOI 10.1121/1.417993.
   Pedersen E. R., 2012, JOINT BALT NORD AC M.
   Pedersen ER, 2014, INT J AUDIOL, V53, P336, DOI 10.3109/14992027.2013.860486.
   Rennies J, 2014, J ACOUST SOC AM, V135, P1556, DOI 10.1121/1.4863197.
   Rennies J, 2011, J ACOUST SOC AM, V130, P2999, DOI 10.1121/1.3641368.
   Rhebergen KS, 2006, J ACOUST SOC AM, V120, P3988, DOI 10.1121/1.2358008.
   Rhebergen KS, 2009, J ACOUST SOC AM, V126, P3236, DOI 10.1121/1.3257225.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   Smeds K, 2014, J ACOUST SOC AM, V136, P1363, DOI 10.1121/1.4892766.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal CH, 2012, EUR SIGNAL PR CONF, P504.
   Taal CH, 2011, J ACOUST SOC AM, V130, P3013, DOI 10.1121/1.3641373.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   van Wijngaarden S, 2012, ACOUST AUST, V40, P134.
   van Wijngaarden SJ, 2008, J ACOUST SOC AM, V123, P4514, DOI 10.1121/1.2905245.
   Vestergaard M., 1998, ERIKSHOLM CD 01 SPEE.
   vomHovel H., 1984, THESIS.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.
   Wan R, 2010, J ACOUST SOC AM, V128, P3678, DOI 10.1121/1.3502458.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{DV1JS}},
Unique-ID = {{ISI:000382677800003}},
DA = {{2020-12-06}},
}

@article{ ISI:000389315300012,
Author = {Lyu, Bingjiang and Ge, Jianqiao and Niu, Zhendong and Tan, Li Hai and
   Gao, Jia-Hong},
Title = {{Predictive Brain Mechanisms in Sound-to-Meaning Mapping during Speech
   Processing}},
Journal = {{JOURNAL OF NEUROSCIENCE}},
Year = {{2016}},
Volume = {{36}},
Number = {{42}},
Pages = {{10813-10822}},
Month = {{OCT 19}},
Abstract = {{Spoken language comprehension relies not only on the identification of
   individual words, but also on the expectations arising from contextual
   information. A distributed frontotemporal network is known to facilitate
   the mapping of speech sounds onto their corresponding meanings. However,
   how prior expectations influence this efficient mapping at the
   neuroanatomical level, especially in terms of individual words, remains
   unclear. Using fMRI, we addressed this question in the framework of the
   dual-stream model by scanning native speakers of Mandarin Chinese, a
   language highly dependent on context. We found that, within the ventral
   pathway, the violated expectations elicited stronger activations in the
   left anterior superior temporal gyrus and the ventral inferior frontal
   gyrus (IFG) for the phonological-semantic prediction of spoken words.
   Functional connectivity analysis showed that expectations were mediated
   by both top-down modulation from the left ventral IFG to the anterior
   temporal regions and enhanced cross-stream integration through
   strengthened connections between different subregions of the left IFG.
   By further investigating the dynamic causality within the dual-stream
   model, we elucidated how the human brain accomplishes sound-to-meaning
   mapping for words in a predictive manner.}},
Publisher = {{SOC NEUROSCIENCE}},
Address = {{11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ge, JQ; Gao, JH (Corresponding Author), Peking Univ, Ctr MRI Res, Integrated Sci Res Bldg,5 Yiheyuan Rd, Beijing 100871, Peoples R China.
   Lyu, Bingjiang; Ge, Jianqiao; Gao, Jia-Hong, Peking Univ, Sch Phys, Beijing City Key Lab Med Phys \& Engn, Beijing 100871, Peoples R China.
   Lyu, Bingjiang; Ge, Jianqiao; Gao, Jia-Hong, Peking Univ, Acad Adv Interdisciplinary Studies, Ctr MRI Res, Beijing 100871, Peoples R China.
   Lyu, Bingjiang; Ge, Jianqiao; Gao, Jia-Hong, Peking Univ, McGovern Inst Brain Res, Beijing 100871, Peoples R China.
   Niu, Zhendong, Beijing Inst Technol, Sch Comp Sci \& Technol, Beijing 100081, Peoples R China.
   Tan, Li Hai; Gao, Jia-Hong, Shenzhen Inst Neurosci, Ctr Language \& Brain, Shenzhen 518057, Peoples R China.}},
DOI = {{10.1523/JNEUROSCI.0583-16.2016}},
ISSN = {{0270-6474}},
Keywords = {{Chinese; context; expectation; fMRI; speech; top-down}},
Keywords-Plus = {{INTELLIGIBLE SPEECH; LANGUAGE COMPREHENSION; AUDITORY-CORTEX;
   HIERARCHICAL ORGANIZATION; WORD RECOGNITION; TEMPORAL CORTEX;
   VISUAL-CORTEX; FMRI; MULTIVARIATE; NETWORK}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{gejq@pku.edu.cn
   jgao@pku.edu.cn}},
ResearcherID-Numbers = {{Lyu, Bingjiang/AAE-4293-2019
   }},
ORCID-Numbers = {{Lyu, Bingjiang/0000-0001-8554-5138}},
Funding-Acknowledgement = {{China's National Strategic Basic Research Program (973)
   {[}2012CB720700]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}31200761, 31421003,
   81227003, 81430037]; Beijing Municipal Science \& Technology
   CommissionBeijing Municipal Science \& Technology Commission
   {[}Z161100000216152]; Shenzhen Peacock Plan {[}KQTD2015033016104926]}},
Funding-Text = {{This work was supported by China's National Strategic Basic Research
   Program (973; Grant 2012CB720700), the National Natural Science
   Foundation of China (Grants 31200761, 31421003, 81227003, and 81430037),
   Beijing Municipal Science \& Technology Commission (Grant
   Z161100000216152), and Shenzhen Peacock Plan (Grant
   KQTD2015033016104926).}},
Cited-References = {{Abrams DA, 2013, CEREB CORTEX, V23, P1703, DOI 10.1093/cercor/bhs165.
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333.
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Crinion JT, 2003, BRAIN, V126, P1193, DOI 10.1093/brain/awg104.
   Dapretto M, 1999, NEURON, V24, P427, DOI 10.1016/S0896-6273(00)80855-7.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109.
   Durschmid S, 2016, P NATL ACAD SCI USA, V113, P6755, DOI 10.1073/pnas.1525030113.
   Evans S, 2014, CEREB CORTEX, V24, P2350, DOI 10.1093/cercor/bht083.
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011.
   Friederici AD, 2010, HUM BRAIN MAPP, V31, P448, DOI 10.1002/hbm.20878.
   Friston KJ, 2011, NEUROIMAGE, V56, P2089, DOI 10.1016/j.neuroimage.2011.03.062.
   Friston KJ, 2011, NEUROIMAGE, V56, P1202, DOI 10.1016/j.neuroimage.2010.12.039.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 1997, NEUROIMAGE, V6, P218, DOI 10.1006/nimg.1997.0291.
   Friston KJ, 2003, NEUROIMAGE, V19, P1273, DOI 10.1016/S1053-8119(03)00202-7.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Heim S, 2009, HUM BRAIN MAPP, V30, P392, DOI 10.1002/hbm.20512.
   Herrmann B, 2011, NEUROIMAGE, V57, P624, DOI 10.1016/j.neuroimage.2011.04.034.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Kasess CH, 2010, NEUROIMAGE, V49, P3065, DOI 10.1016/j.neuroimage.2009.11.037.
   Koechlin E, 2006, NEURON, V50, P963, DOI 10.1016/j.neuron.2006.05.017.
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103.
   Lau EF, 2016, CEREB CORTEX, V26, P1377, DOI 10.1093/cercor/bhu219.
   Lau EF, 2013, J NEUROSCI, V 33, P17174, DOI 10.1523/JNEUROSCI.1018-13.2013.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Leff AP, 2008, J NEUROSCI, V28, P13209, DOI 10.1523/JNEUROSCI.2903-08.2008.
   MacGregor LJ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1715.
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X.
   McGettigan C, 2012, J COGNITIVE NEUROSCI, V24, P636, DOI 10.1162/jocn\_a\_00161.
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128.
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318.
   Pereira F, 2011, NEUROIMAGE, V56, P476, DOI 10.1016/j.neuroimage.2010.05.026.
   Pernet CR, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00001.
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005.
   Poldrack RA, 1999, NEUROIMAGE, V10, P15, DOI 10.1006/nimg.1999.0441.
   Poldrack RA, 2015, NATURE, V526, P371, DOI 10.1038/nature15692.
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062.
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331.
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009.
   Rosa MJ, 2012, J NEUROSCI METH, V208, P66, DOI 10.1016/j.jneumeth.2012.04.013.
   Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175.
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400.
   Scott SK, 2006, J ACOUST SOC AM, V120, P1075, DOI 10.1121/1.2216725.
   Seghier ML, 2013, NEUROIMAGE, V68, P181, DOI 10.1016/j.neuroimage.2012.12.005.
   Serences JT, 2007, J NEUROSCI, V27, P12893, DOI 10.1523/JNEUROSCI.4021-07.2007.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Stelzer J, 2013, NEUROIMAGE, V65, P69, DOI 10.1016/j.neuroimage.2012.09.063.
   Stephan KE, 2007, NEUROIMAGE, V38, P387, DOI 10.1016/j.neuroimage.2007.07.040.
   Thierry G, 2003, NEURON, V38, P499, DOI 10.1016/S0896-6273(03)00199-5.
   Tuennerhoff J, 2016, NEUROIMAGE, V124, P641, DOI 10.1016/j.neuroimage.2015.09.004.
   Udden J, 2012, PHILOS T R SOC B, V367, P2023, DOI 10.1098/rstb.2012.0009.
   Weber K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148637.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{J. Neurosci.}},
Doc-Delivery-Number = {{EE1BK}},
Unique-ID = {{ISI:000389315300012}},
OA = {{Green Published, Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000386105100002,
Author = {Argyropoulos, Georgios P. D.},
Title = {{The cerebellum, internal models and prediction in `non-motor' aspects of
   language: A critical review}},
Journal = {{BRAIN AND LANGUAGE}},
Year = {{2016}},
Volume = {{161}},
Number = {{SI}},
Pages = {{4-17}},
Month = {{OCT}},
Abstract = {{The emergence of studies on cerebellar contributions in `non-motor'
   aspects of predictive language processing has long been awaited by
   researchers investigating the neural foundations of language and
   cognition. Despite (i) progress in research implicating the cerebellum
   in language processing, (ii) the widely-accepted nature of the uniform,
   multi-modal computation that the cerebellum implements in the form of
   internal models, as well as (iii) the long tradition of psycholinguistic
   studies addressing prediction mechanisms, research directly addressing
   cerebellar contributions to `non-motor' predictive language processing
   has only surfaced in the last five years. This paper provides the first
   review of this novel field, along with a critical assessment of the
   studies conducted so far. While encouraging, the evidence for cerebellar
   involvement in `non-motor' aspects of predictive language processing
   remains inconclusive under further scrutiny. Future directions are
   finally discussed with respect to outstanding questions in this novel
   field of research. (C) 2015 Elsevier Inc. All rights reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Argyropoulos, GPD (Corresponding Author), UCL Inst Child Hlth, Dev Neurosci Programme, 30 Guilford St, London WC1N 1EH, England.
   Argyropoulos, Georgios P. D., UCL Inst Child Hlth, Dev Neurosci Programme, 30 Guilford St, London WC1N 1EH, England.}},
DOI = {{10.1016/j.bandl.2015.08.003}},
ISSN = {{0093-934X}},
EISSN = {{1090-2155}},
Keywords = {{Language; Prediction; Cerebellum; Internal models; Associative learning;
   Priming; Default-mode network}},
Keywords-Plus = {{TRANSCRANIAL MAGNETIC STIMULATION; THETA-BURST STIMULATION; CONSCIOUS
   RESTING STATE; DEFAULT-MODE; MOTOR CONTROL; BRAIN-FUNCTION; PREFRONTAL
   CORTEX; AUDITORY-FEEDBACK; SPEECH-PERCEPTION; LEXICAL DECISION}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences \&
   Neurology; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental}},
Author-Email = {{g.argyropoulos@ucl.ac.uk}},
ResearcherID-Numbers = {{Argyropoulos, Georgios P.D./AAE-5822-2019
   Argyropoulos, Georgios P. D./R-1339-2016}},
ORCID-Numbers = {{Argyropoulos, Georgios P.D./0000-0001-8267-6861
   Argyropoulos, Georgios P. D./0000-0001-8267-6861}},
Cited-References = {{Ackermann H, 1998, NEUROSCI LETT, V247, P187, DOI 10.1016/S0304-3940(98)00328-0.
   Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742.
   Ackermann Hermann, 2004, Behav Cogn Neurosci Rev, V3, P14, DOI 10.1177/1534582304263251.
   ALBUS J S, 1971, Mathematical Biosciences, V10, P25, DOI 10.1016/0025-5564(71)90051-4.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arasanz CP, 2012, CORTEX, V48, P718, DOI 10.1016/j.cortex.2011.02.021.
   Argyropoulos G. P., 2008, EVOLUTION LANGUAGE, P10, DOI {[}DOI 10.1142/9789812776129\_, 10.1142/9789812776129\_0002].
   Argyropoulos G. P., 2011, THESIS.
   Argyropoulos GP, 2013, CEREBELLUM, V12, P83, DOI 10.1007/s12311-012-0398-y.
   Argyropoulos GP, 2011, BEHAV NEUROSCI, V125, P724, DOI 10.1037/a0025134.
   Argyropoulos GP, 2011, CEREBELLUM, V10, P540, DOI 10.1007/s12311-011-0269-y.
   Argyropoulos GP, 2009, BRAIN TALK DISCOURSE, P193.
   Balsters JH, 2008, NEUROIMAGE, V43, P388, DOI 10.1016/j.neuroimage.2008.07.010.
   Balsters JH, 2010, NEUROIMAGE, V49, P2045, DOI 10.1016/j.neuroimage.2009.10.045.
   Balsters JH, 2013, CEREB CORTEX, V23, P1433, DOI 10.1093/cercor/bhs127.
   Balsters JH, 2011, J NEUROSCI, V31, P2305, DOI 10.1523/JNEUROSCI.4358-10.2011.
   Bellebaum C, 2011, CORTEX, V47, P128, DOI 10.1016/j.cortex.2009.07.016.
   Bernard JA, 2012, FRONT NEUROANAT, V6, DOI 10.3389/fnana.2012.00031.
   Binder JR, 1999, J COGNITIVE NEUROSCI, V11, P80, DOI 10.1162/089892999563265.
   Blakemore SJ, 2001, NAT REV NEUROSCI, V2, P561, DOI 10.1038/35086023.
   Blakemore SJ, 2001, NEUROREPORT, V12, P3741, DOI 10.1097/00001756-200112040-00027.
   BLOEDEL JR, 1992, BEHAV BRAIN SCI, V15, P666.
   BLUMSTEIN SE, 1982, BRAIN LANG, V17, P301, DOI 10.1016/0093-934X(82)90023-2.
   BROWN C, 1993, J COGNITIVE NEUROSCI, V5, P34, DOI 10.1162/jocn.1993.5.1.34.
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5.
   Buccino G, 2005, COGNITIVE BRAIN RES, V24, P355, DOI 10.1016/j.cogbrainres.2005.02.020.
   Buckner RL, 2011, J NEUROPHYSIOL, V106, P2322, DOI 10.1152/jn.00339.2011.
   Callan DE, 2007, CEREBELLUM, V6, P321, DOI 10.1080/14734220601187733.
   Cappa SF, 2002, NEUROLOGY, V59, P720, DOI 10.1212/WNL.59.5.720.
   Chomsky N., 1981, LECT GOVT BINDING.
   Christian KM, 2005, BEHAV NEUROSCI, V119, P526, DOI 10.1037/0735-7044.119.2.526.
   Coffman KA, 2011, P NATL ACAD SCI USA, V108, P16068, DOI 10.1073/pnas.1107904108.
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805.
   Courchesne E, 1997, LEARN MEMORY, V4, P1, DOI 10.1101/lm.4.1.1.
   DAUM I, 1993, BEHAV NEUROSCI, V107, P411, DOI 10.1037/0735-7044.107.3.411.
   De Smet HJ, 2013, BRAIN LANG, V127, P334, DOI 10.1016/j.bandl.2012.11.001.
   Desmond JE, 1998, TRENDS COGN SCI, V2, P355, DOI 10.1016/S1364-6613(98)01211-X.
   Desmond JE, 1998, NEUROIMAGE, V7, P368, DOI 10.1006/nimg.1998.0340.
   Desmurget M, 2001, J NEUROSCI, V21, P2919, DOI 10.1523/JNEUROSCI.21-08-02919.2001.
   Devlin JT, 2007, BRAIN, V130, P610, DOI 10.1093/brain/awl331.
   Ding H, 2012, NEUROSCI LETT, V508, P47, DOI 10.1016/j.neulet.2011.12.016.
   Dow RS, 1958, PHYSL PATHOLOGY CERE.
   Drepper J, 1999, BRAIN, V122, P87, DOI 10.1093/brain/122.1.87.
   Esposito F, 2006, BRAIN RES BULL, V70, P263, DOI 10.1016/j.brainresbull.2006.06.012.
   Ferreira F, 2003, COGNITIVE PSYCHOL, V47, P164, DOI 10.1016/S0010-0285(03)00005-7.
   Ferrucci R, 2008, J COGNITIVE NEUROSCI, V20, P1687, DOI 10.1162/jocn.2008.20112.
   FIEZ JA, 1992, BRAIN, V115, P155, DOI 10.1093/brain/115.1.155.
   Fiez JA, 1997, INT REV NEUROBIOL, V41, P233, DOI 10.1016/S0074-7742(08)60354-2.
   Fransson P, 2005, HUM BRAIN MAPP, V26, P15, DOI 10.1002/hbm.20113.
   Fransson P, 2006, NEUROPSYCHOLOGIA, V44, P2836, DOI 10.1016/j.neuropsychologia.2006.06.017.
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001.
   Frings M, 2006, NEUROSCI LETT, V409, P19, DOI 10.1016/j.neulet.2006.08.058.
   Gebhart AL, 2002, ANN NY ACAD SCI, V978, P318, DOI 10.1111/j.1749-6632.2002.tb07577.x.
   Ghosh SS, 2008, J SPEECH LANG HEAR R, V51, P1183, DOI 10.1044/1092-4388(2008/07-0119).
   GILBERT PFC, 1977, BRAIN RES, V128, P309, DOI 10.1016/0006-8993(77)90997-0.
   Glaser YG, 2013, BRAIN LANG, V126, P314, DOI 10.1016/j.bandl.2013.06.006.
   Golfinopoulos E, 2010, NEUROIMAGE, V52, P862, DOI 10.1016/j.neuroimage.2009.10.023.
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065.
   Grimaldi G, 2014, CEREBELLUM, V13, P121, DOI 10.1007/s12311-013-0514-7.
   Grimaldi G., 2014, NEUROSCIENTIST.
   Grush R, 2004, BEHAV BRAIN SCI, V27, P377, DOI 10.1017/S0140525X04000093.
   Guediche S, 2015, CEREB CORTEX, V25, P1867, DOI 10.1093/cercor/bht428.
   Gusnard DA, 2001, P NATL ACAD SCI USA, V98, P4259, DOI 10.1073/pnas.071043098.
   Gusnard DA, 2001, NAT REV NEUROSCI, V2, P685, DOI 10.1038/35094500.
   Habas C, 2009, J NEUROSCI, V29, P8586, DOI 10.1523/JNEUROSCI.1868-09.2009.
   Hagoort P., 2009, COGNITIVE NEUROSCIEN, P819.
   Halko MA, 2014, J NEUROSCI, V34, P12049, DOI 10.1523/JNEUROSCI.1776-14.2014.
   Hanakawa T, 2008, CEREB CORTEX, V18, P2775, DOI 10.1093/cercor/bhn036.
   Hardwick RM, 2014, BRAIN STIMUL, V7, P643, DOI 10.1016/j.brs.2014.04.009.
   Harrison BJ, 2008, P NATL ACAD SCI USA, V105, P9781, DOI 10.1073/pnas.0711791105.
   HASHIMOTO M, 1995, BRAIN, V118, P1185, DOI 10.1093/brain/118.5.1185.
   Hauk O, 2004, NEURON, V41, P301, DOI 10.1016/S0896-6273(03)00838-9.
   Heinks-Maldonado TH, 2006, NEUROREPORT, V17, P1375, DOI 10.1097/01.wnr.0000233102.43526.e9.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Hosemann J, 2013, NEUROPSYCHOLOGIA, V51, P2224, DOI 10.1016/j.neuropsychologia.2013.07.013.
   Hurley S, 2008, BEHAV BRAIN SCI, V31, P1, DOI 10.1017/S0140525X07003123.
   Hutchison KA, 2003, PSYCHON B REV, V10, P785, DOI 10.3758/BF03196544.
   Iacoboni M, 2008, J PHYSIOL-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003.
   Imamizu H, 2000, NATURE, V403, P192, DOI 10.1038/35003194.
   Ito M, 2000, IMAGE, LANGUAGE, BRAIN, P149.
   ITO M, 1970, INT J NEUROL, V7, P162.
   Ito M, 1984, CEREBELLUM NEURAL CO.
   Ito M, 2008, NAT REV NEUROSCI, V9, P304, DOI 10.1038/nrn2332.
   Jones LL, 2012, CUR ISS PSYCHOL LANG, P44.
   Jordan MI, 2000, NEW COGNITIVE NEUROS, P601.
   Jueptner M, 1997, J NEUROPHYSIOL, V77, P1325.
   Kaan E, 2002, TRENDS COGN SCI, V6, P350, DOI 10.1016/S1364-6613(02)01947-2.
   Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8.
   Kelly RM, 2003, J NEUROSCI, V23, P8432.
   Keren-Happuch E, 2014, HUM BRAIN MAPP, V35, P593, DOI 10.1002/hbm.22194.
   Kineses ZT, 2008, NEUROIMAGE, V39, P1950, DOI 10.1016/j.neuroimage.2007.09.070.
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005.
   Krienen FM, 2009, CEREB CORTEX, V19, P2485, DOI 10.1093/cercor/bhp135.
   Lang CE, 2002, J NEUROPHYSIOL, V87, P1336, DOI 10.1152/jn.00368.2001.
   Leggio MG, 2008, BRAIN, V131, P1332, DOI 10.1093/brain/awn040.
   Leggio MG, 2000, J NEUROL NEUROSUR PS, V69, P102, DOI 10.1136/jnnp.69.1.102.
   Leiner HC, 2010, NEUROPSYCHOL REV, V20, P229, DOI 10.1007/s11065-010-9140-z.
   Lesage E., 2013, THESIS.
   Lesage E., 2014, SOC NEUR ABSTR.
   Lesage E, 2012, CURR BIOL, V22, pR794, DOI 10.1016/j.cub.2012.07.006.
   LIEBERMAN P, 1963, LANG SPEECH, V6, P172, DOI 10.1177/002383096300600306.
   Liuzzi G, 2010, CURR BIOL, V20, P1745, DOI 10.1016/j.cub.2010.08.034.
   Maddox WT, 2005, J COGNITIVE NEUROSCI, V17, P707, DOI 10.1162/0898929053747630.
   Manto M, 2012, CEREBELLUM, V11, P457, DOI 10.1007/s12311-011-0331-9.
   Marien P, 2001, BRAIN LANG, V79, P580, DOI 10.1006/brln.2001.2569.
   Marien P, 2014, CEREBELLUM, V13, P386, DOI 10.1007/s12311-013-0540-5.
   MARR D, 1969, J PHYSIOL-LONDON, V202, P437, DOI 10.1113/jphysiol.1969.sp008820.
   Mazoyer B, 2001, BRAIN RES BULL, V54, P287, DOI 10.1016/S0361-9230(00)00437-8.
   MCCORMICK DA, 1984, SCIENCE, V223, P296, DOI 10.1126/science.6701513.
   McKiernan KA, 2003, J COGNITIVE NEUROSCI, V15, P394, DOI 10.1162/089892903321593117.
   McRae K, 2005, MEM COGNITION, V33, P1174, DOI 10.3758/BF03193221.
   Medina JF, 2009, J NEUROPHYSIOL, V102, P2039, DOI 10.1152/jn.00075.2009.
   Miall RC, 2007, PLOS BIOL, V5, P2733, DOI 10.1371/journal.pbio.0050316.
   Miall RC, 2008, CEREBELLUM, V7, P572, DOI 10.1007/s12311-008-0072-6.
   Miall RC, 2004, NEUROSCI LETT, V371, P185, DOI 10.1016/j.neulet.2004.08.067.
   Miall RC, 2003, NEUROREPORT, V14, P2135, DOI 10.1097/00001756-200312020-00001.
   Middleton FA, 2000, BRAIN RES REV, V31, P236, DOI 10.1016/S0165-0173(99)00040-5.
   MILBERG W, 1981, BRAIN LANG, V14, P371, DOI 10.1016/0093-934X(81)90086-9.
   Mitsuo K, 2003, PROG BRAIN RES, V142, P171.
   Moberget T, 2014, J NEUROSCI, V34, P2871, DOI 10.1523/JNEUROSCI.2264-13.2014.
   MULLER F, 1994, EXP BRAIN RES, V101, P485.
   Nestor PG, 2006, SCHIZOPHR RES, V82, P139, DOI 10.1016/j.schres.2005.10.010.
   Nowak DA, 2007, NEUROPSYCHOLOGIA, V45, P696, DOI 10.1016/j.neuropsychologia.2006.08.011.
   Oliveri M, 2005, NEUROSCI LETT, V376, P188, DOI 10.1016/j.neulet.2004.11.053.
   Oliveri M, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007933.
   Perkell J, 1997, SPEECH COMMUN, V22, P227, DOI 10.1016/S0167-6393(97)00026-5.
   Persson J, 2007, J COGNITIVE NEUROSCI, V19, P1021, DOI 10.1162/jocn.2007.19.6.1021.
   Petersen S E, 1989, J Cogn Neurosci, V1, P153, DOI 10.1162/jocn.1989.1.2.153.
   Picard H, 2008, SCHIZOPHRENIA BULL, V34, P155, DOI 10.1093/schbul/sbm049.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169.
   Polli FE, 2005, P NATL ACAD SCI USA, V102, P15700, DOI 10.1073/pnas.0503657102.
   Pope PA, 2012, BRAIN STIMUL, V5, P84, DOI 10.1016/j.brs.2012.03.006.
   Pulvermuller F, 2005, EUR J NEUROSCI, V21, P793, DOI 10.1111/j.1460-9568.2005.03900.x.
   Puttemans V, 2005, J NEUROSCI, V25, P4270, DOI 10.1523/JNEUROSCI.3866-04.2005.
   Raboyeau G, 2004, NEUROIMAGE, V22, P1808, DOI 10.1016/j.neuroimage.2004.05.011.
   Raichle ME, 2005, J COMP NEUROL, V493, P167, DOI 10.1002/cne.20752.
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676.
   Ramnani N, 2006, CEREB CORTEX, V16, P811, DOI 10.1093/cercor/bhj024.
   Ramnani N, 2006, NAT REV NEUROSCI, V7, P511, DOI 10.1038/nrn1953.
   Rao NK, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00840.
   Riva D, 2000, BRAIN, V123, P1051, DOI 10.1093/brain/123.5.1051.
   Rogers SL, 2008, NEUROPSYCHOLOGIA, V46, P12, DOI 10.1016/j.neuropsychologia.2007.08.010.
   Roxbury T, 2014, BEHAV BRAIN FUNCT, V10, DOI 10.1186/1744-9081-10-34.
   Schmahmann JD, 1997, INT REV NEUROBIOL, V41, P31, DOI 10.1016/S0074-7742(08)60346-3.
   Schmahmann JD, 2000, J NEUROLINGUIST, V13, P189, DOI 10.1016/S0911-6044(00)00011-7.
   Shapiro KA, 2001, J COGNITIVE NEUROSCI, V13, P713, DOI 10.1162/08989290152541386.
   Shulman GL, 1997, J COGNITIVE NEUROSCI, V9, P648, DOI 10.1162/jocn.1997.9.5.648.
   Singh KD, 2008, NEUROIMAGE, V41, P100, DOI 10.1016/j.neuroimage.2008.01.051.
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425.
   Stoodley CJ, 2009, NEUROIMAGE, V44, P489, DOI 10.1016/j.neuroimage.2008.08.039.
   Strick PL, 2009, ANNU REV NEUROSCI, V32, P413, DOI 10.1146/annurev.neuro.31.060407.125606.
   Sturt P, 2005, COGNITIVE SCI, V29, P291, DOI 10.1207/s15516709cog0000\_8.
   Thach WT, 1997, INT REV NEUROBIOL, V41, P599, DOI 10.1016/S0074-7742(08)60372-4.
   Thompson RF, 1997, INT REV NEUROBIOL, V41, P151, DOI 10.1016/S0074-7742(08)60351-7.
   Thompson-Schill SL, 1998, J MEM LANG, V38, P440, DOI 10.1006/jmla.1997.2559.
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166.
   Timmann D, 1996, NEUROREPORT, V7, P2056, DOI 10.1097/00001756-199608120-00041.
   Timmann D, 2004, CEREBELLUM, V3, P75, DOI 10.1080/14734220310024890.
   Timmann D, 2010, CORTEX, V46, P845, DOI 10.1016/j.cortex.2009.06.009.
   Timmann D, 2002, NEUROPSYCHOLOGIA, V40, P788, DOI 10.1016/S0028-3932(01)00181-6.
   Toni I, 1998, NEUROIMAGE, V8, P50, DOI 10.1006/nimg.1998.0349.
   Tourville JA, 2008, NEUROIMAGE, V39, P1429, DOI 10.1016/j.neuroimage.2007.09.054.
   Townsend D. J., 2001, SENTENCE COMPREHENSI.
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616.
   Wilson M, 2005, PSYCHOL BULL, V131, P460, DOI 10.1037/0033-2909.131.3.460.
   Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5.
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2.}},
Number-of-Cited-References = {{170}},
Times-Cited = {{23}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{25}},
Journal-ISO = {{Brain Lang.}},
Doc-Delivery-Number = {{DZ8FA}},
Unique-ID = {{ISI:000386105100002}},
DA = {{2020-12-06}},
}

@article{ ISI:000379904200001,
Author = {Cavalieri, Daniel C. and Palazuelos-Cagigas, Sira E. and Bastos-Filho,
   Teodiano F. and Sarcinelli-Filho, Mario},
Title = {{Combination of Language Models for Word Prediction: An Exponential
   Approach}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2016}},
Volume = {{24}},
Number = {{9}},
Pages = {{1481-1494}},
Month = {{SEP}},
Abstract = {{This paper proposes an exponential interpolation to merge a
   part-of-speech-based language model and a word-based n-gram language
   model to accomplish word prediction tasks. In order to find a set of
   mathematical equations to properly describe the language modeling, a
   model based on partial differential equations is proposed. With the
   appropriate initial conditions, it was found an interpolation model
   similar to the traditional maximum entropy language model. Improvements
   in keystroke saved and perplexity over the word-based n-gram language
   model and two other traditional interpolation models is obtained,
   considering three different languages. The proposed interpolation model
   also provides additional improvement in hit rate parameter.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cavalieri, DC (Corresponding Author), Inst Fed Espirito Santo, Dept Control \& Automat Engn, BR-29173087 Serra, Brazil.
   Cavalieri, Daniel C., Inst Fed Espirito Santo, Dept Control \& Automat Engn, BR-29173087 Serra, Brazil.
   Palazuelos-Cagigas, Sira E., Univ Alcala De Henares, Dept Elect Engn, Madrid 28801, Spain.
   Bastos-Filho, Teodiano F.; Sarcinelli-Filho, Mario, Univ Fed Espirito Santo, Dept Elect Engn, BR-29075910 Vitoria, Brazil.}},
DOI = {{10.1109/TASLP.2016.2547743}},
ISSN = {{2329-9290}},
EISSN = {{2329-9304}},
Keywords = {{Combination of language models; natural language processing (NLP); word
   prediction (WP)}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{daniel.cavalieri@ifes.edu.br
   sira@depeca.uah.es
   tfbastos@ele.ufes.br
   mario.sarcinelli@ufes.br}},
ResearcherID-Numbers = {{Filho, Teodiano Freire Bastos/P-7535-2014
   Cavalieri, Daniel C./G-1364-2018
   Sarcinelli-Filho, Mario/C-4424-2015}},
ORCID-Numbers = {{Filho, Teodiano Freire Bastos/0000-0002-1185-2773
   Cavalieri, Daniel C./0000-0002-4916-1863
   Sarcinelli-Filho, Mario/0000-0002-7696-8996}},
Funding-Acknowledgement = {{Spanish Ministry of Science and InnovationSpanish Government
   {[}TIN2009-08984, TIN2008-06856-C05-05]; CAM-UAH under FUVA project
   {[}CCG10-UAH/TIC-5988]; CAPES/BrazilCAPES {[}150/07]}},
Funding-Text = {{This work was supported by the Spanish Ministry of Science and
   Innovation under projects VISNU (Ref. TIN2009-08984) and SD-TEAM (Ref.
   TIN2008-06856-C05-05), by CAM-UAH under FUVA project
   (CCG10-UAH/TIC-5988) and by CAPES/Brazil under Grant 150/07. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. B. Ma.}},
Cited-References = {{Al-Mubaid H., 2007, INT ARAB J INF TECHN, V4, P264.
   Aliprandi C, 2007, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION, P148.
   Anson D. K., 2005, P RESNA.
   Arnott JL, 2013, COMPUT SPEECH LANG, V27, P1194, DOI 10.1016/j.csl.2012.10.008.
   Axelsson M. W., 1999, PROJECT USE UPPSALA, P25.
   Bacaer N, 2011, SHORT HISTORY OF MATHEMATICAL POPULATION DYNAMICS, P35, DOI 10.1007/978-0-85729-115-8\_6.
   Bacelar do Nascimento M. F., 2000, 2 INT C LANG RES EV, VII, P1603.
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084.
   Berger AL, 1996, COMPUT LINGUIST, V22, P39.
   Bick E, 2000, THESIS.
   Bick E., 2006, P INT JOINT C IBERAM.
   Botha J. A., 2014, CORR.
   Boyce William E, 2012, ELEMENTARY DIFFERENT.
   Brychcin T, 2014, COMPUT SPEECH LANG, V28, P192, DOI 10.1016/j.csl.2013.05.001.
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227.
   Cavalieri DC, 2011, PROCES LENG NAT, P197.
   Chachoo Manzoor Ahmad, 2012, INT J COMPUTER APPL, V39, P7.
   Chen S., 1998, P INT C AC SPEECH SI.
   Christensen H., 2012, HC CORPORA.
   Chueh Chuang-Hua, 2006, COMPUT LINGUIST, V11, P37.
   Clarkson P., 1998, P 5 INT C SPOK LANG, P233.
   Clarkson P., 1999, P 6 EUR C SPEECH COM.
   Clarkson PR, 1997, INT CONF ACOUST SPEE, P799, DOI 10.1109/ICASSP.1997.596049.
   Della Pietra S., 1994, Grammatical Inference and Applications. Second International Colloquium, ICGI-94 Proceedings, P78.
   Fang H, 2015, IEEE-ACM T AUDIO SPE, V23, P2410, DOI 10.1109/TASLP.2015.2482118.
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010.
   Fazly A., 2002, THESIS.
   Fazly A., 2003, TEXTENTRY 03, P9.
   Foulds R., 1980, P INT C REH ENG, P83.
   Francis W.N., 1979, TECH REP.
   Garay-Vitoria N., 2006, Universal Access in the Information Society, V4, P188, DOI 10.1007/s10209-005-0005-9.
   Garay-Vitoria N, 2010, COMPUT SPEECH LANG, V24, P117, DOI 10.1016/j.csl.2009.03.008.
   Ghayoomi M, 2009, IEEE SYS MAN CYBERN, P5083, DOI 10.1109/ICSMC.2009.5346027.
   Graff D., 2006, SPANISH GIGAWORD.
   Graff D, 2003, ENGLISH GIGAWORD.
   Hacioglu Kadri, 2001, P 1 INT C HUM LANG T, P1.
   Ide Nancy, 2010, P ACL 2010 C SHORT P, P68.
   Jurafsky D., 2008, SPEECH LANGUAGE PROC.
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125.
   Koehn P, 2005, MT SUMMIT, V5, P79, DOI DOI 10.3115/1626355.1626380.
   Linares Diego, 2004, ACM T ASIAN LANGUAGE, V3, P113.
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045.
   Neto N, 2011, J BRAZILIAN COMPUTER, V17, P53, DOI DOI 10.1007/S13173-010-0023-1.
   Palazuelos-Cagigas S. E., 2001, THESIS.
   Palazuelos-Cagigas SE, 2011, ASSIST TECHNOL RES S, V29, P424, DOI 10.3233/978-1-60750-814-4-424.
   Pardo T. A. S., 2003, NILCTR0309.
   Pietra S. D., 1995, CORR, V1.
   Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159.
   Santos D., 2004, 5 WORKSH CROSS LANG, P821.
   Smith N. A., 2012, CORR.
   Trnka K, 2007, P HLT NAACL COMP VOL, P173, DOI 10.3115/1614108.1614152.
   Trnka K., 2011, THESIS.
   U. P. F. I. U. de Lingstica Aplicada (IULA), 2012, CORPUS92 CORP.
   van den Bosch A, 2006, TRAITEMENT AUTOMATIQ, V46, P39.
   Voutilainen A., 1994, CREATING USING ENGLI, V13.
   Vyrynen P., 2005, THESIS.
   Wandmacher T., 2008, CORR.
   WANG S, 2005, P INT C MACH LEARN, P948.
   Wang SQ, 2013, BIORESOURCES, V8, P8.
   Wilson C. G., 2004, THESIS.}},
Number-of-Cited-References = {{60}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{DR4WQ}},
Unique-ID = {{ISI:000379904200001}},
DA = {{2020-12-06}},
}

@article{ ISI:000380718000001,
Author = {Jaeger, T. Florian and Weatherholtz, Kodi},
Title = {{What the Heck Is Salience? How Predictive Language Processing
   Contributes to Sociolinguistic Perception}},
Journal = {{FRONTIERS IN PSYCHOLOGY}},
Year = {{2016}},
Volume = {{7}},
Month = {{AUG 3}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Editorial Material}},
Language = {{English}},
Affiliation = {{Jaeger, TF (Corresponding Author), Univ Rochester, Dept Brain \& Cognit Sci, Human Language Proc Lab, Rochester, NY 14620 USA.
   Jaeger, TF (Corresponding Author), Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
   Jaeger, TF (Corresponding Author), Univ Rochester, Dept Linguist, Rochester, NY USA.
   Jaeger, T. Florian; Weatherholtz, Kodi, Univ Rochester, Dept Brain \& Cognit Sci, Human Language Proc Lab, Rochester, NY 14620 USA.
   Jaeger, T. Florian, Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
   Jaeger, T. Florian, Univ Rochester, Dept Linguist, Rochester, NY USA.}},
DOI = {{10.3389/fpsyg.2016.01115}},
Article-Number = {{1115}},
ISSN = {{1664-1078}},
Keywords = {{accent; dialect; idiolect; salience; surprisal; prediction; expectation;
   learning}},
Keywords-Plus = {{INFORMATION; ADAPTATION; CATEGORIES}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{fjaeger@ur.rochester.edu}},
ResearcherID-Numbers = {{Jaeger, T. Florian/O-8224-2019}},
ORCID-Numbers = {{Jaeger, T. Florian/0000-0002-1158-7308}},
Funding-Acknowledgement = {{NSF CAREER awardNational Science Foundation (NSF)NSF - Office of the
   Director (OD) {[}IIS-1150028]; NICHDUnited States Department of Health
   \& Human ServicesNational Institutes of Health (NIH) - USANIH Eunice
   Kennedy Shriver National Institute of Child Health \& Human Development
   (NICHD) {[}R01HD075797]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF
   CHILD HEALTH \& HUMAN DEVELOPMENTUnited States Department of Health \&
   Human ServicesNational Institutes of Health (NIH) - USANIH Eunice
   Kennedy Shriver National Institute of Child Health \& Human Development
   (NICHD) {[}R01HD075797, R01HD075797, R01HD075797, R01HD075797,
   R01HD075797] Funding Source: NIH RePORTER}},
Funding-Text = {{We thank Alice Blumenthal-Drame, Adriana Hanulikova, and Bernd
   Kortmannfororganizing the workshop that led to this special issue,
   Perceptual linguistic salience: Modeling causes and consequence held in
   Freiburg, October 15th to 17th 2014. The ideas expressed here benefitted
   from stimulating discussions with participants at the workshop and from
   the reviewers' comments, who went beyond the expected. Work on this
   paper was partially supported by NSF CAREER award IIS-1150028 and NICHD
   grant R01HD075797 to TFJ. The views expressed here are not necessarily
   those of the funding agencies.}},
Cited-References = {{Agha A, 2003, LANG COMMUN, V23, P231, DOI 10.1016/S0271-5309(03)00012-0.
   Arai M, 2014, Q J EXP PSYCHOL, V67, P60, DOI 10.1080/17470218.2013.790454.
   Auer Peter, 1998, J SOCIOLING, V2, P163, DOI DOI 10.1111/1467-9481.00039.
   Babel Anna M., 2016, AWARENESS CONTROL SO, DOI {[}10.1017/cbo9781139680448., DOI 10.1017/CB09781139680448].
   Bernolet S, 2010, COGNITION, V114, P455, DOI 10.1016/j.cognition.2009.11.005.
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005.
   Campbell-Kibler K, 2012, J ENGL LINGUIST, V40, P281, DOI 10.1177/0075424211427911.
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004.
   COLE RA, 1980, J VERB LEARN VERB BE, V19, P297, DOI 10.1016/S0022-5371(80)90239-X.
   Courville AC, 2006, TRENDS COGN SCI, V10, P294, DOI 10.1016/j.tics.2006.05.004.
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   Drager K., 2016, AWARENESS CONTROL SO, P1, DOI {[}DOI 10.1017/CBO9781139680448.003, 10.1017/CBO9781139680448.003].
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196.
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661.
   Fine AB, 2013, COGNITIVE SCI, V37, P578, DOI 10.1111/cogs.12022.
   Foulkes P., 2015, HDB LANGUAGE EMERGEN, P292, DOI {[}10.1002/9781118346136.ch13, DOI 10.1002/9781118346136.CH13].
   Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006.
   Frank SL, 2011, PSYCHOL SCI, V22, P829, DOI 10.1177/0956797611409589.
   Fraundorf SH, 2016, J MEM LANG, V91, P28, DOI 10.1016/j.jml.2016.05.006.
   Garnsey SM, 1997, J MEM LANG, V37, P58, DOI 10.1006/jmla.1997.2512.
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386.
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159.
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn\_a\_00103.
   Hickey Raymond, 2000, DEV STANDARD ENGLISH, P57, DOI DOI 10.1017/CBO9780511551758.005.
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007.
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013.
   Kaschak MP, 2004, J EXP PSYCHOL GEN, V133, P450, DOI 10.1037/0096-3445.133.3.450.
   Kerswill Paul, 2002, LANGUAGE CHANGE INTE, P81, DOI DOI 10.1515/9783110892598.81.
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695.
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013.
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211.
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299.
   LABOV W., 1972, SOCIOLINGUISTIC PATT.
   Labov William, 1966, SOCIAL STRATIFICATIO.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Linzen T., 2016, COGNITIVE SCI, DOI {[}10.1111/cogs.12274, DOI 10.1111/C0GS.12274.{[}].
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676.
   McDonald SA, 2003, PSYCHOL SCI, V14, P648, DOI 10.1046/j.0956-7976.2003.psci\_1480.x.
   McRae K, 1998, J MEM LANG, V38, P283, DOI 10.1006/jmla.1997.2543.
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005.
   Preston Dennis, 1996, LANG AWARE, V5, P40, DOI DOI 10.1080/09658416.1996.9959890.
   Qian T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00228.
   Racz P., 2013, SALIENCE SOCIOLINGUI.
   Racz P, 2012, ENGL LANG LINGUIST, V16, P57, DOI 10.1017/S1360674311000281.
   Schirmunski V., 1930, GERMANISCH ROMANISCH, V188, P171.
   SCHIRMUNSKI V, 1930, GERMANISCH ROMANISCH, V18, P113.
   Schmid H.-J., 2007, OXFORD HDB COGNITIVE, P117, DOI DOI 10.1093/OXFORDHB/9780199738632.013.0005.
   Schmid HJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01110.
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x.
   Shaw J. A., 2015, P 15 AUSTR INT C SPE, P3.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Squires L., 2014, PENN WORKING PAPERS, V20.
   Squires L., 2016, AWARENESS CONTROL SO, P80, DOI DOI 10.1017/CBO9781139680448.006.
   Squires L, 2014, J ENGL LINGUIST, V42, P144, DOI 10.1177/0075424214526057.
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006.
   Trudgill Peter, 1986, DIALECTS CONTACT.
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007.
   Weatherholtz K., OXF RES ENC IN PRESS.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Front. Psychol.}},
Doc-Delivery-Number = {{DS3YG}},
Unique-ID = {{ISI:000380718000001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000378982900001,
Author = {Bridgeman, Brent and Cho, Yeonsuk and DiPietro, Stephen},
Title = {{Predicting grades from an English language assessment: The importance of
   peeling the onion}},
Journal = {{LANGUAGE TESTING}},
Year = {{2016}},
Volume = {{33}},
Number = {{3}},
Pages = {{307-318}},
Month = {{JUL}},
Abstract = {{Data from 787 international undergraduate students at an urban
   university in the United States were used to demonstrate the importance
   of separating a sample into meaningful subgroups in order to demonstrate
   the ability of an English language assessment to predict the first-year
   grade point average (GPA). For example, when all students were pooled in
   a single analysis, the correlation of scores from the Test of English as
   a Foreign Language (TOEFL) with GPA was .18; in a subsample of
   engineering students from China, the correlation with GPA was .58, or
   .77 when corrected for range restriction. Similarly, the corrected
   correlation of the TOEFL Reading score with GPA for Chinese business
   students changed dramatically (from .01 to .36) when students with an
   extreme discrepancy between their receptive (reading/listening) and
   productive (speaking/writing) scores were trimmed from the sample.}},
Publisher = {{SAGE PUBLICATIONS LTD}},
Address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bridgeman, B (Corresponding Author), Ctr Foundat \& Valid Res, Educ Testing Serv, Rosedale Rd,MS 09-R, Princeton, NJ USA.
   Bridgeman, Brent, Ctr Foundat \& Valid Res, Educ Testing Serv, Rosedale Rd,MS 09-R, Princeton, NJ USA.
   Cho, Yeonsuk, Ctr English Language Learning \& Assessment, Educ Testing Serv, Princeton, NJ USA.
   DiPietro, Stephen, Drexel Univ, Philadelphia, PA USA.}},
DOI = {{10.1177/0265532215583066}},
ISSN = {{0265-5322}},
EISSN = {{1477-0946}},
Keywords = {{China; English language proficiency; grade point average; predictive
   validity; subgroup analysis; sub-scores; TOEFL}},
Keywords-Plus = {{GRADING STANDARDS; ACADEMIC-SUCCESS; VALIDITY; PERFORMANCE; PROFICIENCY}},
Research-Areas = {{Linguistics}},
Web-of-Science-Categories  = {{Linguistics; Language \& Linguistics}},
Author-Email = {{bbridgeman@ets.org}},
Funding-Acknowledgement = {{TOEFL program at Educational Testing Service; Drexel University}},
Funding-Text = {{The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was funded by the TOEFL program at Educational Testing Service
   and in collaboration with Drexel University.}},
Cited-References = {{Al-Ansari S. H., 1999, SYSTEM, V27, P389.
   AYERS JB, 1992, EDUC PSYCHOL MEAS, V52, P973, DOI 10.1177/0013164492052004021.
   Bridgeman B., 2000, 2001 COLL ENTR EX BO.
   Chernyshenko OS, 1999, EDUC PSYCHOL MEAS, V59, P951, DOI 10.1177/00131649921970279.
   Cho Y, 2012, LANG TEST, V29, P421, DOI 10.1177/0265532211430368.
   Davies Alan, 2008, ASSESSING ACAD ENGLI.
   GOLDMAN RD, 1976, EDUC PSYCHOL MEAS, V36, P381, DOI 10.1177/001316447603600217.
   GRAHAM JG, 1987, TESOL QUART, V21, P505, DOI 10.2307/3586500.
   Hassler U, 2003, J ROY STAT SOC D-STA, V52, P367, DOI 10.1111/1467-9884.00365.
   Laosa L., 1991, EARLY CHILDHOOD RES, V6, P313.
   MESSICK S, 1980, AM PSYCHOL, V35, P1012, DOI 10.1037/0003-066X.35.11.1012.
   Neal M. E., 1998, ED424294 ERIC.
   Peters R. M., 1977, EDUC PSYCHOL MEAS, V37, P460.
   Sackett PR, 2000, J APPL PSYCHOL, V85, P112, DOI 10.1037/0021-9010.85.1.112.
   Sawaki Y, 2009, LANG TEST, V26, P5, DOI 10.1177/0265532208097335.
   SHULMAN LS, 1970, REV EDUC RES, V40, P371, DOI 10.2307/1169372.
   STRENTA AC, 1987, J EDUC MEAS, V24, P281, DOI 10.1111/j.1745-3984.1987.tb00280.x.
   VINKE AA, 1993, HIGH EDUC, V26, P275, DOI 10.1007/BF01383487.
   Wiberg M., 2009, PRACTICAL ASSESSMENT, V14, P1.
   YOUNG JW, 1993, REV EDUC RES, V63, P151, DOI 10.3102/00346543063002151.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{20}},
Journal-ISO = {{Lang. Test.}},
Doc-Delivery-Number = {{DQ1TI}},
Unique-ID = {{ISI:000378982900001}},
DA = {{2020-12-06}},
}

@article{ ISI:000377917500012,
Author = {Willems, Roel M. and Frank, Stefan L. and Nijhof, Annabel D. and
   Hagoort, Peter and van den Bosch, Antal},
Title = {{Prediction During Natural Language Comprehension}},
Journal = {{CEREBRAL CORTEX}},
Year = {{2016}},
Volume = {{26}},
Number = {{6}},
Pages = {{2506-2516}},
Month = {{JUN}},
Abstract = {{The notion of prediction is studied in cognitive neuroscience with
   increasing intensity. We investigated the neural basis of 2 distinct
   aspects of word prediction, derived from information theory, during
   story comprehension. We assessed the effect of entropy of next-word
   probability distributions as well as surprisal. A computational model
   determined entropy and surprisal for each word in 3 literary stories.
   Twenty-four healthy participants listened to the same 3 stories while
   their brain activation was measured using fMRI. Reversed speech
   fragments were presented as a control condition. Brain areas sensitive
   to entropy were left ventral premotor cortex, left middle frontal gyrus,
   right inferior frontal gyrus, left inferior parietal lobule, and left
   supplementary motor area. Areas sensitive to surprisal were left
   inferior temporal sulcus ({''}visual word form area{''}), bilateral
   superior temporal gyrus, right amygdala, bilateral anterior temporal
   poles, and right inferior frontal sulcus. We conclude that prediction
   during language comprehension can occur at several levels of processing,
   including at the level of word form. Our study exemplifies the power of
   combining computational linguistics with cognitive neuroscience, and
   additionally underlines the feasibility of studying continuous spoken
   language materials with fMRI.}},
Publisher = {{OXFORD UNIV PRESS INC}},
Address = {{JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Willems, RM (Corresponding Author), Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, POB 9101, NL-6500 HB Nijmegen, Netherlands.
   Willems, Roel M.; Nijhof, Annabel D.; Hagoort, Peter; van den Bosch, Antal, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, POB 9101, NL-6500 HB Nijmegen, Netherlands.
   Frank, Stefan L.; van den Bosch, Antal, Radboud Univ Nijmegen, Ctr Language Studies, NL-6500 HB Nijmegen, Netherlands.
   Willems, Roel M.; Hagoort, Peter, Max Planck Inst Psycholinguist, Nijmegen, Netherlands.}},
DOI = {{10.1093/cercor/bhv075}},
ISSN = {{1047-3211}},
EISSN = {{1460-2199}},
Keywords = {{entropy; fMRI; language; prediction; word surprisal}},
Keywords-Plus = {{TEMPORAL-LOBE; EFFECTIVE CONNECTIVITY; SEMANTIC INTEGRATION; BRAIN;
   WORD; SENTENCE; INFORMATION; ACTIVATION; DISCOURSE; REGIONS}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{roel.willems@donders.ru.nl}},
ResearcherID-Numbers = {{van den Bosch, Antal P.J./G-5072-2011
   van den Bosch, Antal/AAC-2164-2019
   Hagoort, Peter/B-7417-2012
   Frank, Stefan/U-5209-2018
   }},
ORCID-Numbers = {{van den Bosch, Antal P.J./0000-0003-2493-656X
   Willems, Roel/0000-0002-4963-5387
   Frank, Stefan/0000-0002-7026-711X
   Nijhof, Annabel/0000-0002-4153-1284}},
Funding-Acknowledgement = {{European UnionEuropean Union (EU) {[}334028]}},
Funding-Text = {{The research presented here was partly funded by the European Union
   Seventh Framework Programme under grant no. 334028 awarded to S.L.F.}},
Cited-References = {{Ahlheim C, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00273.
   Altmann U, 2014, SOC COGN AFFECT NEUR, V9, P22, DOI 10.1093/scan/nss098.
   Amunts K, 1999, J COMP NEUROL, V412, P319, DOI 10.1002/(SICI)1096-9861(19990920)412:2<319::AID-CNE10>3.0.CO;2-7.
   Awad M, 2007, J NEUROSCI, V27, P11455, DOI 10.1523/JNEUROSCI.5257-06.2007.
   Bar M, 2009, PHILOS T R SOC B, V364, P1181, DOI 10.1098/rstb.2008.0321.
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055.
   Brennan J, 2012, NEUROIMAGE, V60, P1139, DOI 10.1016/j.neuroimage.2012.01.030.
   Brennan J, 2012, BRAIN LANG, V120, P163, DOI 10.1016/j.bandl.2010.04.002.
   Brett M., 2002, NEUROIMAGE, V16, P497, DOI DOI 10.1016/S1053-8119(02)90010-8.
   Brian Roark, 2009, P 2009 C EMP METH NA, P324, DOI DOI 10.3115/1699510.1699553.
   Chow HM, 2014, J COGNITIVE NEUROSCI, V26, P279, DOI 10.1162/jocn\_a\_00487.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Cohen L, 2004, NEUROIMAGE, V23, P1256, DOI 10.1016/j.neuroimage.2004.07.052.
   Cohen L, 2000, BRAIN, V123, P291, DOI 10.1093/brain/123.2.291.
   Crinion JT, 2006, CEREB CORTEX, V16, P1116, DOI 10.1093/cercor/bhj053.
   Crinion JT, 2003, BRAIN, V126, P1193, DOI 10.1093/brain/awg104.
   Dambacher M, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005047.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   den Ouden HEM, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00548.
   Dikker S, 2014, J NEUROSCI, V34, P6267, DOI 10.1523/JNEUROSCI.3796-13.2014.
   Dikker S, 2013, BRAIN LANG, V127, P55, DOI 10.1016/j.bandl.2012.08.004.
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751.
   Eickhoff SB, 2005, NEUROIMAGE, V25, P1325, DOI 10.1016/j.neuroimage.2004.12.034.
   Eickhoff SB, 2006, NEUROIMAGE, V32, P570, DOI 10.1016/j.neuroimage.2006.04.204.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Ferreira F, 2007, LANG LINGUIST COMPAS, V1, P71, DOI 10.1111/j.1749-818x.2007.00007.x.
   Ferstl EC, 2008, HUM BRAIN MAPP, V29, P581, DOI 10.1002/hbm.20422.
   Fiebach CJ, 2006, NEURON, V51, P251, DOI 10.1016/j.neuron.2006.06.007.
   Frank S., 2012, P 34 ANN C COGN SCI, P1554.
   Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006.
   Frank SL, 2013, TOP COGN SCI, V5, P475, DOI 10.1111/tops.12025.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402.
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004.
   Hagoort P, 2009, COGNITIVE NEUROSCIEN.
   Hagoort P, 2014, ANNU REV NEUROSCI, V37, P347, DOI 10.1146/annurev-neuro-071013-013847.
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416.
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159.
   Herbert C, 2009, SOC COGN AFFECT NEUR, V4, P35, DOI 10.1093/scan/nsn027.
   Hsu CT, 2015, CORTEX, V63, P282, DOI 10.1016/j.cortex.2014.09.002.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Jacobs AM, 2015, COGNITIVE NEUROSCIENCE OF NATURAL LANGUAGE USE, P135.
   Jacobson A, 1999, DE STALKER.
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643.
   Koehn Philipp, 2010, STAT MACHINE TRANSLA.
   Kok P, 2012, NEURON, V75, P265, DOI 10.1016/j.neuron.2012.04.034.
   Kurby CA, 2013, BRAIN LANG, V126, P338, DOI 10.1016/j.bandl.2013.07.003.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004.
   Lau EF, 2016, CEREB CORTEX, V26, P1377, DOI 10.1093/cercor/bhu219.
   Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011.
   Levy J, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006675.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Mahowald K, 2013, COGNITION, V126, P313, DOI 10.1016/j.cognition.2012.09.010.
   Mason RA, 2004, PSYCHOL SCI, V15, P1, DOI 10.1111/j.0963-7214.2004.01501001.x.
   MAZOYER BM, 1993, J COGNITIVE NEUROSCI, V5, P467, DOI 10.1162/jocn.1993.5.4.467.
   MCCARTHY G, 1995, J NEUROSCI, V15, P1080.
   Menenti L, 2009, J COGNITIVE NEUROSCI, V21, P2358, DOI 10.1162/jocn.2008.21163.
   Molinaro N, 2013, NEUROIMAGE, V72, P120, DOI 10.1016/j.neuroimage.2013.01.031.
   Monsalve I.F, 2012, P 13 C EUR CHAPT ASS, P398.
   Nastase S, 2014, HUM BRAIN MAPP, V35, P1111, DOI 10.1002/hbm.22238.
   Nijhof AD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116492.
   NOBRE AC, 1994, NATURE, V372, P260, DOI 10.1038/372260a0.
   Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639.
   Oostdijk N., 2000, P 2 INT C LANG RES E, P887.
   Peelen MV, 2014, TRENDS COGN SCI, V18, P242, DOI 10.1016/j.tics.2014.02.004.
   Peper R, 1999, DOOI.
   Piantadosi ST, 2011, P NATL ACAD SCI USA, V108, P3526, DOI 10.1073/pnas.1012551108.
   Poser BA, 2010, NEUROIMAGE, V51, P261, DOI 10.1016/j.neuroimage.2010.01.108.
   Robertson DA, 2000, PSYCHOL SCI, V11, P255, DOI 10.1111/1467-9280.00251.
   Schafer R, 2012, P 8 INT C LANG RES E.
   Schubotz RI, 2004, J NEUROSCI, V24, P5467, DOI 10.1523/JNEUROSCI.1169-04.2004.
   Slotnick SD, 2003, COGNITIVE BRAIN RES, V17, P75, DOI 10.1016/S0926-6410(03)00082-X.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Snijders TM, 2010, NEUROIMAGE, V52, P1633, DOI 10.1016/j.neuroimage.2010.05.035.
   Speer NK, 2009, PSYCHOL SCI, V20, P989, DOI 10.1111/j.1467-9280.2009.02397.x.
   St George M, 1999, BRAIN, V122, P1317, DOI 10.1093/brain/122.7.1317.
   Stolcke A., 2002, P INT C SPOK LANG PR, P901.
   Strange BA, 2005, NEURAL NETWORKS, V18, P225, DOI 10.1016/j.neunet.2004.12.004.
   Tobia MJ, 2012, NEUROIMAGE, V63, P1730, DOI 10.1016/j.neuroimage.2012.08.017.
   Turken AU, 2011, FRONT SYST NEUROSCI, V5, DOI 10.3389/fnsys.2011.00001.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van den Bosch Antal, 2009, Prague Bulletin of Mathematical Linguistics, P17.
   Van der Meer V, 1999, EILANDGASTEN.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Vandenberghe R, 2002, J COGNITIVE NEUROSCI, V14, P550, DOI 10.1162/08989290260045800.
   Vinckier F, 2007, NEURON, V55, P143, DOI 10.1016/j.neuron.2007.05.031.
   Wallentin M, 2011, BRAIN LANG, V119, P221, DOI 10.1016/j.bandl.2011.04.006.
   Wehbe L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112575.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Willems RM, 2015, COGNITIVE NEUROSCIENCE OF NATURAL LANGUAGE USE, P1.
   Willems RM, 2014, NAT REV NEUROSCI, V15, P193, DOI 10.1038/nrn3679.
   Willems RM, 2011, SOC COGN AFFECT NEUR, V6, P404, DOI 10.1093/scan/nsq050.
   Xu J, 2005, NEUROIMAGE, V25, P1002, DOI 10.1016/j.neuroimage.2004.12.013.}},
Number-of-Cited-References = {{94}},
Times-Cited = {{63}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{27}},
Journal-ISO = {{Cereb. Cortex}},
Doc-Delivery-Number = {{DO6TX}},
Unique-ID = {{ISI:000377917500012}},
OA = {{Bronze, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000380149500003,
Author = {Buchweitz, Augusto},
Title = {{Language and reading development in the brain today: neuromarkers and
   the case for prediction}},
Journal = {{JORNAL DE PEDIATRIA}},
Year = {{2016}},
Volume = {{92}},
Number = {{3, 1}},
Pages = {{S8-S13}},
Month = {{MAY-JUN}},
Abstract = {{Objectives: The goal of this article is to provide an account of
   language development in the brain using the new information about brain
   function gleaned from cognitive neuroscience. This account goes beyond
   describing the association between language and specific brain areas to
   advocate the possibility of predicting language outcomes using
   brain-imaging data. The goal is to address the current evidence about
   language development in the brain and prediction of language outcomes.
   Sources: Recent studies will be discussed in the light of the evidence
   generated for predicting language outcomes and using new methods of
   analysis of brain data.
   Summary of the data: The present account of brain behavior will address:
   (1) the development of a hardwired brain circuit for spoken language;
   (2) the neural adaptation that follows reading instruction and fosters
   the ``grafting'' of visual processing areas of the brain onto the
   hardwired circuit of spoken language; and (3) the prediction of language
   development and the possibility of translational neuroscience.
   Conclusions: Brain imaging has allowed for the identification of neural
   indices (neuromarkers) that reflect typical and atypical language
   development; the possibility of predicting risk for language disorders
   has emerged. A mandate to develop a bridge between neuroscience and
   health and cognition-related outcomes may pave the way for translational
   neuroscience. (C) 2016 Sociedade Brasileira de Pediatria. Published by
   Elsevier Editora Ltda. All rights reserved.}},
Publisher = {{SOC BRASIL PEDIATRIA}},
Address = {{RUA SANTA CLARA 292, RIO DE JANEIRO, RJ, CEP 22401-01, BRAZIL}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Buchweitz, A (Corresponding Author), Pontificia Univ Catolica Rio Grande PUCRS, Sch Letters, Inst Cerebro Rio Grande Sul Inscer, Porto Alegre, RS, Brazil.
   Buchweitz, Augusto, Pontificia Univ Catolica Rio Grande PUCRS, Sch Letters, Inst Cerebro Rio Grande Sul Inscer, Porto Alegre, RS, Brazil.}},
DOI = {{10.1016/j.jped.2016.01.005}},
ISSN = {{0021-7557}},
EISSN = {{1678-4782}},
Keywords = {{Language development; Brain imaging; Prediction}},
Keywords-Plus = {{WORD FORM AREA; WHITE-MATTER; NEURAL REPRESENTATIONS; SENTENCE
   COMPREHENSION; COGNITIVE NEUROSCIENCE; SOCIOECONOMIC-STATUS; POOR
   READERS; FMRI; DYSLEXIA; CHILDREN}},
Research-Areas = {{Pediatrics}},
Web-of-Science-Categories  = {{Pediatrics}},
Author-Email = {{augusto.buchweitz@pucrs.br}},
ResearcherID-Numbers = {{Buchweitz, Augusto/G-3829-2012
   Buchweitz, Augusto/J-5384-2019}},
ORCID-Numbers = {{Buchweitz, Augusto/0000-0003-3791-7472
   Buchweitz, Augusto/0000-0003-3791-7472}},
Cited-References = {{Bandettini PA, 2012, NEUROIMAGE, V62, P575, DOI 10.1016/j.neuroimage.2012.04.026.
   Bauer AJ, 2015, HUM BRAIN MAPP, V36, P3213, DOI 10.1002/hbm.22842.
   Beaulieu C, 2005, NEUROIMAGE, V25, P1266, DOI 10.1016/j.neuroimage.2004.12.053.
   Beddington J, 2008, NATURE, V455, P1057, DOI 10.1038/4551057a.
   Buchweitz A, 2012, BRAIN LANG, V120, P282, DOI 10.1016/j.bandl.2011.09.003.
   Buchweitz Augusto, 2009, Psychol. Neurosci., V2, P111, DOI 10.3922/j.psns.2009.2.003.
   Cabeza R, 2000, J COGNITIVE NEUROSCI, V12, P1, DOI 10.1162/08989290051137585.
   Can DD, 2013, BRAIN LANG, V124, P34, DOI 10.1016/j.bandl.2012.10.007.
   Castro-Caldas A, 1998, BRAIN, V121, P1053, DOI 10.1093/brain/121.6.1053.
   Chang KMK, 2011, NEUROIMAGE, V56, P716, DOI 10.1016/j.neuroimage.2010.04.271.
   Cohen L, 2002, BRAIN, V125, P1054, DOI 10.1093/brain/awf094.
   Cohen L, 2000, BRAIN, V123, P291, DOI 10.1093/brain/123.2.291.
   Dehaene S., 2009, READING BRAIN NEW SC.
   Dehaene S, 2011, TRENDS COGN SCI, V15, P254, DOI 10.1016/j.tics.2011.04.003.
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140.
   Devlin JT, 2006, J COGNITIVE NEUROSCI, V18, P911, DOI 10.1162/jocn.2006.18.6.911.
   Gabrieli JDE, 2015, NEURON, V85, P11, DOI 10.1016/j.neuron.2014.10.047.
   Gabrieli JDE, 2009, SCIENCE, V325, P280, DOI 10.1126/science.1171999.
   Hoeft F, 2007, BEHAV NEUROSCI, V121, P602, DOI 10.1037/0735-7044.121.3.602.
   Hoeft F, 2011, P NATL ACAD SCI USA, V108, P361, DOI 10.1073/pnas.1008950108.
   Hoff E, 2005, J COMMUN DISORD, V38, P271, DOI 10.1016/j.jcomdis.2005.02.003.
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612.
   Huettel SA, 2004, FUNCTIONAL MAGNETIC.
   Just MA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113879.
   Kassam KS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066032.
   Keller TA, 2009, NEURON, V64, P624, DOI 10.1016/j.neuron.2009.10.018.
   Klingberg T, 2000, NEURON, V25, P493, DOI 10.1016/S0896-6273(00)80911-3.
   Kovelman I, 2012, CEREB CORTEX, V22, P754, DOI 10.1093/cercor/bhr094.
   Logothetis NK, 2008, NATURE, V453, P869, DOI 10.1038/nature06976.
   Logothetis NK, 2001, NATURE, V412, P150, DOI 10.1038/35084005.
   Maurer U, 2011, NEUROIMAGE, V57, P714, DOI 10.1016/j.neuroimage.2010.10.055.
   Mencl WE, 2009, CHILDREN LEARN READ, P87.
   Meyler A, 2007, CEREB CORTEX, V17, P2780, DOI 10.1093/cercor/bhm006.
   Michael EB, 2001, HUM BRAIN MAPP, V13, P239, DOI 10.1002/hbm.1036.
   Mitchell TM, 2008, SCIENCE, V320, P1191, DOI 10.1126/science.1152876.
   Mitchell TM, 2009, SCIENCE, V326, P1644, DOI 10.1126/science.1174459.
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287.
   MORAIS J, 1979, COGNITION, V7, P323, DOI 10.1016/0010-0277(79)90020-9.
   Myers CA, 2014, PSYCHOL SCI, V25, P1870, DOI 10.1177/0956797614544511.
   Noble KG, 2015, NAT NEUROSCI, V18, P773, DOI 10.1038/nn.3983.
   Pegado F, 2014, J EXP PSYCHOL GEN, V143, P887, DOI 10.1037/a0033198.
   Preston JL, 2010, BRAIN, V133, P2185, DOI 10.1093/brain/awq163.
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x.
   Pugh KR, 2014, J NEUROSCI, V34, P4082, DOI 10.1523/JNEUROSCI.3907-13.2014.
   Reis A, 1997, J INT NEUROPSYCH SOC, V3, P444, DOI 10.1017/S135561779700444X.
   Rosen BR, 2012, NEUROIMAGE, V62, P1316, DOI 10.1016/j.neuroimage.2012.03.004.
   Rueckl JG, 2015, P NATL ACAD SCI USA, V112, P15510, DOI 10.1073/pnas.1509321112.
   Shaywitz BA, 2004, BIOL PSYCHIAT, V55, P926, DOI 10.1016/j.biopsych.2003.12.019.
   Shaywitz BA, 2002, BIOL PSYCHIAT, V52, P101, DOI 10.1016/S0006-3223(02)01365-3.
   Shaywitz S, 2008, OVERCOMING DYSLEXIA.
   Shaywitz SE, 2008, DEV PSYCHOPATHOL, V20, P1329, DOI 10.1017/S0954579408000631.
   Shinkareva SV, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001394.
   Shonkoff JP, 2000, NEURONS NEIGHBORHOOD.
   Ullman MT, 2005, CORTEX, V41, P399, DOI 10.1016/S0010-9452(08)70276-4.
   Ullman MT, 1997, J COGNITIVE NEUROSCI, V9, P266, DOI 10.1162/jocn.1997.9.2.266.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{18}},
Journal-ISO = {{J. Pediatr.}},
Doc-Delivery-Number = {{DR8LN}},
Unique-ID = {{ISI:000380149500003}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000372488200021,
Author = {Sohoglu, Ediz and Davis, Matthew H.},
Title = {{Perceptual learning of degraded speech by minimizing prediction error}},
Journal = {{PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA}},
Year = {{2016}},
Volume = {{113}},
Number = {{12}},
Pages = {{E1747-E1756}},
Month = {{MAR 22}},
Abstract = {{Human perception is shaped by past experience on multiple time-scales.
   Sudden and dramatic changes in perception occur when prior knowledge or
   expectations match stimulus content. These immediate effects contrast
   with the longer-term, more gradual improvements that are characteristic
   of perceptual learning. Despite extensive investigation of these two
   experience-dependent phenomena, there is considerable debate about
   whether they result from common or dissociable neural mechanisms. Here
   we test single-and dual-mechanism accounts of experience-dependent
   changes in perception using concurrent magnetoencephalographic and EEG
   recordings of neural responses evoked by degraded speech. When speech
   clarity was enhanced by prior knowledge obtained from matching text, we
   observed reduced neural activity in a peri-auditory region of the
   superior temporal gyrus (STG). Critically, longer-term improvements in
   the accuracy of speech recognition following perceptual learning
   resulted in reduced activity in a nearly identical STG region. Moreover,
   short-term neural changes caused by prior knowledge and longer-term
   neural changes arising from perceptual learning were correlated across
   subjects with the magnitude of learning-induced changes in recognition
   accuracy. These experience-dependent effects on neural processing could
   be dissociated from the neural effect of hearing physically clearer
   speech, which similarly enhanced perception but increased rather than
   decreased STG responses. Hence, the observed neural effects of prior
   knowledge and perceptual learning cannot be attributed to epiphenomenal
   changes in listening effort that accompany enhanced perception. Instead,
   our results support a predictive coding account of speech perception;
   computational simulations show how a single mechanism, minimization of
   prediction error, can drive immediate perceptual effects of prior
   knowledge and longer-term perceptual learning of degraded speech.}},
Publisher = {{NATL ACAD SCIENCES}},
Address = {{2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sohoglu, E; Davis, MH (Corresponding Author), MRC, Cognit \& Brain Sci Unit, Cambridge CB2 7EF, England.
   Sohoglu, Ediz; Davis, Matthew H., MRC, Cognit \& Brain Sci Unit, Cambridge CB2 7EF, England.
   Sohoglu, Ediz, UCL, Ear Inst, London WC1X 8EE, England.}},
DOI = {{10.1073/pnas.1523266113}},
ISSN = {{0027-8424}},
Keywords = {{perceptual learning; predictive coding; speech perception;
   magnetoencephalography; vocoded speech}},
Keywords-Plus = {{NOISE-VOCODED SPEECH; COCHLEAR IMPLANTS; AUDITORY-CORTEX; SOURCE
   RECONSTRUCTION; PERCEIVED CLARITY; RAPID ADAPTATION; DISTORTED SPEECH;
   SPOKEN LANGUAGE; FREE-ENERGY; BRAIN}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{e.sohoglu@gmail.com
   matt.davis@mrc-cbu.cam.ac.uk}},
ORCID-Numbers = {{Davis, Matt/0000-0003-2239-0778
   Sohoglu, Ediz/0000-0002-0755-6445}},
Funding-Acknowledgement = {{Medical Research Council (MRC) Centenary Award; MRCMedical Research
   Council UK (MRC) {[}MC-A060-5PQ80]; Medical Research CouncilMedical
   Research Council UK (MRC) {[}MC\_U105580446] Funding Source:
   researchfish}},
Funding-Text = {{We thank Maarten van Casteren, Clare Cook, and Lucy MacGregor for
   excellent technical support during data collection; Nicolas Barascud for
   providing Matlab code to plot source dipole locations; and Helen Blank,
   Thomas Cope, two anonymous reviewers, and the editor for helpful
   comments on an earlier draft of this manuscript. This research was
   supported by a Medical Research Council (MRC) Centenary Award (to E.S.)
   and MRC Grant MC-A060-5PQ80 (to M.H.D.).}},
Cited-References = {{Ahissar M, 1997, NATURE, V387, P401, DOI 10.1038/387401a0.
   Ahissar M, 2004, TRENDS COGN SCI, V8, P457, DOI 10.1016/j.tics.2004.08.011.
   Alain C, 2010, J COGNITIVE NEUROSCI, V22, P392, DOI 10.1162/jocn.2009.21279.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Azadpour M, 2015, J ACOUST SOC AM, V138, P44, DOI 10.1121/1.4922226.
   Baayen RH, 1993, CELEX LEXICAL DATABA.
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131.
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222.
   Davis MH, 2003, J NEUROSCI, V23, P3423.
   Dolan RJ, 1997, NATURE, V389, P596, DOI 10.1038/39309.
   Dorjee D, 2012, CORTEX, V48, P509, DOI 10.1016/j.cortex.2011.06.016.
   Eickhoff SB, 2005, NEUROIMAGE, V25, P1325, DOI 10.1016/j.neuroimage.2004.12.034.
   Eisner F, 2010, J NEUROSCI, V30, P7179, DOI 10.1523/JNEUROSCI.4040-09.2010.
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013.
   Fenn KM, 2003, NATURE, V425, P614, DOI 10.1038/nature01951.
   Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003.
   FRAUENFELDER UH, 1990, J EXP PSYCHOL HUMAN, V16, P77, DOI 10.1037/0096-1523.16.1.77.
   Friston KJ, 2006, NEUROIMAGE, V30, P1097, DOI 10.1016/j.neuroimage.2006.02.007.
   Friston KJ, 2006, HUM BRAIN MAPP, V27, P722, DOI 10.1002/hbm.20214.
   Friston KJ, 2007, NEUROIMAGE, V34, P220, DOI 10.1016/j.neuroimage.2006.08.035.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585.
   GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1016/S0364-0213(87)80025-3.
   Hansen P., 2010, MEG INTRO METHODS.
   Hayasaka S, 2004, NEUROIMAGE, V22, P676, DOI 10.1016/j.neuroimage.2004.01.041.
   Henson RN, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00076.
   Henson RN, 2010, HIPPOCAMPUS, V20, P1315, DOI 10.1002/hipo.20857.
   Henson RN, 2009, NEUROIMAGE, V47, P581, DOI 10.1016/j.neuroimage.2009.04.063.
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460.
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   HOWES D, 1957, J ACOUST SOC AM, V29, P296, DOI 10.1121/1.1908862.
   Huyck JJ, 2012, J ACOUST SOC AM, V131, pEL236, DOI 10.1121/1.3685511.
   JACOBY LL, 1988, J EXP PSYCHOL LEARN, V14, P240, DOI 10.1037/0278-7393.14.2.240.
   Jesse A, 2011, PSYCHON B REV, V18, P943, DOI 10.3758/s13423-011-0129-2.
   Kiebel SJ, 2008, NEUROIMAGE, V39, P728, DOI 10.1016/j.neuroimage.2007.09.005.
   Kilian-Hutten N, 2011, NEUROIMAGE, V57, P1601, DOI 10.1016/j.neuroimage.2011.05.043.
   Kilner JM, 2013, CLIN NEUROPHYSIOL, V124, P2062, DOI 10.1016/j.clinph.2013.03.024.
   Kilner JM, 2010, ANN APPL STAT, V4, P1272, DOI 10.1214/10-AOAS337.
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007.
   Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303.
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323.
   Litvak V, 2008, NEUROIMAGE, V42, P1490, DOI 10.1016/j.neuroimage.2008.06.022.
   Litvak V, 2011, COMPUT INTEL NEUROSC, DOI 10.1155/2011/852961.
   LOFTUS GR, 1994, PSYCHON B REV, V1, P476, DOI 10.3758/BF03210951.
   Ludmer R, 2011, NEURON, V69, P1002, DOI 10.1016/j.neuron.2011.02.013.
   McGettigan C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00018.
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000\_79.
   MILLER GA, 1963, J VERB LEARN VERB BE, V2, P217, DOI 10.1016/S0022-5371(63)80087-0.
   Mirman D, 2006, PSYCHON B REV, V13, P958, DOI 10.3758/BF03213909.
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002.
   Mitterer H, 2009, PLOS ONE, V4, pA146, DOI 10.1371/journal.pone.0007785.
   Moore DR, 2009, NAT NEUROSCI, V12, P686, DOI 10.1038/nn.2326.
   Moran RJ, 2013, J NEUROSCI, V33, P8227, DOI 10.1523/JNEUROSCI.4255-12.2013.
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477.
   Myers EB, 2014, J MEM LANG, V76, P80, DOI 10.1016/j.jml.2014.06.007.
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9.
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008.
   PASCUALMARQUI RD, 1994, INT J PSYCHOPHYSIOL, V18, P49, DOI 10.1016/0167-8760(84)90014-X.
   Peelle JE, 2005, J EXP PSYCHOL HUMAN, V31, P1315, DOI 10.1037/0096-1523.31.6.1315.
   Petrov AA, 2005, PSYCHOL REV, V112, P715, DOI 10.1037/0033-295X.112.4.715.
   Phillips C, 2005, NEUROIMAGE, V24, P997, DOI 10.1016/j.neuroimage.2004.10.030.
   Polat U, 2004, P NATL ACAD SCI USA, V101, P6692, DOI 10.1073/pnas.0401200101.
   POLLACK I, 1959, J ACOUST SOC AM, V31, P273, DOI 10.1121/1.1907712.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331.
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191.
   Rosen S, 1999, J ACOUST SOC AM, V106, P3629, DOI 10.1121/1.428215.
   Ross B, 2009, HEARING RES, V248, P48, DOI 10.1016/j.heares.2008.11.012.
   Rubin N, 1997, CURR BIOL, V7, P461, DOI 10.1016/S0960-9822(06)00217-X.
   Scott SK, 2006, J ACOUST SOC AM, V120, P1075, DOI 10.1121/1.2216725.
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303.
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008.
   Stacey PC, 2010, INT J AUDIOL, V49, P347, DOI 10.3109/14992020903397838.
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309.
   Taulu S, 2005, IEEE T SIGNAL PROCES, V53, P3359, DOI 10.1109/TSP.2005.853302.
   Tremblay KL, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00028.
   Wager TD, 2005, NEUROIMAGE, V26, P99, DOI 10.1016/j.neuroimage.2005.01.011.
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035.
   Yvert B, 2005, NEUROIMAGE, V28, P140, DOI 10.1016/j.neuroimage.2005.05.056.}},
Number-of-Cited-References = {{85}},
Times-Cited = {{31}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{18}},
Journal-ISO = {{Proc. Natl. Acad. Sci. U. S. A.}},
Doc-Delivery-Number = {{DH0QH}},
Unique-ID = {{ISI:000372488200021}},
OA = {{Bronze, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000371275700001,
Author = {Lewis, Ashley G. and Schoffelen, Jan-Mathijs and Schriefers, Herbert and
   Bastiaansen, Marcel},
Title = {{A Predictive Coding Perspective on Beta Oscillations during
   Sentence-Level Language Comprehension}},
Journal = {{FRONTIERS IN HUMAN NEUROSCIENCE}},
Year = {{2016}},
Volume = {{10}},
Month = {{MAR 3}},
Abstract = {{Oscillatory neural dynamics have been steadily receiving more attention
   as a robust and temporally precise signature of network activity related
   to language processing. We have recently proposed that oscillatory
   dynamics in the beta and gamma frequency ranges measured during
   sentence-level comprehension might be best explained from a predictive
   coding perspective. Under our proposal we related beta oscillations to
   both the maintenance/change of the neural network configuration
   responsible for the construction and representation of sentence-level
   meaning, and to top down predictions about upcoming linguistic input
   based on that sentence-level meaning. Here we zoom in on these
   particular aspects of our proposal, and discuss both old and new
   supporting evidence. Finally, we present some preliminary
   magnetoencephalography data from an experiment comparing Dutch subject-
   and object-relative clauses that was specifically designed to test our
   predictive coding framework. Initial results support the first of the
   two suggested roles for beta oscillations in sentence-level language
   comprehension.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bastiaansen, M (Corresponding Author), Max Planck Inst Psycholinguist, Neurobiol Language Dept, Nijmegen, Netherlands.
   Bastiaansen, M (Corresponding Author), NHTV Breda Univ Appl Sci, Acad Leisure, Breda, Netherlands.
   Lewis, Ashley G., Haskins Labs Inc, New Haven, CT USA.
   Lewis, Ashley G.; Schoffelen, Jan-Mathijs; Bastiaansen, Marcel, Max Planck Inst Psycholinguist, Neurobiol Language Dept, Nijmegen, Netherlands.
   Lewis, Ashley G.; Schoffelen, Jan-Mathijs, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, Ctr Cognit Neuroimaging, NL-6525 ED Nijmegen, Netherlands.
   Schriefers, Herbert, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, Donders Ctr Cognit, NL-6525 ED Nijmegen, Netherlands.
   Bastiaansen, Marcel, NHTV Breda Univ Appl Sci, Acad Leisure, Breda, Netherlands.}},
DOI = {{10.3389/fnhum.2016.00085}},
Article-Number = {{85}},
ISSN = {{1662-5161}},
Keywords = {{language comprehension; neural oscillations; beta; predictive coding;
   EEG; MEG}},
Keywords-Plus = {{DYNAMICS; UNIFICATION; RESPONSES; BRAIN; DISCOURSE; ANIMACY; SPEECH;
   MEMORY; WORDS}},
Research-Areas = {{Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Neurosciences; Psychology}},
Author-Email = {{bastiaansen4.m@nhtv.nl}},
ResearcherID-Numbers = {{Lewis, Ashley/C-8984-2015
   Lewis, Ashley Glen/K-5410-2019
   Schriefers, Herbert/D-8532-2012
   Schoffelen, Jan-Mathijs/D-3716-2009}},
ORCID-Numbers = {{Lewis, Ashley/0000-0003-4737-2525
   Lewis, Ashley Glen/0000-0003-4737-2525
   Schoffelen, Jan-Mathijs/0000-0003-0923-6610}},
Funding-Acknowledgement = {{NWO VIDI grantNetherlands Organization for Scientific Research (NWO)
   {[}864.14.011]; IMPRS PhD fellowship from the Max Planck Society}},
Funding-Text = {{This work is partly supported by an NWO VIDI grant to JS (grant number
   864.14.011), and an IMPRS PhD fellowship from the Max Planck Society to
   AL.}},
Cited-References = {{Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0.
   Bastiaansen M, 2015, J COGNITIVE NEUROSCI, V27, P2095, DOI 10.1162/jocn\_a\_00829.
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283.
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038.
   Bressler SL, 2015, CURR OPIN NEUROBIOL, V31, P62, DOI 10.1016/j.conb.2014.08.010.
   Davidson DJ, 2007, BRAIN RES, V1158, P81, DOI 10.1016/j.brainres.2007.04.082.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015.
   Friederici AD, 2015, TRENDS COGN SCI, V19, P329, DOI 10.1016/j.tics.2015.03.012.
   Friston KJ, 2015, CURR OPIN NEUROBIOL, V31, P1, DOI 10.1016/j.conb.2014.05.004.
   Friston KJ, 2013, CURR OPIN NEUROBIOL, V23, P172, DOI 10.1016/j.conb.2012.11.010.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004.
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Jackendoff R, 2007, BRAIN RES, V1146, P2, DOI 10.1016/j.brainres.2006.08.111.
   Kielar A, 2015, NEUROIMAGE, V105, P507, DOI 10.1016/j.neuroimage.2014.11.016.
   Kielar A, 2014, J COGNITIVE NEUROSCI, V26, P2840, DOI 10.1162/jocn\_a\_00670.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014.
   Lewis AG, 2015, BRAIN LANG, V148, P51, DOI 10.1016/j.bandl.2015.01.003.
   Luo Y, 2010, NEUROSCIENCE, V169, P654, DOI 10.1016/j.neuroscience.2010.05.032.
   Magyari L, 2014, J COGNITIVE NEUROSCI, V26, P2530, DOI 10.1162/jocn\_a\_00673.
   Mak WM, 2008, MEM COGNITION, V36, P170, DOI 10.3758/MC.36.1.170.
   Mak WM, 2006, J MEM LANG, V54, P466, DOI 10.1016/j.jml.2006.01.001.
   Mak WM, 2002, J MEM LANG, V47, P50, DOI 10.1006/jmla.2001.2837.
   Meyer L, 2013, CORTEX, V49, P711, DOI 10.1016/j.cortex.2012.03.006.
   Mitra PP, 1999, BIOPHYS J, V76, P691, DOI 10.1016/S0006-3495(99)77236-X.
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049.
   Perez A, 2012, NEUROPSYCHOLOGIA, V50, P2584, DOI 10.1016/j.neuropsychologia.2012.07.009.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Wang L, 2012, HUM BRAIN MAPP, V33, P2898, DOI 10.1002/hbm.21410.
   Weiss S, 2005, INT J PSYCHOPHYSIOL, V57, P129, DOI 10.1016/j.ijpsycho.2005.03.013.
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{36}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{Front. Hum. Neurosci.}},
Doc-Delivery-Number = {{DF3VH}},
Unique-ID = {{ISI:000371275700001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000370247700022,
Author = {Diepeveen, F. Babette and Dusseldorp, Elise and Bol, Gerard W. and
   Oudesluys-Murphy, Anne Marie and Verkerk, Paul H.},
Title = {{Failure to meet language milestones at two years of age is predictive of
   specific language impairment}},
Journal = {{ACTA PAEDIATRICA}},
Year = {{2016}},
Volume = {{105}},
Number = {{3}},
Pages = {{304-310}},
Month = {{MAR}},
Abstract = {{AimThis study established predictive properties of single language
   milestones for specific language impairment (SLI) after the age of four,
   as these had not previously been reported in the literature.
   MethodsIn this nested case-control study, children attending special
   needs schools for severe speech and language difficulties were matched
   with children attending mainstream schools. Data covering the ages of
   zero to four years were retrieved from well-child care clinics and the
   outcomes of 23 language milestones in the Dutch Developmental Instrument
   were analysed. The predictive properties were expressed as positive
   likelihood ratios, sensitivity and specificity.
   ResultsWe included 253 pairs of children with and without SLI, aged from
   four to 11 years. The mean age was eight years and three months, and
   77\% were boys. From the age of 18 months, cases and controls differed
   significantly on all milestones (p < 0.01). After 24 months, the
   language milestones had positive likelihood ratios that ranging from 6
   to 108. In general, language milestones had a high specificity (range
   77-100\%), but the sensitivity was relatively low (range 0-68\%).
   ConclusionFailure to meet language milestones from the age of 24 months
   was predictive of SLI, but the use of separate milestones had limited
   value due to low sensitivity.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Diepeveen, FB (Corresponding Author), Netherlands Org Appl Sci Res TNO, POB 2215, NL-2301 CE Leiden, Netherlands.
   Diepeveen, F. Babette; Dusseldorp, Elise; Verkerk, Paul H., Netherlands Org Appl Sci Res TNO, POB 2215, NL-2301 CE Leiden, Netherlands.
   Dusseldorp, Elise, Leiden Univ, Inst Psychol, Dept Methodol \& Stat, Leiden, Netherlands.
   Bol, Gerard W., Univ Groningen, Dept Linguist, Groningen, Netherlands.
   Oudesluys-Murphy, Anne Marie, Leiden Univ, Willem Alexander Childrens Hosp, Med Ctr, Leiden, Netherlands.}},
DOI = {{10.1111/apa.13271}},
ISSN = {{0803-5253}},
EISSN = {{1651-2227}},
Keywords = {{Developmental language disorder; Language milestones; Predictive
   properties; Specific language impairment; Validity}},
Keywords-Plus = {{PRIMARY SPEECH; DELAY; CHILDREN; PREVALENCE; TOOL}},
Research-Areas = {{Pediatrics}},
Web-of-Science-Categories  = {{Pediatrics}},
Author-Email = {{babettediepeveen@hotmail.com}},
ORCID-Numbers = {{Oudesluys-Murphy, Anne Marie/0000-0003-2282-0571
   Diepeveen, Babette/0000-0002-7718-4480}},
Funding-Acknowledgement = {{ZonMw, the Netherlands Organisation for Health Research and
   DevelopmentNetherlands Organization for Health Research and Development
   {[}200320016]}},
Funding-Text = {{This research was supported by a grant from ZonMw, the Netherlands
   Organisation for Health Research and Development (grant number
   200320016).}},
Cited-References = {{Bishop DVM, 2014, INT J LANG COMM DIS, V49, P381, DOI 10.1111/1460-6984.12101.
   Brothers KB, 2008, CLIN PEDIATR, V47, P271, DOI 10.1177/0009922807309419.
   COPLAN J, 1990, PEDIATRICS, V86, P963.
   Duby JC, 2006, PEDIATRICS, V118, P405, DOI 10.1542/peds.2006-1231.
   ERNSTER VL, 1994, PREV MED, V23, P587, DOI 10.1006/pmed.1994.1093.
   GLASCOE FP, 1990, PEDIATRICS, V86, P547.
   Jacobusse G, 2006, STAT MED, V25, P2272, DOI 10.1002/sim.2351.
   Laurent de Angulo MS, 2008, ONTWIKKELINGSONDERZO.
   Law J, 2000, INT J LANG COMM DIS, V35, P165, DOI 10.1080/136828200247133.
   Law J, 2000, DEV MED CHILD NEUROL, V42, P190, DOI 10.1017/S0012162200000335.
   McLaughlin MR, 2011, AM FAM PHYSICIAN, V83, P1183.
   Nelson HD, 2006, PEDIATRICS, V117, pE298, DOI 10.1542/peds.2005-1467.
   RESCORLA L, 1989, J SPEECH HEAR DISORD, V54, P587, DOI 10.1044/jshd.5404.587.
   Rydz D, 2005, J CHILD NEUROL, V20, P4, DOI 10.1177/08830738050200010201.
   Schum RL, 2007, PEDIATR CLIN N AM, V54, P425, DOI 10.1016/j.pcl.2007.02.010.
   SIMEL DL, 1991, J CLIN EPIDEMIOL, V44, P763, DOI 10.1016/0895-4356(91)90128-V.
   St Clair MC, 2011, J COMMUN DISORD, V44, P186, DOI 10.1016/j.jcomdis.2010.09.004.
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{Acta Paediatr.}},
Doc-Delivery-Number = {{DD9LS}},
Unique-ID = {{ISI:000370247700022}},
DA = {{2020-12-06}},
}

@article{ ISI:000371841300016,
Author = {Droege, Alexander and Fleischer, Juerg and Schlesewsky, Matthias and
   Bornkessel-Schlesewsky, Ina},
Title = {{Neural mechanisms of sentence comprehension based on predictive
   processes and decision certainty: Electrophysiological evidence from
   non-canonical linearizations in a flexible word order language}},
Journal = {{BRAIN RESEARCH}},
Year = {{2016}},
Volume = {{1633}},
Pages = {{149-166}},
Month = {{FEB 15}},
Abstract = {{The specificity or generality of language-related event-related brain
   potentials (ERPs) has been a point of continuing debate in the cognitive
   neuroscience of language. The present study measured ERPs to (preferred)
   subject-before-object (SO) and (dispreferred) object before-subject (OS)
   word orders in German while manipulating morphosyntactic and semantic
   cues to correct sentence interpretation. We presented sentence pairs as
   connected speech (context and target sentences) and examined ERPs at the
   position of the first argument (noun phrase) in the target sentence. At
   this position, word order was determinable by either (a) case marking
   (morphosyntactic cue); (b) animacy (semantic cue); or (c) the preceding
   context sentence (local ambiguity; contextual cue). Following each
   sentence pair, participants judged the acceptability of the second
   sentence in the context of the first and performed a probe word
   recognition task. Results showed a biphasic N400-P600 pattern at the
   first noun phrase in the OS conditions irrespectively of which cues
   (syntactic or semantic) were available to the parser for disambiguation.
   N400 latency varied as a function of temporal cue availability and P600
   amplitude increased for unambiguous object-initial conditions even
   though these were rated acceptable in the judgment task. These findings
   support an interpretation of ERP components in terms of general
   cognitive mechanisms such as predictive processes (N400) and decision
   certainty (P600 as an instance of the P300) rather than a
   domain-specific view of a semantic N400 and a syntactic P600. (c) 2015
   Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Droge, A (Corresponding Author), Univ Marburg, FB09,Deutschhausstr 3, D-35032 Marburg, Germany.
   Droege, Alexander; Fleischer, Juerg, Univ Marburg, Dept German Linguist, Deutschhausstr 3, D-35032 Marburg, Germany.
   Schlesewsky, Matthias; Bornkessel-Schlesewsky, Ina, Univ S Australia, Cognit Neurosci Lab, Sch Psychol Social Work \& Social Policy, Amy Wheaton Bldg,Magill Campus,GPO Box 2471, Adelaide, SA 5001, Australia.}},
DOI = {{10.1016/j.brainres.2015.12.045}},
ISSN = {{0006-8993}},
EISSN = {{1872-6240}},
Keywords = {{N400; P600; P300; Prediction; Semantics; Syntax}},
Keywords-Plus = {{BRAIN POTENTIALS; SYNTACTIC INTEGRATION; P600; ERP; REVEAL; P300;
   INFORMATION; SPECIFICITY; SENSITIVITY; COMPLEXITY}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{alexander.droege@uni-marburg.de}},
ORCID-Numbers = {{Bornkessel-Schlesewsky, Ina/0000-0002-3238-6492}},
Funding-Acknowledgement = {{German State of Hesse}},
Funding-Text = {{This research project was part of the LOEWE program ``Fundierung
   linguistischer Basiskategorien{''} (TP6: ``Der Zusammenhang der
   Kasusmarkierung, Serialisierungsfixier-ung and Belebtheitshierarchie in
   den deutschen Regional-sprachen{''}) funded by the German State of
   Hesse. We would like to thank Phillip Alday, Simon Kasper, Jona
   Sassenhagen, and Oliver Schallert for many fruitful discussions, and
   Elisabeth Rabs for her invaluable help with the stimulus preparation and
   EEG recordings. We are also grateful to Sophia Oertel and Ann-Kristin
   Reimchen for stimulus recordings, and Sarah Munde for her help with
   participant recruitment and in the lab.}},
Cited-References = {{Alday P. M., 2015, LINGUIST VANGUARD, V1.
   Alday P. M., 2015, THESIS PHILIPPS U MA.
   Berwick RC, 2013, TRENDS COGN SCI, V17, P89, DOI 10.1016/j.tics.2012.12.002.
   Blake Barry, 2001, CASE.
   Bornkessel I, 2004, J MEM LANG, V51, P495, DOI 10.1016/j.jml.2004.06.011.
   Bornkessel I, 2003, J EXP PSYCHOL LEARN, V29, P871, DOI 10.1037/0278-7393.29.5.871.
   Bornkessel I, 2002, COGNITION, V85, pB21, DOI 10.1016/S0010-0277(02)00076-8.
   Bornkessel I, 2006, PSYCHOL REV, V113, P787, DOI 10.1037/0033-295X.113.4.787.
   Bornkessel-Schlesewsky I, 2009, PROCESSING SYNTAX MO.
   Bornkessel-Schlesewsky I., 2015, NEUROBIOLOGY LANGUAG, P357.
   Bornkessel-Schlesewsky I, 2013, BRAIN LANG, V125, P60, DOI 10.1016/j.bandl.2013.01.010.
   Bornkessel-Schlesewsky I, 2011, BRAIN LANG, V117, P133, DOI 10.1016/j.bandl.2010.09.010.
   Bornkessel-Schlesewsky I, 2009, LANG LINGUIST COMPAS, V3, P19, DOI 10.1111/j.1749-818x.2008.00099.x.
   Bornkessel-Schlesewsky I, 2009, LINGUA, V119, P1541, DOI 10.1016/j.lingua.2008.03.005.
   Bornkessel-Schlesewsky I, 2008, BRAIN RES REV, V59, P55, DOI 10.1016/j.brainresrev.2008.05.003.
   Brouwer H, 2012, BRAIN RES, V1446, P127, DOI 10.1016/j.brainres.2012.01.055.
   Choudhary KK, 2009, NEUROPSYCHOLOGIA, V47, P3012, DOI 10.1016/j.neuropsychologia.2009.05.009.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   Coulson S, 1998, LANG COGNITIVE PROC, V13, P21, DOI 10.1080/016909698386582.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Dikker S, 2011, BRAIN LANG, V118, P23, DOI 10.1016/j.bandl.2011.02.006.
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751.
   Dikker S, 2009, COGNITION, V110, P293, DOI 10.1016/j.cognition.2008.09.008.
   DOMALSKI P, 1991, PSYCHOL SCI, V2, P173, DOI 10.1111/j.1467-9280.1991.tb00126.x.
   DONCHIN E, 1981, PSYCHOPHYSIOLOGY, V18, P493, DOI 10.1111/j.1469-8986.1981.tb01815.x.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Friederici AD, 2000, HUM BRAIN MAPP, V11, P1, DOI 10.1002/1097-0193(200009)11:1<1::AID-HBM10>3.0.CO;2-B.
   Friederici AD, 2004, NEUROREPORT, V15, P165, DOI 10.1097/00001756-200401190-00032.
   Friederici AD, 2002, J PSYCHOLINGUIST RES, V31, P45, DOI 10.1023/A:1014376204525.
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011.
   Frisch S, 2005, COGNITIVE BRAIN RES, V25, P484, DOI 10.1016/j.cogbrainres.2005.07.010.
   Frisch S, 2003, CLIN NEUROPHYSIOL, V114, P336, DOI 10.1016/S1388-2457(02)00366-8.
   Frisch S, 2001, NEUROREPORT, V12, P3391, DOI 10.1097/00001756-200110290-00048.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Gunter TC, 1999, PSYCHOPHYSIOLOGY, V36, P126, DOI 10.1017/S004857729997155X.
   Gunter TC, 1997, PSYCHOPHYSIOLOGY, V34, P660, DOI 10.1111/j.1469-8986.1997.tb02142.x.
   Hagoort P, 2003, COGNITIVE BRAIN RES, V16, P38, DOI 10.1016/S0926-6410(02)00208-2.
   Hagoort P, 2009, STRUNGMANN FORUM REP, P279.
   Hahne A, 1999, J COGNITIVE NEUROSCI, V11, P194, DOI 10.1162/089892999563328.
   Haider Hubert, 1998, SPRACHE PRAGMATIK, V49.
   Haupt FS, 2008, J MEM LANG, V59, P54, DOI 10.1016/j.jml.2008.02.003.
   Horberg T, 2013, LANG COGNITIVE PROC, V28, P388, DOI 10.1080/01690965.2011.651345.
   Huynh H., 1970, J AM STAT ASSOC, V65, P1582, DOI DOI 10.1080/01621459.1970.10481187.
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084.
   Kaan E, 2003, J COGNITIVE NEUROSCI, V15, P98, DOI 10.1162/089892903321107855.
   Kaan E, 2009, STRUNGMANN FORUM REP, P117.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   Kempe V, 1999, LANG COGNITIVE PROC, V14, P129, DOI 10.1080/016909699386329.
   Kolk H, 2007, BRAIN LANG, V100, P257, DOI 10.1016/j.bandl.2006.07.006.
   Kolk HHJ, 2003, BRAIN LANG, V85, P1, DOI 10.1016/S0093-934X(02)00548-5.
   Kretzschmar F., 2010, THESIS PHILIPPS U MA.
   Kuperberg GR, 2003, COGNITIVE BRAIN RES, V17, P117, DOI 10.1016/S0926-6410(03)00086-7.
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003.
   Lenerz Jurgen, 1977, STUDIEN DTSCH GRAMMA, V5.
   MACWHINNEY B, 1984, J VERB LEARN VERB BE, V23, P127, DOI 10.1016/S0022-5371(84)90093-8.
   Mauchly JW, 1940, ANN MATH STAT, V11, P204, DOI 10.1214/aoms/1177731915.
   Molinaro N, 2011, CORTEX, V47, P908, DOI 10.1016/j.cortex.2011.02.019.
   Mueller JL, 2005, J COGNITIVE NEUROSCI, V17, P1229, DOI 10.1162/0898929055002463.
   Munte TF, 1998, NEUROPSYCHOLOGIA, V36, P217, DOI 10.1016/s0028-3932(97)00119-x.
   Muralikrishnan R, 2015, BRAIN RES, V1608, P108, DOI 10.1016/j.brainres.2014.11.046.
   Nieuwland MS, 2013, BRAIN LANG, V126, P151, DOI 10.1016/j.bandl.2013.04.005.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Osterhout L, 1999, LANG COGNITIVE PROC, V14, P1, DOI 10.1080/016909699386356.
   Osterhout L, 1997, BRAIN LANG, V59, P494, DOI 10.1006/brln.1997.1793.
   OSTERHOUT L, 1992, J MEM LANG, V31, P785, DOI 10.1016/0749-596X(92)90039-Z.
   Osterhout L, 1996, J COGNITIVE NEUROSCI, V8, P507, DOI 10.1162/jocn.1996.8.6.507.
   OSTERHOUT L, 1994, J EXP PSYCHOL LEARN, V20, P786, DOI 10.1037/0278-7393.20.4.786.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019.
   Primus Beatrice, 1999, CASES THEMATIC ROLES.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rosler F, 1998, J MEM LANG, V38, P150, DOI 10.1006/jmla.1997.2551.
   Sassenhagen J, 2015, CORTEX, V66, pA3, DOI 10.1016/j.cortex.2014.12.019.
   Sassenhagen J, 2014, BRAIN LANG, V137, P29, DOI 10.1016/j.bandl.2014.07.010.
   Schlesewsky M, 2003, BRAIN LANG, V86, P116, DOI 10.1016/S0093-934X(02)00540-0.
   Schlesewsky M, 2006, J GER LINGUIST, V18, P1, DOI DOI 10.1017/S1470542706000018.
   Swaab T.Y., 2012, OXFORD HDB EVENT REL, P397, DOI DOI 10.1093/OXFORDHB/9780195374148.013.0197.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Tanner D, 2014, NEUROPSYCHOLOGIA, V56, P289, DOI 10.1016/j.neuropsychologia.2014.02.002.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   de Meerendonk N, 2009, LANG LINGUIST COMPAS, V3, DOI 10.1111/j.1749-818x.2009.00163.x.
   van de Meerendonk N, 2010, J COGNITIVE NEUROSCI, V22, P67, DOI 10.1162/jocn.2008.21170.
   van den Brink D, 2004, J COGNITIVE NEUROSCI, V16, P1068, DOI 10.1162/0898929041502670.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   van Herten M, 2006, J COGNITIVE NEUROSCI, V18, P1181, DOI 10.1162/jocn.2006.18.7.1181.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Vissers CTWM, 2008, NEUROPSYCHOLOGIA, V46, P967, DOI 10.1016/j.neuropsychologia.2007.11.027.
   Wang LM, 2009, LANG COGNITIVE PROC, V24, P1180, DOI 10.1080/01690960802159937.
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8.
   Wolff S, 2008, BRAIN LANG, V107, P133, DOI 10.1016/j.bandl.2008.06.003.}},
Number-of-Cited-References = {{98}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{22}},
Journal-ISO = {{Brain Res.}},
Doc-Delivery-Number = {{DG1PZ}},
Unique-ID = {{ISI:000371841300016}},
DA = {{2020-12-06}},
}

@article{ ISI:000389009300009,
Author = {Jensen, Tobias Lindstrom and Giacobello, Daniele and van Waterschoot,
   Toon and Christensen, Mads Graesboll},
Title = {{Fast algorithms for high-order sparse linear prediction with
   applications to speech processing}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2016}},
Volume = {{76}},
Pages = {{143-156}},
Month = {{FEB}},
Abstract = {{In speech processing applications, imposing sparsity constraints on
   high-order linear prediction coefficients and prediction residuals has
   proven successful in overcoming some of the limitation of conventional
   linear predictive modeling. However, this modeling scheme, named sparse
   linear prediction, is generally formulated as a linear programming
   problem that comes at the expenses of a much higher computational burden
   compared to the conventional approach. In this paper, we propose to
   solve the optimization problem by combining splitting methods with two
   approaches: the Douglas-Rachford method and the alternating direction
   method of multipliers. These methods allow to obtain solutions with a
   higher computational efficiency, orders of magnitude faster than with
   general purpose software based on interior-point methods. Furthermore,
   computational savings are achieved by solving the sparse linear
   prediction problem with lower accuracy than in previous work. In the
   experimental analysis, we clearly show that a solution with lower
   accuracy can achieve approximately the same performance as a high
   accuracy solution both objectively, in terms of prediction gain, as well
   as with perceptually relevant measures, when evaluated in a speech
   reconstruction application. (C) 2015 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jensen, TL (Corresponding Author), Aalborg Univ, Signal \& Informat Proc, Dept Elect Syst, Aalborg, Denmark.
   Jensen, Tobias Lindstrom; Giacobello, Daniele, Aalborg Univ, Signal \& Informat Proc, Dept Elect Syst, Aalborg, Denmark.
   van Waterschoot, Toon, Katholieke Univ Leuven, Ctr Dynam Syst Signal Proc \& Data Analyt STADIUS, Dept Elect Engn ESAT, Leuven, Belgium.
   Christensen, Mads Graesboll, Aalborg Univ, Audio Anal Lab, AD MT, Aalborg, Denmark.}},
DOI = {{10.1016/j.specom.2015.09.013}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Sparse linear prediction; Speech and audio processing; Linear
   programming; Real-time optimization; Speech reconstruction; Packet loss
   concealment}},
Keywords-Plus = {{JOINT ESTIMATION; SHORT-TERM; OPTIMIZATION; RECOVERY; TOEPLITZ}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{tlj@es.aau.dk
   giacobello@ieee.org
   toon.vanwaterschoot@esat.kuleuven.be
   mgc@create.aau.dk}},
ResearcherID-Numbers = {{Christensen, Mads G/I-4132-2018
   Giacobello, Daniele/J-7962-2013
   Giacobello, Daniele/AAI-3724-2020
   Jensen, Tobias Lindstrom/L-3096-2015
   van Waterschoot, Toon/A-8145-2015}},
ORCID-Numbers = {{Christensen, Mads G/0000-0003-3586-7969
   Giacobello, Daniele/0000-0001-8708-8604
   Giacobello, Daniele/0000-0001-8708-8604
   Jensen, Tobias Lindstrom/0000-0003-4262-0577
   van Waterschoot, Toon/0000-0002-6323-7350}},
Funding-Acknowledgement = {{Villum Fonden {[}00007165] Funding Source: researchfish}},
Cited-References = {{Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910.
   Alipoor G, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P454, DOI 10.1109/TSP.2012.6256335.
   AMMAR GS, 1988, SIAM J MATRIX ANAL A, V9, P61, DOI 10.1137/0609005.
   Andersen ED, 2003, MATH PROGRAM, V95, P249, DOI 10.1007/s10107-002-0349-3.
   Angelosante Daniele, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P335, DOI 10.1109/ICASSP.2014.6853613.
   Angelosante D, 2013, IEEE SIGNAL PROC MAG, V30, P64, DOI 10.1109/MSP.2013.2267231.
   Atal BS, 2006, IEEE SIGNAL PROC MAG, V23, P154, DOI 10.1109/MSP.2006.1598091.
   ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679.
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542.
   Bensmida S., 2012, IEEE INT MICR S DIG, P1.
   Bessette B, 2002, IEEE T SPEECH AUDI P, V10, P620, DOI 10.1109/TSA.2002.804299.
   Bilekstrom T., 2004, THESIS.
   BITMEAD RR, 1980, LINEAR ALGEBRA APPL, V34, P103, DOI 10.1016/0024-3795(80)90161-5.
   BOCHUD N, 2013, INT CONF ACOUST SPEE, P2844.
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016.
   Christensen M., 2009, MULTIPITCH ESTIMATIO.
   Combettes PL, 2007, IEEE J-STSP, V1, P564, DOI 10.1109/JSTSP.2007.910264.
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090.
   Defraene B, 2014, IEEE-ACM T AUDIO SPE, V22, P1648, DOI 10.1109/TASLP.2014.2344862.
   Defraene B, 2012, IEEE T AUDIO SPEECH, V20, P2657, DOI 10.1109/TASL.2012.2210875.
   DENOEL E, 1985, IEEE T ACOUST SPEECH, V33, P1397, DOI 10.1109/TASSP.1985.1164759.
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100.
   Douglas J, 1956, T AM MATH SOC, V82, P421, DOI {[}10.1090/S0002-9947-1956-0084194-4, DOI 10.1090/S0002-9947-1956-0084194-4].
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204.
   Ekman LA, 2008, IEEE T AUDIO SPEECH, V16, P65, DOI 10.1109/TASL.2007.909448.
   ELJAROUDI A, 1991, IEEE T SIGNAL PROCES, V39, P411, DOI 10.1109/78.80824.
   Erer I, 2014, EUR SIGNAL PR CONF, P1751.
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301.
   Gabay D., 1976, Computers \& Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1.
   Gabay D., 1983, AUGMENTED LAGRANGIAN, P299, DOI DOI 10.1016/S0168-2024(08)70034-1.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Gersho Allen, 1992, VECTOR QUANTIZATION.
   Giacobello Daniele, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2524.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Giacobello D, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1353.
   Giacobello D, 2009, INT CONF ACOUST SPEE, P4109, DOI 10.1109/ICASSP.2009.4960532.
   GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41.
   Godsill S. J., 1998, DIGITAL AUDIO RESTOR.
   Golub G. H., 2013, MATRIX COMPUTATIONS.
   Grant M, 2011, CVX MATLAB SOFTWARE.
   Halberstadt A., 1997, EUROSPEECH, P401.
   Hansen J. H. L., 1987, DISCRETE TIME PROCES, DOI Englewood Cliffs, NJ, USA.
   HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   ITAKURA F, 1970, ELECTRON COMMUN JPN, V53, P36.
   ITU-T, 2010, PERC OBJ LIST QUAL A, P863.
   JAIN JR, 1979, IEEE T ACOUST SPEECH, V27, P612, DOI 10.1109/TASSP.1979.1163313.
   Jensen TL, 2013, INT CONF ACOUST SPEE, P8184, DOI 10.1109/ICASSP.2013.6639260.
   KABAL P, 1989, IEEE T ACOUST SPEECH, V37, P642, DOI 10.1109/29.17556.
   Kameoka H, 2010, IEEE T AUDIO SPEECH, V18, P1507, DOI 10.1109/TASL.2009.2036287.
   KAY SM, 1979, IEEE T ACOUST SPEECH, V27, P478, DOI 10.1109/TASSP.1979.1163275.
   Koloda J, 2013, IEEE T MULTIMEDIA, V15, P957, DOI 10.1109/TMM.2013.2238524.
   LEE CH, 1988, IEEE T ACOUST SPEECH, V36, P642, DOI 10.1109/29.1574.
   LEVINSON N, 1946, J MATH PHYS CAMB, V25, P261, DOI 10.1002/sapm1946251261.
   LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Mattingley J, 2012, OPTIM ENG, V13, P1, DOI 10.1007/s11081-011-9176-9.
   Mattingley J, 2010, IEEE SIGNAL PROC MAG, V27, P50, DOI 10.1109/MSP.2010.936020.
   Moreau J-J, 1965, B SOC MATH FRANCE, V93, P273, DOI 10.24033/bsmf.1625.
   Murthi MN, 1998, INT CONF ACOUST SPEE, P369, DOI 10.1109/ICASSP.1998.674444.
   Murthi MN, 2000, IEEE T SPEECH AUDI P, V8, P221, DOI 10.1109/89.841206.
   Nesterov Y., 2007, CTR OPERATIONS RES E.
   Nesterov Y., 1994, INTERIOR POINT POLYN.
   O'Connor D, 2014, SIAM J IMAGING SCI, V7, P1724, DOI 10.1137/13094671X.
   Patrinos P, 2014, IEEE DECIS CONTR P, P4234, DOI 10.1109/CDC.2014.7040049.
   Saito S., 1967, J AEOUST SOC JPN.
   SPINGARN JE, 1985, MATH PROGRAM, V32, P199, DOI 10.1007/BF01586091.
   Stoica P., 2005, SPECTRAL ANAL SIGNAL.
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.
   Vaidyanathan P.P., 2009, THEORY LINEAR PREDIC.
   van Waterschoot T, 2008, EURASIP J AUDIO SPEE, DOI 10.1155/2008/706935.
   Vandenberghe L., 2013, DOUGLAS RACHFORD MET.
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892.
   Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761.
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983.}},
Number-of-Cited-References = {{77}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{ED7AY}},
Unique-ID = {{ISI:000389009300009}},
DA = {{2020-12-06}},
}

@article{ ISI:000366538600012,
Author = {Chen, Fei},
Title = {{Predicting the intelligibility of noise-corrupted speech non-intrusively
   by across-band envelope correlation}},
Journal = {{BIOMEDICAL SIGNAL PROCESSING AND CONTROL}},
Year = {{2016}},
Volume = {{24}},
Pages = {{109-113}},
Month = {{FEB}},
Abstract = {{Recent psychoacoustic studies found that across-band envelope
   correlation (ABEC) carried important information for speech
   intelligibility. This motivated the present work to propose an
   ABEC-based intelligibility measure that could be used to non-intrusively
   predict speech intelligibility in noise using only temporal envelope
   waveforms extracted from the noise-corrupted speech. The proposed
   ABEC-based metric (denoted as ABECm) was computed by averaging the
   correlation coefficients of mean-removed envelope waveforms from
   adjacent frequency bands of the noise-corrupted speech. The ABECm
   measures were evaluated with intelligibility scores obtained from
   normal-hearing listeners presented with sentences corrupted by four
   types of maskers in a total of 22 conditions. High correlation (r= 0.96)
   was obtained between ABECm values and listeners' sentence recognition
   scores, and this correlation was comparable to those computed with
   existing intrusive and non-intrusive intelligibility measures. This
   suggests that across-band envelope correlation may work as a simple but
   efficient predictor of speech intelligibility in noise, whose
   computation does not need access to the clean reference signal. (C) 2015
   Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chen, F (Corresponding Author), South Univ Sci \& Technol China, Dept Elect \& Elect Engn, Xueyuan Rd 1088, Shenzhen 518055, Guangdong, Peoples R China.
   Chen, Fei, South Univ Sci \& Technol China, Dept Elect \& Elect Engn, Shenzhen 518055, Guangdong, Peoples R China.}},
DOI = {{10.1016/j.bspc.2015.09.007}},
ISSN = {{1746-8094}},
EISSN = {{1746-8108}},
Keywords = {{Speech perception in noise; Intelligibility prediction; Across-band
   envelope correlation}},
Keywords-Plus = {{REVERBERANT; LISTENERS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Biomedical}},
Author-Email = {{fchen@sustc.edu.cn}},
ResearcherID-Numbers = {{Chen, Fei/G-4674-2018
   Chen, Fei/AAK-6755-2020}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61571213]}},
Funding-Text = {{This work was partially supported by the National Natural Science
   Foundation of China (grant no. 61571213).}},
Cited-References = {{{[}Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225.
   Chen F, 2013, BIOMED SIGNAL PROCES, V8, P311, DOI 10.1016/j.bspc.2012.11.007.
   Chen F, 2010, J ACOUST SOC AM, V128, P3715, DOI 10.1121/1.3502473.
   Crouzet O, 2001, WORKSH CONS REL AC C.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052.
   Healy EW, 2005, J SPEECH LANG HEAR R, V48, P1236, DOI 10.1044/1092-4388(2005/085).
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Loizou PC, 2013, SPEECH ENHANCEMENT T.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Roberts B, 2011, P ROY SOC B-BIOL SCI, V278, P1595, DOI 10.1098/rspb.2010.1554.
   Santos JF, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P55, DOI 10.1109/IWAENC.2014.6953337.
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Biomed. Signal Process. Control}},
Doc-Delivery-Number = {{CY6SH}},
Unique-ID = {{ISI:000366538600012}},
DA = {{2020-12-06}},
}

@article{ ISI:000365627300003,
Author = {Huettig, Falk and Mani, Nivedita},
Title = {{Is prediction necessary to understand language? Probably not}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2016}},
Volume = {{31}},
Number = {{1, SI}},
Pages = {{19-31}},
Month = {{JAN 2}},
Abstract = {{Some recent theoretical accounts in the cognitive sciences suggest that
   prediction is necessary to understand language. Here we evaluate this
   proposal. We consider arguments that prediction provides a unified
   theoretical principle of the human mind and that it pervades cortical
   function. We discuss whether evidence of human abilities to detect
   statistical regularities is necessarily evidence for predictive
   processing and evaluate suggestions that prediction is necessary for
   language learning. We point out that not all language users appear to
   predict language and that suboptimal input makes prediction often very
   challenging. Prediction, moreover, is strongly context-dependent and
   impeded by resource limitations. We also argue that it may be
   problematic that most experimental evidence for predictive language
   processing comes from prediction-encouraging experimental set-ups. We
   conclude that languages can be learned and understood in the absence of
   prediction. Claims that all language processing is predictive in nature
   are premature.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Huettig, F (Corresponding Author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   Huettig, Falk, Max Planck Inst Psycholinguist, NL-6500 AH Nijmegen, Netherlands.
   Huettig, Falk, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, NL-6525 ED Nijmegen, Netherlands.
   Mani, Nivedita, Univ Gottingen, Psychol Language Grp, D-37073 Gottingen, Germany.}},
DOI = {{10.1080/23273798.2015.1072223}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Cognition; language processing; learning; prediction; predictive coding}},
Keywords-Plus = {{AGE-RELATED-CHANGES; EYE-MOVEMENTS; INDIVIDUAL-DIFFERENCES; TRANSITIONAL
   PROBABILITIES; COMPUTATIONAL PRINCIPLES; WORD RECOGNITION; UPCOMING
   WORDS; VISUAL WORLD; FREQUENCY; PREDICTABILITY}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{falk.huettig@mpi.nl}},
ResearcherID-Numbers = {{Mani, Nivedita/F-8795-2010}},
ORCID-Numbers = {{Mani, Nivedita/0000-0002-9843-4629}},
Cited-References = {{Altarriba J, 1996, MEM COGNITION, V24, P477, DOI 10.3758/BF03200936.
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Anderson ML, 2013, BEHAV BRAIN SCI, V36, P204, DOI 10.1017/S0140525X1200221X.
   Ashby J, 2005, Q J EXP PSYCHOL-A, V58, P1065, DOI 10.1080/02724980443000476.
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283.
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038.
   BATES E, 1993, DEV REV, V13, P436, DOI 10.1006/drev.1993.1020.
   Block N, 2013, BEHAV BRAIN SCI, V36, P205, DOI 10.1017/S0140525X12002245.
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6.
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005.
   Bowman H, 2013, BEHAV BRAIN SCI, V36, P206, DOI 10.1017/S0140525X12002324.
   Bressler SL, 2015, CURR OPIN NEUROBIOL, V31, P62, DOI 10.1016/j.conb.2014.08.010.
   Brouwer S, 2013, APPL PSYCHOLINGUIST, V34, P519, DOI 10.1017/S0142716411000853.
   Carrasco M, 2004, NAT NEUROSCI, V7, P308, DOI 10.1038/nn1194.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Chang F, 2013, BEHAV BRAIN SCI, V36, P350, DOI 10.1017/S0140525X12002518.
   Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009.
   Davidson DJ, 2007, BRAIN RES, V1158, P81, DOI 10.1016/j.brainres.2007.04.082.
   De Ruiter JP, 2006, LANGUAGE, V82, P515, DOI 10.1353/lan.2006.0130.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844.
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015.
   Farmer TA, 2013, BEHAV BRAIN SCI, V36, P211, DOI 10.1017/S0140525X12002312.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006.
   Frisson S, 2005, J EXP PSYCHOL LEARN, V31, P862, DOI 10.1037/0278-7393.31.5.862.
   Friston KJ, 2015, CURR OPIN NEUROBIOL, V31, P1, DOI 10.1016/j.conb.2014.05.004.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Gibson E, 2013, P NATL ACAD SCI USA, V110, P8051, DOI 10.1073/pnas.1216438110.
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063.
   Gollan TH, 2011, J EXP PSYCHOL GEN, V140, P186, DOI 10.1037/a0022256.
   Hagoort P, 2004, SCIENCE, V304, P438, DOI 10.1126/science.1095455.
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004.
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416.
   Hahn U., 2008, PROBABILISTIC MIND, P121.
   Hahne A., 2001, BILING-LANG COGN, V4, P123, DOI DOI 10.1017/S1366728901000232.
   Hald LA, 2006, BRAIN LANG, V96, P90, DOI 10.1016/j.bandl.2005.06.007.
   Hand CJ, 2010, J EXP PSYCHOL HUMAN, V36, P1294, DOI 10.1037/a0020363.
   Huang HW, 2012, NEUROPSYCHOLOGIA, V50, P26, DOI 10.1016/j.neuropsychologia.2011.10.018.
   Huettig F, 2007, J MEM LANG, V57, P460, DOI 10.1016/j.jml.2007.02.001.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Huettig F, 2015, DYSLEXIA, V21, P97, DOI 10.1002/dys.1497.
   Huettig F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00285.
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003.
   Huettig F, 2011, ACTA PSYCHOL, V137, P138, DOI 10.1016/j.actpsy.2010.07.013.
   Jackendoff R, 2007, BRAIN RES, V1146, P2, DOI 10.1016/j.brainres.2006.08.111.
   Johnson K, 2004, PHILOS SCI, V71, P571, DOI 10.1086/423752.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kennedy A, 2013, Q J EXP PSYCHOL, V66, P601, DOI 10.1080/17470218.2012.676054.
   Kidd E, 2012, DEV PSYCHOL, V48, P171, DOI 10.1037/a0025405.
   Kielar A, 2014, J COGNITIVE NEUROSCI, V26, P2840, DOI 10.1162/jocn\_a\_00670.
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695.
   Kliegl R, 2004, EUR J COGN PSYCHOL, V16, P262, DOI 10.1080/09541440340000213.
   Kretzschmar F., J EXPT PSYCHOL LEARN.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014.
   Luo Y, 2010, NEUROSCIENCE, V169, P654, DOI 10.1016/j.neuroscience.2010.05.032.
   MacWhinney B, 2004, J CHILD LANG, V31, P883, DOI 10.1017/S0305000904006336.
   Mani N, 2014, J EXP CHILD PSYCHOL, V126, P264, DOI 10.1016/j.jecp.2014.05.004.
   Mani N, 2012, J MEM LANG, V66, P612, DOI 10.1016/j.jml.2012.03.003.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Mani N, 2011, COGNITION, V121, P196, DOI 10.1016/j.cognition.2011.06.013.
   Mani N, 2010, PSYCHOL SCI, V21, P908, DOI 10.1177/0956797610373371.
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   McDonald SA, 2003, PSYCHOL SCI, V14, P648, DOI 10.1046/j.0956-7976.2003.psci\_1480.x.
   McDonald SA, 2003, VISION RES, V43, P1735, DOI 10.1016/S0042-6989(03)00237-2.
   McQueen JM, 2014, ATTEN PERCEPT PSYCHO, V76, P190, DOI 10.3758/s13414-013-0560-8.
   Meyer AS, 2007, PSYCHON B REV, V14, P710, DOI 10.3758/BF03196826.
   Mishra RK, 2012, J EYE MOVEMENT RES, V5.
   Misyak JB, 2010, TOP COGN SCI, V2, P138, DOI 10.1111/j.1756-8765.2009.01072.x.
   Mitterer H, 2013, J EXP PSYCHOL LEARN, V39, P977, DOI 10.1037/a0029196.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Norris D, 2006, PSYCHOL REV, V113, P327, DOI 10.1037/0033-295X.113.2.327.
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142.
   Pelucchi B, 2009, COGNITION, V113, P244, DOI 10.1016/j.cognition.2009.07.011.
   Penolazzi B, 2009, NEUROSCI LETT, V465, P74, DOI 10.1016/j.neulet.2009.08.065.
   Perruchet P, 2008, MEM COGNITION, V36, P1299, DOI 10.3758/MC.36.7.1299.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Popper K, 2014, LOGIC SCI DISCOVERY.
   Rasmussen D, 2013, BEHAV BRAIN SCI, V36, P223, DOI 10.1017/S0140525X12002154.
   Rayner K, 2004, J EXP PSYCHOL HUMAN, V30, P720, DOI 10.1037/0096-1523.30.4.720.
   Rayner K, 2006, PSYCHOL AGING, V21, P448, DOI 10.1037/0882-7974.21.3.448.
   Rayner K, 2009, BIOL PSYCHOL, V80, P4, DOI 10.1016/j.biopsycho.2008.05.002.
   Rohde DLT, 1999, COGNITION, V72, P67, DOI 10.1016/S0010-0277(99)00031-1.
   Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78.
   Rommers J, 2013, J COGNITIVE NEUROSCI, V25, P762, DOI 10.1162/jocn\_a\_00337.
   Rommers J, 2013, NEUROPSYCHOLOGIA, V51, P437, DOI 10.1016/j.neuropsychologia.2012.12.002.
   Rowland CF, 2012, COGNITION, V125, P49, DOI 10.1016/j.cognition.2012.06.008.
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926.
   Seidenberg MS, 1999, COGNITIVE SCI, V23, P569, DOI 10.1016/S0364-0213(99)00016-6.
   Sloman A, 2013, BEHAV BRAIN SCI, V36, P230, DOI 10.1017/S0140525X12002439.
   St Clair MC, 2009, COGNITIVE SCI, V33, P1317, DOI 10.1111/j.1551-6709.2009.01065.x.
   Staub A, 2013, PSYCHON B REV, V20, P1304, DOI 10.3758/s13423-013-0444-x.
   Staub A, 2011, PSYCHON B REV, V18, P371, DOI 10.3758/s13423-010-0046-9.
   Tremblay P, 2013, NEUROIMAGE, V66, P318, DOI 10.1016/j.neuroimage.2012.10.055.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Wang L, 2012, HUM BRAIN MAPP, V33, P2898, DOI 10.1002/hbm.21410.
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008.
   Whitford V, 2014, Q J EXP PSYCHOL, V67, P1151, DOI 10.1080/17470218.2013.848216.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wlotko EW, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00181.
   Wlotko EW, 2012, PSYCHOPHYSIOLOGY, V49, P770, DOI 10.1111/j.1469-8986.2012.01366.x.}},
Number-of-Cited-References = {{112}},
Times-Cited = {{97}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{47}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{CX3VJ}},
Unique-ID = {{ISI:000365627300003}},
OA = {{Other Gold, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000365627300004,
Author = {Kuperberg, Gina R. and Jaeger, T. Florian},
Title = {{What do we mean by prediction in language comprehension?}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2016}},
Volume = {{31}},
Number = {{1, SI}},
Pages = {{32-59}},
Month = {{JAN 2}},
Abstract = {{We consider several key aspects of prediction in language comprehension:
   its computational nature, the representational level(s) at which we
   predict, whether we use higher-level representations to predictively
   pre-activate lower level representations, and whether we commit in any
   way to our predictions, beyond pre-activation. We argue that the bulk of
   behavioural and neural evidence suggests that we predict
   probabilistically and at multiple levels and grains of representation.
   We also argue that we can, in principle, use higher-level inferences to
   predictively pre-activate information at multiple lower representational
   levels. We suggest that the degree and level of predictive
   pre-activation might be a function of its expected utility, which, in
   turn, may depend on comprehenders' goals and their estimates of the
   relative reliability of their prior knowledge and the bottom-up input.
   Finally, we argue that all these properties of language understanding
   can be naturally explained and productively explored within a
   multi-representational hierarchical actively generative architecture
   whose goal is to infer the message intended by the producer, and in
   which predictions play a crucial role in explaining the bottom-up input.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kuperberg, GR (Corresponding Author), Tufts Univ, Dept Psychol, Medford, MA 02155 USA.
   Kuperberg, Gina R., Tufts Univ, Dept Psychol, Medford, MA 02155 USA.
   Kuperberg, Gina R., Tufts Univ, Ctr Cognit Sci, Medford, MA 02155 USA.
   Kuperberg, Gina R., Harvard Univ, Sch Med, Massachusetts Gen Hosp, Dept Psychiat, Charlestown, MA USA.
   Kuperberg, Gina R., Harvard Univ, Sch Med, Athinoula A Martinos Ctr Biomed Imaging, Massachusetts Gen Hosp, Charlestown, MA USA.
   Jaeger, T. Florian, Univ Rochester, Dept Brain \& Cognit Sci, Rochester, MA USA.
   Jaeger, T. Florian, Univ Rochester, Dept Comp Sci, Rochester, MA USA.
   Jaeger, T. Florian, Univ Rochester, Dept Linguist, Rochester, MA USA.}},
DOI = {{10.1080/23273798.2015.1102299}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Language comprehension; prediction error; generative model;
   probabilistic; surprisal}},
Keywords-Plus = {{THEMATIC ROLE-ASSIGNMENT; SPOKEN WORD RECOGNITION; PARAFOVEAL VISUAL
   INFORMATION; INTERACTIVE ACTIVATION MODEL; EYE-MOVEMENTS; SENTENCE
   COMPREHENSION; PROBABILISTIC MODELS; TIME-COURSE; SEMANTIC RELATEDNESS;
   REFERENTIAL DOMAINS}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{kuperber@nmr.mgh.harvard.edu}},
ResearcherID-Numbers = {{Jaeger, T. Florian/O-8224-2019}},
ORCID-Numbers = {{Jaeger, T. Florian/0000-0002-1158-7308}},
Funding-Acknowledgement = {{NIMHUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) {[}R01 MH071635]; NICHDUnited States Department of Health \&
   Human ServicesNational Institutes of Health (NIH) - USANIH Eunice
   Kennedy Shriver National Institute of Child Health \& Human Development
   (NICHD) {[}R01 HD082527, R01 HD075797]; NSF CAREER grantNational Science
   Foundation (NSF)NSF - Office of the Director (OD) {[}IIS 1150028];
   Direct For Computer \& Info Scie \& EnginrNational Science Foundation
   (NSF)NSF - Directorate for Computer \& Information Science \&
   Engineering (CISE) {[}1150028] Funding Source: National Science
   Foundation; Div Of Information \& Intelligent SystemsNational Science
   Foundation (NSF)NSF - Directorate for Computer \& Information Science \&
   Engineering (CISE) {[}1150028] Funding Source: National Science
   Foundation; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH \&
   HUMAN DEVELOPMENTUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health \& Human Development (NICHD)
   {[}R01HD075797, R01HD082527, R01HD075797, R01HD082527, R01HD075797,
   R01HD082527, R01HD082527, R01HD075797, R01HD075797, R01HD082527] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States
   Department of Health \& Human ServicesNational Institutes of Health
   (NIH) - USANIH National Institute of Mental Health (NIMH)
   {[}R01MH071635, R01MH071635, R01MH071635, R01MH071635, R01MH071635,
   R01MH071635, R01MH071635, R01MH071635, R01MH071635, R01MH071635,
   R01MH071635] Funding Source: NIH RePORTER}},
Funding-Text = {{This work was partially funded by NIMH {[}R01 MH071635] and NICHD {[}R01
   HD082527] grants to G. R. K., as well as by NICHD {[}R01 HD075797] and
   an NSF CAREER grant {[}IIS 1150028] to T. F. J.}},
Cited-References = {{Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558.
   ALTMANN G, 1988, COGNITION, V30, P191, DOI 10.1016/0010-0277(88)90020-0.
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004.
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, J MEM LANG, V41, P124, DOI 10.1006/jmla.1999.2640.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Anderson J. R., 1990, ADAPTIVE CHARACTER T.
   Arai M, 2013, LANG COGNITIVE PROC, V28, P525, DOI 10.1080/01690965.2012.658072.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914.
   Arnon I, 2010, J MEM LANG, V62, P67, DOI 10.1016/j.jml.2009.09.005.
   Attwell D, 2001, J CEREBR BLOOD F MET, V21, P1133, DOI 10.1097/00004647-200110000-00001.
   BALOTA DA, 1985, COGNITIVE PSYCHOL, V17, P364, DOI 10.1016/0010-0285(85)90013-1.
   Becker C. A., 1985, READING RES ADV THEO, V5, P125.
   BECKER CA, 1980, MEM COGNITION, V8, P493, DOI 10.3758/BF03213769.
   Bejjanki VR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019812.
   Bever T., 1970, COGNITION DEV LANGUA, P279, DOI DOI 10.1093/ACPROF:OSO/9780199677139.003.0001.
   Bicknell K, 2012, VIS COGN, V20, P422, DOI 10.1080/13506285.2012.668144.
   Bock K., 1987, Natural Language Generation: New Results in Artificial Intelligence, Psychology and Linguistics. Proceedings of the NATO Advanced Research Workshop, P351.
   Bock K., 1994, HDB PSYCHOLINGUISTIC, P945.
   Bornkessel-Schlesewsky I, 2009, LANG LINGUIST COMPAS, V3, P19, DOI 10.1111/j.1749-818x.2008.00099.x.
   Boston MF, 2008, J EYE MOVEMENT RES, V2.
   Brothers T, 2015, COGNITION, V136, P135, DOI 10.1016/j.cognition.2014.10.017.
   Brown-Schmidt S, 2008, COGNITIVE SCI, V32, P643, DOI 10.1080/03640210802066816.
   Brown-Schmidt S, 2015, PSYCHOL LEARN MOTIV, V62, P59, DOI 10.1016/bs.plm.2014.09.003.
   BUSH RR, 1951, PSYCHOL REV, V58, P313, DOI 10.1037/h0054388.
   Camblin CC, 2007, BRAIN RES, V1146, P172, DOI 10.1016/j.brainres.2006.07.033.
   CEDERGREN HJ, 1974, LANGUAGE, V50, P333, DOI 10.2307/412441.
   Chambers CG, 2004, J EXP PSYCHOL LEARN, V30, P687, DOI 10.1037/0278-7393.30.3.687.
   Chambers CG, 2002, J MEM LANG, V47, P30, DOI 10.1006/jmla.2001.2832.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Chater N., 1998, RATIONAL MODELS COGN, P441.
   Chater N, 2006, TRENDS COGN SCI, V10, P335, DOI 10.1016/j.tics.2006.05.006.
   Chomsky N., 1965, ASPECTS THEORY SYNTA.
   CHWILLA DJ, 1995, PSYCHOPHYSIOLOGY, V32, P274, DOI 10.1111/j.1469-8986.1995.tb02956.x.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Clark H. H., 1992, ARENAS LANGUAGE USE.
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004.
   COLE RA, 1980, J VERB LEARN VERB BE, V19, P297, DOI 10.1016/S0022-5371(80)90239-X.
   CONNINE CM, 1991, J MEM LANG, V30, P234, DOI 10.1016/0749-596X(91)90005-5.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   Crain S., 1985, NATURAL LANGUAGE PAR, P320, DOI DOI 10.1017/CBO9780511597855.011.
   Crocker MW, 2000, J PSYCHOLINGUIST RES, V29, P647, DOI 10.1023/A:1026560822390.
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, V2, P249, DOI DOI 10.1016/B978-012369374-7/50009-2.
   Dahan D, 2010, CURR DIR PSYCHOL SCI, V19, P121, DOI 10.1177/0963721410364726.
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014.
   DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889.
   Dayan P, 1996, NEURAL NETWORKS, V9, P1385, DOI 10.1016/S0893-6080(96)00009-3.
   De Ruiter JP, 2006, LANGUAGE, V82, P515, DOI 10.1353/lan.2006.0130.
   Dell G. S., 1991, BRIDGES PSYCHOL LING, P105.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DeLong KA, 2014, LANG LINGUIST COMPAS, V8, P631, DOI 10.1111/lnc3.12093.
   Demberg V, 2013, COMPUT LINGUIST, V39, P1025, DOI 10.1162/COLI\_a\_00160.
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008.
   Dikker S, 2013, BRAIN LANG, V127, P55, DOI 10.1016/j.bandl.2012.08.004.
   Dikker S, 2011, BRAIN LANG, V118, P23, DOI 10.1016/j.bandl.2011.02.006.
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751.
   Dikker S, 2009, COGNITION, V110, P293, DOI 10.1016/j.cognition.2008.09.008.
   DowtyDavid R, 1979, WORD MEANING MONTAGU.
   Doya K, 2007, BAYESIAN BRAIN PROBA.
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6.
   Elman J. L., 1984, SPEECH LANGUAGE, V10, P337.
   Elman Jeffrey L, 2004, NATURE NURTURE ESSAY, P111, DOI DOI 10.4324/9781410611192.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015.
   Farmer TA, 2006, P NATL ACAD SCI USA, V103, P12203, DOI 10.1073/pnas.0602173103.
   Farmer TA, 2013, BEHAV BRAIN SCI, V36, P211, DOI 10.1017/S0140525X12002312.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Federmeier KD, 2005, MEM COGNITION, V33, P871, DOI 10.3758/BF03193082.
   Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215.
   Feldman NH, 2013, PSYCHOL REV, V120, P751, DOI 10.1037/a0034245.
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196.
   FERREIRA F, 1986, J MEM LANG, V25, P348, DOI 10.1016/0749-596X(86)90006-9.
   Ferreira F, 2003, COGNITIVE PSYCHOL, V47, P164, DOI 10.1016/S0010-0285(03)00005-7.
   Ferreira F, 2001, J PSYCHOLINGUIST RES, V30, P3, DOI 10.1023/A:1005290706460.
   Ferreira F, 2013, J MEM LANG, V69, P165, DOI 10.1016/j.jml.2013.06.001.
   Ferreira F, 2007, LANG LINGUIST COMPAS, V1, P71, DOI 10.1111/j.1749-818x.2007.00007.x.
   Fillmore CJ, 2006, COGN LINGUIST RES, V34, P373, DOI 10.1515/9783110199901.373.
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661.
   FISCHLER I, 1979, J VERB LEARN VERB BE, V18, P1, DOI 10.1016/S0022-5371(79)90534-6.
   Fodor J, 1983, MODULARITY MIND ESSA.
   FORSTER KI, 1981, Q J EXP PSYCHOL-A, V33, P465, DOI 10.1080/14640748108400804.
   Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006.
   Frank SL, 2013, TOP COGN SCI, V5, P475, DOI 10.1111/tops.12025.
   Frank SL, 2011, PSYCHOL SCI, V22, P829, DOI 10.1177/0956797611409589.
   FRAUENFELDER UH, 1987, COGNITION, V25, P1, DOI 10.1016/0010-0277(87)90002-3.
   Frisson S, 2005, J EXP PSYCHOL LEARN, V31, P862, DOI 10.1037/0278-7393.31.5.862.
   Friston K, 2015, COGN NEUROSCI-UK, V6, P187, DOI 10.1080/17588928.2015.1020053.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000081.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Fruchter J, 2015, J COGNITIVE NEUROSCI, V27, P1912, DOI 10.1162/jocn\_a\_00822.
   Garnsey SM, 1997, J MEM LANG, V37, P58, DOI 10.1006/jmla.1997.2512.
   Garrod S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00751.
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646.
   Gaskell MG, 2003, J PHONETICS, V31, P447, DOI 10.1016/S0095-4470(03)00012-3.
   Gaskell MG, 1999, COGNITIVE SCI, V23, P439.
   Gershman SJ, 2012, LEARN BEHAV, V40, P255, DOI 10.3758/s13420-012-0080-8.
   Gibson E, 2000, J PSYCHOLINGUIST RES, V29, P231, DOI 10.1023/A:1005153330168.
   Gibson E, 2013, LANG COGNITIVE PROC, V28, P125, DOI 10.1080/01690965.2010.536656.
   GORRELL P, 1989, J PSYCHOLINGUIST RES, V18, P61, DOI 10.1007/BF01069047.
   Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211.
   Griffiths TL, 2015, TOP COGN SCI, V7, P217, DOI 10.1111/tops.12142.
   Griffiths TL, 2010, TRENDS COGN SCI, V14, P357, DOI 10.1016/j.tics.2010.05.004.
   Groppe DM, 2010, BRAIN RES, V1361, P54, DOI 10.1016/j.brainres.2010.09.003.
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386.
   Hagoort P., 2009, COGNITIVE NEUROSCIEN, P819.
   Hale J, 2003, J PSYCHOLINGUIST RES, V32, P101, DOI 10.1023/A:1022492123056.
   Hale JT, 2011, COGNITIVE SCI, V35, P399, DOI 10.1111/j.1551-6709.2010.01145.x.
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn\_a\_00103.
   Hare M, 2003, J MEM LANG, V48, P281, DOI 10.1016/S0749-596X(02)00516-8.
   Hare M, 2007, J MEM LANG, V56, P410, DOI 10.1016/j.jml.2006.08.007.
   Hartshorne JK, 2015, LANG COGN NEUROSCI, V30, P716, DOI 10.1080/23273798.2015.1008524.
   Hayhoe M, 2005, TRENDS COGN SCI, V9, P188, DOI 10.1016/j.tics.2005.02.009.
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004.
   Hohwy J, 2008, COGNITION, V108, P687, DOI 10.1016/j.cognition.2008.05.010.
   Howes A, 2009, PSYCHOL REV, V116, P717, DOI 10.1037/a0017187.
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223.
   Hutchison KA, 2007, J EXP PSYCHOL LEARN, V33, P645, DOI 10.1037/0278-7393.33.4.645.
   Jackendoff R., 2002, FDN LANGUAGE BRAIN M.
   Jackendoff R., 1987, LANGUAGE PROCESSING, P91.
   Jaeger TF, 2013, BEHAV BRAIN SCI, V36, P359, DOI 10.1017/S0140525X12002762.
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013.
   Jaeger TF, 2010, COGNITIVE PSYCHOL, V61, P23, DOI 10.1016/j.cogpsych.2010.02.002.
   Johnson-Laird P.N, 1983, MENTAL MODELS.
   JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603\_1.
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6.
   Kaiser E, 2004, COGNITION, V94, P113, DOI 10.1016/j.cognition.2004.01.002.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kamide Y, 2012, COGNITION, V124, P66, DOI 10.1016/j.cognition.2012.03.001.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   KATZ JJ, 1963, LANGUAGE, V39, P170, DOI 10.2307/411200.
   Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105.
   Kim A, 2012, J COGNITIVE NEUROSCI, V24, P1104, DOI 10.1162/jocn\_a\_00148.
   Kintsch W, 2001, COGNITIVE SCI, V25, P173, DOI 10.1207/s15516709cog2502\_1.
   KINTSCH W, 1988, PSYCHOL REV, V95, P163, DOI 10.1037/0033-295X.95.2.163.
   Kleinschmidt D., 2012, P 34 ANN C COGN SCI, P605.
   Kleinschmidt D. F., 2015, P 37 ANN M COGN SCI, P1129.
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695.
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007.
   Knoeferle P, 2005, COGNITION, V95, P95, DOI 10.1016/j.cognition.2004.03.002.
   Kolk HHJ, 2003, BRAIN LANG, V85, P1, DOI 10.1016/S0093-934X(02)00548-5.
   Kruschke JK, 2008, LEARN BEHAV, V36, P210, DOI 10.3758/LB.36.3.210.
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211.
   Kuperberg G. R., 2013, UNRAVELING BEHAV NEU, P176.
   Kuperberg GR, 2007, BRAIN RES, V1146, P23, DOI 10.1016/j.brainres.2006.12.063.
   Kuperberg GR, 2011, J COGNITIVE NEUROSCI, V23, P1230, DOI 10.1162/jocn.2010.21452.
   Kuperberg GR, 2003, COGNITIVE BRAIN RES, V17, P117, DOI 10.1016/S0926-6410(03)00086-7.
   Kurumada C, 2015, J MEM LANG, V83, P152, DOI 10.1016/j.jml.2015.03.003.
   Kurumada C, 2014, COGNITION, V133, P335, DOI 10.1016/j.cognition.2014.05.017.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   LABOV W, 1969, LANGUAGE, V45, P715, DOI 10.2307/412333.
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028.
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211.
   Lau EF, 2013, J COGNITIVE NEUROSCI, V25, P484, DOI 10.1162/jocn\_a\_00328.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Laughlin SB, 1998, NAT NEUROSCI, V1, P36, DOI 10.1038/236.
   Levinson S. C., 2013, HDB CONVERSATION ANA, P103, DOI DOI 10.1002/9781118325001.CH6.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Levy R, 2009, P NATL ACAD SCI USA, V106, P21086, DOI 10.1073/pnas.0907664106.
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014.
   Lewis RL, 2014, TOP COGN SCI, V6, P279, DOI 10.1111/tops.12086.
   Lewis RL, 2013, TOP COGN SCI, V5, P581, DOI 10.1111/tops.12032.
   Lewis RL, 2000, J PSYCHOLINGUIST RES, V29, P241, DOI 10.1023/A:1005105414238.
   Linzen T, 2016, COGNITIVE SCI, V40, P1382, DOI 10.1111/cogs.12274.
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1.
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676.
   MACDONALD MC, 1992, COGNITIVE PSYCHOL, V24, P56, DOI 10.1016/0010-0285(92)90003-K.
   MacKay D. J, 2003, INFORM THEORY INFERE, V7.
   Magyari L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00376.
   Marr D., 1982, VISION COMPUTATIONAL.
   Marslen-Wilson W., 1988, LANG COGNITIVE PROC, V3, P1, DOI {[}10.1080/01690968808402079, DOI 10.1080/01690968808402079].
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9.
   MASSARO DW, 1989, COGNITIVE PSYCHOL, V21, P398, DOI 10.1016/0010-0285(89)90014-5.
   Matsuki K, 2011, J EXP PSYCHOL LEARN, V37, P913, DOI 10.1037/a0022964.
   MCCARTHY G, 1993, ELECTROEN CLIN NEURO, V88, P210, DOI 10.1016/0168-5597(93)90005-A.
   McClelland JL, 1989, LANG COGNITIVE PROC, V4, pSI287, DOI 10.1080/01690968908406371.
   McClelland J. L., 1998, RATIONAL MODELS COGN.
   McClelland JL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00503.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   MCCLELLAND JL, 1981, J EXP PSYCHOL HUMAN, V7, P634, DOI 10.1037/0096-1523.7.3.634.
   MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375.
   McDonald SA, 2003, PSYCHOL SCI, V14, P648, DOI 10.1046/j.0956-7976.2003.psci\_1480.x.
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191.
   MCKOON G, 1992, PSYCHOL REV, V99, P440, DOI 10.1037/0033-295X.99.3.440.
   McRae K, 1997, LANG COGNITIVE PROC, V12, P137, DOI 10.1080/016909697386835.
   Mcrae K, 2009, LANG LINGUIST COMPAS, V3, P1417, DOI 10.1111/j.1749-818x.2009.00174.x.
   Metusalem R, 2012, J MEM LANG, V66, P545, DOI 10.1016/j.jml.2012.01.001.
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491.
   MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366.
   Myers JL, 1998, DISCOURSE PROCESS, V26, P131, DOI 10.1080/01638539809545042.
   Neely J. H., 1991, BASIC PROCESSES READ, P264, DOI DOI 10.1016/J.BRAINRES.2007.05.058.
   NEELY JH, 1989, J EXP PSYCHOL LEARN, V15, P1003, DOI 10.1037/0278-7393.15.6.1003.
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005.
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4.
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241.
   Norris D, 2006, PSYCHOL REV, V113, P327, DOI 10.1037/0033-295X.113.2.327.
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357.
   Otten M, 2007, BRAIN RES, V1153, P166, DOI 10.1016/j.brainres.2007.03.058.
   Paczynski M, 2012, J MEM LANG, V67, P426, DOI 10.1016/j.jml.2012.07.003.
   Paczynski M, 2011, LANG COGNITIVE PROC, V26, P1402, DOI 10.1080/01690965.2011.580143.
   Perfors A, 2011, COGNITION, V120, P302, DOI 10.1016/j.cognition.2010.11.015.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Posner M.I., 1975, INFORMATION PROCESSI, P55.
   Pyykkonen P, 2010, EXP PSYCHOL, V57, P5, DOI 10.1027/1618-3169/a000002.
   Qian T., 2011, P 33 ANN C COGN SCI, P3313.
   Qian T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00228.
   Rabovsky M, 2014, COGNITION, V132, P68, DOI 10.1016/j.cognition.2014.03.010.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rayner K, 1996, PSYCHON B REV, V3, P504, DOI 10.3758/BF03214555.
   Rayner K, 2001, VISION RES, V41, P943, DOI 10.1016/S0042-6989(00)00310-2.
   Rescorla R. A., 1972, CLASSICAL CONDITION, V2, P64, DOI DOI 10.1101/GR.110528.110.
   Rohde H, 2011, COGNITION, V118, P339, DOI 10.1016/j.cognition.2010.10.016.
   Rohde H, 2014, COGNITION, V133, P667, DOI 10.1016/j.cognition.2014.08.012.
   RUMELHART DE, 1982, PSYCHOL REV, V89, P60, DOI 10.1037/0033-295X.89.1.60.
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243.
   Salverda AP, 2011, ACTA PSYCHOL, V137, P172, DOI 10.1016/j.actpsy.2010.09.010.
   Sanford AJ, 1998, DISCOURSE PROCESS, V26, P159, DOI 10.1080/01638539809545043.
   SANFORD AJ, 1990, COMPREHENSION PROCESSES IN READING, P515.
   Schank R. C., 1977, SCRIPTS PLANS GOALS.
   SCHWANENFLUGEL PJ, 1988, J EXP PSYCHOL LEARN, V14, P344, DOI 10.1037/0278-7393.14.2.344.
   SCHWANENFLUGEL PJ, 1985, J MEM LANG, V24, P232, DOI 10.1016/0749-596X(85)90026-9.
   Sedivy JC, 1999, COGNITION, V71, P109, DOI 10.1016/S0010-0277(99)00025-6.
   Shadlen Michael N., 1994, Current Opinion in Neurobiology, V4, P569, DOI 10.1016/0959-4388(94)90059-0.
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x.
   SIMON HA, 1990, ANNU REV PSYCHOL, V41, P1, DOI 10.1146/annurev.ps.41.020190.000245.
   SIMON HA, 1956, PSYCHOL REV, V63, P129, DOI 10.1037/h0042769.
   Sitnikova T., 2008, UNDERSTANDING EVENTS, P639, DOI 10.1093/acprof:oso/9780195188370.003.0026.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Snedeker J, 2008, J MEM LANG, V58, P574, DOI 10.1016/j.jml.2007.08.001.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Sonderegger M, 2010, COGNITION IN FLUX, P375.
   SPIVEYKNOWLTON MJ, 1993, CAN J EXP PSYCHOL, V47, P276, DOI 10.1037/h0078826.
   STANOVICH KE, 1981, J EXP PSYCHOL HUMAN, V7, P658.
   STANOVICH KE, 1983, J EXP PSYCHOL GEN, V112, P1, DOI 10.1037/0096-3445.112.1.1.
   STANOVICH KE, 1979, MEM COGNITION, V7, P77, DOI 10.3758/BF03197588.
   Staub A, 2015, LANG LINGUIST COMPAS, V9, P311, DOI 10.1111/lnc3.12151.
   Staub A, 2015, J MEM LANG, V82, P1, DOI 10.1016/j.jml.2015.02.004.
   Stilp CE, 2010, P NATL ACAD SCI USA, V107, P12387, DOI 10.1073/pnas.0913625107.
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106.
   SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4.
   Szostak CM, 2013, ATTEN PERCEPT PSYCHO, V75, P1533, DOI 10.3758/s13414-013-0492-3.
   Tanenhaus M. K., 1995, HDB COGNITION PERCEP, P217.
   Tanenhaus M. K., 2006, HDB PSYCHOLINGUISTIC, P863, DOI DOI 10.1016/B978-012369374-7/50023-7.
   Tanenhaus M. K., 2004, INTERFACE LANGUAGE V, P279.
   Tanenhaus MK, 2008, PHILOS T R SOC B, V363, P1105, DOI 10.1098/rstb.2007.2162.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401.
   Tooley KM, 2010, LANG LINGUIST COMPAS, V4, P925, DOI 10.1111/j.1749-818x.2010.00249.x.
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x.
   Traxler MJ, 2014, TRENDS COGN SCI, V18, P605, DOI 10.1016/j.tics.2014.08.001.
   Traxler MJ, 1998, J MEM LANG, V39, P558, DOI 10.1006/jmla.1998.2600.
   Traxler MJ, 2000, J EXP PSYCHOL LEARN, V26, P1266, DOI 10.1037//0278-7393.26.5.1266.
   TRUESWELL JC, 1993, J EXP PSYCHOL LEARN, V19, P528, DOI 10.1037/0278-7393.19.3.528.
   TRUESWELL JC, 1994, J MEM LANG, V33, P285, DOI 10.1006/jmla.1994.1014.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van den Broek P, 2001, MEM COGNITION, V29, P1081, DOI 10.3758/BF03206376.
   van Dijk T. A., 1983, STRATEGIES DISCOURSE.
   van Gompel RPG, 2005, J MEM LANG, V52, P284, DOI 10.1016/j.jml.2004.11.003.
   van Gompel RPG, 2001, J MEM LANG, V45, P225, DOI 10.1006/jmla.2001.2773.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Wacongne C, 2011, P NATL ACAD SCI USA, V108, P20754, DOI 10.1073/pnas.1117807108.
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392.
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wilson MP, 2009, J MEM LANG, V60, P368, DOI 10.1016/j.jml.2008.09.005.
   Wlotko EW, 2015, CORTEX, V68, P20, DOI 10.1016/j.cortex.2015.03.014.
   Wlotko EW, 2012, NEUROIMAGE, V62, P356, DOI 10.1016/j.neuroimage.2012.04.054.
   Wood JN, 2003, NAT REV NEUROSCI, V4, P139, DOI 10.1038/nrn1033.
   Woods DL, 2010, J ACOUST SOC AM, V127, P1609, DOI 10.1121/1.3293005.
   Xiang M, 2015, LANG COGN NEUROSCI, V30, P648, DOI 10.1080/23273798.2014.995679.
   Yoon SO, 2012, PSYCHON B REV, V19, P699, DOI 10.3758/s13423-012-0262-6.
   Zwaan RA, 1998, PSYCHOL BULL, V123, P162, DOI 10.1037/0033-2909.123.2.162.}},
Number-of-Cited-References = {{281}},
Times-Cited = {{246}},
Usage-Count-Last-180-days = {{9}},
Usage-Count-Since-2013 = {{109}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{CX3VJ}},
Unique-ID = {{ISI:000365627300004}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000365627300011,
Author = {Molinaro, Nicola and Monsalve, Irene F. and Lizarazu, Mikel},
Title = {{Is there a common oscillatory brain mechanism for producing and
   predicting language?}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2016}},
Volume = {{31}},
Number = {{1, SI}},
Pages = {{145-158}},
Month = {{JAN 2}},
Abstract = {{Recent proposals have suggested that language prediction is supported by
   the neurophysiological mechanisms involved in language production. Both
   prediction and production in language imply information processing
   percolating down from abstract semantic representations to lower-level
   processing steps, either for articulation (action) or active sensation
   (perception). Language production studies have repeatedly reported
   desynchronisation of oscillatory beta power (13-30 Hz) over the left
   frontal cortex during word generation. Crucially, predictive coding
   theories propose that the beta frequency channel mediates top-down
   propagation of information during prediction. The present study
   evaluates initial experimental evidence on pre-stimulus activity during
   speech production and discusses the similar oscillatory dynamics
   involved in preparation for perception of words. We try to better
   characterise what processing dynamics the pre-stimulus beta-band
   activity represents, illustrating with some results from our lab. This
   evidence motivates the need for more fine-grained psycholinguistic
   paradigms to better characterise whether prediction and production are
   supported by similar neurophysiological mechanisms.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Molinaro, N (Corresponding Author), BCBL Basque Ctr Cognit Brain \& Language, Paseo Mikeletegi 69,2, Donostia San Sebastian 20009, Spain.
   Molinaro, Nicola; Monsalve, Irene F.; Lizarazu, Mikel, BCBL Basque Ctr Cognit Brain \& Language, Donostia San Sebastian 20009, Spain.
   Molinaro, Nicola, Ikerbasque Basque Fdn Sci, Bilbao, Spain.}},
DOI = {{10.1080/23273798.2015.1077978}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Prediction; language production; language comprehension; beta-band
   activity; electrophysiology}},
Keywords-Plus = {{NEURONAL OSCILLATIONS; NEURAL OSCILLATIONS; SYNCHRONIZATION; SPEECH;
   EXPECTATION; AREA; ACTIVATION; FREQUENCY; REFLECTS; CORTEX}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{n.molinaro@bcbl.eu}},
ResearcherID-Numbers = {{Monsalve, Irene Fernandez/H-9898-2015
   Molinaro, Nicola/D-2208-2014
   }},
ORCID-Numbers = {{Monsalve, Irene Fernandez/0000-0002-0137-7200
   Molinaro, Nicola/0000-0002-7549-6042
   Basque Center on Cognition, Brain and Language, BCBL./0000-0002-8345-6892}},
Funding-Acknowledgement = {{Spanish Ministry of Economy and Competitiveness {[}PSI2012-32350];
   Ikesbasque Research Fellowship}},
Funding-Text = {{This work was supported in part by grant PSI2012-32350 from the Spanish
   Ministry of Economy and Competitiveness and an Ikesbasque Research
   Fellowship to Nicola Molinaro.}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103.
   Arnal LH, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00225.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038.
   Bastos AM, 2015, NEURON, V85, P390, DOI 10.1016/j.neuron.2014.12.018.
   Boylan C, 2014, BRAIN LANG, V137, P40, DOI 10.1016/j.bandl.2014.07.009.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   Buzsaki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Cohen L, 2000, BRAIN, V123, P291, DOI 10.1093/brain/123.2.291.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   den Ouden HEM, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00548.
   Dikker S, 2013, BRAIN LANG, V127, P55, DOI 10.1016/j.bandl.2012.08.004.
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Findlay AM, 2012, ANN NEUROL, V71, P668, DOI 10.1002/ana.23530.
   Fisher AE, 2008, INT J PSYCHOPHYSIOL, V68, P111, DOI 10.1016/j.ijpsycho.2007.12.005.
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Frye RE, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00156.
   GASTAUT MH, 1952, REV NEUROL, V87, P176.
   Hanslmayr S, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00074.
   Hari R, 1998, P NATL ACAD SCI USA, V95, P15061, DOI 10.1073/pnas.95.25.15061.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Jackendoff R., 2002, FDN LANGUAGE.
   Jenkinson N, 2011, TRENDS NEUROSCI, V34, P611, DOI 10.1016/j.tins.2011.09.003.
   Jensen O, 2014, TRENDS NEUROSCI, V37, P357, DOI 10.1016/j.tins.2014.04.001.
   Jenson D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00656.
   Klein M, 2015, CEREB CORTEX, V25, P1715, DOI 10.1093/cercor/bht350.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Liljestrom M, 2015, HUM BRAIN MAPP, V36, P1202, DOI 10.1002/hbm.22697.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Molinaro N, 2008, PSYCHOPHYSIOLOGY, V45, P1008, DOI 10.1111/j.1469-8986.2008.00694.x.
   Molinaro N, 2013, LANG COGNITIVE PROC, V28, P762, DOI 10.1080/01690965.2012.665465.
   Molinaro N, 2013, NEUROIMAGE, V72, P120, DOI 10.1016/j.neuroimage.2013.01.031.
   Molinaro N, 2010, BIOL PSYCHOL, V83, P176, DOI 10.1016/j.biopsycho.2009.12.006.
   Monsalve IF, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00847.
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320.
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8.
   Piai V, 2014, NEUROPSYCHOLOGIA, V53, P146, DOI 10.1016/j.neuropsychologia.2013.11.014.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160.
   Rahnev D, 2011, J NEUROSCI, V31, P10741, DOI 10.1523/JNEUROSCI.1478-11.2011.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Roehm D, 2007, J COGNITIVE NEUROSCI, V19, P1259, DOI 10.1162/jocn.2007.19.8.1259.
   Schubotz RI, 2007, TRENDS COGN SCI, V11, P211, DOI 10.1016/j.tics.2007.02.006.
   Siegel M, 2008, NEURON, V60, P709, DOI 10.1016/j.neuron.2008.09.010.
   Singh KD, 2002, NEUROIMAGE, V16, P103, DOI 10.1006/nimg.2001.1050.
   Summerfield C, 2009, TRENDS COGN SCI, V13, P403, DOI 10.1016/j.tics.2009.06.003.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550.
   Vespignani F, 2010, J COGNITIVE NEUROSCI, V22, P1682, DOI 10.1162/jocn.2009.21293.
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008.
   Ward LM, 2003, TRENDS COGN SCI, V7, P553, DOI 10.1016/j.tics.2003.10.012.
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201.
   Wheat KL, 2010, J NEUROSCI, V30, P5229, DOI 10.1523/JNEUROSCI.4448-09.2010.}},
Number-of-Cited-References = {{66}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{19}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{CX3VJ}},
Unique-ID = {{ISI:000365627300011}},
DA = {{2020-12-06}},
}

@article{ ISI:000365627300002,
Author = {Norris, Dennis and McQueen, James M. and Cutler, Anne},
Title = {{Prediction, Bayesian inference and feedback in speech recognition}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2016}},
Volume = {{31}},
Number = {{1, SI}},
Pages = {{4-18}},
Month = {{JAN 2}},
Abstract = {{Speech perception involves prediction, but how is that prediction
   implemented? In cognitive models prediction has often been taken to
   imply that there is feedback of activation from lexical to pre-lexical
   processes as implemented in interactive-activation models (IAMs). We
   show that simple activation feedback does not actually improve speech
   recognition. However, other forms of feedback can be beneficial. In
   particular, feedback can enable the listener to adapt to changing input,
   and can potentially help the listener to recognise unusual input, or
   recognise speech in the presence of competing sounds. The common feature
   of these helpful forms of feedback is that they are all ways of
   optimising the performance of speech recognition using Bayesian
   inference. That is, listeners make predictions about speech because
   speech recognition is optimal in the sense captured in Bayesian models.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Norris, D (Corresponding Author), MRC, Cognit \& Brain Sci Unit, Cambridge, England.
   Norris, Dennis, MRC, Cognit \& Brain Sci Unit, Cambridge, England.
   McQueen, James M., Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, NL-6525 ED Nijmegen, Netherlands.
   McQueen, James M.; Cutler, Anne, Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   Cutler, Anne, Univ Western Sydney, MARCS Inst, Penrith, NSW 2751, Australia.}},
DOI = {{10.1080/23273798.2015.1081703}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Speech recognition; Bayesian inference; feedback; prediction}},
Keywords-Plus = {{TOP-DOWN INFLUENCES; AUDITORY WORD RECOGNITION; SPOKEN-LANGUAGE;
   PHONETIC CATEGORIZATION; INTERACTIVE ACTIVATION; CORTICAL ORGANIZATION;
   NEURAL-NETWORKS; REACTION-TIME; PERCEPTION; MODEL}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{dennis.norris@mrc-cbu.cam.ac.uk}},
ResearcherID-Numbers = {{Cutler, Anne/C-9467-2012
   McQueen, James M./B-2212-2010
   Cutler, Anne/U-9396-2019
   }},
ORCID-Numbers = {{Cutler, Anne/0000-0002-4203-0692
   McQueen, James M./0000-0003-3734-6286
   Cutler, Anne/0000-0002-4203-0692
   Norris, Dennis/0000-0001-9257-317X}},
Funding-Acknowledgement = {{Medical Research CouncilMedical Research Council UK (MRC)
   {[}MC\_U105580447] Funding Source: Medline}},
Cited-References = {{Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arai M, 2013, LANG COGNITIVE PROC, V28, P525, DOI 10.1080/01690965.2012.658072.
   Bever TG, 2010, BIOLINGUISTICS, V4, P174.
   Brouwer S, 2013, APPL PSYCHOLINGUIST, V34, P519, DOI 10.1017/S0142716411000853.
   Brunelliere A, 2013, BRAIN LANG, V125, P82, DOI 10.1016/j.bandl.2013.01.007.
   Chambers CG, 2002, J MEM LANG, V47, P30, DOI 10.1006/jmla.2001.2832.
   Clos M, 2014, HUM BRAIN MAPP, V35, P61, DOI 10.1002/hbm.22151.
   CONNINE CM, 1987, J MEM LANG, V26, P527, DOI 10.1016/0749-596X(87)90138-0.
   CONNINE CM, 1993, J EXP PSYCHOL LEARN, V19, P81, DOI 10.1037/0278-7393.19.1.81.
   CUTLER A, 1976, PERCEPT PSYCHOPHYS, V20, P55, DOI 10.3758/BF03198706.
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498.
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014.
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109.
   Drew PJ, 2003, J NEUROPHYSIOL, V89, P2697, DOI 10.1152/jn.00801.2002.
   ELMAN JL, 1988, J MEM LANG, V27, P143, DOI 10.1016/0749-596X(88)90071-X.
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196.
   Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857.
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110.
   Geisler WS, 2002, NAT NEUROSCI, V5, P508, DOI 10.1038/nn0602-508.
   Geisler WS, 2003, VISUAL NEUROSCIENCES, P825.
   Gilbert CD, 2007, NEURON, V54, P677, DOI 10.1016/j.neuron.2007.05.019.
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005.
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027.
   HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686.
   Halle M, 1959, P SEM SPEECH COMPR P, V2.
   HARRISON CW, 1952, AT\&T TECH J, V31, P766.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597.
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527.
   Hosoya T, 2005, NATURE, V436, P71, DOI 10.1038/nature03689.
   HOWES D, 1957, J ACOUST SOC AM, V29, P296, DOI 10.1121/1.1908862.
   Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142.
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467.
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362.
   Kilner James M, 2007, Cogn Process, V8, P159, DOI 10.1007/s10339-007-0170-2.
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695.
   Larson E, 2009, J NEUROPHYSIOL, V101, P323, DOI 10.1152/jn.90664.2008.
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279.
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001.
   Magnuson JS, 2008, COGNITION, V108, P866, DOI 10.1016/j.cognition.2008.06.005.
   Magnuson JS, 2003, COGNITIVE SCI, V27, P285, DOI 10.1016/S0364-0213(03)00004-1.
   MANN VA, 1981, J ACOUST SOC AM, V69, P548, DOI 10.1121/1.385483.
   Marr D., 1982, VISION.
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357.
   McClelland JL, 2014, COGNITIVE SCI, V38, P1139, DOI 10.1111/cogs.12146.
   McClelland JL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00503.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   MCCLELLAND JL, 1991, COGNITIVE PSYCHOL, V23, P1, DOI 10.1016/0010-0285(91)90002-6.
   McQueen JM, 2012, LANG LEARN DEV, V8, P317, DOI 10.1080/15475441.2011.641887.
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000\_79.
   McQueen JM, 2009, J MEM LANG, V61, P1, DOI 10.1016/j.jml.2009.03.002.
   MCQUEEN JM, 1991, J EXP PSYCHOL HUMAN, V17, P433, DOI 10.1037/0096-1523.17.2.433.
   MCQUEEN JM, 1995, LANG COGNITIVE PROC, V10, P309, DOI 10.1080/01690969508407098.
   McQueen JM, 2003, COGNITIVE SCI, V27, P795, DOI 10.1016/S0364-0213(03)00069-7.
   MILLER JL, 1984, PERCEPT PSYCHOPHYS, V36, P329, DOI 10.3758/BF03202785.
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477.
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053.
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4.
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9.
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241.
   Norris D, 2006, PSYCHOL REV, V113, P327, DOI 10.1037/0033-295X.113.2.327.
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357.
   Norris D, 2012, PSYCHOL REV, V119, P517, DOI 10.1037/a0028450.
   Norris D, 2009, PSYCHOL REV, V116, P207, DOI 10.1037/a0014259.
   OLIVER BM, 1952, AT\&T TECH J, V31, P724, DOI 10.1002/j.1538-7305.1952.tb01403.x.
   Pece AEC, 2007, COMPUT VIS IMAGE UND, V106, P130, DOI 10.1016/j.cviu.2006.10.002.
   Pelli DG, 2006, VISION RES, V46, P4646, DOI 10.1016/j.visres.2006.04.023.
   Pitt MA, 1998, J MEM LANG, V39, P347, DOI 10.1006/jmla.1998.2571.
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160.
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301.
   POLLACK I, 1959, J ACOUST SOC AM, V31, P273, DOI 10.1121/1.1907712.
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721.
   RUBIN P, 1976, PERCEPT PSYCHOPHYS, V19, P394, DOI 10.3758/BF03199398.
   RUMELHART DE, 1982, PSYCHOL REV, V89, P60, DOI 10.1037/0033-295X.89.1.60.
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474.
   Samuel AG, 2003, J MEM LANG, V48, P416, DOI 10.1016/S0749-596X(02)00514-4.
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207.
   Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104.
   Sjerps MJ, 2010, J EXP PSYCHOL HUMAN, V36, P195, DOI 10.1037/a0016803.
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   SRINIVASAN MV, 1982, PROC R SOC SER B-BIO, V216, P427, DOI 10.1098/rspb.1982.0085.
   Travis KE, 2013, CEREB CORTEX, V23, P2370, DOI 10.1093/cercor/bhs228.
   Ueno T, 2011, NEURON, V72, P385, DOI 10.1016/j.neuron.2011.09.013.
   van Alphen P, 2001, J EXP PSYCHOL HUMAN, V27, P1057, DOI 10.1037//0096-1523.27.5.1057.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.
   WARREN RM, 1972, SCIENCE, V176, P1149, DOI 10.1126/science.176.4039.1149.
   Yildiz IB, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003219.
   Yildiz IB, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002303.
   YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59.
   Zhou B., 2014, ADV NEURAL INFORM PR, P487, DOI DOI 10.1162/153244303322533223.}},
Number-of-Cited-References = {{96}},
Times-Cited = {{41}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{18}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{CX3VJ}},
Unique-ID = {{ISI:000365627300002}},
OA = {{Green Published, Other Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000365627300005,
Author = {Gambi, Chiara and Pickering, Martin J.},
Title = {{Predicting and imagining language}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2016}},
Volume = {{31}},
Number = {{1, SI}},
Pages = {{60-72}},
Month = {{JAN 2}},
Abstract = {{To what extent is predicting language akin to imagining language?
   Recently, researchers have argued that covert simulation of the
   production system underlies both articulation imagery and predicting
   what somebody is about to say. Moreover, experimental evidence
   implicates potentially similar production-related mechanisms in
   prediction during language comprehension and in mental imagery tasks. We
   discuss evidence in favour of this proposal and argue that imagining
   others' utterances can also implicate covert simulation. Finally, we
   briefly review evidence that speakers in joint language tasks cannot
   help but mentally represent (i.e., imagine) whether others are engaging
   in language production, and that they do so using mechanisms that are
   also implicated in preparing to speak.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gambi, C (Corresponding Author), Univ Edinburgh, Dept Psychol, Edinburgh, Midlothian, Scotland.
   Gambi, Chiara; Pickering, Martin J., Univ Edinburgh, Dept Psychol, Edinburgh, Midlothian, Scotland.}},
DOI = {{10.1080/23273798.2015.1049188}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Speech imagery; prediction; forward models; joint tasks}},
Keywords-Plus = {{SPEECH PRODUCTION; INNER SPEECH; ERROR-DETECTION; IMAGERY;
   COMPREHENSION; IMAGINATION; INFORMATION; PERFORMANCE; PERCEPTION;
   ACTIVATION}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{cgambi@exseed.ed.ac.uk}},
ResearcherID-Numbers = {{Gambi, Chiara/J-2361-2018
   }},
ORCID-Numbers = {{Gambi, Chiara/0000-0002-1568-7779
   Pickering, Martin/0000-0002-2005-049X}},
Cited-References = {{Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014.
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Atkinson JR, 2006, SCHIZOPHRENIA BULL, V32, P701, DOI 10.1093/schbul/sbj063.
   Atmaca S, 2011, EXP BRAIN RES, V211, P371, DOI 10.1007/s00221-011-2709-9.
   Baddeley A. D., 1986, WORKING MEMORY.
   Baus C, 2014, COGNITION, V133, P395, DOI 10.1016/j.cognition.2014.07.006.
   Behroozmand R, 2011, BMC NEUROSCI, V12, DOI 10.1186/1471-2202-12-54.
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006.
   Corley M, 2011, J EXP PSYCHOL LEARN, V37, P162, DOI 10.1037/a0021321.
   Cummins F, 2003, J PHONETICS, V31, P139, DOI 10.1016/S0095-4470(02)00082-7.
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017.
   Emmorey K, 2009, J MEM LANG, V61, P398, DOI 10.1016/j.jml.2009.06.001.
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006.
   Gambi C., HDB PSYCHOLINGUISTIC.
   Gambi C, 2015, J EXP PSYCHOL LEARN, V41, P1, DOI 10.1037/a0037438.
   Gambi C, 2013, BEHAV BRAIN SCI, V36, P423, DOI 10.1017/S0140525X12001926.
   Goldman Alvin J., 2006, SIMULATING MINDS PHI.
   Grush R, 2004, BEHAV BRAIN SCI, V27, P377, DOI 10.1017/S0140525X04000093.
   Heinks-Maldonado TH, 2006, NEUROREPORT, V17, P1375, DOI 10.1097/01.wnr.0000233102.43526.e9.
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Hurley S, 2008, PHILOS PHENOMEN RES, V77, P755, DOI 10.1111/j.1933-1592.2008.00220.x.
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106.
   Kempen G, 2014, NEUROINFORMATICS, V12, P111, DOI 10.1007/s12021-013-9191-4.
   Knoblich G, 2011, PSYCHOL LEARN MOTIV, V54, P59, DOI 10.1016/B978-0-12-385527-5.00003-6.
   Knolle F, 2013, CORTEX, V49, P2449, DOI 10.1016/j.cortex.2012.12.012.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Lesage E, 2012, CURR BIOL, V22, pR794, DOI 10.1016/j.cub.2012.07.006.
   Levelt WJM., 1989, SPEAKING INTENTION A.
   Levinson S.C., 2000, PRESUMPTIVE MEANINGS.
   Loehr JD, 2013, J COGNITIVE NEUROSCI, V25, P1049, DOI 10.1162/jocn\_a\_00388.
   MacKay D.G., 1992, AUDITORY IMAGERY, P121.
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013.
   Nozari N, 2011, COGNITIVE PSYCHOL, V63, P1, DOI 10.1016/j.cogpsych.2011.05.001.
   Oppenheim GM, 2008, COGNITION, V106, P528, DOI 10.1016/j.cognition.2007.02.006.
   Oppenheim GM, 2010, MEM COGNITION, V38, P1147, DOI 10.3758/MC.38.8.1147.
   Perrone-Bertolotti M, 2014, BEHAV BRAIN RES, V261, P220, DOI 10.1016/j.bbr.2013.12.034.
   Pezzulo G, 2011, MIND LANG, V26, P78, DOI 10.1111/j.1468-0017.2010.01411.x.
   Pickering MJ, 2014, TRENDS COGN SCI, V18, P451, DOI 10.1016/j.tics.2014.05.006.
   Pickering MJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00132.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169.
   REISBERG D, 1989, Q J EXP PSYCHOL-A, V41, P619, DOI 10.1080/14640748908402385.
   Scott M, 2013, J ACOUST SOC AM, V133, pEL286, DOI 10.1121/1.4794932.
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603.
   SMITH JD, 1995, NEUROPSYCHOLOGIA, V33, P1433, DOI 10.1016/0028-3932(95)00074-D.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Tan X, 2012, FRONT HUM NEUROSCI, V6, DOI {[}10.3389/fnhum.2012.00305, 10.3389/fnhum.2012.00314].
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Thomas NJT, 1999, COGNITIVE SCI, V23, P207, DOI 10.1016/S0364-0213(99)00004-X.
   Tian X, 2015, J COGNITIVE NEUROSCI, V27, P352, DOI 10.1162/jocn\_a\_00692.
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn\_a\_00381.
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166.
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Vesper C, 2014, NEUROPSYCHOLOGIA, V55, P115, DOI 10.1016/j.neuropsychologia.2013.05.024.
   Vesper C, 2013, J EXP PSYCHOL HUMAN, V39, P48, DOI 10.1037/a0028066.
   WHEELDON LR, 1995, J MEM LANG, V34, P311, DOI 10.1006/jmla.1995.1014.
   Ylinen S, 2015, CEREB CORTEX, V25, P1576, DOI 10.1093/cercor/bht351.
   Yuen I, 2010, P NATL ACAD SCI USA, V107, P592, DOI 10.1073/pnas.0904774107.}},
Number-of-Cited-References = {{61}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{CX3VJ}},
Unique-ID = {{ISI:000365627300005}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394400033,
Author = {Bhaysar, Himanshu N. and Patel, Tanvina B. and Patil, Hemant A.},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Novel Nonlinear Prediction Based Features for Spoofed Speech Detection}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{155-159}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{Several speech synthesis and voice conversion techniques can easily
   generate or manipulate speech to deceive the speaker verification (SV)
   systems. Hence, there is a need to develop spoofing countermeasures to
   detect the human speech from spoofed speech. System-based features have
   been known to contribute significantly to this task. In this paper, we
   extend a recent study of Linear Prediction (LP) and Long-Term Prediction
   (LTP)-based features to LP and Nonlinear Prediction (NLP)-based
   features. To evaluate the effectiveness of the proposed countermeasure,
   we use the corpora provided at the ASVspoof 2015 challenge. A Gaussian
   Mixture Model (GMM)-based classifier is used and the \% Equal Error Rate
   (EER) is used as a performance measure. On the development set, it is
   found that LP-LTP and LP-NLP features gave an average EER of 4.78 \% and
   9.18 \%, respectively. Score-level fusion of LP-LTP (and LP-NLP) with
   Mel Frequency Cepstral Coefficients (MFCC) gave an EER of 0.8 \% (and
   1.37 \%), respectively. After score-level fusion of LP-LTP, LP-NLP and
   MFCC features, the EER is significantly reduced to 0.57 \%. The LP-LTP
   and LP-NLP features have found to work well even for Blizzard Challenge
   2012 speech database.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bhaysar, HN (Corresponding Author), DA IICT, Gandhinagar 382007, India.
   Bhaysar, Himanshu N.; Patel, Tanvina B.; Patil, Hemant A., DA IICT, Gandhinagar 382007, India.}},
DOI = {{10.21437/Interspeech.2016-1002}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{Speaker verification; spoof detection; linear prediction; long-term
   prediction; nonlinear prediction}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{himanshu\_bhaysar@daiict.ac.in
   tanvina\_bhupendrabhai\_patel@daiict.ac.in
   hemant\_patil@daiict.ac.in}},
Cited-References = {{Alam MJ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2072.
   Alegre F., 2014, P 13 INT C BIOM SPEC, P157.
   ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679.
   Bonastre J.-F., 2006, P IEEE SPEAK LANG RE, P1.
   De Leon PL, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P370.
   Janicki A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2077.
   KORENBERG MJ, 1988, ANN BIOMED ENG, V16, P123, DOI 10.1007/BF02367385.
   Lau YW, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P145.
   Liu Y, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2082.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Martin A, 1997, P EUR, V4, P1895.
   Novoselov S, 2016, INT CONF ACOUST SPEE, P5475, DOI 10.1109/ICASSP.2016.7472724.
   Patel T. B., 2015, P INT C AC SPEECH SI, P5105.
   Patel TB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2062.
   Patil H. A., 2013, P ANN C INT SPEECH C, P1687.
   Perrot P, 2012, FORENSIC SPEAKER RECOGNITION: LAW ENFORCEMENT AND COUNTER-TERRORISM, P469, DOI 10.1007/978-1-4614-0263-3\_16.
   Sanchez J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2042.
   Stylianou Y, 2009, INT CONF ACOUST SPEE, P3585, DOI 10.1109/ICASSP.2009.4960401.
   Tokuda K, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON SPEECH SYNTHESIS, P227.
   Vaseghi S.V, 2008, ADV DIGITAL SIGNAL P.
   Weng S., 2015, ARXIV150706711 CORN.
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2037.
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005.
   Xiao X, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2052.
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004.
   1999, DIGITAL CELLULAR TEL.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394400033}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394400127,
Author = {Schaedler, Marc Rene and Huelsmeier, David and Warzybok, Anna and
   Hochmuth, Sabine and Kollmeier, Birger},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Microscopic multilingual Matrix test predictions using an ASR-based
   speech recognition model}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{610-614}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{In an attempt to predict the outcomes of matrix sentence tests in
   different languages and various noise conditions for native listeners,
   the simulation framework for auditory discrimination experiments (FADE)
   and the extended Speech Intelligibility Index (eSII) is employed. FADE
   uses an automatic speech recognition system to simulate recognition
   experiments and reports the highest achievable performance as the
   outcome, which showed good predictions for the German matrix test in
   noise. The eSII is based on the short-time analysis of weighted
   signal-to-noise ratios in different frequency bands. In contrast to many
   other approaches, including the eSII, FADE uses no empirical reference.
   In this work, the FADE approach is evaluated for predictions of the
   German, Polish, Russian, and Spanish matrix test in stationary and
   fluctuating noise conditions. The FADE based predictions yield a high
   correlation (Pearsons R-2 = 0.94) with the empirical data and a
   root-mean-square (RMS) prediction error of 1.9 dB outperforming the
   eSII-based predictions (R-2 = 0.78, RMS = 4.2 dB). FADE can also predict
   the data of subgroups with only stationary or only fluctuating noises,
   while the eSII cannot. The FADE-based predictions seem to generalize
   over different languages and noise conditions.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Schadler, MR (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Med Phys, D-26111 Oldenburg, Germany.
   Schaedler, Marc Rene, Carl von Ossietzky Univ Oldenburg, Med Phys, D-26111 Oldenburg, Germany.
   Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, D-26111 Oldenburg, Germany.}},
DOI = {{10.21437/Interspeech.2016-1119}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{speech intelligibility prediction; matrix sentence test; robust ASR
   features; modeling approaches}},
Keywords-Plus = {{INTELLIGIBILITY PREDICTION; RECEPTION THRESHOLD; FLUCTUATING NOISE;
   PERCEPTION; LISTENERS; LANGUAGES; SENTENCES; INDEX}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{marc.r.schaedler@uni-oldenburg.de
   david.huelsmeier@uni-oldenburg.de
   a.warzybok@uni-oldenburg.de
   sabine.hochmuth@uni-oldenburg.de
   birger.kollmeier@uni-oldenburg.de}},
Funding-Acknowledgement = {{Cluster of Excellence Grant ``Hearing4all{''}}},
Funding-Text = {{This work was supported by the Cluster of Excellence Grant
   ``Hearing4all{''}.}},
Cited-References = {{Ansi A., 1997, NEW YORK AM NAT STAN, V19, P90.
   Barker J, 2007, SPEECH COMMUN, V49, P402, DOI 10.1016/j.specom.2006.11.003.
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575.
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152.
   Dreschler WA, 2001, AUDIOLOGY, V40, P148.
   FISHER WD, 1958, J AM STAT ASSOC, V53, P789, DOI 10.2307/2281952.
   FLETCHER H, 1950, J ACOUST SOC AM, V22, P89, DOI 10.1121/1.1906605.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203.
   Hochmuth S, 2015, INT J AUDIOL, V54, P62, DOI 10.3109/14992027.2015.1046502.
   Hochmuth S, 2012, INT J AUDIOL, V51, P536, DOI 10.3109/14992027.2012.670731.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   Jurgens T, 2009, J ACOUST SOC AM, V126, P2635, DOI 10.1121/1.3224721.
   Kollmeier B, 2015, INT J AUDIOL, V54, P3, DOI 10.3109/14992027.2015.1020971.
   Ozimek E, 2010, INT J AUDIOL, V49, P444, DOI 10.3109/14992021003681030.
   Rhebergen KS, 2006, J ACOUST SOC AM, V120, P3988, DOI 10.1121/1.2358008.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   Schadler MR, 2015, INT J AUDIOL, V54, P100, DOI 10.3109/14992027.2015.1061708.
   Schadler MR, 2015, J ACOUST SOC AM, V137, P2047, DOI 10.1121/1.4916618.
   Schaller M. R., 2015, J ACOUSTICAL S UNPUB.
   Wagener K, 1999, Z AUDIOL, V38, P86.
   Wagener K, 1999, Z AUDIOL, V38, P4.
   Wagener K, 1999, Z AUDIOL, V38, P44, DOI DOI 10.3109/00206099909073001.
   Warzybok A, 2015, INT J AUDIOL, V54, P35, DOI 10.3109/14992027.2015.1020969.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394400127}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394400130,
Author = {Karbasi, Mandie and Abdelaziz, Ahmed Hussen and Meutzner, Hendrik and
   Kolossa, Dorothea},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Blind Non-Intrusive Speech Intelligibility Prediction using Twin-HMMs}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{625-629}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{Automatic prediction of speech intelligibility is highly desirable in
   the speech research community, since listening tests are time-consuming
   and can not be used online. Most of the available objective speech
   intelligibility measures are intrusive methods, as they require a clean
   reference signal in addition to the corresponding noisy/processed signal
   at hand. In order to overcome the problem of predicting the speech
   intelligibility in the absence of the clean reference signal, we have
   proposed in {[}1] to employ a recognition/synthesis framework called
   twin hidden Markov model (THMM) for synthesizing the clean features,
   required inside an intrusive intelligibility prediction method. The new
   framework can predict the speech intelligibility equally well as
   well-known intrusive methods like the short-time objective
   intelligibility (STOI). The original THMM, however, requires the correct
   transcription for synthesizing the clean reference features, which is
   not always available. In this paper, we go one step further and
   investigate the use of the recognized transcription instead of the
   oracle transcription for obtaining a more widely applicable speech
   intelligibility prediction. We show that the output of the
   newly-proposed blind approach is highly correlated with the human speech
   recognition results, collected via crowdsourcing in different noise
   conditions.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Karbasi, M (Corresponding Author), Ruhr Univ Bochum, Cognit Signal Proc Grp, D-44801 Bochum, Germany.
   Karbasi, Mandie; Meutzner, Hendrik; Kolossa, Dorothea, Ruhr Univ Bochum, Cognit Signal Proc Grp, D-44801 Bochum, Germany.
   Abdelaziz, Ahmed Hussen, Int Comp Sci Inst, Berkeley, CA 94704 USA.}},
DOI = {{10.21437/Interspeech.2016-155}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{Speech intelligibility prediction; twin-HMM; speech recognition; speech
   synthesis; non-intrusive methods; objective measures}},
Keywords-Plus = {{QUALITY}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{mandie.karbasi@rub.de
   ahmedha@icsi.berkeley.edu
   hendrik.meutzner@rub.de
   dorothea.kolossa@rub.de}},
ORCID-Numbers = {{Karbasi, Mahdie/0000-0003-4200-6729}},
Funding-Acknowledgement = {{European UnionEuropean Union (EU) {[}317521]}},
Funding-Text = {{This research has received funding from the European Union's Seventh
   Framework Programme FP7/2007-2013/ under REA grant agreement no
   {[}317521]. The authors would like to thank Jon Barker for providing a
   noisy version of the Grid database with comprehensive listening test
   results.}},
Cited-References = {{Abdelaziz AH, 2013, INT CONF ACOUST SPEE, P3726, DOI 10.1109/ICASSP.2013.6638354.
   American National Standards Institute, 1997, METH CALC SPEECH INT.
   Barker J, 2007, SPEECH COMMUN, V49, P402, DOI 10.1016/j.specom.2006.11.003.
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005.
   Falk TH, 2013, INT CONF ACOUST SPEE, P7820, DOI 10.1109/ICASSP.2013.6639186.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Fingscheidt T., 2013, P 4 INT WORKSH PERC.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   KARBASI M, 2016, P ICASSP, P624.
   Nemala SK, 2010, INT CONF ACOUST SPEE, P4742, DOI 10.1109/ICASSP.2010.5495170.
   Santos JF, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P55, DOI 10.1109/IWAENC.2014.6953337.
   Sharma D., 2013, P INT C REC TRENDS I, P1.
   Sharma D, 2010, EUR SIGNAL PR CONF, P1899.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Taghia J, 2014, IEEE-ACM T AUDIO SPE, V22, P6, DOI 10.1109/TASL.2013.2281574.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394400130}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394400231,
Author = {Najnin, Shamima and Banerjee, Bonny},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Emergence of Vocal Developmental Sequences in a Predictive Coding Model
   of Speech Acquisition}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{1113-1117}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{Learning temporal patterns among primitive speech sequences and being
   able to control the motor apparatus for effective production of the
   learned patterns are imperative for speech acquisition in infants. In
   this paper, we develop a predictive coding model whose objective is to
   minimize the sensory (auditory) and proprioceptive prediction errors.
   Temporal patterns are learned by minimizing the former while control is
   learned by minimizing the latter. The model is learned using a set of
   synthetically generated syllables, as in other contemporary models. We
   show that the proposed model outperforms existing ones in learning
   vocalization classes. It also computes the control/muscle activation
   which is useful for determining the degree of easiness of vocalization.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Najnin, S (Corresponding Author), Univ Memphis, Dept Elect \& Comp Engn, Memphis, TN 38152 USA.
   Banerjee, Bonny, Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   Najnin, Shamima; Banerjee, Bonny, Univ Memphis, Dept Elect \& Comp Engn, Memphis, TN 38152 USA.}},
DOI = {{10.21437/Interspeech.2016-1126}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{speech acquisition; babbling; predictive coding}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{snajnin@memphis.edu
   bbnerjee@memphis.edu}},
Funding-Acknowledgement = {{NSFNational Science Foundation (NSF) {[}IIS-1231620]}},
Funding-Text = {{This research was supported by NSF grant IIS-1231620.}},
Cited-References = {{Auzou P, 2000, CLIN LINGUIST PHONET, V14, P131.
   Brown H, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00218.
   Chao K.-Y., 2008, COMPUT LINGUIST, V13, P215.
   Fang Q, 2009, ACOUST SCI TECHNOL, V30, P277, DOI 10.1250/ast.30.277.
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006.
   Heintz I, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P684.
   Howard IS., 2014, PLOSONE.
   Kanda H, 2009, IEEE INT CONF ROBOT, P4036.
   Kroger BJ, 2009, SPEECH COMMUN, V51, P793, DOI 10.1016/j.specom.2008.08.002.
   Kuhl PK, 2014, COLD SH Q B, V79, P211, DOI 10.1101/sqb.2014.79.024802.
   Lillicrap T. P., 2015, ARXIV150902971.
   MAEDA S, 1990, NATO ADV SCI I D-BEH, V55, P131.
   Messum P, 2015, J PHONETICS, V53, P125, DOI 10.1016/j.wocn.2015.08.005.
   Miura K, 2012, ADV ROBOTICS, V26, P23, DOI 10.1163/016918611X607347.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Mordatch Igor, 2014, ROBOTICS SCI SYSTEMS.
   Moulin-Frier C., 2012, P 2012 IEEE INT C DE, P1.
   Moulin-Frier C, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01006.
   Muhammad W, 2015, ADAPT BEHAV, V23, P265, DOI 10.1177/1059712315607363.
   Murakamli M, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P208, DOI 10.1109/DEVLRN.2015.7346142.
   Oiler D.K., 2000, EMERGENCE SPEECH CAP.
   Philippsen AK, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P195, DOI 10.1109/DEVLRN.2014.6982981.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Stuart A., 1993, ORIGINS ORDER SELF O.
   Tassa Y, 2014, IEEE INT CONF ROBOT, P1168, DOI 10.1109/ICRA.2014.6907001.
   Warlaumont Anne S., 2013, 2013 IEEE Third Joint International Conference on Development and Learning and Epigenetic Robotics (ICDL), DOI 10.1109/DevLrn.2013.6652547.
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337.
   Westermann G, 2004, BRAIN LANG, V89, P393, DOI 10.1016/S0093-934X(03)00345-6.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394400231}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394401045,
Author = {Liu, Hong and Wang, Xiuling and Sun, Miao and Pang, Cheng},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Multi-Channel Linear Prediction Based on Binaural Coherence for Speech
   Dereverberation}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{1735-1739}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{It has been shown that the multi-channel linear prediction (MCLP) can
   achieve blind speech dereverberation effectively. However, it always
   degrades the binaural cues which are exploited for human sound
   localization, i.e., interaural time differences (ITD) and interaural
   level differences (ILD). To overcome this problem, the multiple
   input-single output structure of conventional MCLP is modified to a
   binaural input-output structure for suppressing reverberation and
   preserving binaural cues simultaneously. First, by employing a binaural
   coherence model with head shadowing effects, the variance of desired
   signal can be estimated the same to both ears, which can ensure no
   modification of ILD. Then, the variance is utilized to calculate the
   prediction coefficients in a maximum-likelihood (ML) sense. Finally, the
   desired signals can be obtained as the prediction errors in MCLP. And
   since the algorithm does not disturb the phase of input signal, the ITD
   cue is kept. Evaluations with measured binaural room impulse responses
   (BRIRs) show that the proposed method yields a good performance on both
   speech dereverberation and binaural cues preservation.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Liu, H (Corresponding Author), Peking Univ, Shenzhen Grad Sch, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.
   Liu, Hong; Wang, Xiuling; Sun, Miao; Pang, Cheng, Peking Univ, Shenzhen Grad Sch, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.}},
DOI = {{10.21437/Interspeech.2016-729}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{binaural dereverbaration; binaural cues; coherence; head shadowing;
   multi-channel linear prediction}},
Keywords-Plus = {{TIME-DELAY; FILTER; MODEL}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{hongliu@pku.edu.cn
   wangxiuling@sz.pku.edu.cn
   sunmiao@sz.pku.edu.cn
   chengpang@sz.pku.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) {[}61340046, 60875050, 60675025];
   National High Technology Research and Development Program of China (863
   Program)National High Technology Research and Development Program of
   China {[}2006AA04Z247]; Specialized Research Fund for the Doctoral
   Program of Higher EducationSpecialized Research Fund for the Doctoral
   Program of Higher Education (SRFDP) {[}20130001110011]; Natural Science
   Foundation of Guangdong ProvinceNational Natural Science Foundation of
   Guangdong Province {[}2015A030311034]; Science and Technology Innovation
   Commission of Shenzhen Municipality {[}JCYJ20130331144631730,
   JCYJ20130331144716089]}},
Funding-Text = {{This work is supported by National Natural Science Foundation of China
   (NSFC, No. 61340046, 60875050, 60675025), National High Technology
   Research and Development Program of China (863 Program, No.
   2006AA04Z247), Specialized Research Fund for the Doctoral Program of
   Higher Education (No. 20130001110011), Natural Science Foundation of
   Guangdong Province(No. 2015A030311034), Science and Technology
   Innovation Commission of Shenzhen Municipality (No.
   JCYJ20130331144631730, No. JCYJ20130331144716089).}},
Cited-References = {{Blauert J., 1996, SPATIAL HEARING PSYC.
   Braun S, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P124, DOI 10.1109/IWAENC.2014.6953351.
   Falk T. H., 2008, IEEE INT WORKSH AC E.
   FURUI S, 2001, DIGITAL SPEECH PROCE.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Habets EAP, 2009, IEEE SIGNAL PROC LET, V16, P770, DOI 10.1109/LSP.2009.2024791.
   Iwata Y, 2012, INT CONF ACOUST SPEE, P245, DOI 10.1109/ICASSP.2012.6287863.
   Jeub M., 2009, P INT C DIG SIGN PRO, P1.
   Jeub M, 2010, IEEE T AUDIO SPEECH, V18, P1732, DOI 10.1109/TASL.2010.2052156.
   Jukic A, 2015, INT CONF ACOUST SPEE, P96, DOI 10.1109/ICASSP.2015.7177939.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830.
   Kuttruff H., 2000, ROOM ACOUSTICS.
   Liu H., 2012, P INT C INTERSPEECH, P1732.
   McCowan IA, 2003, IEEE T SPEECH AUDI P, V11, P709, DOI 10.1109/TSA.2003.818212.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Pang C, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3436.
   Schning G., 2015, CHEM BER, V110, P3231.
   Schwartz B., 2013, SIGN PROC C EUSIPCO, P1.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Zhang J, 2015, IEEE T SIGNAL PROCES, V63, P4771, DOI 10.1109/TSP.2015.2447496.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394401045}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394401050,
Author = {Gowda, Dhananjaya and Alku, Paavo},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Time-varying quasi-closed-phase weighted linear prediction analysis of
   speech for accurate formant detection and tracking}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{1760-1764}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{In this paper, we propose a new method for accurate detection,
   estimation and tracking of formants in speech signals using time-varying
   quasi-closed phase analysis (TVQCP). The proposed method combines two
   different methods of analysis namely, the time-varying linear prediction
   (TVLP) and quasi-closed phase (QCP) analysis. TVLP helps in better
   tracking of formant frequencies by imposing a time-continuity constraint
   on the linear prediction (LP) coefficients. QCP analysis, a type of
   weighted LP (WLP), improves the estimation accuracies of the formant
   frequencies by using a carefully designed weight function on the error
   signal that is minimized. The QCP weight function emphasizes the
   closed-phase region of the glottal cycle, and also weights down the
   regions around the main excitations. This results in reduced coupling of
   the subglottal cavity and the excitation source. Experimental results on
   natural speech signals show that the proposed method performs
   considerably better than the detect-and-track approach used in popular
   tools like Wavesurfer or Praat.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gowda, D (Corresponding Author), Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.
   Gowda, Dhananjaya; Alku, Paavo, Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.}},
DOI = {{10.21437/Interspeech.2016-153}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{Quasi-closed-phase (QCP) analysis; weighted linear prediction (WLP);
   time-varying linear prediction (TVLP); time-varying weighted linear
   prediction (TVWLP); time-varying quasi-closed phase (TVQCP) analysis}},
Keywords-Plus = {{INVERSE FILTERING ANALYSIS}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{dhananjaya.gowda@aalto.fi
   paavo.alku@aalto.fi}},
ResearcherID-Numbers = {{Alku, Paavo/E-2400-2012
   }},
ORCID-Numbers = {{Alku, Paavo/0000-0002-8173-9418}},
Funding-Acknowledgement = {{Academy of FinlandAcademy of Finland {[}256961, 284671]}},
Funding-Text = {{This work has been funded by the Academy of Finland (project no. 256961
   and 284671).}},
Cited-References = {{Airaksinen M, 2014, IEEE-ACM T AUDIO SPE, V22, P596, DOI 10.1109/TASLP.2013.2294585.
   Alku P., 2013, J ACOUSTICAL SOC AM, V134.
   Alku P, 2011, SADHANA-ACAD P ENG S, V36, P623, DOI 10.1007/s12046-011-0041-5.
   Boersma, 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7.
   Chetupalli S., 2014, AC SPEECH SIGN PROC, P6290.
   Deng L., 2006, P INT C AC SPEECH SI.
   Deng L., 2004, P INT C AC SPEECH SI, V1.
   Deng L, 2007, IEEE T AUDIO SPEECH, V15, P13, DOI 10.1109/TASL.2006.876724.
   Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265.
   Durrieu JL, 2013, IEEE T AUDIO SPEECH, V21, P2541, DOI 10.1109/TASL.2013.2277941.
   Fant G., 1960, ACOUSTIC THEORY SPEE, P1.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Gowda D, 2016, INT CONF ACOUST SPEE, P4980, DOI 10.1109/ICASSP.2016.7472625.
   HALL MG, 1983, SIGNAL PROCESS, V5, P267, DOI 10.1016/0165-1684(83)90074-9.
   Hillenbrand J., 1995, J ACOUSTICAL SOC AM, V97.
   Iribe Y, 2012, INT CONF ACOUST SPEE, P5133, DOI 10.1109/ICASSP.2012.6289076.
   KAY SM, 1988, MODERN SPECTRUM ESTI.
   MA CX, 1993, SPEECH COMMUN, V12, P69, DOI 10.1016/0167-6393(93)90019-H.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Mehta D. D., 2012, J ACOUSTICAL SOC AM, V132.
   Mustafa K, 2006, IEEE T AUDIO SPEECH, V14, P435, DOI 10.1109/TSA.2005.855840.
   PINTO NB, 1989, IEEE T ACOUST SPEECH, V37, P1870, DOI 10.1109/29.45534.
   Pohjalainen J., 2009, P INTERSPEECH.
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649.
   Schnell K, 2008, INT CONF ACOUST SPEE, P3941, DOI 10.1109/ICASSP.2008.4518516.
   Sjolander K., 2000, P INT C SPOKEN LANGU, V2000, P464.
   Wipf D, 2010, IEEE J-STSP, V4, P317, DOI 10.1109/JSTSP.2010.2042413.
   WONG DY, 1979, IEEE T ACOUST SPEECH, V27, P350, DOI 10.1109/TASSP.1979.1163260.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394401050}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394402019,
Author = {Braunschweiler, Norbert and Maia, Ranniery},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Pause prediction from text for speech synthesis with user-definable
   pause insertion likelihood threshold}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{3191+}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{Predicting the location of pauses from text is an important aspect for
   speech synthesizers. The accuracy of pause prediction can significantly
   influence both naturalness and intelligibility. Pauses which help
   listeners to better parse the synthesized speech into meaningful units
   are deemed to increase naturalness and intelligibility ratings, while
   pauses in unexpected or incorrect locations can reduce these ratings and
   cause confusion. This paper presents a multi-stage pause prediction
   approach including first prosodic chunk prediction, followed by a
   feature scoring algorithm and finally a pause sequence evaluation
   module. Preference tests showed that the new method outperformed a
   pauses-at-punctuation baseline while not yet matching human performance.
   In addition, the approach includes two more functionalities: (1) a
   user-specifiable pause insertion rate and (2) multiple output formats in
   the form of binary pauses, multi-level pauses or as a score reflecting
   pause strength.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Braunschweiler, N (Corresponding Author), Toshiba Res Europe Ltd, Cambridge Res Lab, Cambridge, England.
   Braunschweiler, Norbert; Maia, Ranniery, Toshiba Res Europe Ltd, Cambridge Res Lab, Cambridge, England.}},
DOI = {{10.21437/Interspeech.2016-752}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{pause prediction; phrasing; prosody; speech synthesis; machine learning}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{norbert.braunschweiler@crl.toshiba.co.uk
   ranniery.maia@crl.toshiba.co.uk}},
Cited-References = {{Atterer M., 2002, P SPEECH PROS 2002 A.
   Bachenko J., 1990, Computational Linguistics, V16, P155.
   Bell P., 2006, SPEECH PROS 2006.
   Bogels S, 2013, NEUROPSYCHOLOGIA, V51, P2715, DOI 10.1016/j.neuropsychologia.2013.09.008.
   Brierley C., 2011, THESIS.
   Burrows T., 2005, P INTERSPEECH 2005 9, P1829.
   Chen Q, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1581.
   Ingulfsen T., 2004, UCAMCLTR610.
   Keri V., 2007, P INT C NAT LANG PRO.
   Liu F., 2012, 2011 INT C EL COMM A, P811.
   Miranda J, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P132, DOI 10.1109/ASRU.2013.6707718.
   Mishra T, 2015, INT CONF ACOUST SPEE, P4919, DOI 10.1109/ICASSP.2015.7178906.
   Ostendorf M., 1989, J COMPUTATIONAL LING, V20, P26.
   Parlikar A., 2013, P 8 ISCA SPEECH SYNT.
   Paulik M, 2008, INT CONF ACOUST SPEE, P5105, DOI 10.1109/ICASSP.2008.4518807.
   Quinlan J.R., 1993, C4 5 PROGRAMMING MAC.
   Read I, 2007, COMPUT SPEECH LANG, V21, P519, DOI 10.1016/j.csl.2006.09.004.
   Rosenberg A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3066.
   Silverman K., 1992, ICSLP, P12.
   Sorin C., 1987, P 11 ICPHS TALL EST, P125.
   Steinhauer K, 2001, J PSYCHOLINGUIST RES, V30, P267, DOI 10.1023/A:1010443001646.
   Tauberer J., 2008, P SPEECH PROS 2008 4.
   Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041.
   Nguyen TT, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2719.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394402019}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000409394402021,
Author = {Zheng, Yibin and Li, Ya and Wen, Zhengqi and Ding, Xingguang and Tao,
   Jianhua},
Book-Group-Author = {{Int Speech Commun Assoc}},
Title = {{Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis
   by Using Enhanced Embedding Feature and Model Fusion Approach}},
Booktitle = {{17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES}},
Series = {{Interspeech}},
Year = {{2016}},
Pages = {{3201-3205}},
Note = {{17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016), San
   Francisco, CA, SEP 08-12, 2016}},
Organization = {{apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN;
   Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd;
   Yandex; Raytheon Technol}},
Abstract = {{Hierarchical prosody structure generation is an important but
   challenging component for speech synthesis systems. In this paper, we
   investigate the use of enhanced embedding (joint learning of character
   and word embedding (CWE)) features and different model fusion approaches
   at both character and word level for Mandarin prosodic boundaries
   prediction. For CWE module, the internal structures of words and non
   compositional words are considered in the word embedding, while the
   character ambiguity is addressed by multiple prototype character
   embedding. For model fusion module, linear function (LF) and gradient
   boosting decision tree (GBDT), are investigated at the decision level
   respectively, with the important features selected by feature ranking
   module used as its input. Experiment results show the effectiveness of
   the proposed enhanced embedding features and the two model fusion
   approaches at both character and word level.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zheng, YB (Corresponding Author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   Zheng, Yibin; Li, Ya; Wen, Zhengqi; Ding, Xingguang; Tao, Jianhua, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   Tao, Jianhua, Chinese Acad Sci, Inst Automat, CAS Ctr Excellence Brain Sci \& Intelligence Techn, Beijing 100190, Peoples R China.}},
DOI = {{10.21437/Interspeech.2016-1060}},
ISSN = {{2308-457X}},
ISBN = {{978-1-5108-3313-5}},
Keywords = {{prosodic boundaries prediction; model fusion; BLSTM; enhanced embedding
   features; speech synthesis}},
Research-Areas = {{Acoustics; Computer Science; Engineering; Linguistics}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical \& Electronic; Linguistics}},
Author-Email = {{yibin.zheng@nlpr.ia.ac.cn
   yli@nlpr.ia.ac.cn
   zqwen@nlpr.ia.ac.cn
   xingguang.ding@nlpr.ia.ac.cn
   jhtao@nlpr.ia.ac.cn}},
Funding-Acknowledgement = {{National High-Tech Research and Development Program of China (863
   Program)National High Technology Research and Development Program of
   China {[}2015AA016305]; National Natural Science Foundation of China
   (NSFC)National Natural Science Foundation of China (NSFC) {[}61305003,
   61425017, 61403386]; Strategic Priority Research Program of the CAS
   {[}XDB02080006]; Major Program for the National Social Science Fund of
   China {[}13ZD189]}},
Funding-Text = {{This work is supported by the National High-Tech Research and
   Development Program of China (863 Program) (No. 2015AA016305), the
   National Natural Science Foundation of China (NSFC) (No.61305003,
   No.61425017, No.61403386), the Strategic Priority Research Program of
   the CAS (Grant XDB02080006) and partly supported by the Major Program
   for the National Social Science Fund of China (13\&ZD189).}},
Cited-References = {{Ananthakrishnan S, 2005, INT CONF ACOUST SPEE, P269.
   {[}Anonymous], 2013, CRF OR TOOLK VERS 0.
   Busser G. J., 2001, P 4 ISCA TUT RES WOR.
   Chen X., 2015, P 24 INT JOINT C ART.
   Chen ZG, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1421.
   CHU M, 2001, COMPUT LINGUIST, V6, P61.
   Ding C., 2015, AUT SPEECH REC UND A.
   Fan Y., 2014, P INTERSPEECH, P1964.
   Fernandez R, 2014, INTERSPEECH, P805.
   Fernandez R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1606.
   Fernandez R, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1429.
   Hasegawa-Johnson M, 2005, SPEECH COMMUN, V46, P418, DOI 10.1016/j.specom.2005.01.009.
   Hastie T, 2009, ELEMENTS STAT LEARNI, P337.
   Hu Q, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P854.
   King  S., 2011, INTERSPEECH, P2157.
   Kuncheva L. I., 2004, WILEY INTERSCIENCE.
   Lai S., 2015, CREDIT UNION TIMES.
   Liu CL, 2005, PATTERN RECOGN, V38, P11, DOI 10.1016/j.patcog.2004.05.013.
   Menze H. Bjoern, 2008, BMC BIOINFORMATICS.
   Merritt T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2207.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Pennington J., 2014, P EMNLP C, P1532, DOI DOI 10.3115/V1/D14-1162.
   Rendel A., 2016, INT C AC SPEECH SIGN.
   Rosenberg  A., 2012, INTERSPEECH, P2558.
   Rosenberg A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3066.
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093.
   Sridhar VKR, 2008, IEEE T AUDIO SPEECH, V16, P797, DOI 10.1109/TASL.2008.917071.
   Vadapalli A, 2014, INTERSPEECH, P41.
   Van Rijsbergen CJ, 1979, INFORM RETRIEVAL.
   Wang PL, 2015, INT CONF ACOUST SPEE, P4879, DOI 10.1109/ICASSP.2015.7178898.
   Wightman CW, 1994, IEEE T SPEECH AUDI P, V2, P469, DOI 10.1109/89.326607.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI2LY}},
Unique-ID = {{ISI:000409394402021}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000405610900063,
Author = {Zheng, Yibin and Li, Ya and Wen, Zhengqi and Liu, Bin and Tao, Jianhua},
Editor = {{Lee, T and Xie, L and Dang, J and Wang, HM and Wei, J and Feng, H and Hou, Q and Wei, Y}},
Title = {{Text-based sentential stress prediction using continuous lexical
   embedding for Mandarin speech synthesis}},
Booktitle = {{2016 10TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING
   (ISCSLP)}},
Year = {{2016}},
Note = {{10th International Symposium on Chinese Spoken Language Processing
   (ISCSLP), Tianjin, PEOPLES R CHINA, OCT 17-20, 2016}},
Organization = {{Int Speech Commun Assoc; ISCA Special Interest Grp Chinese Spoken
   Language Proc; Tianjin Univ; IEEE Beijing Sect}},
Abstract = {{Stress is an important parameter for prosody processing in speech
   synthesis. However, it is not easy to stress from text analysis due to
   the complicated information. In this paper, we explore the novel use of
   the continuous lexical embedding and bidirectional long short-term
   memory recurrent neural network (BLSTM) model into sentential stress
   prediction for Mandarin speech synthesis. We look at augmenting the
   baseline features with word representations that are derived from text,
   providing continuous embedding of the lexicon in a low-dimensional
   space. Although learned in an unsupervised fashion, such features
   capture semantic and syntactic properties that make them amenable for
   stress prediction. We deploy various embedding models on Mandarin
   sentential stress prediction, showing substantial gains (relative gain
   gains of approximately 7.4\% in F1 score).}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zheng, YB (Corresponding Author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   Zheng, YB (Corresponding Author), Univ Chinese Acad Sci, Sch Comp \& Control Engn, Beijing, Peoples R China.
   Zheng, Yibin; Li, Ya; Wen, Zhengqi; Liu, Bin; Tao, Jianhua, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   Tao, Jianhua, Chinese Acad Sci, Inst Automat, CAS Ctr Excellence Brain Sci \& Intelligence Techn, Beijing 100190, Peoples R China.
   Zheng, Yibin; Tao, Jianhua, Univ Chinese Acad Sci, Sch Comp \& Control Engn, Beijing, Peoples R China.}},
ISBN = {{978-1-5090-4293-7}},
Keywords = {{word embedding; sentential stress prediction; speech synthesis; BLSTM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{yibin.zheng@nlpr.ia.ac.cn
   yli@nlpr.ia.ac.cn
   zgwen@nlpr.ia.ac.cn
   liubin@nlpr.ia.ac.cn
   jhtao@nlpr.ia.ac.cn}},
Funding-Acknowledgement = {{National High-Tech Research and Development Program of China (863
   Program)National High Technology Research and Development Program of
   China {[}2015AA016305]; National Natural Science Foundation of China
   (NSFC)National Natural Science Foundation of China (NSFC) {[}61305003,
   61425017, 61403386]; Strategic Priority Research Program of the CAS
   {[}XDB02080006]; Major Program for the National Social Science Fund of
   China {[}13ZD189]}},
Funding-Text = {{This work is supported by the National High-Tech Research and
   Development Program of China (863 Program) (No. 2015AA016305), the
   National Natural Science Foundation of China (NSFC) (No.61305003,
   No.61425017, No.61403386), the Strategic Priority Research Program of
   the CAS (Grant XDB02080006) and partly supported by the Major Program
   for the National Social Science Fund of China (13\&ZD189).}},
Cited-References = {{{[}Anonymous], 2015, CWE JOINT LEARNING C.
   Bastien F., 2012, DEEP LEARN UNS FEAT.
   Chen X., 2015, P 24 INT JOINT C ART.
   Fernandez R, 2014, INTERSPEECH, P805.
   Fernandez R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1606.
   Fujisaki H., 2004, SPEECH PROS 2004 INT.
   Lai S., 2015, CREDIT UNION TIMES.
   Lebret R, 2014, EACL.
   Li Y., 2014, INT C SPEECH PROS.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Mikolov T., 2013, P ICLR.
   Nenkova A., 2007, P HLT ACL ROCH NY AP, P9.
   Pennington J., 2014, P EMNLP C, P1532, DOI DOI 10.3115/V1/D14-1162.
   Pennington Jeffrey, 2015, GLOVE GLOBAL VECTORS.
   Rosenberg  A., 2012, INTERSPEECH, P2558.
   Rosenberg A, 2015, P INTERSPEECH.
   Shao Y, 2007, CHINESE J ACOUSTIC, V26, P49.
   Tao J., 2002, AUTOMATIC STRESS PRE.
   Vadapalli A, 2014, INTERSPEECH, P41.
   Wang P., 2015, ACOUSTICS SPEECH SIG, P4879.
   Xu J., 2000, CHINESE J ACOUSTICS, V25, P335.
   Yu K, 2010, INT CONF ACOUST SPEE, P4238, DOI 10.1109/ICASSP.2010.5495690.
   Zen HG, 2015, INT CONF ACOUST SPEE, P4470, DOI 10.1109/ICASSP.2015.7178816.
   Zhao Q., 2006, STUDY AUTOMATIC PRED, V31, P203.
   {[}朱维彬 ZHU Weibin], 2007, {[}中文信息学报, Journal of Chinese Information Processing], V21, P122.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BI1DZ}},
Unique-ID = {{ISI:000405610900063}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000400169400044,
Author = {Vijayalakshmi, R. and Priya, S.},
Book-Group-Author = {{IEEE}},
Title = {{An Interactive Speech Therapy Session using Linear Predictive Coding in
   Matlab and Arduino}},
Booktitle = {{PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION
   CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT)}},
Year = {{2016}},
Pages = {{217-220}},
Note = {{International Conference on Advanced Communication Control and Computing
   Technologies (ICACCCT), Syed Ammal Engn Coll, Ramanathapuram, INDIA, MAY
   25-27, 2016}},
Organization = {{IEEE Madras Sect}},
Abstract = {{Speech Therapy has become an efficient tool to bring back proper speech
   for patients suffering from various speech disorders. Patients are more
   benefitted when the speech therapy session is interactive where there is
   a visible change in the environment. Hence, the proposed system aims at
   manipulating devices when the user input is correct and also indicates
   if the user input is incorrect. Speech recognition has been done using
   the concept if Linear predictive coding and Arduino Uno board is used
   for hardware interface.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Vijayalakshmi, R (Corresponding Author), SA Engn Coll, Dept EEE, Chennai, Tamil Nadu, India.
   Vijayalakshmi, R.; Priya, S., SA Engn Coll, Dept EEE, Chennai, Tamil Nadu, India.}},
ISBN = {{978-1-4673-9545-8}},
Keywords = {{Speech therapy; Arduino; Linear Predictive Coding; Speech processing;
   ATmega328 microcontroller}},
Keywords-Plus = {{RECOGNITION}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{viji1192@gmail.com
   priyasakthikumar@gmail.com}},
Cited-References = {{Cubukcu A, 2015, SIG PROCESS COMMUN, P1801, DOI 10.1109/SIU.2015.7130204.
   Hornero G, 2015, IEEE ACCESS, V3, P1288, DOI 10.1109/ACCESS.2015.2466110.
   Jensen J, 2015, IEEE-ACM T AUDIO SPE, V23, P186, DOI 10.1109/TASLP.2014.2377591.
   Khaldi K, 2016, IET SIGNAL PROCESS, V10, P69, DOI 10.1049/iet-spr.2013.0425.
   Korkmaz OE, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P1254, DOI 10.1109/ELECO.2015.7394435.
   Orozco-Arroyave JR, 2015, IEEE J BIOMED HEALTH, V19, P1820, DOI 10.1109/JBHI.2015.2467375.
   Ranchal R, 2013, IEEE T LEARN TECHNOL, V6, P299, DOI 10.1109/TLT.2013.21.
   Stewart D, 2014, IEEE T CYBERNETICS, V44, P175, DOI 10.1109/TCYB.2013.2250954.
   Tiple C, 2015, E HLTH BIOENG C, V1, P1, DOI {[}10.1109/EHB.2015.7391472, DOI 10.1109/EHB.2015.7391472].
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101.
   Zhang ZX, 2015, IEEE-ACM T AUDIO SPE, V23, P115, DOI 10.1109/TASLP.2014.2375558.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BH4BD}},
Unique-ID = {{ISI:000400169400044}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000399233100011,
Author = {Alatwi, Aadel and So, Stephen and Paliwal, Kuldip K.},
Editor = {{Wysocki, TA and Wysocki, BJ}},
Title = {{Perceptually Motivated Linear Prediction Cepstral Features for Network
   Speech Recognition}},
Booktitle = {{2016 10TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND
   COMMUNICATION SYSTEMS (ICSPCS)}},
Year = {{2016}},
Note = {{10th International Conference on Signal Processing and Communication
   Systems (ICSPCS), Surfers Paradise, AUSTRALIA, DEC 19-21, 2016}},
Organization = {{IEEE; IEEE Commun Soc; MITRE; Univ Nebraska, Peter Kiewit Inst}},
Abstract = {{In this paper, we propose a new method for modifying the power spectrum
   of input speech to obtain a set of perceptually motivated Linear
   Prediction (LP) parameters that provide noise-robustness to Automatic
   Speech Recognition (ASR) features. Experiments were performed to compare
   the recognition accuracy obtained from Perceptual Linear
   Prediction-Cepstral Coefficients (PLP-LPCCs) and cepstral features
   derived from the conventional Linear Prediction Coding (LPC) parameters
   with that obtained from the proposed method. The results show that,
   using the proposed approach, the speech recognition performance was on
   average 4.93\% to 7.09\% and 3\% to 5.71\% better than the conventional
   method and the PLP-LPCCs, respectively, depending on the recognition
   task.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Alatwi, A (Corresponding Author), Griffith Univ, Signal Proc Lab, Brisbane, Qld 4111, Australia.
   Alatwi, Aadel; So, Stephen; Paliwal, Kuldip K., Griffith Univ, Signal Proc Lab, Brisbane, Qld 4111, Australia.}},
ISBN = {{978-1-5090-0941-1}},
Keywords = {{Linear prediction coefficients; Network speech recognition; Spectral
   estimation}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{aadel.alatwi@griffithuni.edu.au
   s.so@griffith.edu.au
   k.paliwal@griffith.edu.au}},
Cited-References = {{ETSI, 2007, 126090 ETSI TS.
   Evermann Gunnar, 2006, HTK BOOK VERSION 3 4.
   Fisher W. M, 1986, P DARPA WORKSH SPEEC, P93.
   Fletcher H, 1940, REV MOD PHYS, V12, P0047, DOI 10.1103/RevModPhys.12.47.
   Hayes MH, 2009, STAT DIGITAL SIGNAL.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   KAY SM, 1979, IEEE T ACOUST SPEECH, V27, P478, DOI 10.1109/TASSP.1979.1163275.
   Kiss I., 2000, P INT C SPOK LANG PR.
   Kleijn W.B., 1995, SPEECH CODING SYNTHE.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Makhoul J., 1975, ACOUST SPEECH SIGNAL, V23, P283.
   Moore B.C.J., 1997, INTRO PSYCHOL HEARIN.
   Rabiner L., 1993, FUNDAMENTALS SPEECH.
   Rao P.R., 2013, COMMUNICATION SYSTEM.
   So S, 2006, SPEECH COMMUN, V48, P746, DOI 10.1016/j.specom.2005.10.002.
   Tan Z.H., 2010, MOBILE MULTIMEDIA PR.
   Trabelsi A., 2007, CIRC SYST 2007 NEWCA, P93.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH2SJ}},
Unique-ID = {{ISI:000399233100011}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000392177200006,
Author = {Andersen, Asger Heidemann and Schoenmaker, Esther and van de Par, Steven},
Book-Group-Author = {{IEEE}},
Title = {{SPEECH INTELLIGIBILITY PREDICTION AS A CLASSIFICATION PROBLEM}},
Booktitle = {{2016 IEEE 26TH INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL
   PROCESSING (MLSP)}},
Series = {{IEEE International Workshop on Machine Learning for Signal Processing}},
Year = {{2016}},
Note = {{26th IEEE International Workshop on Machine Learning for Signal
   Processing (MLSP), Salerno, ITALY, SEP 13-16, 2016}},
Organization = {{IEEE; IEEE Signal Proc Soc, Machine Learning Signal Proc Tech Comm}},
Abstract = {{Speech Intelligibility Prediction (SIP) algorithms are becoming
   increasingly popular for objective evaluation of speech processing
   algorithms and transmission systems. Most often, SIP algorithms aim to
   predict the average intelligibility of an average listener in some
   specific listening condition. In the present work, we instead consider
   the aim of predicting the intelligibility of singlewords. I.e. we
   attempt to predict whether or not a subject in a listening experiment
   was able to correctly repeat a particular word. We base the prediction
   on a noisy and potentially processed/degraded recording of the spoken
   word (as presented to a subject), as well as a clean reference recording
   of the spoken word. The problem can be treated as a supervised binary
   classification problem of predicting whether a specific word will or
   will not be understood. We investigate a number of different ways to
   extract features from the degraded and clean speech samples. The
   classification is carried out by means of Fisher discriminant analysis.
   Despite the large variability of speech intelligibility experiments, it
   is possible to obtain a considerable degree of predictive power.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Andersen, AH (Corresponding Author), Oticon AS, DK-2765 Smorum, Denmark.
   Andersen, Asger Heidemann, Oticon AS, DK-2765 Smorum, Denmark.
   Schoenmaker, Esther; van de Par, Steven, Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.}},
ISSN = {{2161-0363}},
ISBN = {{978-1-5090-0746-2}},
Keywords = {{Speech intelligibility prediction; speech enhancement; binary
   classification; applications of machine learning}},
Keywords-Plus = {{NORMAL-HEARING LISTENERS; RECEPTION THRESHOLD; FLUCTUATING NOISE; MODEL;
   RECOGNITION; PERCEPTION; INDEX}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Cited-References = {{ANSI, 1997, S351997 ANSI.
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575.
   Bishop C. M., 2006, PATTERN RECOGNITION.
   Bronkhorst AW, 2000, ACUSTICA, V86, P117.
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104.
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600.
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959.
   DURLACH NI, 1963, J ACOUST SOC AM, V35, P1206, DOI 10.1121/1.1918675.
   Ellis D. P. W, 2005, PLP RASTA MFCC INVER.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Geravanchizadeh M, 2015, J ACOUST SOC AM, V138, P4004, DOI 10.1121/1.4938230.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   Jorgensen S, 2015, ACTA ACUST UNITED AC, V101, P1016, DOI 10.3813/AAA.918896.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Meyer BT, 2010, J ACOUST SOC AM, V128, P3126, DOI 10.1121/1.3493450.
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825.
   Rhebergen KS, 2006, J ACOUST SOC AM, V120, P3988, DOI 10.1121/1.2358008.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   Schadler MR, 2015, INT J AUDIOL, V54, P100, DOI 10.3109/14992027.2015.1061708.
   Schoenmaker E., 2013, 21 INT C AC MONTR CA.
   Schoenmaker E, 2016, J ACOUST SOC AM, V139, P2589, DOI 10.1121/1.4948568.
   Smeds K, 2014, J ACOUST SOC AM, V136, P1363, DOI 10.1121/1.4892766.
   SOndergaard P., 2013, TECHNOLOGY BINAURAL, P33, DOI DOI 10.1007/978-3-642-37762-4\_2.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BG8BL}},
Unique-ID = {{ISI:000392177200006}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000391380901108,
Author = {Singh, Shashi Pal and Kumar, Ajai and Mandad, Daya Chand and Jadwani,
   Yasha},
Book-Group-Author = {{IEEE}},
Title = {{Word and Phrase Prediction Tool for English and Hindi language}},
Booktitle = {{2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND
   OPTIMIZATION TECHNIQUES (ICEEOT)}},
Year = {{2016}},
Pages = {{1485-1488}},
Note = {{International Conference on Electrical, Electronics, and Optimization
   Techniques (ICEEOT), Palnchur, INDIA, MAR 03-05, 2016}},
Organization = {{DMI Coll Engn; IEEE DMI Coll Student Branch}},
Abstract = {{Prediction of text while writing has been of utmost importance to
   people. Prediction has served as a helping hand to people who are slow
   in typing, or who do not have a good vocabulary. In a country of 336
   million populations where people are more frequent in Hindi language,
   and want to get prediction in Hindi as well. Writing the entire phrases
   on their own, makes it more prone to errors and mistakes that are made
   while typing. The prediction tool reduces the chances of having errors
   while typing. It helps the user for typing efficiently and with a faster
   speed.
   The tool is able to predict using multiple algorithms and also we tried
   to build our own bilingual database which contains phrases of variable
   length along with their frequency of occurrence in corpus. Whenever a
   word or phrase is selected from the prediction list, its frequency is
   increased by one. Consequently, the most frequently used word will have
   highest frequency/probability leading to increase in efficiency of
   predictions. Those words and phrases that are not present in the
   database but have been typed by the user are fed into the database for
   being used in future predictions. Thus, longer the tool is used, better
   results it will show
   Thus, this paper proposes a bilingual word prediction tool that predicts
   words and phrases for both English and Hindi language. The tool uses
   different models for the prediction and hence provides a comparison as
   to which model is better to use and gives better results.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Singh, SP (Corresponding Author), Ctr Dev Adv Comp, AAI, Pune, Maharashtra, India.
   Singh, Shashi Pal; Kumar, Ajai; Mandad, Daya Chand, Ctr Dev Adv Comp, AAI, Pune, Maharashtra, India.
   Jadwani, Yasha, Banasthali Vidyapith, Banasthali, India.}},
ISBN = {{978-1-4673-9939-5}},
Keywords = {{Phrase prediction; probability; bilingual database; corpus; Natural
   Language Processing}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{shashis@cdac.in
   ajai@cdac.in
   dayam@cdac.in
   jadwani.yasha@gmail.com}},
Cited-References = {{Anson Denis, EFFECTS WORD COMPLET.
   Ghayoomi Masood, 2009, OVERVIEW EXISTING LA, P1.
   HIGGINBOTHAM DJ, 1992, AUGMENTATIVE ALTERNA, V8, P258, DOI DOI 10.1080/07434619212331276303.
   Levine Simon P., 1994, MODELING SPEED TEXT, P1.
   MacArthur Charles A., 1999, OVERCOMING BARRIERS.
   Wandmacher Tonio, 2007, METHODS INTEGRATE LA, P1.}},
Number-of-Cited-References = {{6}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG7JO}},
Unique-ID = {{ISI:000391380901108}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000390779200017,
Author = {Salehi, Haniyeh and Parsa, Vijay},
Book-Group-Author = {{IEEE}},
Title = {{Nonintrusive Speech Quality Estimation Based on Perceptual Linear
   Prediction}},
Booktitle = {{2016 IEEE CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING
   (CCECE)}},
Series = {{Canadian Conference on Electrical and Computer Engineering}},
Year = {{2016}},
Note = {{IEEE Canadian Conference on Electrical and Computer Engineering (CCECE),
   Vancouver, CANADA, MAY 14-18, 2016}},
Organization = {{IEEE; IEEE Vancouver Sect}},
Abstract = {{Objective measures of speech quality are attractive because they
   facilitate performance assessment of hearing aids (HAs) without the need
   for human listeners. Objective speech quality predictions are usually
   performed intrusively, wherein the ``closeness{''} between the reference
   and HA output speech recordings is quantitied. In this paper, we focus
   on nonintrusive estimation of HA speech quality based on Perceptual
   Linear Prediction (PLP) modeling approach. In PLP, perceptual phenomena
   such as non-uniform filter bank analysis and nonlinear mapping between
   sound intensity and its perceived loudness are incorporated into the
   linear prediction feature extraction process. In this work, PLP and
   PLP-based cepstral coefficients were computed from HA speech recordings
   and their statistical properties were utilized as features for speech
   quality estimation. A custom database of HA speech recordings obtained
   in different noisy and reverberant environments was used to investigate
   the predictive performance of these individual features. In addition,
   regression functions that linearly combined the features and mapped to
   the predicted quality scores, were derived and validated. Experimental
   results show that the proposed nonintrusive speech quality estimates
   correlate well with subjective ratings of speech quality by heating
   impaired listeners.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Salehi, H (Corresponding Author), Univ Western Ontario, Natl Ctr Audiol \& Elect \& Comp Engn, London, ON, Canada.
   Salehi, Haniyeh; Parsa, Vijay, Univ Western Ontario, Natl Ctr Audiol \& Elect \& Comp Engn, London, ON, Canada.}},
ISSN = {{0840-7789}},
ISBN = {{978-1-4673-8721-7}},
Keywords = {{Perceptual Linear Prediction; Nonintnlsive speech quality assessment;
   hewing aids}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{hsalehi@uwo.ca
   vparsa@uwo.ca}},
Cited-References = {{ABRAMS HB, 2015, HEAR REV, V22, P16.
   {[}Anonymous], 2004, P563 ITUT.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Kates JM, 2010, J AUDIO ENG SOC, V58, P363.
   Loizou PC, 2011, STUD COMPUT INTELL, V346, P623.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Preacher K.J, 2002, CALCULATION TEST DIF.
   Rabiner L. R., 1978, DIGITAL PROCESSING S.
   Salehi H, 2015, IEEE WORK APPL SIG.
   Smeds K, 2015, J AM ACAD AUDIOL, V26, P183, DOI 10.3766/jaaa.26.2.7.
   STEIGER JH, 1980, PSYCHOL BULL, V87, P245, DOI 10.1037/0033-2909.87.2.245.
   Suelzle D., 2013, ELECTROACOUSTIC BEHA.
   Suelzle D, 2013, J ACOUST SOC AM, V133, pEL412, DOI 10.1121/1.4802186.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG6QC}},
Unique-ID = {{ISI:000390779200017}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000390719100056,
Author = {Nagalavi, Deepa and Hanumanthappa, M.},
Book-Group-Author = {{IEEE}},
Title = {{N-gram Word Prediction Language Models to Identify the Sequence of
   Article Blocks in English E-Newspapers}},
Booktitle = {{2016 INTERNATIONAL CONFERENCE ON COMPUTATION SYSTEM AND INFORMATION
   TECHNOLOGY FOR SUSTAINABLE SOLUTIONS (CSITSS)}},
Year = {{2016}},
Pages = {{307-311}},
Note = {{1st IEEE International Conference on Computational Systems and
   Information Technology for Sustainable Solutions (CSITSS), R V Coll
   Engn, Bengaluru, INDIA, OCT 06-08, 2016}},
Organization = {{IEEE; IEEE Comp Soc, Bangalore Chapter; TEQIP 1 2; Oracle; Honda; HPE}},
Abstract = {{In the analysis of newspaper page, an identification of individual
   article is an essential task. Since the articles are the most important
   information unit in a newspaper. A newspaper contains variety of
   multiple articles with different heterogeneous page layouts.
   Consequently the articles in a page are divided into multiple unordered
   blocks. In this paper the link is established between different blocks
   of an article with the reading order of a sentence. It is identified
   with an N-Gram based linguistic processing approach for the retrieval of
   individual article from newspaper. The model predicts the preceding word
   knowing the previous content with the probability of a word sequence.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Nagalavi, D (Corresponding Author), Bangalore Univ, Dept Comp Sci \& Applicat, Bangalore, Karnataka, India.
   Nagalavi, Deepa; Hanumanthappa, M., Bangalore Univ, Dept Comp Sci \& Applicat, Bangalore, Karnataka, India.}},
ISBN = {{978-1-5090-1022-6}},
Keywords = {{N-Gram; Newspaper; Natural Language Processing; Word Prediction; backoff
   method; Interpolation}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{deepatnagalavi@bub.ernet.in
   hanu6572@bub.ernet.in}},
Cited-References = {{Agarwal Sachin, 2007, C RIAO2007 PITTS PA.
   BICKEL S, 2005, P HUM LANG TECHN C C, P193.
   Gendron Gerald R., 2015, MODSIM WORLD 2015, P1.
   Ghayoomi Masood, 2009, P 2009 IEEE INT C SY.
   Haque M, 2015, INT J FOUND COMPUT S, DOI {[}10.5121/ijfcst.2015.5607, DOI 10.5121/IJFCST.2015.5607].
   Makkar R, 2015, ADV COMPUTER SCI INF, V2, P177.
   Shashi Pal Singh, 2016, INT C EL EL OPT TECH.
   Wiegand Karl, 2012, NAACL HLT 2012 WORKS, P28.
   Wu Xiaoyi, 2015, LECT NOTES ARTIF INT, V9449, P275, DOI {[}10.1007/978-3-319-25789-126, DOI 10.1007/978-3-319-25789-126].}},
Number-of-Cited-References = {{9}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG6PJ}},
Unique-ID = {{ISI:000390719100056}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000389510800030,
Author = {Chen, Xiao and Xu, Bo},
Editor = {{Chen, G and Peng, J}},
Title = {{Stable-time Prediction during Incremental Speech Recognition}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE OF ONLINE ANALYSIS AND COMPUTING
   SCIENCE (ICOACS)}},
Year = {{2016}},
Pages = {{135-138}},
Note = {{IEEE International Conference of Online Analysis and Computing Science
   (ICOACS), Chongqing, PEOPLES R CHINA, MAY 28-29, 2016}},
Organization = {{IEEE}},
Abstract = {{Incremental speech recognition (ISR) is the key technology to increase
   the efficiency of human-computer interaction and obtain the good user
   experience. However, ISR's results are not stable. The earlier methods
   decide whether to output the current best partial result by stable-time.
   These methods can increase stability, but introduce a lag which lowers
   the advantage of user experience. In this paper, a new method based on
   the stable-time prediction is proposed. It predicts the probable
   stable-time of the current best partial result in the future, using the
   acoustic score information of N-best paths of successive frames. So it
   can determine whether to output the current best partial result in
   advance. It can reduce lags and improve performance. Results indicate
   that, the proposed method outperforms the baseline. At the lag of 0.2s,
   the proposed method results in an absolute improvement of 1.2\% and
   achieves a stability of 92.2\%. And at the other lags, the proposed
   method also results in a similar improvement.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Chen, X (Corresponding Author), Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr IDMTech, Beijing, Peoples R China.
   Chen, Xiao; Xu, Bo, Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr IDMTech, Beijing, Peoples R China.}},
ISBN = {{978-1-4673-7755-3}},
Keywords = {{incremental speech recognition; stability; lag; stable-time prediction}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods}},
Author-Email = {{xiao.chen@ia.ac.cn}},
Cited-References = {{Allen J., 2007, P 2007 WORKSH SEM PR, P761.
   Bangalore  S., 2012, P 2012 C N AM CHAPT, P437.
   Baumann Timo, 2009, P NAACL HLT BOULD US, P380.
   Bolanos D., 2012, SPOK LANG TECHN WORK, P354.
   Bolanos D., 2011, ACM T SPEECH LANGUAG, V7, P16.
   Bolanos D, 2013, SPEECH COMMUN, V55, P221, DOI 10.1016/j.specom.2012.08.002.
   Fink GA, 1998, IEEE IND ELEC, P2012, DOI 10.1109/IECON.1998.724027.
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126.
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977.
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y.
   McGraw I, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1018.
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357.
   Selfridge E., 2011, P ANN M SPEC INT GRO, P110.
   Selfridge E.O., 2012, P 13 ANN M SPEC INT, P275.
   WACHSMUTH S, 1998, P EUR SIGN PROC C RH, V1, P371.
   Ward W., 2011, ACM T SPEECH LANG PR, V7, P18.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BG5JK}},
Unique-ID = {{ISI:000389510800030}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000388373400102,
Author = {Parchami, Mahdi and Zhu, Wei-Ping and Champagne, Benoit},
Book-Group-Author = {{IEEE}},
Title = {{SPEECH DEREVERBERATION USING LINEAR PREDICTION WITH ESTIMATION OF EARLY
   SPEECH SPECTRAL VARIANCE}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING PROCEEDINGS}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2016}},
Pages = {{504-508}},
Note = {{41st IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Shanghai, PEOPLES R CHINA, MAR 20-25, 2016}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{In this paper, we present a new dereverberation algorithm based on the
   weighted prediction error (WPE) method. In contrast to the conventional
   WPE method which alternatively estimates the reverberation prediction
   weights and early speech spectral variance, the proposed algorithm
   estimates the latter efficiently by employing a geometric spectral
   enhancement approach and a proper estimate for late reverberant spectral
   variance (LRSV). Hence, our algorithm does not require iterations to
   estimate the reverberation prediction weights nor needs alternation
   between the prediction weights and the spectral variance of early
   speech. Performance assessments demonstrate considerable improvements in
   terms of speech quality measures and computational load compared to
   previous WPE-based dereverberation methods.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Parchami, M (Corresponding Author), Concordia Univ, Dept Elect \& Comp Engn, Montreal, PQ, Canada.
   Parchami, Mahdi; Zhu, Wei-Ping, Concordia Univ, Dept Elect \& Comp Engn, Montreal, PQ, Canada.
   Champagne, Benoit, McGill Univ, Dept Elect \& Comp Engn, Montreal, PQ, Canada.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-9988-0}},
Keywords = {{Late reverberant spectral variance; linear prediction-based
   dereverberation; statistical model-based speech enhancement}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{m\_parch@ece.concordia.ca
   weiping@ece.concordia.ca
   benoit.champagne@mcgill.ca}},
Cited-References = {{{[}Anonymous], 2013, REVERB CHALLENGE.
   Cohen I., 2010, SPEECH PROCESSING MO.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Habets E. A. P., 2007, THESIS.
   Habets EAP, 2009, IEEE SIGNAL PROC LET, V16, P770, DOI 10.1109/LSP.2009.2024791.
   Iwata Y, 2012, INT CONF ACOUST SPEE, P245, DOI 10.1109/ICASSP.2012.6287863.
   Jukic Ante, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5172, DOI 10.1109/ICASSP.2014.6854589.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita T, 2013, 2013 9TH INTERNATIONAL WORKSHOP ON ELECTROMAGNETIC COMPATIBILITY OF INTEGRATED CIRCUITS (EMC COMPO 2013), P1, DOI 10.1109/EMCCompo.2013.6735162.
   Kodrasi I, 2013, IEEE T AUDIO SPEECH, V21, P1879, DOI 10.1109/TASL.2013.2260743.
   Lehmann E. A., IMAGE SOURCE METHOD.
   Lollmann H. W., 2010, P INT WORKSH AC ECH.
   Lu Y, 2008, SPEECH COMMUN, V50, P453, DOI 10.1016/j.specom.2008.01.003.
   Maas R, 2012, INT CONF ACOUST SPEE, P297, DOI 10.1109/ICASSP.2012.6287875.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Schmid D, 2012, INT CONF ACOUST SPEE, P17, DOI 10.1109/ICASSP.2012.6287806.
   Togami M, 2013, INT CONF ACOUST SPEE, P7447, DOI 10.1109/ICASSP.2013.6639110.
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG3XQ}},
Unique-ID = {{ISI:000388373400102}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000388373400126,
Author = {Karbasi, Mahdie and AbdelAziz, Ahmed Hussen and Kolossa, Dorothea},
Book-Group-Author = {{IEEE}},
Title = {{TWIN-HMM-BASED NON-INTRUSIVE SPEECH INTELLIGIBILITY PREDICTION}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING PROCEEDINGS}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2016}},
Pages = {{624-628}},
Note = {{41st IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Shanghai, PEOPLES R CHINA, MAR 20-25, 2016}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Most of the objective measures employed for speech intelligibility
   prediction require a clean reference signal, which is not accessible in
   all realistic scenarios. In this paper, we propose to re-synthesize the
   relevant features of the clean signal using only the noisy speech signal
   and utilize them inside an intelligibility prediction framework which
   requires a reference. A statistical model called twin hidden Markov
   model (THMM) is used to synthesize the clean speech features. For the
   intelligibility prediction framework, the short-time objective
   intelligibility (STOI) measure is used as an accurate and well-known
   method. The experimental results show a high correlation between the
   twin-HMM-based STOI (THMMB-STOI) and the human speech recognition
   results, even slightly outperforming the conventional STOI predictions
   computed using the actual clean reference signals.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Karbasi, M (Corresponding Author), Ruhr Univ Bochum, Cognit Signal Proc Grp, Inst Commun Acoust, D-44801 Bochum, Germany.
   Karbasi, Mahdie; AbdelAziz, Ahmed Hussen; Kolossa, Dorothea, Ruhr Univ Bochum, Cognit Signal Proc Grp, Inst Commun Acoust, D-44801 Bochum, Germany.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-9988-0}},
Keywords = {{Speech intelligibility prediction; twin HMM; non-intrusive method;
   objective measures}},
Keywords-Plus = {{ENHANCEMENT}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{Mahdie.Karbasi@rub.de
   Ahmed.HussenAbdelAziz@rub.de
   Dorothea.Kolossa@rub.de}},
ResearcherID-Numbers = {{Kolossa, Dorothea/D-5177-2013}},
ORCID-Numbers = {{Karbasi, Mahdie/0000-0003-4200-6729
   Kolossa, Dorothea/0000-0003-0678-3053}},
Cited-References = {{Abdelaziz AH, 2013, INTERSPEECH, P867.
   Abdelaziz AH, 2013, INT CONF ACOUST SPEE, P3726, DOI 10.1109/ICASSP.2013.6638354.
   ANSI, 1997, S351997 ANSI.
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Gao JB, 2015, INT CONF ACOUST SPEE, P2095, DOI 10.1109/ICASSP.2015.7178340.
   Hsu CC, 2015, INT CONF ACOUST SPEE, P370, DOI 10.1109/ICASSP.2015.7177993.
   Jorgensen S., 2011, J ACOUST SOC AM, V129, P2384.
   Nemala SK, 2010, INT CONF ACOUST SPEE, P4742, DOI 10.1109/ICASSP.2010.5495170.
   Sharma D., 2013, P INT C REC TRENDS I, P1.
   Sharma D, 2010, EUR SIGNAL PR CONF, P1899.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Taghia J, 2014, IEEE-ACM T AUDIO SPE, V22, P6, DOI 10.1109/TASL.2013.2281574.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BG3XQ}},
Unique-ID = {{ISI:000388373400126}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000388373405026,
Author = {Gowda, Dhananjaya and Airaksinen, Manu and Alku, Paavo},
Book-Group-Author = {{IEEE}},
Title = {{QUASI CLOSED PHASE ANALYSIS OF SPEECH SIGNALS USING TIME VARYING
   WEIGHTED LINEAR PREDICTION FOR ACCURATE FORMANT TRACKING}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING PROCEEDINGS}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2016}},
Pages = {{4980-4984}},
Note = {{41st IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Shanghai, PEOPLES R CHINA, MAR 20-25, 2016}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Recent research on temporally weighted linear prediction shows that
   quasi closed phase (QCP) analysis of speech signals provides better
   modeling of the vocal tract and the glottal source. Quasi closed phase
   analysis gives more weightage on the closed phase of the glottal cycle,
   at the same time deemphasizing the region around the instant of
   significant excitation which is often poorly predicted. However, all the
   traditional analysis techniques including the QCP analysis is performed
   over short intervals of time. They do not impose any continuity
   constraints either on the vocal tract system or the glottal source. Such
   constraints are often imposed at a later stage to either smooth or track
   the estimated features over time. Time varying linear prediction (TVLP)
   provides a framework for modeling speech with a long-term continuity
   constraint imposed on the vocal tract shape. In this paper, we propose a
   new method for accurate modeling and tracking of the vocal tract
   resonances by integrating the advantages of a QCP analysis with that of
   TVLP. Formant tracking experiments show consistent improvement in
   performance over traditional LP or TVLP methods under a variety of
   conditions including different voice types and over a wide range of
   fundamental frequency.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gowda, D (Corresponding Author), Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.
   Gowda, Dhananjaya; Airaksinen, Manu; Alku, Paavo, Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-9988-0}},
Keywords = {{Quasi closed phase analysis; time varying linear prediction; weighted
   linear prediction; formant tracking}},
Keywords-Plus = {{INVERSE FILTERING ANALYSIS}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{dhananjaya.gowda@aalto.fi
   manu.airakslnen@aalto.fi
   paavo.alku@aalto.fi}},
ResearcherID-Numbers = {{Alku, Paavo/E-2400-2012
   }},
ORCID-Numbers = {{Airaksinen, Manu/0000-0002-8031-2260
   Alku, Paavo/0000-0002-8173-9418}},
Cited-References = {{Airaksinen M, 2014, IEEE-ACM T AUDIO SPE, V22, P596, DOI 10.1109/TASLP.2013.2294585.
   Alku P., 2013, J ACOUSTICAL SOC AM, V134.
   Alku P, 2011, SADHANA-ACAD P ENG S, V36, P623, DOI 10.1007/s12046-011-0041-5.
   Chetupalli S., 2014, AC SPEECH SIGN PROC, P6290.
   Deng L, 2006, INT CONF ACOUST SPEE, P369.
   Fant G., 1985, STL QPSR, V4, P1, DOI DOI 10.1016/0167-6393(89)90001-0.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   HALL MG, 1983, SIGNAL PROCESS, V5, P267, DOI 10.1016/0165-1684(83)90074-9.
   KAY SM, 1988, MODERN SPECTRUM ESTI.
   MA CX, 1993, SPEECH COMMUN, V12, P69, DOI 10.1016/0167-6393(93)90019-H.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Pohjalainen J., 2009, P INTERSPEECH.
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649.
   Schnell K, 2008, INT CONF ACOUST SPEE, P3941, DOI 10.1109/ICASSP.2008.4518516.
   Sjolander K., 2000, P INT C SPOKEN LANGU, V2000, P464.
   Talkin D., 1987, J ACOUST SOC AM, V82.
   WIPF D, 2010, SELECTED TOPICS SIGN, V4, P317, DOI DOI 10.1109/JSTSP.2010.2042413.
   WONG DY, 1979, IEEE T ACOUST SPEECH, V27, P350, DOI 10.1109/TASSP.1979.1163260.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG3XQ}},
Unique-ID = {{ISI:000388373405026}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000388373405029,
Author = {Andersen, Asper Heidemann and de Haan, Jan Mark and Tan, Zheng-Hua and
   Jensen, Jesper},
Book-Group-Author = {{IEEE}},
Title = {{A METHOD FOR PREDICTING THE INTELLIGIBILITY OF NOISY AND NON-LINEARLY
   ENHANCED BINAURAL SPEECH}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING PROCEEDINGS}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2016}},
Pages = {{4995-4999}},
Note = {{41st IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Shanghai, PEOPLES R CHINA, MAR 20-25, 2016}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{We propose and evaluate a binaural speech intelligibility measure. The
   measure is a binaural extension of the Short-Time Objective
   Intelligibility (STOI) measure and focuses on predicting the
   intelligibility of noisy speech which has been enhanced by a speech
   processing algorithm (e.g. in a hearing aid). We show that the measure
   can accurately predict 1) the Speech Reception Threshold (SRT) for a
   frontal speaker masked by a point noise source in the horizontal plane,
   2) the improvement in SRT obtained by independently processing the left
   and right ear signals with Ideal Time Frequency Segregation (ITFS), and
   3) the intelligibility of speech in the presence of multiple interferers
   as well as the effect of processing the noisy signals with 2-microphone
   MVDR beamforming as used in hearing aids. Finally, we show that the
   computational demands associated with the measure are favourable in
   comparison with those of a previously proposed measure with similar
   properties.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Andersen, AH (Corresponding Author), Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.
   Andersen, AH (Corresponding Author), Oticon AS, DK-2765 Smorum, Denmark.
   Andersen, Asper Heidemann; Tan, Zheng-Hua; Jensen, Jesper, Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.
   Andersen, Asper Heidemann; de Haan, Jan Mark; Jensen, Jesper, Oticon AS, DK-2765 Smorum, Denmark.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-9988-0}},
Keywords = {{binaural speech intelligibility prediction; enhanced speech; speech in
   noise}},
Keywords-Plus = {{REVERBERATION; EQUALIZATION; QUALITY; HEARING; MODEL; ROOMS}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{aha@es.aau.dk
   janh@oticon.com
   zt@es.aau.dk
   jje@es.aau.dk}},
Cited-References = {{Algazi V. R., 2001, P 2001 IEEE WORKSH A.
   American National Standard Institute S3.5-1997, 1997, S351997 AM NAT STAND.
   Andersen AH, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2563.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575.
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152.
   Bronkhorst AW, 2000, ACUSTICA, V86, P117.
   Durlach N. I., 1972, F MODERN AUDITORY TH, P371.
   DURLACH NI, 1963, J ACOUST SOC AM, V35, P1206, DOI 10.1121/1.1918675.
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   Holube I, 2010, INT J AUDIOL, V49, P891, DOI 10.3109/14992027.2010.506889.
   HOUTGAST T, 1971, ACUSTICA, V25, P355.
   Jelfs S, 2011, HEARING RES, V275, P96, DOI 10.1016/j.heares.2010.12.005.
   Jensen J, 2014, IEEE-ACM T AUDIO SPE, V22, P430, DOI 10.1109/TASLP.2013.2295914.
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002.
   Lavandier M, 2012, J ACOUST SOC AM, V131, P218, DOI 10.1121/1.3662075.
   Lavandier M, 2010, J ACOUST SOC AM, V127, P387, DOI 10.1121/1.3268612.
   Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617.
   Pedersen ER, 2014, INT J AUDIOL, V53, P336, DOI 10.3109/14992027.2013.860486.
   Rennies J, 2011, J ACOUST SOC AM, V130, P2999, DOI 10.1121/1.3641368.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal CH, 2012, EUR SIGNAL PR CONF, P504.
   Taal CH, 2011, J ACOUST SOC AM, V130, P3013, DOI 10.1121/1.3641373.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   VESTERGAARD M, 1998, 0500801 OT RES CTR.
   vomHovel H., 1984, THESIS.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.
   Wan R, 2010, J ACOUST SOC AM, V128, P3678, DOI 10.1121/1.3502458.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BG3XQ}},
Unique-ID = {{ISI:000388373405029}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000388373405161,
Author = {Rendel, Asaf and Fernandez, Raul and Hoory, Ron and Ramabhadran, Bhuvana},
Book-Group-Author = {{IEEE}},
Title = {{USING CONTINUOUS LEXICAL EMBEDDINGS TO IMPROVE SYMBOLIC-PROSODY
   PREDICTION IN A TEXT-TO-SPEECH FRONT-END}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING PROCEEDINGS}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2016}},
Pages = {{5655-5659}},
Note = {{41st IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Shanghai, PEOPLES R CHINA, MAR 20-25, 2016}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{The prediction of symbolic prosodic categories from text is an
   important, but challenging, natural-language processing task given the
   various ways in which an input can be realized, and the fact that
   knowledge about what features determine this realization is incomplete
   or inaccessible to the model. In this work, we look at augmenting
   baseline features with lexical representations that are derived from
   text, providing continuous embeddings of the lexicon in a
   lower-dimensional space. Although learned in an unsupervised fashion,
   such features capture semantic and syntactic properties that make them
   amenable for prosody prediction. We deploy various embedding models on
   prominence-and phrase-break prediction tasks, showing substantial gains,
   particularly for prominence prediction.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Rendel, A (Corresponding Author), IBM Haifa Res Lab, Haifa, Israel.
   Rendel, Asaf; Hoory, Ron, IBM Haifa Res Lab, Haifa, Israel.
   Fernandez, Raul; Ramabhadran, Bhuvana, IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-9988-0}},
Keywords = {{word embeddings; prominence prediction; prosodic phrasing; speech
   synthesis; deep learning}},
Keywords-Plus = {{RECURRENT NEURAL-NETWORK}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{asafren@il.ibm.com
   fernanra@us.ibm.com}},
Cited-References = {{Bansal M., 2015, P NAACL HLT, P102.
   Bastien F., 2012, DEEP LEARN UNS FEAT.
   Fan Y., 2014, P INTERSPEECH, P1964.
   Fernandez R, 2014, INTERSPEECH, P805.
   Fernandez R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1606.
   Fernandez R, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1429.
   Graff D, 2003, ENGLISH GIGAWORD.
   HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C.
   Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   Mikolov T., 2013, P ICLR.
   Nenkova A., 2007, P HLT ACL ROCH NY AP, P9.
   Pennington J., 2014, P EMNLP C, P1532, DOI DOI 10.3115/V1/D14-1162.
   Pennington Jeffrey, 2015, GLOVE GLOBAL VECTORS.
   Read  I., 2007, INTERSPEECH, P297.
   Rosenberg  A., 2012, INTERSPEECH, P2558.
   Rosenberg A., 2009, THESIS.
   Rosenberg A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3066.
   Ross K, 1996, COMPUT SPEECH LANG, V10, P155, DOI 10.1006/csla.1996.0010.
   Vadapalli A, 2014, INTERSPEECH, P41.
   Wang PL, 2015, INT CONF ACOUST SPEE, P4879, DOI 10.1109/ICASSP.2015.7178898.
   Zen HG, 2015, INT CONF ACOUST SPEE, P4470, DOI 10.1109/ICASSP.2015.7178816.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BG3XQ}},
Unique-ID = {{ISI:000388373405161}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000388373405163,
Author = {Tanaka, Kou and Kameoka, Hirokazu and Toda, Tomoki and Nakamura, Satoshi},
Book-Group-Author = {{IEEE}},
Title = {{STATISTICAL F-0 PREDICTION FOR ELECTROLARYNGEAL SPEECH ENHANCEMENT
   CONSIDERING GENERATIVE PROCESS OF F-0 CONTOURS WITHIN PRODUCT OF EXPERTS
   FRAMEWORK}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING PROCEEDINGS}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2016}},
Pages = {{5665-5669}},
Note = {{41st IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Shanghai, PEOPLES R CHINA, MAR 20-25, 2016}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{We have previously proposed a statistical fundamental frequency (F-0)
   prediction method that makes it possible to predict the underlying F-0
   contour of electrolaryngeal (EL) speech from its spectral feature
   sequence. Although this method was shown to contribute to improving the
   naturalness of EL speech as a whole, the predicted F-0 contour was still
   unnatural compared with that in normal speech. One possible solution to
   improve the naturalness of the predicted F-0 contours would be to take
   account of the physical mechanism of vocal phonation. Recently a
   statistical model of voice F-0 contours was formulated by constructing a
   stochastic counterpart of the Fujisaki model, a well-founded
   mathematical model representing the control mechanism of vocal fold
   vibration. This paper proposes a Product-of -Experts model to
   incorporate this generative model of voice F-0 contours into the
   statistical F-0 prediction model. Based on the constructed model, we
   derive algorithms for parameter training and F-0 prediction.
   Experimental results revealed that the proposed method successfully
   outperformed our previously proposed method in terms of the naturalness
   of the predicted F-0 contours.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Tanaka, K (Corresponding Author), Nara Inst Sci \& Technol, Grad Sch Informat Sci, Ikoma, Nara, Japan.
   Tanaka, Kou; Nakamura, Satoshi, Nara Inst Sci \& Technol, Grad Sch Informat Sci, Ikoma, Nara, Japan.
   Kameoka, Hirokazu, NTT Corp, NTT Commun Sci Labs, Tokyo, Tokyo, Japan.
   Toda, Tomoki, Nagoya Univ, Informat Technol Ctr, Nagoya, Aichi 4648601, Japan.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-9988-0}},
Keywords = {{Electrolaryngeal speech enhancement; F-0 prediction; Generative model;
   Product of Experts}},
Keywords-Plus = {{VOICE CONVERSION}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{ko-t@is.naist.jp
   kameoka.hirokazu@lab.ntt.co.jp
   tomoki@icts.nagoya-u.ac.jp
   s-nakamura@is.naist.jp}},
Cited-References = {{ABE M, 1990, TRI0166 ATR.
   Doi H, 2014, IEEE-ACM T AUDIO SPE, V22, P172, DOI 10.1109/TASLP.2013.2286917.
   FUJISAKI H, 1998, VOCAL FOLD PHYSL VOI, P347.
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018.
   Kameoka H., 2010, P ISCA TUT RES WORKS, P43.
   Kameoka H, 2015, IEEE INT WORKS MACH.
   Kameoka H, 2015, IEEE-ACM T AUDIO SPE, V23, P1042, DOI 10.1109/TASLP.2015.2418576.
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5.
   Kohler KJ, 1990, PAPERS LAB PHONOLOGY, VI, P115.
   Matsuda T, 2012, ACOUST SCI TECHNOL, V33, P221, DOI 10.1250/ast.33.221.
   Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007.
   Narusawa S, 2002, INT CONF ACOUST SPEE, P509.
   Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472.
   Tanaka K, 2014, IEICE T INF SYST, VE97D, P1429, DOI 10.1587/transinf.E97.D.1429.
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344.
   Toda T, 2012, IEEE T AUDIO SPEECH, V20, P2505, DOI 10.1109/TASL.2012.2205241.
   Yoshizato K, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SPEECH PROSODY, VOLS I AND II, P175.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG3XQ}},
Unique-ID = {{ISI:000388373405163}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000389610000084,
Author = {Wang, Lei and Chen, Fei and Lai, Ying-Hui},
Book-Group-Author = {{IEEE}},
Title = {{Segmental Contribution to Predicting Speech Intelligibility in Noisy
   Conditions}},
Booktitle = {{2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)}},
Year = {{2016}},
Pages = {{476-480}},
Note = {{2nd IEEE International Conference on Multimedia Big Data (BigMM), Asia
   Univ, Taipei, TAIWAN, APR 20-22, 2016}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Tech Comm Multimedia Comp; IEEE Tech Comm
   Semant Comp; Minist Educ; Minist Sci \& Technol}},
Abstract = {{It is necessary to identify speech segments carrying important
   information for speech intelligibility, particularly in noise. Earlier
   work based on a relative root-mean-square (RMS) level based segmentation
   suggested that middle-level (ranging from the overall RMS level to 10 dB
   below) segments contained more vowel-consonant boundaries wherein the
   spectral change was often most prominent, and perhaps most robust, in
   the presence of noise, and hence yielded improved performance of
   objective intelligibility modeling. Since the three levels (i.e., high-,
   middle- and low-levels) were defined empirically when proposed, the
   present work assessed how the boundaries of RMS-level based segmentation
   affected the performance of speech intelligibility prediction. When
   evaluated with speech recognition scores obtained with normal-hearing
   listeners and with a total of 72 noise-distorted and noise-suppressed
   conditions, it was shown that choosing 0 and -10 dB to split
   middle-level led to maximized correlation in predicting the
   intelligibility of speech in noise.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, L (Corresponding Author), Southern Univ Sci \& Technol, Dept Elect \& Elect Engn, Shenzhen, Peoples R China.
   Wang, Lei; Chen, Fei, Southern Univ Sci \& Technol, Dept Elect \& Elect Engn, Shenzhen, Peoples R China.
   Lai, Ying-Hui, Yuan Univ, Dept Elect Engn, Chungli, Taiwan.}},
DOI = {{10.1109/BigMM.2016.88}},
ISBN = {{978-1-5090-2179-6}},
Keywords = {{relative RMS-level based segmentation; speech intelligibility;
   intelligibility prediction}},
Keywords-Plus = {{COCHLEA-SCALED ENTROPY; PERCEPTUAL CONTRIBUTIONS; CONSONANTS; VOWELS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
ResearcherID-Numbers = {{Chen, Fei/G-4674-2018
   Chen, Fei/AAK-6755-2020}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Cited-References = {{American National Standards Institute, 1997, METH CALC SPEECH INT.
   {[}Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225.
   Chen F, 2013, J ACOUST SOC AM, V134, pEL178, DOI 10.1121/1.4812820.
   Chen F, 2012, J ACOUST SOC AM, V131, P4104, DOI 10.1121/1.3695401.
   Chen F, 2010, J ACOUST SOC AM, V128, P3715, DOI 10.1121/1.3502473.
   Chen F, 2010, INT CONF ACOUST SPEE, P4726, DOI 10.1109/ICASSP.2010.5495166.
   Fogerty D, 2009, J ACOUST SOC AM, V126, P847, DOI 10.1121/1.3159302.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   Hu Y, 2007, J ACOUST SOC AM, V122, P1777, DOI 10.1121/1.2766778.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Loizou PC, 2013, SPEECH ENHANCEMENT T.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Stilp CE, 2010, P NATL ACAD SCI USA, V107, P12387, DOI 10.1073/pnas.0913625107.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BG5OO}},
Unique-ID = {{ISI:000389610000084}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000386654100045,
Author = {Dietzen, T. and Spriet, A. and Tirry, W. and Doclo, S. and Moonen, M.
   and van Waterschoot, T.},
Book-Group-Author = {{IEEE}},
Title = {{PARTITIONED BLOCK FREQUENCY DOMAIN KALMAN FILTER FOR MULTI-CHANNEL
   LINEAR PREDICTION BASED BLIND SPEECH DEREVERBERATION}},
Booktitle = {{2016 IEEE INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC)}},
Year = {{2016}},
Note = {{15th International Workshop on Acoustic Signal Enhancement (IWAENC),
   Xian, PEOPLES R CHINA, SEP 13-16, 2016}},
Organization = {{iFLYTEK; CVTOUCH; Goertek; DOLBY; Microsoft; IEEE XIAN}},
Abstract = {{The multi-channel linear prediction framework for blind speech
   dereverberation has gained increased popularity over the recent years.
   While adaptive dereverberation is desirable, most multi-channel linear
   prediction algorithms are based on either batch or iterative
   frame-by-frame processing, where individual frames are treated
   independently. In this paper, we derive a partitioned block frequency
   domain Kalman filter that offers adaptive processing. The so-called
   excessive whitening problem is avoided by including an estimate of the
   target speech signal coloration in the filter update. The impact of
   constraining the state covariance matrix is discussed. The convergence
   behavior of the algorithm is evaluated in terms of the evolution of the
   room acoustical parameters direct-to-reverberant ratio, clarity index
   and early decay time, indicating good dereverberation performance.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Dietzen, T (Corresponding Author), NXP Software, Leuven, Belgium.
   Dietzen, T (Corresponding Author), Katholieke Univ Leuven, Dept Elect Engn ESAT, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, Leuven, Belgium.
   Dietzen, T.; Spriet, A.; Tirry, W., NXP Software, Leuven, Belgium.
   Doclo, S., Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, Oldenburg, Germany.
   Doclo, S., Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4All, Oldenburg, Germany.
   Dietzen, T.; Moonen, M.; van Waterschoot, T., Katholieke Univ Leuven, Dept Elect Engn ESAT, STADIUS Ctr Dynam Syst Signal Proc \& Data Analyt, Leuven, Belgium.
   van Waterschoot, T., Katholieke Univ Leuven, Dept Elect Engn ESAT ETC, Geel, Belgium.}},
ISBN = {{978-1-5090-2007-2}},
Keywords = {{Dereverberation; multi-channel linear prediction; Kalman filter;
   partitioned block frequency domain}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Cited-References = {{{[}Anonymous], 2009, 338212009 ISO.
   Bang \& Olufsen, 1992, MUS FOR ARCH.
   Bradley JS, 2011, APPL ACOUST, V72, P713, DOI 10.1016/j.apacoust.2011.04.004.
   Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698.
   Dietzen T., 2016, AUDIO EXAMPLES IWAEN.
   Dietzen T., 2016, P AES 60 C DER REV A.
   Enzner G, 2006, SIGNAL PROCESS, V86, P1140, DOI 10.1016/j.sigpro.2005.09.013.
   Enzner G., 2006, THESIS.
   Hadad E, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P313, DOI 10.1109/IWAENC.2014.6954309.
   Haykin S., 2002, ADAPTIVE FILTER THEO.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Kuech Fabian, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1295, DOI 10.1109/ICASSP.2014.6853806.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   MOULINES E, 1995, IEEE T SIGNAL PROCES, V43, P14, DOI 10.1109/78.365282.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Parada PP, 2016, IEEE-ACM T AUDIO SPE, V24, P719, DOI 10.1109/TASLP.2016.2521486.
   Sayed AH, 1994, IEEE SIGNAL PROC MAG, V11, P18, DOI 10.1109/79.295229.
   SCHROEDER MR, 1962, J ACOUST SOC AM, V34, P76, DOI 10.1121/1.1909022.
   Schwartz B, 2015, IEEE-ACM T AUDIO SPE, V23, P394, DOI 10.1109/TASLP.2014.2372342.
   Sommen P.C.W., 1992, THESIS.
   SOO JS, 1990, IEEE T ACOUST SPEECH, V38, P373, DOI 10.1109/29.103078.
   Triki M., 2005, P 2005 INT WORKSH AC, P173.
   Valero ML, 2015, INT CONF ACOUST SPEE, P599, DOI 10.1109/ICASSP.2015.7178039.
   Yang JM, 2014, IEEE-ACM T AUDIO SPE, V22, P608, DOI 10.1109/TASLP.2013.2294578.
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2009, INT CONF ACOUST SPEE, P3733, DOI 10.1109/ICASSP.2009.4960438.
   Zahorik P, 2002, J ACOUST SOC AM, V112, P2110, DOI 10.1121/1.1506692.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BG1CJ}},
Unique-ID = {{ISI:000386654100045}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000386654100038,
Author = {Jukic, Ante and Wang, Zichao and van Waterschoot, Toon and Gerkmann,
   Timo and Doclo, Simon},
Book-Group-Author = {{IEEE}},
Title = {{CONSTRAINED MULTI-CHANNEL LINEAR PREDICTION FOR ADAPTIVE SPEECH
   DEREVERBERATION}},
Booktitle = {{2016 IEEE INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC)}},
Year = {{2016}},
Note = {{15th International Workshop on Acoustic Signal Enhancement (IWAENC),
   Xian, PEOPLES R CHINA, SEP 13-16, 2016}},
Organization = {{iFLYTEK; CVTOUCH; Goertek; DOLBY; Microsoft; IEEE XIAN}},
Abstract = {{This paper presents a speech dereverberation algorithm combining
   adaptive multi-channel linear prediction (MCLP) with a statistical model
   for the undesired reverberation. More specifically, we propose to
   constrain the power of the MCLP-based late reverberation estimate with
   the late reverberant power estimated using the exponential decay model,
   thereby preventing excessive cancellation of the speech signal.
   Simulation results show that incorporating the constraint improves the
   performance of the adaptive dereverberation method when the prediction
   filters need to adapt quickly.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Jukic, A (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, Oldenburg, Germany.
   Jukic, Ante; Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, Oldenburg, Germany.
   Wang, Zichao, Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4All, Oldenburg, Germany.
   van Waterschoot, Toon, Rice Univ, Houston, TX USA.
   Gerkmann, Timo, Katholieke Univ Leuven, Dept Elect Engn, ESAT STADIUS ETC, Leuven, Belgium.}},
ISBN = {{978-1-5090-2007-2}},
Keywords = {{speech dereverberation; multi-channel linear prediction; constrained
   linear prediction; adaptive filtering}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{ante.jukic@uni-oldenburg.de}},
ResearcherID-Numbers = {{Gerkmann, Timo/I-3353-2014}},
ORCID-Numbers = {{Gerkmann, Timo/0000-0002-8678-4699}},
Cited-References = {{Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016.
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498.
   Haykin S.O., 2013, ADAPTIVE FILTER THEO.
   Jukic Ante, 2015, 2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). Proceedings, P1, DOI 10.1109/WASPAA.2015.7336927.
   Jukic A., 2016, P AES 60 INT C LEUV.
   Jukic A, 2015, IEEE-ACM T AUDIO SPE, V23, P1509, DOI 10.1109/TASLP.2015.2438549.
   Kinoshita K, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0306-6.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Lebart K, 2001, ACUSTICA, V87, P359.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Yoshihara T, 2013, P INST NAVIG PAC PNT, P1.
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2009, INT CONF ACOUST SPEE, P3733, DOI 10.1109/ICASSP.2009.4960438.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BG1CJ}},
Unique-ID = {{ISI:000386654100038}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000386654100034,
Author = {Wang, Lei and Chen, Fei},
Book-Group-Author = {{IEEE}},
Title = {{ASSESSING THE SEGMENTAL CONTRIBUTION TO THE NON-INTRUSIVE
   INTELLIGIBILITY PREDICTION OF NOISE-SUPPRESSED SPEECH}},
Booktitle = {{2016 IEEE INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC)}},
Year = {{2016}},
Note = {{15th International Workshop on Acoustic Signal Enhancement (IWAENC),
   Xian, PEOPLES R CHINA, SEP 13-16, 2016}},
Organization = {{iFLYTEK; CVTOUCH; Goertek; DOLBY; Microsoft; IEEE XIAN}},
Abstract = {{It has always been challenging to non-intrusively predict speech
   intelligibility without the access of clean reference speech signal.
   This is extremely so in the scenario when predicting the intelligibility
   of noise-suppressed speech because of the non-linear distortion
   introduced by noise-suppression algorithms. The purpose of this study
   was to assess the segmental contribution to the non-intrusive
   intelligibility prediction of noise-suppressed speech by using the
   speech-to-reverberation-modulation-energy-ratio (SRMR) measure. To do
   this, speech signal was first split into different segments based on the
   relative root-mean-square level, and selected (e.g., all, high-level or
   middle-level) segments were used to compute the SRMR measure. The SRMR
   measures were correlated with the subjective intelligibility scores
   collected from human listeners, including a total of 72 conditions with
   linear and non-linear distortions. Experimental data showed that while
   the SRMR measure could not well model the intelligibility of
   noise-suppressed speech (i.e., correlation coefficient 0.37), the
   high-level-based SRMR measure may yield the correlation comparable to
   that computed with all segments. This indicates that high-level segments
   contain information accounting for the non-intrusive intelligibility
   prediction traditionally obtained with all segments.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, L (Corresponding Author), Southern Univ Sci \& Technol, Dept Elect \& Elect Engn, Shenzhen, Peoples R China.
   Wang, Lei; Chen, Fei, Southern Univ Sci \& Technol, Dept Elect \& Elect Engn, Shenzhen, Peoples R China.}},
ISBN = {{978-1-5090-2007-2}},
Keywords = {{Non-intrusive intelligibility prediction; RMS-level based speech
   segmentation}},
Keywords-Plus = {{REVERBERANT; COHERENCE}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
ResearcherID-Numbers = {{Chen, Fei/AAK-6755-2020
   Chen, Fei/G-4674-2018}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Cited-References = {{American National Standards Institute, 1997, METH CALC SPEECH INT.
   {[}Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225.
   Chen F., 2016, P 17 ANN C INT SPEEC.
   Chen F, 2016, BIOMED SIGNAL PROCES, V24, P109, DOI 10.1016/j.bspc.2015.09.007.
   Chen F, 2013, BIOMED SIGNAL PROCES, V8, P311, DOI 10.1016/j.bspc.2012.11.007.
   Chen F, 2013, J ACOUST SOC AM, V133, pEL405, DOI 10.1121/1.4800189.
   Chen F, 2012, J ACOUST SOC AM, V131, P4104, DOI 10.1121/1.3695401.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   Gomez AM, 2012, SPEECH COMMUN, V54, P503, DOI 10.1016/j.specom.2011.11.001.
   Hossain ME, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150415.
   Hu Y, 2007, J ACOUST SOC AM, V122, P1777, DOI 10.1121/1.2766778.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Loizou PC, 2011, J ACOUST SOC AM, V130, P986, DOI 10.1121/1.3605668.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG1CJ}},
Unique-ID = {{ISI:000386654100034}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000386311000012,
Author = {Sarwar, Sheikh Muhammad and Abdullah-Al-Mamun},
Book-Group-Author = {{IEEE}},
Title = {{Next Word Prediction for Phonetic Typing by Grouping Language Models}},
Booktitle = {{PROCEEDINGS OF 2016 2ND INTERNATIONAL CONFERENCE ON INFORMATION
   MANAGEMENT (ICIM2016)}},
Year = {{2016}},
Note = {{2nd International Conference on Information Management (ICIM), London,
   ENGLAND, MAY 07-08, 2016}},
Organization = {{IEEE}},
Abstract = {{In this paper, we present a language model based framework for instant
   messaging, that can predict probable next word given a set of current
   words. Our goal is to facilitate the task of instant messaging by
   suggesting relevant words to the user. Generally, at the time of sending
   personal messages, a user follows a specific style of communication with
   a specific group of people. This phenomenon is much more evident in
   other languages apart from English. For example, in Bengali language,
   there are three counterparts of you, that is used to address the second
   person in English. Considering this fact, there are at least three
   styles of writing texts in Bengali language: informal, semi-formal and
   formal. Therefore, it is quite necessary to generate next words based on
   the linguistic style adopted by a user, when sending messages to a
   specific set of people. In this paper, we develop a solution to this
   issue by adopting different language models when exchanging messages
   with different groups of people. Our method clusters language models
   based on user interactions, and we show the effectiveness of our method
   using a popular metric hit ratio. This model can be widely adapted for
   predicting next words in smart-phone devices and expedite the
   communication between users, specifically at the time of phonetic
   typing.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sarwar, SM (Corresponding Author), Univ Dhaka, Inst Informat Technol, Dhaka, Bangladesh.
   Sarwar, Sheikh Muhammad, Univ Dhaka, Inst Informat Technol, Dhaka, Bangladesh.
   Abdullah-Al-Mamun, Univ Asia Pacific, Dept Comp Sci \& Engn, Dhaka, Bangladesh.}},
ISBN = {{978-1-5090-1471-2}},
Keywords = {{Next Word Prediction; Phonetic Typing; Language Models}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{smsarwar@du.ac.bd
   mamun05@uap-bd.edu}},
Cited-References = {{Brants T., 2007, P 2007 JOINT C EMP M, P858.
   Fitrianie S., 2007, TEXT SPEECH DIALOGUE.
   Freedman R. G., 2013, AAAI WORKSHOPS, VWS-13-13.
   Gao J., 2001, USE CLUSTERING TECHN.
   Garay-Vitoria N., 2005, UNIVERSAL ACCESS INF, V4, P188.
   Ghayoomi M, 2009, IEEE SYS MAN CYBERN, P5083, DOI 10.1109/ICSMC.2009.5346027.
   Hunnicutt S., 2009, WORKING PAPERS LINGU, V49, P66.
   JELINEK F, 1977, J ACOUST SOC AM, V62, pS63, DOI 10.1121/1.2016299.
   Kucukyilmaz T, 2008, INFORM PROCESS MANAG, V44, P1448, DOI 10.1016/j.ipm.2007.12.009.
   Wood M. E. J., 1996, TECH REP.
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BG0KN}},
Unique-ID = {{ISI:000386311000012}},
DA = {{2020-12-06}},
}

@article{ ISI:000371618900001,
Author = {Kaan, Edith and Kirkham, Joseph and Wijnen, Frank},
Title = {{Prediction and integration in native and second-language processing of
   elliptical structures}},
Journal = {{BILINGUALISM-LANGUAGE AND COGNITION}},
Year = {{2016}},
Volume = {{19}},
Number = {{1}},
Pages = {{1-18}},
Month = {{JAN}},
Abstract = {{According to recent views of L2-sentence processing, L2-speakers do not
   predict upcoming information to the same extent as do native speakers.
   To investigate L2-speakers' predictive use and integration of syntactic
   information across clauses, we recorded event-related potentials (ERPs)
   from advanced L2-learners and native speakers while they read sentences
   in which the syntactic context did or did not allow noun-ellipsis (Lau,
   E., Stroud, C., Plesch, S., \& Phillips, C. ( 2006). The role of
   structural prediction in rapid syntactic analysis. Brain and Language,
   98, 74-88.) Both native and L2-speakers were sensitive to the context
   when integrating words after the potential ellipsis-site. However,
   native, but not L2-speakers, anticipated the ellipsis, as suggested by
   an ERP difference between elliptical and non-elliptical contexts
   preceding the potential ellipsis-site. In addition, L2-learners
   displayed a late frontal negativity for ungrammaticalities, suggesting
   differences in repair strategies or resources compared with native
   speakers.}},
Publisher = {{CAMBRIDGE UNIV PRESS}},
Address = {{32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kaan, E (Corresponding Author), Univ Florida, Dept Linguist, Box 115454, Gainesville, FL 32611 USA.
   Kaan, Edith; Kirkham, Joseph, Univ Florida, Dept Linguist, Box 115454, Gainesville, FL 32611 USA.
   Wijnen, Frank, Univ Utrecht, Utrecht Inst Linguist OTS, NL-3508 TC Utrecht, Netherlands.}},
DOI = {{10.1017/S1366728914000844}},
ISSN = {{1366-7289}},
EISSN = {{1469-1841}},
Keywords = {{second-language processing; ellipsis; predictive processing; LAN; late
   negativity}},
Keywords-Plus = {{INDIVIDUAL-DIFFERENCES; GRAMMATICAL GENDER; UPCOMING WORDS; BRAIN;
   SENTENCE; L2; BILINGUALS; SPANISH; MEMORY; INTERFERENCE}},
Research-Areas = {{Linguistics; Psychology}},
Web-of-Science-Categories  = {{Linguistics; Psychology, Experimental}},
Author-Email = {{kaan@ufl.edu}},
ORCID-Numbers = {{Wijnen, Frank/0000-0002-7196-6000}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF) {[}NSF
   0957178]; Netherlands Organisation for Scientific ResearchNetherlands
   Organization for Scientific Research (NWO) {[}NWO 040.11.367]}},
Funding-Text = {{The authors would like to thank Natalia Davidson, Chelsea Guerra,
   Kyriaki Neophytou and Marpessa Rietbergen for their help making
   materials and running participants, Ellen Lau for letting us use her
   stimuli, and Iris Mulders and Sjef Pieters for technical assistance at
   the Utrecht site. This research was funded in part by the National
   Science Foundation (NSF 0957178), and a visiting scholars grant from the
   Netherlands Organisation for Scientific Research (NWO 040.11.367)
   awarded to the first author.}},
Cited-References = {{Banon JA, 2012, BRAIN RES, V1456, P49, DOI 10.1016/j.brainres.2012.03.057.
   Chambers CG, 2009, J EXP PSYCHOL LEARN, V35, P1029, DOI 10.1037/a0015901.
   Clahsen H, 2006, APPL PSYCHOLINGUIST, V27, P3, DOI 10.1017/S0142716406060024.
   Corver N, 2010, J COMP GER LINGUIST, V13, P99, DOI 10.1007/s10828-010-9034-8.
   Coulson S, 1998, LANG COGNITIVE PROC, V13, P21, DOI 10.1080/016909698386582.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751.
   Dikker S, 2009, COGNITION, V110, P293, DOI 10.1016/j.cognition.2008.09.008.
   Dimitrova D. V., 2012, NEURAL CORRELA UNPUB.
   Dussias PE, 2013, STUD SECOND LANG ACQ, V35, P353, DOI 10.1017/S0272263112000915.
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756.
   Friederici AD, 2002, J PSYCHOLINGUIST RES, V31, P45, DOI 10.1023/A:1014376204525.
   Friederici AD, 2000, J MEM LANG, V43, P476, DOI 10.1006/jmla.2000.2709.
   Frisch S, 2004, COGNITION, V91, P191, DOI 10.1016/j.cognition.2003.09.009.
   Dowens MG, 2010, J COGNITIVE NEUROSCI, V22, P1870, DOI 10.1162/jocn.2009.21304.
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823.
   Gruter T, 2012, SECOND LANG RES, V28, P191, DOI 10.1177/0267658312437990.
   Gruter T., 2013, 12 C GEN APPR 2 LANG.
   Hahne A, 2002, COGNITIVE BRAIN RES, V13, P339, DOI 10.1016/S0926-6410(01)00127-6.
   Hahne A., 2001, BILING-LANG COGN, V4, P123, DOI DOI 10.1017/S1366728901000232.
   Hopp H, 2013, SECOND LANG RES, V29, P33, DOI 10.1177/0267658312461803.
   Hopp H, 2009, BILING-LANG COGN, V12, P463, DOI 10.1017/S1366728909990253.
   Isel F, 2007, NEUROREPORT, V18, P1885, DOI 10.1097/WNR.0b013e3282f1d518.
   Kaan E, 2003, COGNITIVE BRAIN RES, V17, P621, DOI 10.1016/S0926-6410(03)00175-7.
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084.
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa.
   Kaan E, 2013, J PSYCHOLINGUIST RES, V42, P307, DOI 10.1007/s10936-012-9220-8.
   Kaan E, 2010, LING AKT, V164, P207.
   Keijzer M., 2007, LAST 1 OUT INV UNPUB.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003.
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0.
   Lew-Williams C, 2010, J MEM LANG, V63, P447, DOI 10.1016/j.jml.2010.07.003.
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067).
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001.
   Morgan-Short K, 2012, J COGNITIVE NEUROSCI, V24, P933, DOI 10.1162/jocn\_a\_00119.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   OSTERHOUT L, 1994, J EXP PSYCHOL LEARN, V20, P786, DOI 10.1037/0278-7393.20.4.786.
   Phillips C, 2014, LINGUA, V151, P78, DOI 10.1016/j.lingua.2013.10.003.
   Ruchkin DS, 2003, BEHAV BRAIN SCI, V26, P709, DOI 10.1017/S0140525X03000165.
   Sabourin L, 2004, BRAIN COGNITION, V55, P392, DOI 10.1016/j.bandc.2004.02.056.
   Sabourin L, 2008, SECOND LANG RES, V24, P397, DOI 10.1177/0267658308090186.
   Slevc LR, 2013, BEHAV BRAIN SCI, V36, P373, DOI 10.1017/S0140525X12002683.
   Sorace A, 2011, LINGUIST APPROACH BI, V1, P2, DOI 10.1075/lab.1.1.01sor.
   Steinhauer K, 2012, BRAIN LANG, V120, P135, DOI 10.1016/j.bandl.2011.07.001.
   Streb J, 2004, J PSYCHOLINGUIST RES, V33, P175, DOI 10.1023/B:JOPR.0000027961.12577.d8.
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651.
   Tanner D, 2014, BILING-LANG COGN, V17, P277, DOI 10.1017/S1366728913000370.
   Tanner D, 2014, NEUROPSYCHOLOGIA, V56, P289, DOI 10.1016/j.neuropsychologia.2014.02.002.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van de Meerendonk N, 2011, NEUROIMAGE, V54, P2350, DOI 10.1016/j.neuroimage.2010.10.022.
   Wechsler DA, 1987, WECHSLER MEMORY SCAL.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0.}},
Number-of-Cited-References = {{54}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{19}},
Journal-ISO = {{Biling.-Lang. Cogn.}},
Doc-Delivery-Number = {{DF8OY}},
Unique-ID = {{ISI:000371618900001}},
DA = {{2020-12-06}},
}

@article{ ISI:000368208100002,
Author = {Rahdari, Farhad and Eftekhari, Mahdi and Mousavi, Reza},
Title = {{A two-level multi-gene genetic programming model for speech quality
   prediction in Voice over Internet Protocol systems}},
Journal = {{COMPUTERS \& ELECTRICAL ENGINEERING}},
Year = {{2016}},
Volume = {{49}},
Pages = {{9-24}},
Month = {{JAN}},
Abstract = {{The main aim of this study is to develop a low-complexity non-intrusive
   quality prediction model in Voice over Internet Protocol (VoIP) systems.
   In order to gain this goal, a 2-level structure for predicting the
   quality of speech is proposed. Furthermore, the capabilities of
   multi-gene genetic programming are investigated through developing a
   number of parallel models and different feature vectors. These models
   are utilized in two hierarchical levels to construct the final model. To
   consider the transmission media and speech signal characteristics in
   quality measurement process, both network impairments and per-frame
   features are employed simultaneously for developing models. Several
   experiments are performed based on the proposed structure while
   different combinations of speech feature types in the cases of noise
   free and noisy speech signals are examined. The obtained results
   indicate that using parallel models in a 2-level structure enhances the
   accuracy of derived models as compared with 1-level structure and common
   single-gene GP models. (C) 2015 Elsevier Ltd. All rights reserved.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Rahdari, F (Corresponding Author), Grad Univ Adv Technol, Inst Sci \& High Technol \& Environm Sci, Dept Comp \& IT, Kerman, Iran.
   Rahdari, Farhad, Grad Univ Adv Technol, Inst Sci \& High Technol \& Environm Sci, Dept Comp \& IT, Kerman, Iran.
   Eftekhari, Mahdi, Shahid Bahonar Univ Kerman, Dept Comp Engn, Kerman, Iran.
   Mousavi, Reza, Grad Univ Adv Technol, Dept Elect \& Comp Engn, Kerman, Iran.}},
DOI = {{10.1016/j.compeleceng.2015.10.008}},
ISSN = {{0045-7906}},
EISSN = {{1879-0755}},
Keywords = {{VoIP; 2-level structure; Speech quality prediction; Non-intrusive;
   Multi-gene GP; PESQ}},
Keywords-Plus = {{NETWORKS}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical \& Electronic}},
Author-Email = {{rahdarifar@icst.ac.ir
   m.eftekhari@mail.uk.ac.ir
   r.mousavi@student.kgut.ac.ir}},
ResearcherID-Numbers = {{Eftekhari/U-6889-2019}},
Funding-Acknowledgement = {{Institute of Science and High Technology and Environmental Sciences,
   Graduate University of Advanced Technology, Kerman, Iran {[}7.1614]}},
Funding-Text = {{The authors gratefully acknowledge the financial support provided by
   Institute of Science and High Technology and Environmental Sciences,
   Graduate University of Advanced Technology, Kerman, Iran, under Contract
   number 7.1614.}},
Cited-References = {{Al-Akhras M, 2009, NEUROCOMPUTING, V72, P2595, DOI 10.1016/j.neucom.2008.10.019.
   {[}Anonymous], 2003, G107 ITUT.
   {[}Anonymous], 2004, P563 ITUT.
   Daeangsi T, 2015, MULTIMEDIA SYST, V21, P1.
   Falk TH, 2006, IEEE SIGNAL PROC LET, V13, P108, DOI 10.1109/LSP.2005.861598.
   Grancharov V, 2006, IEEE T AUDIO SPEECH, V14, P1948, DOI 10.1109/TASL.2006.883250.
   GUPTA S, 2013, SIGNAL IMAGE PROCESS, V4, P101.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   Kim DS, 2005, IEEE T SPEECH AUDI P, V13, P821, DOI 10.1109/TSA.2005.851924.
   Mrvova M, 2013, 2013 23RD INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P361, DOI 10.1109/RadioElek.2013.6530946.
   Narwaria M, 2012, IEEE T AUDIO SPEECH, V20, P1217, DOI 10.1109/TASL.2011.2174223.
   Poli R., 2008, FIELD GUIDE GENETIC.
   Raake A, 2013, P INTERSPEECH.
   Raake A., 2007, SPEECH QUALITY VOIP.
   Radhakrishnan K, 2011, PERFORM EVALUATION, V68, P347, DOI 10.1016/j.peva.2011.01.001.
   Rahdari F, 2014, IRAN J FUZZY SYST, V11, P49.
   Rahdari F, 2012, P 16 CSI INT S ART I.
   Rahdari F, 2014, P 4 INT C COMP KNOWL.
   Raja M A, 2008, THESIS.
   Sathapornvajana S, 2013, WIRELESS PERS COMMUN, V69, P1067, DOI 10.1007/s11277-013-1066-3.
   Searson D. P., 2010, P INT MULT ENG COMP.
   Sun LF, 2006, IEEE T MULTIMEDIA, V8, P809, DOI 10.1109/TMM.2006.876279.
   Vaseghi S.V, 2008, ADV DIGITAL SIGNAL P.
   Wang Jing, 2010, Journal of Beijing Institute of Technology, V19, P76.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Comput. Electr. Eng.}},
Doc-Delivery-Number = {{DB0OT}},
Unique-ID = {{ISI:000368208100002}},
DA = {{2020-12-06}},
}

@article{ ISI:000366805900053,
Author = {Yang, Lei and Zhang, Junxi and Wu, Xiaojun and Zhang, Yumei and Li,
   Jingjing},
Title = {{A chaotic time series prediction model for speech signal encoding based
   on genetic programming}},
Journal = {{APPLIED SOFT COMPUTING}},
Year = {{2016}},
Volume = {{38}},
Pages = {{754-761}},
Month = {{JAN}},
Abstract = {{In this paper, a novel solving method for speech signal chaotic time
   series prediction model was proposed. A phase space was reconstructed
   based on speech signal's chaotic characteristics and the genetic
   programming (GP) algorithm was introduced for solving the speech chaotic
   time series prediction models on the phase space with the embedding
   dimension m and time delay tau. And then, the speech signal's chaotic
   time series models were built. By standardized processing of these
   models and optimizing parameters, a speech signal's coding model of
   chaotic time series with certain generalization ability was obtained. At
   last, the experimental results showed that the proposed method can get
   the speech signal chaotic time series prediction models much more
   effectively, and had a better coding accuracy than linear predictive
   coding (LPC) algorithms and neural network model. (C) 2015 Elsevier B.V.
   All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.
   Yang, Lei; Wu, Xiaojun; Li, Jingjing, Shaanxi Normal Univ, Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.
   Wu, Xiaojun; Zhang, Yumei, Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.
   Yang, Lei; Wu, Xiaojun; Zhang, Yumei, Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   Zhang, Junxi, Xian Aeronaut, Dept Vehicle Engn, Xian 710077, Peoples R China.}},
DOI = {{10.1016/j.asoc.2015.10.003}},
ISSN = {{1568-4946}},
EISSN = {{1872-9681}},
Keywords = {{Chaotic time series prediction; Genetic programming; Nonlinear coding
   model}},
Keywords-Plus = {{PRACTICAL METHOD; NEURAL-NETWORK; IMPLEMENTATION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications}},
Author-Email = {{xjwu@snnu.edu.cn}},
Funding-Acknowledgement = {{NSF of ChinaNational Natural Science Foundation of China (NSFC)
   {[}11172342, 11372167, 11502133]; Program of Shaanxi Science and
   Technology Innovation Team {[}2014KTC-18]; Shaanxi Natural Science
   Foundation Project {[}2014JM8353]}},
Funding-Text = {{This work reported in this paper was supported by the NSF of China
   (Grant no. 11172342, 11372167, 11502133), the Program of Shaanxi Science
   and Technology Innovation Team (Grant no. 2014KTC-18), and the Shaanxi
   Natural Science Foundation Project (2014JM8353). The authors thank the
   referees for their valuable suggestions and comments}},
Cited-References = {{ABARBANEL HDI, 1993, REV MOD PHYS, V65, P1331, DOI 10.1103/RevModPhys.65.1331.
   Andreae P, 2008, INT J KNOWL-BASED IN, V12, P15, DOI 10.3233/KES-2008-12103.
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8.
   Chan KY, 2011, J ENG DESIGN, V22, P55, DOI 10.1080/09544820902911374.
   Chen L., 2000, J PLA U SCI TECHNOLO, V1, P11.
   Conrads M., 1998, Genetic Programming. First European Workshop, EuroGP'98. Proceedings, P113.
   Dajer ME, 2005, IEEE INT SYM MULTIM, P765.
   Estevez PA, 2005, ELECTRON LETT, V41, P1141, DOI 10.1049/el:20052475.
   Kim HS, 1999, PHYSICA D, V127, P48, DOI 10.1016/S0167-2789(98)00240-1.
   Kocal OH, 2008, IEEE T INF FOREN SEC, V3, P651, DOI 10.1109/TIFS.2008.2004289.
   Kokkinos I, 2005, IEEE T SPEECH AUDI P, V13, P1098, DOI 10.1109/TSA.2005.852982.
   Koza JR, 1994, GENETIC PROGRAMMING.
   Lee YS, 2011, KNOWL-BASED SYST, V24, P66, DOI 10.1016/j.knosys.2010.07.006.
   Matthew K.L., 2012, INT J ADV RES ARTIF, V1, P39.
   Miranian A, 2013, IEEE T NEUR NET LEAR, V24, P207, DOI 10.1109/TNNLS.2012.2227148.
   Naniwa Y, 2012, PROC INFO COMMUN, V4, P291.
   Ogorzalek M, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL IV, PROCEEDINGS, P564.
   Parkes Andrew J., 2012, Genetic Programming. Proceedings of the 15th European Conference, EuroGP 2012, P158, DOI 10.1007/978-3-642-29139-5\_14.
   Pulakka H, 2011, IEEE T AUDIO SPEECH, V19, P2170, DOI 10.1109/TASL.2011.2118206.
   Qin Ai-na, 2008, Computer Engineering and Applications, V44, P141.
   Qingfang M., 2005, SYST ENG THEORY PRAC, P83.
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P.
   Scanzio S, 2010, INT CONF ACOUST SPEE, P4902, DOI 10.1109/ICASSP.2010.5495108.
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100.
   Sun JF, 2007, SIGNAL PROCESS, V87, P2431, DOI 10.1016/j.sigpro.2007.03.020.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.
   Wagner N, 2007, IEEE T EVOLUT COMPUT, V11, P433, DOI 10.1109/TEVC.2006.882430.
   Wu XJ, 2013, APPL SOFT COMPUT, V13, P3314, DOI 10.1016/j.asoc.2013.02.008.
   Xiaojun W., 2011, ACTA ELECT SIN, V39, P1261.
   Xie HY, 2006, LECT NOTES COMPUT SC, V3907, P460.
   Xie XF, 2002, IEEE C EVOL COMPUTAT, P1456.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{26}},
Journal-ISO = {{Appl. Soft. Comput.}},
Doc-Delivery-Number = {{CZ0OQ}},
Unique-ID = {{ISI:000366805900053}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000422629200004,
Author = {Ehara, Hiroyuki and Sanda, Takako and Sakurai, Toshiaki},
Title = {{Switched orthogonalization of fixed-codebook search in code-excited
   linear-predictive speech coder: Derivation of conditions for switching}},
Journal = {{ACOUSTICAL SCIENCE AND TECHNOLOGY}},
Year = {{2016}},
Volume = {{37}},
Number = {{1}},
Pages = {{30-35}},
Abstract = {{This document presents an algorithm of switched orthogonalization of
   fixed-codebook (FCB) search in code-excited linear-predictive (CELP)
   speech coder and derivation of conditions for switching.
   Orthogonalization of FCB search is an early 1990' s technology, and
   later efficient implementation was developed on some algebraic CELP
   (ACELP) speech coders standardized in 2000s. ITU-T Recommendation
   G.729.1 is such speech coder standardized in 2006. Orthogonalization of
   FCB search does not degrade CELP coder performance if ideal gain
   parameters are applied to codebook vectors. However, because of limited
   performance of gain quantization and overall optimization of CELP coding
   algorithm, the orthogonalization does not always give improved coder
   performance. This document presents a switched orthogonalization
   algorithm based on an estimated adaptive codebook (ACB) gain parameter,
   which is obtained through the orthogonalized FCB search. The algorithm
   was evaluated in G.729.1 coder. While the orthogonalization was switched
   off on 20\% of voicing frames, segmental SNR was improved by around 0.1
   dB in average.}},
Publisher = {{ACOUSTICAL SOC JAPAN}},
Address = {{NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ehara, H (Corresponding Author), Panasonic Corp, AVC Networks Co, Tsuzuki Ku, 600 Saedo Cho, Yokohama, Kanagawa 2248539, Japan.
   Ehara, Hiroyuki; Sanda, Takako; Sakurai, Toshiaki, Panasonic Corp, AVC Networks Co, Tsuzuki Ku, 600 Saedo Cho, Yokohama, Kanagawa 2248539, Japan.}},
DOI = {{10.1250/ast.37.30}},
ISSN = {{1346-3969}},
EISSN = {{1347-5177}},
Keywords = {{Code-excited linear-prediction; Speech coding; Orthogonalization}},
Research-Areas = {{Acoustics}},
Web-of-Science-Categories  = {{Acoustics}},
Author-Email = {{ehara.hiroyuki@jp.panasonic.com}},
Cited-References = {{{*}3GPP, 1999, 26090 3GPP TS.
   Adoul J., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1957.
   Amada T., 1996, Transactions of the Institute of Electronics, Information and Communication Engineers A, VJ79-A, P1092.
   Ikedo J., 1995, P IEICE ISS C 1995, P255.
   JOHNSON M, 1990, GLOBECOM 90 - IEEE GLOBAL TELECOMMUNICATIONS CONFERENCE \& EXHIBITION, VOLS 1-3, P542, DOI 10.1109/GLOCOM.1990.116570.
   Kataoka A, 1997, 1997 IEEE WORKSHOP ON SPEECH CODING FOR TELECOMMUNICATIONS, PROCEEDINGS, P69, DOI 10.1109/SCFT.1997.623900.
   Massaloux D, 2007, INT CONF ACOUST SPEE, P1105.
   Schroeder M. R., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8), P937.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Acoust. Sci. Technol.}},
Doc-Delivery-Number = {{VB8VJ}},
Unique-ID = {{ISI:000422629200004}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000386163000008,
Author = {Freunberger, Dominik and Roehm, Dietmar},
Title = {{Semantic prediction in language comprehension: evidence from brain
   potentials}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2016}},
Volume = {{31}},
Number = {{9}},
Pages = {{1193-1205}},
Abstract = {{Do people predict specific word-forms during language comprehension? In
   an Event-Related Potential (ERP) study participants read German
   sentences with predictable (The goalkeeper claims that the slick ball
   was easy to CATCH.) and unpredictable (The kids boasted that the young
   horse was easy to SADDLE.) verbs. Verbs were either consistent with the
   expected word-form (catch/saddle) or inconsistent and therefore led to
   ungrammaticality ({*}catches/{*}saddles). ERPs within the N400
   time-window were modulated by predictability but not by the surface-form
   of the verbs, suggesting that no exact word-forms were predicted. Based
   on our results we will argue that predictions included semantic rather
   than form-information. Furthermore, ungrammatical verbs led to a strong
   P600, probably due to task-saliency whereas correct unpredictable verbs
   elicited an anterior post-N400 positivity. Because the contexts were
   moderately constraining, this might reflect discourse revision processes
   rather than inhibition of a predicted word.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Freunberger, D (Corresponding Author), Salzburg Univ, Ctr Cognit Neurosci, Salzburg, Austria.
   Freunberger, Dominik; Roehm, Dietmar, Salzburg Univ, Ctr Cognit Neurosci, Salzburg, Austria.}},
DOI = {{10.1080/23273798.2016.1205202}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{Language comprehension; prediction; N400; P300}},
Keywords-Plus = {{EYE-MOVEMENTS; ELECTROPHYSIOLOGICAL EVIDENCE; CLOZE PROBABILITY; GENDER
   AGREEMENT; WORD PERCEPTION; ERP COMPONENTS; MEMORY; N400; INTEGRATION;
   CONSTRAINT}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{dominik.freunberger@sbg.ac.at}},
ResearcherID-Numbers = {{cohorts, Doctoral College Imaging the Mind - all/I-4689-2018
   }},
ORCID-Numbers = {{Roehm, Dietmar/0000-0002-2370-4348}},
Funding-Acknowledgement = {{Austrian Science Fund (FWF)Austrian Science Fund (FWF) {[}FWF-W1233]}},
Funding-Text = {{This work was supported by the Austrian Science Fund (FWF) {[}grant
   number FWF-W1233].}},
Cited-References = {{BALOTA DA, 1985, COGNITIVE PSYCHOL, V17, P364, DOI 10.1016/0010-0285(85)90013-1.
   Bar M, 2009, PHILOS T R SOC B, V364, P1235, DOI 10.1098/rstb.2008.0310.
   Bornkessel I, 2006, PSYCHOL REV, V113, P787, DOI 10.1037/0033-295X.113.4.787.
   Brothers T, 2015, COGNITION, V136, P135, DOI 10.1016/j.cognition.2014.10.017.
   Brouwer H, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00758.
   Brouwer H, 2012, BRAIN RES, V1446, P127, DOI 10.1016/j.brainres.2012.01.055.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Delong KA, 2011, PSYCHOPHYSIOLOGY, V48, P1203, DOI 10.1111/j.1469-8986.2011.01199.x.
   DONCHIN E, 1988, BEHAV BRAIN SCI, V11, P357, DOI 10.1017/S0140525X00058027.
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133.
   Friederici AD, 1996, J EXP PSYCHOL LEARN, V22, P1219, DOI 10.1037/0278-7393.22.5.1219.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823.
   Holcomb PJ, 2002, J COGNITIVE NEUROSCI, V14, P938, DOI 10.1162/089892902760191153.
   Hosemann J, 2013, NEUROPSYCHOLOGIA, V51, P2224, DOI 10.1016/j.neuropsychologia.2013.07.013.
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014.
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007.
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084.
   Kaan E, 2003, J COGNITIVE NEUROSCI, V15, P98, DOI 10.1162/089892903321107855.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3.
   Kulakova E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00548.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   KUTAS M, 1993, LANG COGNITIVE PROC, V8, P533, DOI 10.1080/01690969308407587.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Loerts H, 2013, J NEUROLINGUIST, V26, P561, DOI 10.1016/j.jneuroling.2013.03.003.
   Molinaro N, 2010, BIOL PSYCHOL, V83, P176, DOI 10.1016/j.biopsycho.2009.12.006.
   Munte TF, 1999, COGNITIVE BRAIN RES, V7, P241, DOI 10.1016/S0926-6410(98)00028-7.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160.
   R Development Core Team, 2010, R LANG ENV STAT COMP.
   Rayner K, 1996, PSYCHON B REV, V3, P504, DOI 10.3758/BF03214555.
   Rayner K, 2011, J EXP PSYCHOL HUMAN, V37, P514, DOI 10.1037/a0020990.
   Roehm D, 2007, J COGNITIVE NEUROSCI, V19, P1259, DOI 10.1162/jocn.2007.19.8.1259.
   Sassenhagen J, 2015, CORTEX, V66, pA3, DOI 10.1016/j.cortex.2014.12.019.
   Sassenhagen J, 2014, BRAIN LANG, V137, P29, DOI 10.1016/j.bandl.2014.07.010.
   Thornhill DE, 2012, INT J PSYCHOPHYSIOL, V83, P382, DOI 10.1016/j.ijpsycho.2011.12.007.
   Traxler MJ, 2000, J EXP PSYCHOL LEARN, V26, P1266, DOI 10.1037//0278-7393.26.5.1266.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   VERLEGER R, 1988, BEHAV BRAIN SCI, V11, P343, DOI 10.1017/S0140525X00058015.
   Vespignani F, 2010, J COGNITIVE NEUROSCI, V22, P1682, DOI 10.1162/jocn.2009.21293.
   Vissers CTWM, 2006, BRAIN RES, V1106, P150, DOI 10.1016/j.brainres.2006.05.012.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.}},
Number-of-Cited-References = {{52}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{DZ8ZT}},
Unique-ID = {{ISI:000386163000008}},
OA = {{Green Published, Other Gold}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000526952500079,
Author = {Bertero, Dario and Fung, Pascale},
Editor = {{Calzolari, N and Choukri, K and Declerck, T and Goggi, S and Grobelnik, M and Maegaard, B and Mariani, J and Mazo, H and Moreno, A and Odijk, J and Piperidis, S}},
Title = {{Deep Learning of Audio and Language Features for Humor Prediction}},
Booktitle = {{LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION}},
Year = {{2016}},
Pages = {{496-501}},
Note = {{10th International Conference on Language Resources and Evaluation
   (LREC), Portoroz, SLOVENIA, MAY 23-28, 2016}},
Organization = {{European Language Resources Assoc; Evaluat \& Language Resources
   Distribut Agcy; Ist Linguistica Computazionale; European Media Lab GmbH;
   Intel}},
Abstract = {{We propose a comparison between various supervised machine learning
   methods to predict and detect humor in dialogues. We retrieve our
   humorous dialogues from a very popular TV sitcom: ``The Big Bang
   Theory{''}. We build a corpus where punchlines are annotated using the
   canned laughter embedded in the audio track. Our comparative study
   involves a linear-chain Conditional Random Field over a Recurrent Neural
   Network and a Convolutional Neural Network. Using a combination of
   word-level and audio frame-level features, the CNN outperforms the other
   methods, obtaining the best F-score of 68:5\% over 66:5\% by CRF and
   52:9\% by RNN. Our work is a starting point to developing more effective
   machine learning and neural network models on the humor prediction task,
   as well as developing machines capable in understanding humor in
   general.}},
Publisher = {{EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA}},
Address = {{55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bertero, D (Corresponding Author), Hong Kong Univ Sci \& Technol, Human Language Technol Ctr, Dept Elect \& Comp Engn, Clear Water Bay, Hong Kong, Peoples R China.
   Bertero, Dario; Fung, Pascale, Hong Kong Univ Sci \& Technol, Human Language Technol Ctr, Dept Elect \& Comp Engn, Clear Water Bay, Hong Kong, Peoples R China.}},
ISBN = {{978-2-9517408-9-1}},
Keywords = {{humor prediction; neural networks; TV-sitcoms}},
Keywords-Plus = {{RECOGNITION; STRESS}},
Research-Areas = {{Linguistics}},
Web-of-Science-Categories  = {{Language \& Linguistics}},
Author-Email = {{dbertero@connect.ust.hk
   pascale@ece.ust.hk}},
Funding-Acknowledgement = {{Hong Kong Phd Fellowship Scheme {[}16214415]; Hong Kong Research Grants
   CouncilHong Kong Research Grants Council}},
Funding-Text = {{This work was partially funded by the Hong Kong Phd Fellowship Scheme,
   and partially by grant \#16214415 of the Hong Kong Research Grants
   Council.}},
Cited-References = {{ANDERSON CA, 1989, BASIC APPL SOC PSYCH, V10, P101, DOI 10.1207/s15324834basp1002\_1.
   Attardo S, 1997, HUMOR, V10, P395, DOI 10.1515/humr.1997.10.4.395.
   ATTARDO S, 1993, J PRAGMATICS, V19, P537, DOI 10.1016/0378-2166(93)90111-2.
   Bamman D., 2015, 9 INT AAAI C WEB SOC.
   Barbieri F, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4258.
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223.
   Bergstra J, 2010, P PYTH SCI COMP C SC.
   Bertero D., 2016, AC SPEECH SIGN PROC.
   Collobert R, 2011, J MACH LEARN RES, V12, P2493.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI {[}DOI 10.1145/2502081.2502224, 10.1145/2502081.2502224].
   Fang YW, 2015, CHIN CONTR CONF, P2367, DOI 10.1109/ChiCC.2015.7260003.
   Fung P, 2015, SCI AM, V313, P60.
   Han K, 2014, INTERSPEECH, P223.
   Hetzron R., 1991, HUMOR INT J HUMOR RE.
   Joshi A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P757.
   Karoui J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P644.
   LaFave L., 1976, SUPERIORITY ENHANCED.
   Lafferty J., 2001, CONDITIONAL RANDOM F.
   Lefcourt HM, 1997, J RES PERS, V31, P523, DOI 10.1006/jrpe.1997.2191.
   Lefcourt HM, 2012, HUMOR LIFE STRESS AN.
   Liu Y, 2006, IEEE T AUDIO SPEECH, V14, P1526, DOI 10.1109/TASL.2006.878255.
   Martineau William H, 1972, PSYCHOL HUMOR, P101, DOI DOI 10.1016/B978-0-12-288950-9.50011-0.
   Mikolov T., 2013, COMPUTING RES REPOSI, V1301, P3781, DOI DOI 10.1109/TNN.2003.820440].
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748.
   Okazaki N., 2007, CRFSUITE FAST IMPLEM.
   PASCANU R, 2012, ARXIV E PRINTS, V1211, P5063.
   Pascanu R., 2013, ARXIV13126026.
   Rakov R, 2013, INTERSPEECH, P842.
   Reyes A, 2013, LANG RESOUR EVAL, V47, P239, DOI 10.1007/s10579-012-9196-x.
   Reyes A, 2012, DECIS SUPPORT SYST, V53, P754, DOI 10.1016/j.dss.2012.05.027.
   Riloff E., 2013, P 2013 C EMP METH NA, P704.
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798.
   Sumners A D, 1988, Issues Ment Health Nurs, V9, P169, DOI 10.3109/01612848809140921.
   Wang M., 2013, P 6 INT JOINT C NAT.
   Zhang JJ, 2012, IEEE T AUDIO SPEECH, V20, P2492, DOI 10.1109/TASL.2012.2215592.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO8EW}},
Unique-ID = {{ISI:000526952500079}},
DA = {{2020-12-06}},
}

@article{ ISI:000368592300005,
Author = {McMurray, Bob and Jongman, Allard},
Title = {{What Comes After /f/? Prediction in Speech Derives From Data-Explanatory
   Processes}},
Journal = {{PSYCHOLOGICAL SCIENCE}},
Year = {{2016}},
Volume = {{27}},
Number = {{1}},
Pages = {{43-52}},
Month = {{JAN}},
Abstract = {{Acoustic cues are short-lived and highly variable, which makes speech
   perception a difficult problem. However, most listeners solve this
   problem effortlessly. In the present experiment, we demonstrated that
   part of the solution lies in predicting upcoming speech sounds and that
   predictions are modulated by high-level expectations about the current
   sound. Participants heard isolated fricatives (e.g., s, sh) and
   predicted the upcoming vowel. Accuracy was above chance, which suggests
   that fine-grained detail in the signal can be used for prediction. A
   second group performed the same task but also saw a still face and a
   letter corresponding to the fricative. This group performed markedly
   better, which suggests that high-level knowledge modulates prediction by
   helping listeners form expectations about what the fricative should have
   sounded like. This suggests a form of data explanation operating in
   speech perception: Listeners account for variance due to their knowledge
   of the talker and current phoneme, and they use what is left over to
   make more accurate predictions about the next sound.}},
Publisher = {{SAGE PUBLICATIONS INC}},
Address = {{2455 TELLER RD, THOUSAND OAKS, CA 91320 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{McMurray, B (Corresponding Author), Univ Iowa, Dept Psychol \& Brain Sci, 11 Seashore Hall East, Iowa City, IA 52242 USA.
   McMurray, Bob, Univ Iowa, Dept Psychol \& Brain Sci, 11 Seashore Hall East, Iowa City, IA 52242 USA.
   Jongman, Allard, Univ Kansas, Dept Linguist, Lawrence, KS 66045 USA.}},
DOI = {{10.1177/0956797615609578}},
ISSN = {{0956-7976}},
EISSN = {{1467-9280}},
Keywords = {{speech perception; anticipation; predictive coding; generative models;
   social expectations; auditory processing; open data}},
Keywords-Plus = {{SPOKEN-WORD RECOGNITION; ANTICIPATORY COARTICULATION; VOWEL
   COARTICULATION; AUDITORY-CORTEX; PERCEPTION; INFORMATION;
   CATEGORIZATION; FRICATIVES}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{bob-mcmurray@uiowa.edu}},
ResearcherID-Numbers = {{jongman, allard/A-8377-2009}},
ORCID-Numbers = {{jongman, allard/0000-0002-7384-2036}},
Funding-Acknowledgement = {{National Institutes of HealthUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USA {[}DC0008089];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health \& Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness \& Other
   Communication Disorders (NIDCD) {[}P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, R01DC008089, P50DC000242,
   R01DC008089, P50DC000242, P50DC000242, R01DC008089, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, R01DC008089,
   P50DC000242, P50DC000242, P50DC000242, R01DC008089, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC008089, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, R01DC008089, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, R01DC008089, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, R01DC008089, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242] Funding Source: NIH RePORTER}},
Funding-Text = {{This research was supported by National Institutes of Health Grant No.
   DC0008089 awarded to B. McMurray.}},
Cited-References = {{Apfelbaum KS, 2014, LANG COGN NEUROSCI, V29, P1070, DOI 10.1080/01690965.2013.824995.
   Bates D., 2011, LME4 LINEAR MIXED EF.
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177.
   Blank H, 2013, NEUROIMAGE, V65, P109, DOI 10.1016/j.neuroimage.2012.09.047.
   BLUMSTEIN SE, 1979, J ACOUST SOC AM, V66, P1001, DOI 10.1121/1.383319.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Cole J, 2010, J PHONETICS, V38, P167, DOI 10.1016/j.wocn.2009.08.004.
   Daniloff R., 1974, EXPT PHONETICS, P100.
   Fowler C., 1986, INVARIANCE VARIABILI, P123.
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251.
   Gow D. W., 2007, LAB PHONOLOGY, V9, P173.
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584.
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764.
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027.
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140.
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100.
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413.
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695.
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6.
   MARTIN JG, 1981, J ACOUST SOC AM, V69, P559, DOI 10.1121/1.385484.
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325.
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4.
   NEAREY TM, 1990, J PHONETICS, V18, P347, DOI 10.1016/S0095-4470(19)30379-1.
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241.
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x.
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172.
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   R Development Core Team, 2008, R LANG ENV STAT COMP.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Rhodes G., 2011, OXFORD HDB FACE PERC, P263, DOI DOI 10.1093/OXFORDHB/9780199559053.001.0001.
   Salverda AP, 2014, J MEM LANG, V71, P145, DOI 10.1016/j.jml.2013.11.002.
   Smits R, 2001, J EXP PSYCHOL HUMAN, V27, P1145, DOI 10.1037/0096-1523.27.5.1145.
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006.
   von Kriegstein K, 2010, J NEUROSCI, V30, P629, DOI 10.1523/JNEUROSCI.2742-09.2010.
   Wolpert DM, 2001, CURR BIOL, V11, pR729, DOI 10.1016/S0960-9822(01)00432-8.
   YENIKOMSHIAN GH, 1981, J ACOUST SOC AM, V70, P966, DOI 10.1121/1.387031.}},
Number-of-Cited-References = {{41}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Psychol. Sci.}},
Doc-Delivery-Number = {{DB5ZI}},
Unique-ID = {{ISI:000368592300005}},
OA = {{Green Accepted, Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000366066400011,
Author = {Huettig, Falk},
Title = {{Four central questions about prediction in language processing}},
Journal = {{BRAIN RESEARCH}},
Year = {{2015}},
Volume = {{1626}},
Number = {{SI}},
Pages = {{118-135}},
Month = {{NOV 11}},
Abstract = {{The notion that prediction is a fundamental principle of human
   information processing has been en vogue over recent years. The
   investigation of language processing may be particularly illuminating
   for testing this claim. Linguists traditionally have argued prediction
   plays only a minor role during language understanding because of the
   vast possibilities available to the language user as each word is
   encountered. In the present review I consider four central questions of
   anticipatory language processing: Why (i.e. what is the function of
   prediction in language processing)? What (i.e. what are the cues used to
   predict up-coming linguistic information and what type of
   representations are predicted)? How (what mechanisms are involved in
   predictive language processing and what is the role of possible
   mediating factors such as working memory)? When (i.e. do individuals
   always predict up-coming input during language processing)? I propose
   that prediction occurs via a set of diverse PACS (production-,
   association-, combinatorial-, and simulation-based prediction)
   mechanisms which are minimally required for a comprehensive account of
   predictive language processing. Models of anticipatory language
   processing must be revised to take multiple mechanisms, mediating
   factors, and situational context into account. Finally, I conjecture
   that the evidence considered here is consistent with the notion that
   prediction is an important aspect but not a fundamental principle of
   language processing.
   This article is part of a Special Issue entitled SI: Prediction and
   Attention. (C) 2015 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Huettig, F (Corresponding Author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   Huettig, Falk, Max Planck Inst Psycholinguist, NL-6500 AH Nijmegen, Netherlands.
   Huettig, Falk, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, NL-6525 ED Nijmegen, Netherlands.}},
DOI = {{10.1016/j.brainres.2015.02.014}},
ISSN = {{0006-8993}},
EISSN = {{1872-6240}},
Keywords = {{Language processing; Prediction}},
Keywords-Plus = {{SPOKEN-WORD RECOGNITION; AGE-RELATED-CHANGES; SEMANTIC MEMORY
   ORGANIZATION; EYE-MOVEMENTS; INDIVIDUAL-DIFFERENCES; SENTENCE
   COMPREHENSION; VISUAL WORLD; TIME-COURSE; TRANSITIONAL PROBABILITIES;
   DISCOURSE CONTEXT}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{falk.huettig@mpi.nl}},
Cited-References = {{Acheson DJ, 2008, BEHAV RES METHODS, V40, P278, DOI 10.3758/BRM.40.1.278.
   Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742.
   Aglioti SM, 2008, NAT NEUROSCI, V11, P1109, DOI 10.1038/nn.2182.
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arbib MA, 2005, BEHAV BRAIN SCI, V28, P105, DOI 10.1017/S0140525X05000038.
   Arias-Trejo N, 2013, COGNITION, V128, P214, DOI 10.1016/j.cognition.2013.03.008.
   Arias-Trejo N, 2009, PHILOS T R SOC B, V364, P3633, DOI 10.1098/rstb.2009.0146.
   Arnett JJ, 2008, AM PSYCHOL, V63, P602, DOI 10.1037/0003-066X.63.7.602.
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Bar M, 2009, PHILOS T R SOC B, V364, P1235, DOI 10.1098/rstb.2008.0310.
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147.
   Blair J. R., 1989, CLIN NEUROPSYCHOL, V3, P129, DOI DOI 10.1080/13854048908403285.
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005.
   BRADY JP, 1971, BEHAV THER, V2, P129, DOI 10.1016/S0005-7894(71)80001-1.
   Brouwer S, 2013, APPL PSYCHOLINGUIST, V34, P519, DOI 10.1017/S0142716411000853.
   Cavanagh P, 2005, TRENDS COGN SCI, V9, P349, DOI 10.1016/j.tics.2005.05.009.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   Chang F, 2013, BEHAV BRAIN SCI, V36, P350, DOI 10.1017/S0140525X12002518.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Clark H. H., 1996, USING LANGUAGE.
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009.
   Copland DA, 2003, NEUROIMAGE, V20, P302, DOI 10.1016/S1053-8119(03)00279-9.
   Corsi P. M, 1972, HUMAN MEMORY MEDIAL.
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498.
   De Deyne S, 2013, BEHAV RES METHODS, V45, P480, DOI 10.3758/s13428-012-0260-7.
   De Ruiter JP, 2006, LANGUAGE, V82, P515, DOI 10.1353/lan.2006.0130.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Drake E, 2015, MEM COGNITION, V43, P111, DOI 10.3758/s13421-014-0451-9.
   Duncan J, 2010, TRENDS COGN SCI, V14, P172, DOI 10.1016/j.tics.2010.01.004.
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   Evans N, 2009, BEHAV BRAIN SCI, V32, P429, DOI 10.1017/S0140525X0999094X.
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Federmeier KD, 2005, PSYCHOPHYSIOLOGY, V42, P133, DOI 10.1111/j.1469-8986.2005.00274.x.
   Federmeier KD, 2001, J EXP PSYCHOL LEARN, V27, P202, DOI 10.1037/0278-7393.27.1.202.
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133.
   Ferretti TR, 2001, J MEM LANG, V44, P516, DOI 10.1006/jmla.2000.2728.
   Friederici AD, 2003, CEREB CORTEX, V13, P170, DOI 10.1093/cercor/13.2.170.
   Frisson S, 2005, J EXP PSYCHOL LEARN, V31, P862, DOI 10.1037/0278-7393.31.5.862.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Gallese V, 2003, PHILOS T R SOC B, V358, P517, DOI 10.1098/rstb.2002.1234.
   Ganis G, 1996, J COGNITIVE NEUROSCI, V8, P89, DOI 10.1162/jocn.1996.8.2.89.
   Gathercole S. E., 1996, CHILDRENS TEST NONWO.
   GAZZANIGA MS, 1983, AM PSYCHOL, V38, P525, DOI 10.1037/0003-066X.38.5.525.
   Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313.
   Grainger J, 1996, J MEM LANG, V35, P623, DOI 10.1006/jmla.1996.0033.
   GUTIERREZ R, 1995, NEUROSCI LETT, V195, P93, DOI 10.1016/0304-3940(94)11789-L.
   Hagoort P, 2004, SCIENCE, V304, P438, DOI 10.1126/science.1095455.
   Halgren E, 2002, NEUROIMAGE, V17, P1101, DOI 10.1006/nimg.2002.1268.
   Hayhoe MM, 2003, J VISION, V3, P49, DOI 10.1167/3.1.6.
   Hellige J. B., 1993, HEMISPHERIC ASYMMETR, V6.
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P111, DOI 10.1017/S0140525X10000725.
   Hintz F., 2015, EVENT KNOWLEDG UNPUB.
   Hintz F., 2014, P 27 ANN CUNY C HUM.
   Huang HW, 2012, NEUROPSYCHOLOGIA, V50, P26, DOI 10.1016/j.neuropsychologia.2011.10.018.
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003.
   Huettig F., DYSLEXIA IN PRESS.
   Huettig F, 2007, J MEM LANG, V57, P460, DOI 10.1016/j.jml.2007.02.001.
   Huettig F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00285.
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003.
   Huettig F, 2011, ACTA PSYCHOL, V137, P138, DOI 10.1016/j.actpsy.2010.07.013.
   Huettig R, 2012, P 18 ARCH MECH LANG.
   Hunnius S, 2010, DEV PSYCHOL, V46, P446, DOI 10.1037/a0016543.
   Jackendoff R., 2002, FDN LANGUAGE BRAIN M.
   Jackendoff R, 2007, BRAIN RES, V1146, P2, DOI 10.1016/j.brainres.2006.08.111.
   James A., 2013, P 19 ARCH MECH LANG.
   James W, 1890, PRINCIPLES PSYCHOL.
   Kahneman D., 2011, THINKING FAST SLOW.
   Kaiser E, 2004, COGNITION, V94, P113, DOI 10.1016/j.cognition.2004.01.002.
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Keller PE, 2008, Q J EXP PSYCHOL, V61, P275, DOI 10.1080/17470210601160864.
   Kiehl KA, 2002, NEUROIMAGE, V17, P842, DOI 10.1006/nimg.2002.1244.
   Kilner JM, 2004, NAT NEUROSCI, V7, P1299, DOI 10.1038/nn1355.
   Knoeferle P, 2005, COGNITION, V95, P95, DOI 10.1016/j.cognition.2004.03.002.
   Knoeferle P, 2007, J MEM LANG, V57, P519, DOI 10.1016/j.jml.2007.01.003.
   Kosslyn S.M., 2006, CASE MENTAL IMAGERY.
   Kosslyn SM, 2002, AM PSYCHOL, V57, P341, DOI 10.1037//0003-066X.57.5.341.
   Kotz SA, 2002, NEUROIMAGE, V17, P1761, DOI 10.1006/nimg.2002.1316.
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010.
   Kukona A, 2011, COGNITION, V119, P23, DOI 10.1016/j.cognition.2010.12.002.
   Kuperberg GR, 2007, BRAIN RES, V1146, P23, DOI 10.1016/j.brainres.2006.12.063.
   Kuperberg GR, 2003, J COGNITIVE NEUROSCI, V15, P272, DOI 10.1162/089892903321208204.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935.
   LAND MF, 1994, NATURE, V369, P742, DOI 10.1038/369742a0.
   Land MF, 1997, PHILOS T ROY SOC B, V352, P1231, DOI 10.1098/rstb.1997.0105.
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004.
   Lesage E, 2012, CURR BIOL, V22, pR794, DOI 10.1016/j.cub.2012.07.006.
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676.
   Mani N, 2014, J EXP CHILD PSYCHOL, V126, P264, DOI 10.1016/j.jecp.2014.05.004.
   Mani N, 2013, BEHAV BRAIN SCI, V36, P365, DOI 10.1017/S0140525X12002646.
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284.
   Mani N, 2011, COGNITION, V121, P196, DOI 10.1016/j.cognition.2011.06.013.
   Matsumoto A, 2005, NEUROIMAGE, V24, P624, DOI 10.1016/j.neuroimage.2004.09.008.
   McCauley S. M., 2011, P 33 ANN C COGN SCI, P1619.
   McDonald SA, 2003, VISION RES, V43, P1735, DOI 10.1016/S0042-6989(03)00237-2.
   McFarland DH, 2001, J SPEECH LANG HEAR R, V44, P128, DOI 10.1044/1092-4388(2001/012).
   McIntosh GC, 1997, J NEUROL NEUROSUR PS, V62, P22, DOI 10.1136/jnnp.62.1.22.
   McQueen JM, 2014, ATTEN PERCEPT PSYCHO, V76, P190, DOI 10.3758/s13414-013-0560-8.
   Mennie N, 2007, EXP BRAIN RES, V179, P427, DOI 10.1007/s00221-006-0804-0.
   Metusalem R, 2012, J MEM LANG, V66, P545, DOI 10.1016/j.jml.2012.01.001.
   Mishra RK, 2012, J EYE MOVEMENT RES, V5.
   Misyak JB, 2010, TOP COGN SCI, V2, P138, DOI 10.1111/j.1756-8765.2009.01072.x.
   Montag J. L., 2014, P 27 ANN CUNY C HUM.
   Moulton ST, 2009, PHILOS T R SOC B, V364, P1273, DOI 10.1098/rstb.2008.0314.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Ni W, 2000, J COGNITIVE NEUROSCI, V12, P120, DOI 10.1162/08989290051137648.
   Paivio A., 1990, MENTAL REPRESENTATIO.
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720.
   Pecher D, 2009, PSYCHON B REV, V16, P914, DOI 10.3758/PBR.16.5.914.
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142.
   Pelucchi B, 2009, COGNITION, V113, P244, DOI 10.1016/j.cognition.2009.07.011.
   Perruchet P, 2008, MEM COGNITION, V36, P1299, DOI 10.3758/MC.36.7.1299.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169.
   Popper K. R., 1959, LOGIC SCI DISCOVERY.
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231.
   Prinz W, 2006, CORTEX, V42, P515, DOI 10.1016/S0010-9452(08)70389-7.
   PYLYSHYN Z, 1989, COGNITION, V32, P65, DOI 10.1016/0010-0277(89)90014-0.
   RADEAU M, 1989, MEM COGNITION, V17, P525, DOI 10.3758/BF03197074.
   Ramnani N, 2004, NAT NEUROSCI, V7, P85, DOI 10.1038/nn1168.
   Ramscar M, 2014, TOP COGN SCI, V6, P5, DOI 10.1111/tops.12078.
   Rayner K, 1996, PSYCHON B REV, V3, P504, DOI 10.3758/BF03214555.
   Rayner K, 2006, PSYCHOL AGING, V21, P448, DOI 10.1037/0882-7974.21.3.448.
   Rayner K, 2009, BIOL PSYCHOL, V80, P4, DOI 10.1016/j.biopsycho.2008.05.002.
   Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78.
   Rommers J., ATTEN PERCE IN PRESS.
   Rommers J, 2013, PSYCHOL SCI, V24, P2218, DOI 10.1177/0956797613490746.
   Rommers J, 2013, NEUROPSYCHOLOGIA, V51, P437, DOI 10.1016/j.neuropsychologia.2012.12.002.
   Rossell SL, 2003, NEUROPSYCHOLOGIA, V41, P550, DOI 10.1016/S0028-3932(02)00181-1.
   Rothermich K, 2013, NEUROIMAGE, V70, P89, DOI 10.1016/j.neuroimage.2012.12.013.
   Rowland CF, 2012, COGNITION, V125, P49, DOI 10.1016/j.cognition.2012.06.008.
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926.
   Salverda AP, 2011, ACTA PSYCHOL, V137, P172, DOI 10.1016/j.actpsy.2010.09.010.
   Schiller NO, 2009, NEUROIMAGE, V44, P520, DOI 10.1016/j.neuroimage.2008.09.019.
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603.
   Sebanz N, 2005, J EXP PSYCHOL HUMAN, V31, P1234, DOI 10.1037/0096-1523.31.6.1234.
   Sebanz N, 2003, COGNITION, V88, pB11, DOI 10.1016/S0010-0277(03)00043-X.
   Sebanz N, 2009, TOP COGN SCI, V1, P353, DOI 10.1111/j.1756-8765.2009.01024.x.
   St Clair MC, 2009, COGNITIVE SCI, V33, P1317, DOI 10.1111/j.1551-6709.2009.01065.x.
   Stanfield RA, 2001, PSYCHOL SCI, V12, P153, DOI 10.1111/1467-9280.00326.
   Stanovich KE, 2000, BEHAV BRAIN SCI, V23, P645, DOI 10.1017/S0140525X00003435.
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425.
   Thorn ASC, 1999, Q J EXP PSYCHOL-A, V52, P303, DOI 10.1080/027249899391089.
   TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9.
   UNDERWOOD BJ, 1975, AM PSYCHOL, V30, P128, DOI 10.1037/h0076759.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   Van der Elst W, 2006, J INT NEUROPSYCH SOC, V12, P80, DOI 10.1017/S1355617706060115.
   Vogel EK, 2008, CURR DIR PSYCHOL SCI, V17, P171, DOI 10.1111/j.1467-8721.2008.00569.x.
   von Helmholtz H., 1860, HDB PHYSL OPTIK, V3.
   von Hofsten C, 2004, TRENDS COGN SCI, V8, P266, DOI 10.1016/j.tics.2004.04.002.
   Wassenburg SI, 2010, Q J EXP PSYCHOL, V63, P1665, DOI 10.1080/17470218.2010.502579.
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0.
   Weber A, 2006, COGNITION, V99, pB63, DOI 10.1016/j.cognition.2005.07.001.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Willits J., 2009, P 31 ANN C COGN SCI, P2570.
   Wilson M, 2005, PSYCHON B REV, V12, P957, DOI 10.3758/BF03206432.
   Wlotko EW, 2007, NEUROPSYCHOLOGIA, V45, P3001, DOI 10.1016/j.neuropsychologia.2007.05.013.
   Wlotko EW, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00181.
   Wlotko EW, 2012, PSYCHOPHYSIOLOGY, V49, P770, DOI 10.1111/j.1469-8986.2012.01366.x.
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238.
   Zwaan RA, 2004, PSYCHOL LEARN MOTIV, V44, P35.
   Zwaan RA, 2014, TRENDS COGN SCI, V18, P229, DOI 10.1016/j.tics.2014.02.008.}},
Number-of-Cited-References = {{176}},
Times-Cited = {{87}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{36}},
Journal-ISO = {{Brain Res.}},
Doc-Delivery-Number = {{CX9ZX}},
Unique-ID = {{ISI:000366066400011}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000368822000007,
Author = {Zhang Yu-Mei and Hu Xiao-Jun and Wu Xiao-Jun and Bai Shu-Lin and Lu Gang},
Title = {{Volterra prediction model for speech signal series}},
Journal = {{ACTA PHYSICA SINICA}},
Year = {{2015}},
Volume = {{64}},
Number = {{20}},
Month = {{OCT 20}},
Abstract = {{The given English phonemes, words and sentences are sampled and
   preprocessed. For these real measured speech signal series, time delay
   and embedding dimension are determined by using mutual information
   method and Cao's method, respectively, so as to perform phase space
   reconstruction of the speech signal series. By using small data set
   method, the largest Lyapunov exponent of the speech signal series is
   calculated and the fact that its value is greater than zero presents
   chaotic characteristics of the speech signal series. This, in fact,
   performs the chaotic characteristic identification of the speech signal
   series. By introducing second-order Volterra series, in this paper we
   put forward a type of nonlinear prediction model with an explicit
   structure. To overcome some intrinsic shortcomings caused by improper
   parameter selection when using the least mean square (LMS) algorithm to
   update Volterra model efficiency, by using a variable convergence factor
   technology based on a posteriori error assumption on the basis of LMS
   algorithm, a novel Davidon-Fletcher-Powell-based second of Volterra
   filter (DFPSOVF) is constructed and is performed to predict speech
   signal series of the given English phonemes, words and sentences with
   chaotic characteristics. Simulation results under MATLAB 7.0 environment
   show that the proposed nonlinear model DFPSOVF can guarantee its
   stability and convergence and there are no divergence problems in using
   LMS algorithm; for single-frame and multi-frame of the measured speech
   signals, when root mean square error (RMSE) is used as an evaluation
   criterion the prediction accuracy of the proposed nonlinear prediction
   model DFPSOVF in this paper is better than that of the linear prediction
   (LP) that is traditionally employed. The primary results of single-frame
   and multi-frame predictions are given. So, the proposed DFPSOVF model
   can substitute linear prediction model on certain conditions. Meanwhile,
   it can better reflect trends and regularity of the speech signal series
   and fully meet requirements for speech signal prediction. The memory
   length of the proposed prediction model may be selected by the embedding
   dimension of the speech signal series. The proposed model can present a
   nonlinear analysis and more valuable model structure for speech signal
   series, and opens up a new way to speech signal reconstruction and
   compression coding so as to improve complexity and process effect of
   speech signal processing method.}},
Publisher = {{CHINESE PHYSICAL SOC}},
Address = {{P O BOX 603, BEIJING 100080, PEOPLES R CHINA}},
Type = {{Article}},
Language = {{Chinese}},
Affiliation = {{Wu, XJ (Corresponding Author), Shaanxi Normal Univ, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Peoples R China.
   Zhang Yu-Mei; Wu Xiao-Jun; Lu Gang, Shaanxi Normal Univ, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Peoples R China.
   Zhang Yu-Mei; Hu Xiao-Jun; Wu Xiao-Jun; Lu Gang, Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.
   Zhang Yu-Mei; Wu Xiao-Jun, Northwestern Polytech Univ, Sch Automat Control, Xian 710072, Peoples R China.
   Bai Shu-Lin, Northwestern Polytech Univ, Sch Elect \& Informat, Xian 710072, Peoples R China.}},
DOI = {{10.7498/aps.64.200507}},
Article-Number = {{200507}},
ISSN = {{1000-3290}},
Keywords = {{speech signal; chaos; Volterra prediction model; Davidon-Fletcher-Powell
   algorithm}},
Keywords-Plus = {{CHAOTIC TIME-SERIES; PRACTICAL METHOD; FILTERS}},
Research-Areas = {{Physics}},
Web-of-Science-Categories  = {{Physics, Multidisciplinary}},
Author-Email = {{wythe@snnu.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}11502133, 11172342, 11372167, 61202153];
   Key Science and Technology Innovation Team in Shaanxi Province, China
   {[}2014KTC-18]; Science and Technology Plan of Xi'an City, China
   {[}CXY1437(1)]; Science and Technology Plan of Yulin City, China
   {[}2014cxy-09, sf13-43, 2012cxy3-6]}},
Funding-Text = {{Project supported by the National Natural Science Foundation of China
   (Grant Nos. 11502133, 11172342, 11372167, 61202153), the Key Science and
   Technology Innovation Team in Shaanxi Province, China (Grant No.
   2014KTC-18), the Science and Technology Plan of Xi'an City, China (Grant
   No. CXY1437(1)), and the Science and Technology Plan of Yulin City,
   China (Grant Nos. 2014cxy-09, sf13-43, 2012cxy3-6).}},
Cited-References = {{Abarbanel HDI, 2001, PHYS LETT A, V281, P368, DOI 10.1016/S0375-9601(01)00128-1.
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8.
   Chen DY, 2012, ACTA PHYS SIN-CH ED, V61.
   Cheng XF, 2013, ACTA PHYS SIN-CH ED, V62, DOI 10.7498/aps.62.168701.
   deCampos MLR, 1997, IEEE T CIRCUITS-II, V44, P924, DOI 10.1109/82.644046.
   Guerin A, 2003, IEEE T SPEECH AUDI P, V11, P672, DOI 10.1109/TSA.2003.818077.
   Iasonas K, 2005, IEEE T SPEECH AUDIO, V13, P1098.
   Li HC, 2005, CHINESE PHYS, V14, P2181, DOI 10.1088/1009-1963/14/11/007.
   Maciej O, 2002, IEEE INT S CIRC SYST, P564.
   MARAGOS P, 1991, INT CONF ACOUST SPEE, P417, DOI 10.1109/ICASSP.1991.150365.
   Mathews VJ, 1991, IEEE SIGNAL PROC MAG, V8, P10, DOI 10.1109/79.127998.
   Max A L, 2011, ADV NONLINEAR SPEECH, V7015, P9.
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P.
   Sigrist Z, 2012, SIGNAL PROCESS, V92, P1010, DOI 10.1016/j.sigpro.2011.10.013.
   Sun JF, 2007, SIGNAL PROCESS, V87, P2431, DOI 10.1016/j.sigpro.2007.03.020.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.
   Wei Rui-xuan, 2005, Acta Electronica Sinica, V33, P656.
   Wu XJ, 2013, APPL SOFT COMPUT, V13, P3314, DOI 10.1016/j.asoc.2013.02.008.
   Zhang JS, 2005, CHINESE PHYS, V14, P49, DOI 10.1088/1009-1963/14/1/011.
   Zhang YM, 2013, ACTA PHYS SIN-CH ED, V62, DOI 10.7498/aps.62.190509.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{Acta Phys. Sin.}},
Doc-Delivery-Number = {{DB9FO}},
Unique-ID = {{ISI:000368822000007}},
DA = {{2020-12-06}},
}

@article{ ISI:000361089800005,
Author = {Lewis, Ashley Glen and Wang, Lin and Bastiaansen, Marcel},
Title = {{Fast oscillatory dynamics during language comprehension: Unification
   versus maintenance and prediction?}},
Journal = {{BRAIN AND LANGUAGE}},
Year = {{2015}},
Volume = {{148}},
Pages = {{51-63}},
Month = {{SEP}},
Abstract = {{The role of neuronal oscillations during language comprehension is not
   yet well understood. In this paper we review and reinterpret the
   functional roles of beta-and gamma-band oscillatory activity during
   language comprehension at the sentence and discourse level. We discuss
   the evidence in favor of a role for beta and gamma in unification (the
   unification hypothesis), and in light of mounting evidence that cannot
   be accounted for under this hypothesis, we explore an alternative
   proposal linking beta and gamma oscillations to maintenance and
   prediction (respectively) during language comprehension. Our
   maintenance/prediction hypothesis is able to account for most of the
   findings that are currently available relating beta and gamma
   oscillations to language comprehension, and is in good agreement with
   other proposals about the roles of beta and gamma in domain-general
   cognitive processing. In conclusion we discuss proposals for further
   testing and comparing the prediction and unification hypotheses. (C)
   2015 Elsevier Inc. All rights reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bastiaansen, M (Corresponding Author), NHTV Breda Univ Appl Sci, Acad Leisure, Archimedesstr 17, NL-4816 BA Breda, Netherlands.
   Lewis, Ashley Glen; Bastiaansen, Marcel, Max Planck Inst Psycholinguist, Neurobiol Language Dept, Nijmegen, Netherlands.
   Lewis, Ashley Glen, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, Ctr Cognit Neuroimaging, NL-6525 ED Nijmegen, Netherlands.
   Wang, Lin, Chinese Acad Sci, Inst Psychol, Key Lab Behav Sci, Beijing 100101, Peoples R China.
   Bastiaansen, Marcel, NHTV Breda Univ Appl Sci, Acad Leisure, NL-4816 BA Breda, Netherlands.}},
DOI = {{10.1016/j.bandl.2015.01.003}},
ISSN = {{0093-934X}},
EISSN = {{1090-2155}},
Keywords = {{EEG; MEG; Language comprehension; Unification; Prediction; Oscillatory
   dynamics; Beta; Gamma}},
Keywords-Plus = {{GAMMA-BAND ACTIVITY; HUMAN BRAIN; PHASE SYNCHRONIZATION;
   BETA-SYNCHRONIZATION; SEMANTIC VIOLATION; HUMAN EEG; TOP-DOWN; MEMORY;
   ATTENTION; RESPONSES}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences \&
   Neurology; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental}},
Author-Email = {{bastiaansen4.m@nhtv.nl}},
ResearcherID-Numbers = {{Lewis, Ashley Glen/K-5410-2019
   Lewis, Ashley/C-8984-2015
   }},
ORCID-Numbers = {{Lewis, Ashley Glen/0000-0003-4737-2525
   Lewis, Ashley/0000-0003-4737-2525
   Wang, Lin/0000-0001-6911-0660}},
Funding-Acknowledgement = {{National Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) {[}31200849]; IMPRS PhD fellowship from Max Planck
   Society}},
Funding-Text = {{We would like to thank the three anonymous reviewers for their very
   helpful comments on an earlier version of this manuscript. This work is
   partly supported by an IMPRS PhD fellowship from the Max Planck Society
   to A.G.L., and a grant from the National Science Foundation of China
   (No. 31200849) to LW.}},
Cited-References = {{Androulidakis AG, 2007, EUR J NEUROSCI, V25, P3758, DOI 10.1111/j.1460-9568.2007.05620.x.
   Androulidakis AG, 2006, EUR J NEUROSCI, V24, P3299, DOI 10.1111/j.1460-9568.2006.05201.x.
   Baggio G, 2011, LANG COGNITIVE PROC, V26, P1338, DOI 10.1080/01690965.2010.542671.
   Bastiaansen M., 2012, OXFORD HDB EVENT REL, P31.
   Bastiaansen M., 2010, 16 ANN M ORG HUM BRA.
   Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0.
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283.
   Bastiaansen MCM, 2008, BRAIN LANG, V106, P15, DOI 10.1016/j.bandl.2007.10.006.
   Bastiaansen MCM, 2005, J COGNITIVE NEUROSCI, V17, P530, DOI 10.1162/0898929053279469.
   Bastiaansen MCM, 2001, INT J PSYCHOPHYSIOL, V43, P91, DOI 10.1016/S0167-8760(01)00181-7.
   Bauer M, 2006, J NEUROSCI, V26, P490, DOI 10.1523/JNEUROSCI.5228-04.2006.
   Beck A, 1973, ACTA NEUROBIOLOGIA S, V3, P1.
   Beck A., 1891, OZNACZENIE LOKALIZAC.
   Berger H, 1929, ARCH PSYCHIAT NERVEN, V87, P527, DOI 10.1007/BF01797193.
   Bertrand O, 2000, INT J PSYCHOPHYSIOL, V38, P211, DOI 10.1016/S0167-8760(00)00166-5.
   Bookheimer S, 2002, ANNU REV NEUROSCI, V25, P151, DOI 10.1146/annurev.neuro.25.112701.142946.
   Braeutigam S, 2001, COGNITIVE BRAIN RES, V10, P365, DOI 10.1016/S0926-6410(00)00055-0.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   Buschman TJ, 2007, SCIENCE, V315, P1860, DOI 10.1126/science.1138071.
   Buschman TJ, 2009, NEURON, V63, P386, DOI 10.1016/j.neuron.2009.06.020.
   Cabeza R, 2000, J COGNITIVE NEUROSCI, V12, P1, DOI 10.1162/08989290051137585.
   Caton R, 1875, BRIT MED J, V2, P278.
   Davidson DJ, 2007, BRAIN RES, V1158, P81, DOI 10.1016/j.brainres.2007.04.082.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015.
   Eulitz C, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-67.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Fox MD, 2005, P NATL ACAD SCI USA, V102, P9673, DOI 10.1073/pnas.0504136102.
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8.
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300.
   Gilbertson T. P., 2005, J NEUROSCI, V28, P1000.
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063.
   GRAY CM, 1989, NATURE, V338, P334, DOI 10.1038/338334a0.
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694.
   Gruber T, 1999, CLIN NEUROPHYSIOL, V110, P2074, DOI 10.1016/S1388-2457(99)00176-5.
   Hagoort P, 2004, SCIENCE, V304, P438, DOI 10.1126/science.1095455.
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004.
   Hagoort P., 2014, ANN REV NEUROSCIENCE, V37.
   Hagoort P., 2009, COGNITIVE NEUROSCIEN, P819.
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013.
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416.
   Hagoort P, 2009, STRUNGMANN FORUM REP, P279.
   Hald LA, 2006, BRAIN LANG, V96, P90, DOI 10.1016/j.bandl.2005.06.007.
   Herrmann CS, 2004, TRENDS COGN SCI, V8, P347, DOI 10.1016/j.tics.2004.06.006.
   Herrmann CS, 2001, VIS COGN, V8, P593, DOI 10.1080/13506280143000142.
   Hoffmann C., 2011, THESIS RADBOUD U NIJ.
   Holz EM, 2010, NEUROIMAGE, V52, P326, DOI 10.1016/j.neuroimage.2010.04.003.
   Indefrey P, 2004, COGNITIVE NEUROSCIENCES III, THIRD EDITION, P759.
   Iversen JR, 2009, ANN NY ACAD SCI, V1169, P58, DOI 10.1111/j.1749-6632.2009.04579.x.
   Jackendoff R., 2002, FDN LANGUAGE BRAIN M.
   Jensen O., 2010, FRONTIERS HUMAN NEUR, P4.
   Jung-Beeman M, 2005, TRENDS COGN SCI, V9, P512, DOI 10.1016/j.tics.2005.09.009.
   Kielar A., 2014, J COGNITIVE NEUROSCI.
   KING JW, 1995, J COGNITIVE NEUROSCI, V7, P376, DOI 10.1162/jocn.1995.7.3.376.
   Konig P, 1991, NEURAL COMPUT, V3, P155, DOI 10.1162/neco.1991.3.2.155.
   Kok P, 2012, CEREB CORTEX, V22, P2197, DOI 10.1093/cercor/bhr310.
   Kopell N, 2011, P NATL ACAD SCI USA, V108, P3779, DOI 10.1073/pnas.1019676108.
   Kopell N, 2000, P NATL ACAD SCI USA, V97, P1867, DOI 10.1073/pnas.97.4.1867.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Lenz D, 2008, BRAIN RES, V1220, P81, DOI 10.1016/j.brainres.2007.10.053.
   Lewis A.G., 2012, THESIS RADBOUD U NIJ.
   Luck S. J., 2005, INTRO EVENT RELATED.
   Luo Y, 2010, NEUROSCIENCE, V169, P654, DOI 10.1016/j.neuroscience.2010.05.032.
   Magyari L., 2014, J COGNITIVE NEUROSCI.
   Makeig S, 2004, TRENDS COGN SCI, V8, P204, DOI 10.1016/j.tics.2004.03.008.
   Meyer L, 2013, CORTEX, V49, P711, DOI 10.1016/j.cortex.2012.03.006.
   Mitra PP, 1999, BIOPHYS J, V76, P691, DOI 10.1016/S0006-3495(99)77236-X.
   Molinaro N, 2013, NEUROIMAGE, V72, P120, DOI 10.1016/j.neuroimage.2013.01.031.
   Monsalve IF, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00847.
   Okazaki M, 2008, NEUROSCI RES, V61, P319, DOI 10.1016/j.neures.2008.03.010.
   Parkes LM, 2006, NEUROIMAGE, V29, P685, DOI 10.1016/j.neuroimage.2005.08.018.
   Pena M, 2012, J COGNITIVE NEUROSCI, V24, P1149, DOI 10.1162/jocn\_a\_00144.
   Penolazzi B, 2009, NEUROSCI LETT, V465, P74, DOI 10.1016/j.neulet.2009.08.065.
   Perez A, 2012, NEUROPSYCHOLOGIA, V50, P2584, DOI 10.1016/j.neuropsychologia.2012.07.009.
   Pesaran B, 2008, NATURE, V453, P406, DOI 10.1038/nature06849.
   Pfurtscheller G, 1997, INT J PSYCHOPHYSIOL, V26, P121, DOI 10.1016/S0167-8760(97)00760-5.
   Pfurtscheller G, 1998, ELECTROMYOGR MOTOR C, V109, P154, DOI 10.1016/S0924-980X(97)00070-2.
   Pfurtscheller G, 1996, ELECTROEN CLIN NEURO, V98, P281, DOI 10.1016/0013-4694(95)00258-8.
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8.
   Pfurtscheller G, 1999, HDB ELECTROENCEPHALO, V6.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pogosyan A, 2009, CURR BIOL, V19, P1637, DOI 10.1016/j.cub.2009.07.074.
   Prfiwdicz-Neminski W. W., 1913, CENTRALBLATT PHYSL, V27, P951.
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x.
   Rayner K., 2012, PSYCHOL READING.
   Rizzuto DS, 2003, P NATL ACAD SCI USA, V100, P7931, DOI 10.1073/pnas.0732061100.
   Rodriguez E, 1999, NATURE, V397, P430, DOI 10.1038/17120.
   Rommers J, 2013, J COGNITIVE NEUROSCI, V25, P762, DOI 10.1162/jocn\_a\_00337.
   SINGER W, 1993, ANNU REV PHYSIOL, V55, P349, DOI 10.1146/annurev.ph.55.030193.002025.
   Singer W, 2011, NEURON, V69, P191, DOI 10.1016/j.neuron.2011.01.008.
   Sporns O, 2004, TRENDS COGN SCI, V8, P418, DOI 10.1016/j.tics.2004.07.008.
   Sporns O, 2012, NEUROIMAGE, V62, P881, DOI 10.1016/j.neuroimage.2011.08.085.
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Tallon-Baudry C, 1998, J NEUROSCI, V18, P4244.
   Tallon-Baudry C, 1999, TRENDS COGN SCI, V3, P151, DOI 10.1016/S1364-6613(99)01299-1.
   TAUROZA S, 1990, APPL LINGUIST, V11, P90, DOI 10.1093/applin/11.1.90.
   Van Berkum JJ, 2004, ANN M COGN NEUR SOC.
   Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550.
   Wang L, 2012, HUM BRAIN MAPP, V33, P2898, DOI 10.1002/hbm.21410.
   Wang L, 2012, FRONT PSYCHOL, V3, DOI {[}10.3389/fpsyg.2012.00187, 10.3389/fpsyg.2012.00438].
   Weiss S, 2005, INT J PSYCHOPHYSIOL, V57, P129, DOI 10.1016/j.ijpsycho.2005.03.013.
   Weiss S, 2003, BRAIN LANG, V85, P325, DOI 10.1016/S0093-934X(03)00067-1.
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201.}},
Number-of-Cited-References = {{104}},
Times-Cited = {{49}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{23}},
Journal-ISO = {{Brain Lang.}},
Doc-Delivery-Number = {{CR1MU}},
Unique-ID = {{ISI:000361089800005}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000360444100399,
Author = {Rommers, Joost and Dickson, Danielle S. and Norton, James J. S. and
   Wlotko, Edward W. and Federmeier, Kara D.},
Title = {{FRONTAL THETA AND DISCONFIRMED PREDICTIONS IN THE LANGUAGE DOMAIN}},
Journal = {{PSYCHOPHYSIOLOGY}},
Year = {{2015}},
Volume = {{52}},
Number = {{1, SI}},
Meeting = {{3-77}},
Pages = {{S93}},
Month = {{SEP}},
Note = {{55th Annual Meeting of the Society-for-Psychophysiological-Research,
   Seattle, WA, SEP 30-OCT 04, 2015}},
Organization = {{Soc Psychophysiol Res}},
Publisher = {{WILEY-BLACKWELL}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Meeting Abstract}},
Language = {{English}},
Affiliation = {{Rommers, Joost; Dickson, Danielle S.; Norton, James J. S.; Federmeier, Kara D., Univ Illinois, Urbana, IL 61801 USA.
   Wlotko, Edward W., Tufts Univ, Medford, MA USA.}},
ISSN = {{0048-5772}},
EISSN = {{1469-8986}},
Keywords = {{language; prediction; time-frequency analysis}},
Research-Areas = {{Psychology; Neurosciences \& Neurology; Physiology}},
Web-of-Science-Categories  = {{Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental}},
Number-of-Cited-References = {{0}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Psychophysiology}},
Doc-Delivery-Number = {{CQ2PS}},
Unique-ID = {{ISI:000360444100399}},
DA = {{2020-12-06}},
}

@article{ ISI:000359020000009,
Author = {Boudewyn, Megan A. and Long, Debra L. and Swaab, Tamara Y.},
Title = {{Graded expectations: Predictive processing and the adjustment of
   expectations during spoken language comprehension}},
Journal = {{COGNITIVE AFFECTIVE \& BEHAVIORAL NEUROSCIENCE}},
Year = {{2015}},
Volume = {{15}},
Number = {{3}},
Pages = {{607-624}},
Month = {{SEP}},
Abstract = {{The goal of this study was to investigate the use of the local and
   global contexts for incoming words during listening comprehension. Local
   context was manipulated by presenting a target noun (e.g., ``cake,{''}
   ``veggies{''}) that was preceded by a word that described a prototypical
   or atypical feature of the noun (e.g., ``sweet,{''} ``healthy{''}).
   Global context was manipulated by presenting the noun in a scenario that
   was consistent or inconsistent with the critical noun (e.g., a birthday
   party). Event-related potentials (ERPs) were examined at the feature
   word and at the critical noun. An N400 effect was found at the feature
   word, reflecting the effect of compatibility with the global context.
   Global predictability and the local feature word consistency interacted
   at the critical noun: A larger N200 was found to nouns that mismatched
   predictions when the context was maximally constraining, relative to
   nouns in the other conditions. A graded N400 response was observed at
   the critical noun, modulated by global predictability and feature
   consistency. Finally, post-N400 positivity effects of context updating
   were observed to nouns that were supported by one contextual cue
   (global/local) but were unsupported by the other. These results indicate
   that (1) incoming words that are compatible with context-based
   expectations receive a processing benefit; (2) when the context is
   sufficiently constraining, specific lexical items may be activated; and
   (3) listeners dynamically adjust their expectations when input is
   inconsistent with their predictions, provided that the inconsistency has
   some level of support from either the global or the local context.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Boudewyn, MA (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA.
   Boudewyn, Megan A.; Long, Debra L.; Swaab, Tamara Y., Univ Calif Davis, Davis, CA 95616 USA.}},
DOI = {{10.3758/s13415-015-0340-0}},
ISSN = {{1530-7026}},
EISSN = {{1531-135X}},
Keywords = {{Prediction; Discourse; Semantics; ERPs}},
Keywords-Plus = {{ELECTROPHYSIOLOGICAL EVIDENCE; SEMANTIC INTEGRATION; SCALP
   DISTRIBUTIONS; NEURAL BASIS; SINGLE-WORD; SENTENCE; DISCOURSE; ERP;
   MEMORY; ANTICIPATION}},
Research-Areas = {{Behavioral Sciences; Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Behavioral Sciences; Neurosciences}},
Author-Email = {{maboudewyn@ucdavis.edu}},
ORCID-Numbers = {{Swaab, Tamara/0000-0001-6551-0229}},
Funding-Acknowledgement = {{NICHD NIH HHSUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health \& Human Development (NICHD)
   {[}R01 HD073948] Funding Source: Medline; NIMH NIH HHSUnited States
   Department of Health \& Human ServicesNational Institutes of Health
   (NIH) - USANIH National Institute of Mental Health (NIMH) {[}R21
   MH099327] Funding Source: Medline; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH \& HUMAN DEVELOPMENTUnited States Department
   of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health \& Human
   Development (NICHD) {[}R01HD073948, R01HD073948, R01HD073948,
   R01HD073948, R01HD073948] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE OF MENTAL HEALTHUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Mental Health (NIMH) {[}R21MH099327, R21MH099327] Funding Source: NIH
   RePORTER}},
Cited-References = {{Boudewyn MA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00060.
   Boudewyn MA, 2012, LANG COGNITIVE PROC, V27, P698, DOI 10.1080/01690965.2011.577980.
   Brothers T, 2015, COGNITION, V136, P135, DOI 10.1016/j.cognition.2014.10.017.
   Camblin CC, 2007, J MEM LANG, V56, P103, DOI 10.1016/j.jml.2006.07.005.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Delong KA, 2011, PSYCHOPHYSIOLOGY, V48, P1203, DOI 10.1111/j.1469-8986.2011.01199.x.
   Diaz MT, 2007, BRAIN RES, V1146, P85, DOI 10.1016/j.brainres.2006.07.034.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Folstein JR, 2008, PSYCHOPHYSIOLOGY, V45, P152, DOI 10.1111/j.1469-8986.2007.00602.x.
   FORSTER KI, 1981, Q J EXP PSYCHOL-A, V33, P465, DOI 10.1080/14640748108400804.
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8.
   Gernsbacher MA, 1997, DISCOURSE PROCESS, V23, P265, DOI 10.1080/01638539709544994.
   GERNSBACHER MA, 1996, MODELS UNDERSTANDING, P289, DOI DOI 10.1162/0898929053747658.
   Hahne A, 1999, J COGNITIVE NEUROSCI, V11, P194, DOI 10.1162/089892999563328.
   Holroyd C, 2004, NEUROPHYSIOLOGY, V78, P447.
   Holroyd CB, 2002, PSYCHOL REV, V109, P679, DOI 10.1037/0033-295X.109.4.679.
   Jackendoff R., 2002, FDN LANGUAGE BRAIN M.
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084.
   Kolk H, 2007, BRAIN LANG, V100, P257, DOI 10.1016/j.bandl.2006.07.006.
   Kuperberg G. R., 2013, UNRAVELING BEHAV NEU, P176.
   Kuperberg GR, 2007, BRAIN RES, V1146, P23, DOI 10.1016/j.brainres.2006.12.063.
   Kuperberg GR, 2003, COGNITIVE BRAIN RES, V17, P117, DOI 10.1016/S0926-6410(03)00086-7.
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6.
   KUTAS M, 1993, LANG COGNITIVE PROC, V8, P533, DOI 10.1080/01690969308407587.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003.
   Lau EF, 2013, J COGNITIVE NEUROSCI, V25, P484, DOI 10.1162/jocn\_a\_00328.
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213.
   MCCARTHY G, 1985, ELECTROEN CLIN NEURO, V62, P203, DOI 10.1016/0168-5597(85)90015-2.
   McRae K, 2005, BEHAV RES METHODS, V37, P547, DOI 10.3758/BF03192726.
   Metusalem R, 2012, J MEM LANG, V66, P545, DOI 10.1016/j.jml.2012.01.001.
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9.
   NAATANEN R, 1995, EAR HEARING, V16, P6.
   Nieuwand MS, 2005, COGNITIVE BRAIN RES, V24, P691, DOI 10.1016/j.cogbrainres.2005.04.003.
   O'Rourke PL, 2011, BRAIN RES, V1392, P62, DOI 10.1016/j.brainres.2011.03.071.
   Osterhout L, 1995, J MEM LANG, V34, P739, DOI 10.1006/jmla.1995.1033.
   Otten M, 2007, BRAIN RES, V1153, P166, DOI 10.1016/j.brainres.2007.03.058.
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463.
   Paczynski M, 2012, J MEM LANG, V67, P426, DOI 10.1016/j.jml.2012.07.003.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Ruchkin DS, 1999, PSYCHOPHYSIOLOGY, V36, P832, DOI 10.1111/1469-8986.3660832.
   Swaab T.Y., 2012, OXFORD HDB EVENT REL, P397, DOI DOI 10.1093/OXFORDHB/9780195374148.013.0197.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Thornhill DE, 2012, INT J PSYCHOPHYSIOL, V83, P382, DOI 10.1016/j.ijpsycho.2011.12.007.
   Urbach TP, 2002, PSYCHOPHYSIOLOGY, V39, P791, DOI 10.1111/1469-8986.3960791.
   van Berkum JJA, 1999, J COGNITIVE NEUROSCI, V11, P657, DOI 10.1162/089892999563724.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van Berkum JJA, 2003, COGNITIVE BRAIN RES, V17, P701, DOI 10.1016/S0926-6410(03)00196-4.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   van Herten M, 2006, J COGNITIVE NEUROSCI, V18, P1181, DOI 10.1162/jocn.2006.18.7.1181.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   VANPETTEN C, 1993, LANG COGNITIVE PROC, V8, P485, DOI 10.1080/01690969308407586.
   VanPetten C, 1997, PSYCHOL SCI, V8, P238, DOI 10.1111/j.1467-9280.1997.tb00418.x.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Yeung N, 2004, PSYCHOL REV, V111, P931, DOI {[}10.1037/0033-295X.111.4.931, 10.1037/0033-295x.111.4.931].}},
Number-of-Cited-References = {{59}},
Times-Cited = {{24}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{Cogn. Affect. Behav. Neurosci.}},
Doc-Delivery-Number = {{CO2XI}},
Unique-ID = {{ISI:000359020000009}},
OA = {{Green Accepted, Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000356006900009,
Author = {Jukic, Ante and van Waterschoot, Toon and Gerkmann, Timo and Doclo,
   Simon},
Title = {{Multi-Channel Linear Prediction-Based Speech Dereverberation With Sparse
   Priors}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2015}},
Volume = {{23}},
Number = {{9}},
Pages = {{1509-1520}},
Month = {{SEP}},
Abstract = {{The quality of speech signals recorded in an enclosure can be severely
   degraded by room reverberation. In this paper, we focus on a class of
   blind batch methods for speech dereverberation in a noiseless scenario
   with a single source, which are based on multi-channel linear prediction
   in the short-time Fourier transform domain. Dereverberation is performed
   by maximum-likelihood estimation of the model parameters that are
   subsequently used to recover the desired speech signal. Contrary to the
   conventional method, we propose to model the desired speech signal using
   a general sparse prior that can be represented in a convex form as a
   maximization over scaled complex Gaussian distributions. The proposed
   model can be interpreted as a generalization of the commonly used
   time-varying Gaussian model. Furthermore, we reformulate both the
   conventional and the proposed method as an optimization problem with an
   l(p)-norm cost function, emphasizing the role of sparsity in the
   considered speech dereverberation methods. Experimental evaluation in
   different acoustic scenarios show that the proposed approach results in
   an improved performance compared to the conventional approach in terms
   of instrumental measures for speech quality.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jukic, A (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.
   Jukic, Ante; Gerkmann, Timo; Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.
   van Waterschoot, Toon, Katholieke Univ Leuven, Dept Elect Engn ESAT, Stadius Ctr Dynam Syst Signal Proc \& Data Analyt, B-3000 Louvain, Belgium.}},
DOI = {{10.1109/TASLP.2015.2438549}},
ISSN = {{2329-9290}},
EISSN = {{2329-9304}},
Keywords = {{Multi-channel linear prediction; sparse priors; speech dereverberation;
   speech enhancement}},
Keywords-Plus = {{REVERBERATION; IDENTIFICATION; ENHANCEMENT; SUPPRESSION; ALGORITHMS;
   NOISE; MODEL}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{ante.jukic@uni-oldenburg.de
   toon.vanwaterschoot@esat.kuleuven.be
   timo.gerkmann@unioldenburg.de
   simon.doclo@uni-oldenburg.de}},
ResearcherID-Numbers = {{van Waterschoot, Toon/A-8145-2015
   Gerkmann, Timo/I-3353-2014
   Doclo, Simon/A-5472-2008
   }},
ORCID-Numbers = {{van Waterschoot, Toon/0000-0002-6323-7350
   Gerkmann, Timo/0000-0002-8678-4699
   Doclo, Simon/0000-0002-3392-2381}},
Funding-Acknowledgement = {{Marie Curie Initial Training Network DREAMSEuropean Union (EU)
   {[}ITN-GA-2012-316969]; Research Foundation Flanders
   (FWO-Vlaanderen)FWO; Cluster of Excellence 1077 ``Hearing4All{''};
   German Research Foundation (DFG)German Research Foundation (DFG)}},
Funding-Text = {{This work was supported in part by the Marie Curie Initial Training
   Network DREAMS under Grant ITN-GA-2012-316969, and in part by the
   Research Foundation Flanders (FWO-Vlaanderen) and the Cluster of
   Excellence 1077 ``Hearing4All,{''} funded by the German Research
   Foundation (DFG). The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Yunxin Zhao.}},
Cited-References = {{Avargel Y, 2007, IEEE T AUDIO SPEECH, V15, P1305, DOI 10.1109/TASL.2006.889720.
   Babacan SD, 2012, LECT NOTES COMPUT SC, V7577, P341, DOI 10.1007/978-3-642-33783-3\_25.
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x.
   Cauchi B., 2014, P REVERB WORKSH FLOR.
   Chartrand R., 2013, P AS C SIGN SYST COM.
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498.
   Delcroix M., 2014, P REVERB WORKSH FLOR.
   Gerkmann T., 2011, P EUR SIGN PROC C EU.
   Gerkmann T., 2010, P INT WORKSH AC ECH.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Giryes R, 2014, LINEAR ALGEBRA APPL, V441, P22, DOI 10.1016/j.laa.2013.03.004.
   Habets EAP, 2009, IEEE SIGNAL PROC LET, V16, P770, DOI 10.1109/LSP.2009.2024791.
   Hendriks R., 2013, SYNTH LECT SPEECH AU, V9, P1, DOI DOI 10.2200/S00473ED1V01Y201301SAP011.
   Ito Nobutaka, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5167, DOI 10.1109/ICASSP.2014.6854588.
   Iwata Y, 2012, INT CONF ACOUST SPEE, P245, DOI 10.1109/ICASSP.2012.6287863.
   Jeub M, 2010, IEEE T AUDIO SPEECH, V18, P1732, DOI 10.1109/TASL.2010.2052156.
   Jukic Ante, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5172, DOI 10.1109/ICASSP.2014.6854589.
   Jukic A, 2014, 2014 4TH JOINT WORKSHOP ON HANDS-FREE SPEECH COMMUNICATION AND MICROPHONE ARRAYS (HSCMA), P23, DOI 10.1109/HSCMA.2014.6843244.
   Kameoka H, 2009, INT CONF ACOUST SPEE, P45, DOI 10.1109/ICASSP.2009.4959516.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Kinoshita T, 2013, 2013 9TH INTERNATIONAL WORKSHOP ON ELECTROMAGNETIC COMPATIBILITY OF INTEGRATED CIRCUITS (EMC COMPO 2013), P1, DOI 10.1109/EMCCompo.2013.6735162.
   Kodrasi Ina, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5177, DOI 10.1109/ICASSP.2014.6854590.
   Kodrasi I, 2013, IEEE T AUDIO SPEECH, V21, P1879, DOI 10.1109/TASL.2013.2260743.
   Lebart K, 2001, ACUSTICA, V87, P359.
   Lotter T, 2005, EURASIP J APPL SIG P, V2005, P1110, DOI 10.1155/ASP.2005.1110.
   Maas R, 2012, INT CONF ACOUST SPEE, P297, DOI 10.1109/ICASSP.2012.6287875.
   Martin R, 2005, IEEE T SPEECH AUDI P, V13, P845, DOI 10.1109/TSA.2005.851927.
   Martin R, 2002, INT CONF ACOUST SPEE, P253.
   Mertins A, 2010, IEEE T AUDIO SPEECH, V18, P249, DOI 10.1109/TASL.2009.2025789.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Nam S, 2013, APPL COMPUT HARMON A, V34, P30, DOI 10.1016/j.acha.2012.03.006.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Novey M, 2010, IEEE T SIGNAL PROCES, V58, P1427, DOI 10.1109/TSP.2009.2036049.
   Omologo M, 1998, SPEECH COMMUN, V25, P75, DOI 10.1016/S0167-6393(98)00030-2.
   Palmer J., 2006, ADV NEURAL INFORM PR, P1059.
   Porter J., 1984, P IEEE INT C AC SPEE, V9, P53.
   Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251.
   Rockafellar R. T., 1970, CONVEX ANAL.
   Schmid D, 2014, IEEE-ACM T AUDIO SPE, V22, P1320, DOI 10.1109/TASLP.2014.2329732.
   Schwartz B, 2013, 2013 PROCEEDINGS OF THE 21ST EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO).
   Sehr A., 2009, THESIS FRIEDRICH ALE.
   Talmon R, 2009, IEEE T AUDIO SPEECH, V17, P546, DOI 10.1109/TASL.2008.2009576.
   Talmon R, 2009, IEEE T AUDIO SPEECH, V17, P1420, DOI 10.1109/TASL.2009.2020891.
   Tashev I., 2010, P INT WORKSH AC ECH.
   Togami M, 2013, INT CONF ACOUST SPEE, P7447, DOI 10.1109/ICASSP.2013.6639110.
   Togami M, 2013, IEEE T AUDIO SPEECH, V21, P1369, DOI 10.1109/TASL.2013.2250960.
   vanWaterschoot T., 2013, P EUR SIGN PROC C EU.
   Wipf David, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P40, DOI 10.1007/978-3-642-40395-8\_4.
   Wipf D, 2010, IEEE J-STSP, V4, P317, DOI 10.1109/JSTSP.2010.2042413.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2011, IEEE T AUDIO SPEECH, V19, P69, DOI 10.1109/TASL.2010.2045183.
   Zhang W, 2010, P INT WORKSH AC ECH.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{47}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{CK1YW}},
Unique-ID = {{ISI:000356006900009}},
DA = {{2020-12-06}},
}

@article{ ISI:000359920400005,
Author = {Lupyan, Gary and Clark, Andy},
Title = {{Words and the World: Predictive Coding and the
   Language-Perception-Cognition Interface}},
Journal = {{CURRENT DIRECTIONS IN PSYCHOLOGICAL SCIENCE}},
Year = {{2015}},
Volume = {{24}},
Number = {{4}},
Pages = {{279-284}},
Month = {{AUG}},
Abstract = {{Can what we know change what we see? Does language affect cognition and
   perception? The last few years have seen increased attention to these
   seemingly disparate questions, but with little theoretical advance. We
   argue that substantial clarity can be gained by considering these
   questions through the lens of predictive processing, a framework in
   which mental representationsfrom the perceptual to the cognitivereflect
   an interplay between downward-flowing predictions and upward-flowing
   sensory signals. This framework provides a parsimonious account of how
   (and when) what we know ought to change what we see and helps us
   understand how a putatively high-level trait such as language can impact
   putatively low-level processes such as perception. Within this
   framework, language begins to take on a surprisingly central role in
   cognition by providing a uniquely focused and flexible means of
   constructing predictions against which sensory signals can be evaluated.
   Predictive processing thus provides a plausible mechanism for many of
   the reported effects of language on perception, thought, and action, and
   new insights on how and when speakers of different languages construct
   the same reality in alternate ways.}},
Publisher = {{SAGE PUBLICATIONS INC}},
Address = {{2455 TELLER RD, THOUSAND OAKS, CA 91320 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lupyan, G (Corresponding Author), Univ Wisconsin, Dept Psychol, 1202 W Johnson St, Madison, WI 53706 USA.
   Lupyan, Gary, Univ Wisconsin, Dept Psychol, Madison, WI 53706 USA.
   Clark, Andy, Univ Edinburgh, Sch Philosophy Psychol \& Language Sci, Edinburgh EH8 9YL, Midlothian, Scotland.}},
DOI = {{10.1177/0963721415570732}},
ISSN = {{0963-7214}},
EISSN = {{1467-8721}},
Keywords = {{perception; language; top-down effects; predictive coding; attention;
   language and thought}},
Keywords-Plus = {{ATTENTION; VISION; ACTIVATION}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{lupyan@wisc.edu}},
ORCID-Numbers = {{Clark, Andy/0000-0002-1233-8629}},
Cited-References = {{Anderson B, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00246.
   Baldo JV, 2010, BRAIN LANG, V113, P59, DOI 10.1016/j.bandl.2010.01.004.
   Boroditsky L., 2010, CAMBRIDGE HDB PSYCHO, P615.
   Boutonnet B, 2015, J NEUROSCI, V35, P9329, DOI 10.1523/JNEUROSCI.5111-14.2015.
   Casasanto D, 2008, LANG LEARN, V58, P63, DOI 10.1111/j.1467-9922.2008.00462.x.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Cukur T, 2013, NAT NEUROSCI, V16, P763, DOI 10.1038/nn.3381.
   Cunningham AE, 1997, DEV PSYCHOL, V33, P934, DOI 10.1037/0012-1649.33.6.934.
   den Ouden HEM, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00548.
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547.
   Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215.
   Friston KJ, 2007, SYNTHESE, V159, P417, DOI 10.1007/s11229-007-9237-y.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Frith CD, 2012, ANNU REV PSYCHOL, V63, P287, DOI 10.1146/annurev-psych-120710-100449.
   Gleitman Lila, 2005, CAMBRIDGE HDB THINKI, P633.
   Helmholtz H.von, 2005, TREATISE PHYSL OPTIC, V3.
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004.
   Hohwy J., 2013, THE PREDICTIVE MIND.
   Lupyan G., TOPICS COGN IN PRESS.
   Lupyan G, 2015, REV EVIDENCE COGNITI.
   Lupyan G, 2012, REV EVIDENCE COGNITI.
   Lupyan G, 2007, PSYCHOL SCI, V18, P1077, DOI 10.1111/j.1467-9280.2007.02028.x.
   Lupyan G, 2015, REV PHILOS PSYCHOL, V6, P547, DOI 10.1007/s13164-015-0253-4.
   Lupyan G, 2013, P NATL ACAD SCI USA, V110, P14196, DOI 10.1073/pnas.1303312110.
   Lupyan G, 2012, PSYCHOL LEARN MOTIV, V57, P255, DOI 10.1016/B978-0-12-394293-7.00007-8.
   Lupyan G, 2012, J EXP PSYCHOL GEN, V141, P170, DOI 10.1037/a0024904.
   Malt BC, 2015, CONCEPTUAL MIND: NEW DIRECTIONS IN THE STUDY OF CONCEPTS, P291.
   McClelland JL, 2014, COGNITIVE SCI, V38, P1139, DOI 10.1111/cogs.12146.
   McClelland JL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00503.
   Pinker S., 1994, LANGUAGE INSTINCT.
   Pylyshyn Z, 1999, BEHAV BRAIN SCI, V22, P341, DOI 10.1017/S0140525X99002022.
   Snedeker Jesse, 2004, WEAVING LEXICON, P257.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{103}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{35}},
Journal-ISO = {{Curr. Dir. Psychol.}},
Doc-Delivery-Number = {{CP5KK}},
Unique-ID = {{ISI:000359920400005}},
DA = {{2020-12-06}},
}

@article{ ISI:000357752900013,
Author = {Lewis, Ashley G. and Bastiaansen, Marcel},
Title = {{A predictive coding framework for rapid neural dynamics during
   sentence-level language comprehension}},
Journal = {{CORTEX}},
Year = {{2015}},
Volume = {{68}},
Number = {{SI}},
Pages = {{155-168}},
Month = {{JUL}},
Abstract = {{There is a growing literature investigating the relationship between
   oscillatory neural dynamics measured using electroencephalography (EEG)
   and/or magnetoencephalography (MEG), and sentence-level language
   comprehension. Recent proposals have suggested a strong link between
   predictive coding accounts of the hierarchical flow of information in
   the brain, and oscillatory neural dynamics in the beta and gamma
   frequency ranges. We propose that findings relating beta and gamma
   oscillations to sentence-level language comprehension might be unified
   under such a predictive coding account. Our suggestion is that
   oscillatory activity in the beta frequency range may reflect both the
   active maintenance of the current network configuration responsible for
   representing the sentence-level meaning under construction, and the
   top-down propagation of predictions to hierarchically lower processing
   levels based on that representation. In addition, we suggest that
   oscillatory activity in the low and middle gamma range reflect the
   matching of top-down predictions with bottom-up linguistic input, while
   evoked high gamma might reflect the propagation of bottom-up prediction
   errors to higher levels of the processing hierarchy. We also discuss
   some of the implications of this predictive coding framework, and we
   outline ideas for how these might be tested experimentally. (C) 2015
   Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER MASSON, CORPORATION OFFICE}},
Address = {{65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Bastiaansen, M (Corresponding Author), NHTV Breda Univ Appl Sci, Acad Leisure, Archimedesstr 17, NL-4816 BA Breda, Netherlands.
   Lewis, Ashley G.; Bastiaansen, Marcel, Max Planck Inst Psycholinguist, Neurobiol Language Dept, Nijmegen, Netherlands.
   Lewis, Ashley G., Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behaviour, Ctr Cognit Neuroimaging, Nijmegen, Netherlands.
   Bastiaansen, Marcel, NHTV Breda Univ Appl Sci, Acad Leisure, NL-4816 BA Breda, Netherlands.}},
DOI = {{10.1016/j.cortex.2015.02.014}},
ISSN = {{0010-9452}},
EISSN = {{1973-8102}},
Keywords = {{Language comprehension; Neural oscillations; Beta; Gamma; Predictive
   coding}},
Keywords-Plus = {{EYE-MOVEMENTS; TIME-COURSE; COMPUTATIONAL PRINCIPLES; OSCILLATORY
   RESPONSES; SEMANTIC INTEGRATION; BETA-SYNCHRONIZATION; WORLD KNOWLEDGE;
   UPCOMING WORDS; VISUAL-CORTEX; BRAIN}},
Research-Areas = {{Behavioral Sciences; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Behavioral Sciences; Neurosciences; Psychology, Experimental}},
Author-Email = {{bastiaansen4.m@nhtv.nl}},
ResearcherID-Numbers = {{Lewis, Ashley/C-8984-2015
   Lewis, Ashley Glen/K-5410-2019}},
ORCID-Numbers = {{Lewis, Ashley/0000-0003-4737-2525
   Lewis, Ashley Glen/0000-0003-4737-2525}},
Funding-Acknowledgement = {{Max Planck SocietyMax Planck Society}},
Funding-Text = {{We would like to thank two anonymous reviewers for their very helpful
   comments on an earlier version of the manuscript, and for many excellent
   suggestions that have improved the manuscript considerably. This work is
   partly supported by an IMPRS PhD fellowship from the Max Planck Society
   to A.G.L.}},
Cited-References = {{Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Baggio G, 2011, LANG COGNITIVE PROC, V26, P1338, DOI 10.1080/01690965.2010.542671.
   BALOTA DA, 1985, COGNITIVE PSYCHOL, V17, P364, DOI 10.1016/0010-0285(85)90013-1.
   Bastiaansen M., 2012, OXFORD HDB EVENT REL, P31.
   Bastiaansen M., 2010, 16 ANN M ORG HUM BRA.
   Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0.
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283.
   Bastiaansen MCM, 2001, INT J PSYCHOPHYSIOL, V43, P91, DOI 10.1016/S0167-8760(01)00181-7.
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038.
   Bressler SL, 2015, CURR OPIN NEUROBIOL, V31, P62, DOI 10.1016/j.conb.2014.08.010.
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477.
   Davidson DJ, 2007, BRAIN RES, V1158, P81, DOI 10.1016/j.brainres.2007.04.082.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6.
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694.
   FORSTER KI, 1981, Q J EXP PSYCHOL-A, V33, P465, DOI 10.1080/14640748108400804.
   Frank Stefan L., 2013, PROCEEDINGS OF THE 5, V2, P878.
   Friederici AD, 1996, J PSYCHOLINGUIST RES, V25, P157, DOI 10.1007/BF01708424.
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8.
   Friston KJ, 2015, CURR OPIN NEUROBIOL, V31, P1, DOI 10.1016/j.conb.2014.05.004.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063.
   GRAY CM, 1989, NATURE, V338, P334, DOI 10.1038/338334a0.
   Hagoort P, 2004, SCIENCE, V304, P438, DOI 10.1126/science.1095455.
   HAGOORT P, 1993, LANG COGNITIVE PROC, V8, P439, DOI 10.1080/01690969308407585.
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004.
   Hagoort P., 2009, COGNITIVE NEUROSCIEN, P819.
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013.
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416.
   Hald LA, 2006, BRAIN LANG, V96, P90, DOI 10.1016/j.bandl.2005.06.007.
   Herrmann CS, 2004, TRENDS COGN SCI, V8, P347, DOI 10.1016/j.tics.2004.06.006.
   Jung-Beeman M, 2005, TRENDS COGN SCI, V9, P512, DOI 10.1016/j.tics.2005.09.009.
   Kaan E, 2002, J PSYCHOLINGUIST RES, V31, P165, DOI 10.1023/A:1014978917769.
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   Kielar A., 2014, J COGNITIVE NEUROSCI, P1.
   Knoeferle P, 2005, COGNITION, V95, P95, DOI 10.1016/j.cognition.2004.03.002.
   Konig P, 1991, NEURAL COMPUT, V3, P155, DOI 10.1162/neco.1991.3.2.155.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Levy R., 2011, 49 ANN M ASS COMP LI.
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006.
   Lewis A. G., 2015, BRAIN LANGUAGE.
   Lisman JE, 2013, NEURON, V77, P1002, DOI 10.1016/j.neuron.2013.03.007.
   Luo Y, 2010, NEUROSCIENCE, V169, P654, DOI 10.1016/j.neuroscience.2010.05.032.
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676.
   Magyari L, 2014, J COGNITIVE NEUROSCI, V26, P2530, DOI 10.1162/jocn\_a\_00673.
   Maier A, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00031.
   McRae K, 2005, MEM COGNITION, V33, P1174, DOI 10.3758/BF03193221.
   MECKLINGER A, 1995, MEM COGNITION, V23, P477, DOI 10.3758/BF03197249.
   Metzner P., 2014, J COGNITIVE NEUROSCI, P1.
   Meyer L, 2013, CORTEX, V49, P711, DOI 10.1016/j.cortex.2012.03.006.
   Molinaro N, 2013, NEUROIMAGE, V72, P120, DOI 10.1016/j.neuroimage.2013.01.031.
   Monsalve IF, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00847.
   Nieuwland MS, 2006, J COGNITIVE NEUROSCI, V18, P1098, DOI 10.1162/jocn.2006.18.7.1098.
   OSTERHOUT L, 1994, J EXP PSYCHOL LEARN, V20, P786, DOI 10.1037/0278-7393.20.4.786.
   Otten M, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-89.
   Parkes LM, 2006, NEUROIMAGE, V29, P685, DOI 10.1016/j.neuroimage.2005.08.018.
   Pena M, 2012, J COGNITIVE NEUROSCI, V24, P1149, DOI 10.1162/jocn\_a\_00144.
   Penolazzi B, 2009, NEUROSCI LETT, V465, P74, DOI 10.1016/j.neulet.2009.08.065.
   Perez A, 2012, NEUROPSYCHOLOGIA, V50, P2584, DOI 10.1016/j.neuropsychologia.2012.07.009.
   Pfurtscheller G, 1997, INT J PSYCHOPHYSIOL, V26, P121, DOI 10.1016/S0167-8760(97)00760-5.
   Pfurtscheller G, 1998, ELECTROMYOGR MOTOR C, V109, P154, DOI 10.1016/S0924-980X(97)00070-2.
   Pfurtscheller G, 1996, ELECTROEN CLIN NEURO, V98, P281, DOI 10.1016/0013-4694(95)00258-8.
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8.
   Pfurtscheller G, 1999, HDB ELECTROENCEPHALO, V6.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Rayner K., 2012, PSYCHOL READING.
   Rommers J, 2013, J COGNITIVE NEUROSCI, V25, P762, DOI 10.1162/jocn\_a\_00337.
   Roopun AK, 2006, P NATL ACAD SCI USA, V103, P15646, DOI 10.1073/pnas.0607443103.
   Roopun AK, 2008, FRONT CELL NEUROSCI, V2, DOI 10.3389/neuro.03.001.2008.
   SCHWANENFLUGEL PJ, 1988, J EXP PSYCHOL LEARN, V14, P344, DOI 10.1037/0278-7393.14.2.344.
   SEIDENBERG MS, 1982, COGNITIVE PSYCHOL, V14, P489, DOI 10.1016/0010-0285(82)90017-2.
   Siegel M, 2012, NAT REV NEUROSCI, V13, P121, DOI 10.1038/nrn3137.
   SINGER W, 1993, ANNU REV PHYSIOL, V55, P349, DOI 10.1146/annurev.ph.55.030193.002025.
   Singer W, 2011, NEURON, V69, P191, DOI 10.1016/j.neuron.2011.01.008.
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013.
   Sussman RS, 2003, LANG COGNITIVE PROC, V18, P143, DOI 10.1080/01690960143000498.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Van Berkum JJ, 2004, ANN M COGN NEUR SOC.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550.
   Wang L, 2012, HUM BRAIN MAPP, V33, P2898, DOI 10.1002/hbm.21410.
   Wang L, 2012, FRONT PSYCHOL, V3, DOI {[}10.3389/fpsyg.2012.00187, 10.3389/fpsyg.2012.00438].
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008.
   Weiss S, 2005, INT J PSYCHOPHYSIOL, V57, P129, DOI 10.1016/j.ijpsycho.2005.03.013.
   Weiss S, 2003, BRAIN LANG, V85, P325, DOI 10.1016/S0093-934X(03)00067-1.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Womelsdorf T, 2007, SCIENCE, V316, P1609, DOI 10.1126/science.1139178.
   ZWITSERLOOD P, 1989, COGNITION, V32, P25, DOI 10.1016/0010-0277(89)90013-9.}},
Number-of-Cited-References = {{99}},
Times-Cited = {{78}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{33}},
Journal-ISO = {{Cortex}},
Doc-Delivery-Number = {{CM5TX}},
Unique-ID = {{ISI:000357752900013}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000357752900014,
Author = {Peelle, Jonathan E. and Sommers, Mitchell S.},
Title = {{Prediction and constraint in audiovisual speech perception}},
Journal = {{CORTEX}},
Year = {{2015}},
Volume = {{68}},
Number = {{SI}},
Pages = {{169-181}},
Month = {{JUL}},
Abstract = {{During face-to-face conversational speech listeners must efficiently
   process a rapid and complex stream of multisensory information. Visual
   speech can serve as a critical complement to auditory information
   because it provides cues to both the timing of the incoming acoustic
   signal (the amplitude envelope, influencing attention and perceptual
   sensitivity) and its content (place and manner of articulation,
   constraining lexical selection). Here we review behavioral and
   neurophysiological evidence regarding listeners' use of visual speech
   information. Multisensory integration of audiovisual speech cues
   improves recognition accuracy, particularly for speech in noise. Even
   when speech is intelligible based solely on auditory information, adding
   visual information may reduce the cognitive demands placed on listeners
   through increasing the precision of prediction. Electrophysiological
   studies demonstrate that oscillatory cortical entrainment to speech in
   auditory cortex is enhanced when visual speech is present, increasing
   sensitivity to important acoustic cues. Neuroimaging studies also
   suggest increased activity in auditory cortex when congruent visual
   information is available, but additionally emphasize the involvement of
   heteromodal regions of posterior superior temporal sulcus as playing a
   role in integrative processing. We interpret these findings in a
   framework of temporally-focused lexical competition in which visual
   speech information affects auditory processing to increase sensitivity
   to acoustic information through an early integration mechanism, and a
   late integration stage that incorporates specific information about a
   speaker's articulators to constrain the number of possible candidates in
   a spoken utterance. Ultimately it is words compatible with both auditory
   and visual information that most strongly determine successful speech
   perception during everyday listening. Thus, audiovisual speech
   perception is accomplished through multiple stages of integration,
   supported by distinct neuroanatomical mechanisms. (C) 2015 Elsevier Ltd.
   All rights reserved.}},
Publisher = {{ELSEVIER MASSON, CORPORATION OFFICE}},
Address = {{65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Peelle, JE (Corresponding Author), Washington Univ, Dept Otolaryngol, 660 South Euclid,Box 8115, St Louis, MO 63110 USA.
   Peelle, Jonathan E., Washington Univ, Dept Otolaryngol, St Louis, MO 63110 USA.
   Sommers, Mitchell S., Washington Univ, Dept Psychol, St Louis, MO 63130 USA.}},
DOI = {{10.1016/j.cortex.2015.03.006}},
ISSN = {{0010-9452}},
EISSN = {{1973-8102}},
Keywords = {{Speech perception; Audiovisual speech; Multisensory integration;
   Predictive coding; Predictive timing}},
Keywords-Plus = {{SUPERIOR TEMPORAL SULCUS; VISUAL SPEECH; NEURAL OSCILLATIONS;
   AUDITORY-CORTEX; NEURONAL OSCILLATIONS; OLDER-ADULTS; MULTISENSORY
   INTERACTIONS; CORTICAL OSCILLATIONS; THETA-OSCILLATIONS;
   WORD-RECOGNITION}},
Research-Areas = {{Behavioral Sciences; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Behavioral Sciences; Neurosciences; Psychology, Experimental}},
Author-Email = {{peellej@ent.wustl.edu}},
ResearcherID-Numbers = {{Peelle, Jonathan/AAA-8299-2020}},
ORCID-Numbers = {{Peelle, Jonathan/0000-0001-9194-854X}},
Funding-Acknowledgement = {{Dana Foundation; NIHUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USA {[}R01AG038490,
   R01AG018029]; NATIONAL INSTITUTE ON AGINGUnited States Department of
   Health \& Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Aging (NIA) {[}R01AG018029, R01AG038490,
   R01AG038490, R01AG018029, R01AG018029, R01AG018029, R01AG018029,
   R01AG038490, R01AG018029, R01AG018029, R01AG038490, R01AG018029,
   R01AG038490, R01AG038490, R01AG018029, R01AG018029, R01AG018029,
   R01AG018029, R01AG018029, R01AG018029, R01AG018029, R01AG018029,
   R01AG018029] Funding Source: NIH RePORTER}},
Funding-Text = {{This work was supported by The Dana Foundation and NIH grants
   R01AG038490 and R01AG018029. We are grateful to Avanti Dey and Kristin
   Van Engen for helpful comments on this work.}},
Cited-References = {{Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220.
   Auer ET, 2002, PSYCHON B REV, V9, P341, DOI 10.3758/BF03196291.
   Beauchamp MS, 2004, NAT NEUROSCI, V7, P1190, DOI 10.1038/nn1333.
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011.
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018.
   BLAMEY P J, 1989, Journal of Rehabilitation Research and Development, V26, P15.
   BRAIDA LD, 1991, Q J EXP PSYCHOL-A, V43, P647, DOI 10.1080/14640749108400991.
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3.
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593.
   Canolty RT, 2006, SCIENCE, V313, P1626, DOI 10.1126/science.1128115.
   Canolty RT, 2010, TRENDS COGN SCI, V14, P506, DOI 10.1016/j.tics.2010.09.001.
   Carlyon RP, 2001, J EXP PSYCHOL HUMAN, V27, P115, DOI 10.1037/0096-1523.27.1.115.
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436.
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011.
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035.
   EGAN JP, 1961, J ACOUST SOC AM, V33, P771, DOI 10.1121/1.1908795.
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565.
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481.
   Erickson LC, 2014, HUM BRAIN MAPP, V35, P5587, DOI 10.1002/hbm.22572.
   Feld J, 2011, SPEECH COMMUN, V53, P220, DOI 10.1016/j.specom.2010.09.003.
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796.
   Fridriksson J, 2008, NEUROIMAGE, V41, P605, DOI 10.1016/j.neuroimage.2008.02.046.
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130.
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063.
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013.
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037.
   Gosselin PA, 2011, INT J AUDIOL, V50, P786, DOI 10.3109/14992027.2011.599870.
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751.
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788.
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668.
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752.
   Hall DA, 2005, J COGNITIVE NEUROSCI, V17, P939, DOI 10.1162/0898929054021175.
   Henry MJ, 2014, P NATL ACAD SCI USA, V111, P14935, DOI 10.1073/pnas.1408741111.
   Henry MJ, 2012, P NATL ACAD SCI USA, V109, P20095, DOI 10.1073/pnas.1213390109.
   Jensen O, 2007, TRENDS COGN SCI, V11, P267, DOI 10.1016/j.tics.2007.05.003.
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187.
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010.
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005.
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735.
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011.
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001.
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004.
   Luo H, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000445.
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786.
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3.
   Massaro DW, 1999, TRENDS COGN SCI, V3, P310, DOI 10.1016/S1364-6613(99)01360-1.
   Mattys SL, 2002, PERCEPT PSYCHOPHYS, V64, P667, DOI 10.3758/BF03194734.
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010.
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0.
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020.
   MILLER JL, 1984, PHONETICA, V41, P215, DOI 10.1159/000261728.
   Mottonen R, 2004, NEUROSCI LETT, V363, P112, DOI 10.1016/j.neulet.2004.03.076.
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009.
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011.
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172.
   Okada K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068959.
   Peelle JE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00253.
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118.
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309.
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320.
   Perrodin C, 2015, P NATL ACAD SCI USA, V112, P273, DOI 10.1073/pnas.1412817112.
   Reisberg D., 1987, HEARING EYE PSYCHOL, P97.
   Romei V, 2010, J NEUROSCI, V30, P8692, DOI 10.1523/JNEUROSCI.0160-10.2010.
   Schroeder CE, 2005, CURR OPIN NEUROBIOL, V15, P454, DOI 10.1016/j.conb.2005.06.008.
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002.
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743.
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1.
   SELTZER B, 1978, BRAIN RES, V149, P1, DOI 10.1016/0006-8993(78)90584-X.
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003.
   Stevenson RA, 2007, EXP BRAIN RES, V179, P85, DOI 10.1007/s00221-006-0770-6.
   Stevenson RA, 2014, BRAIN TOPOGR, V27, P707, DOI 10.1007/s10548-014-0365-7.
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309.
   Tan X, 2012, FRONT HUM NEUROSCI, V6, DOI {[}10.3389/fnhum.2012.00305, 10.3389/fnhum.2012.00314].
   ten Oever S, 2014, NEUROPSYCHOLOGIA, V63, P43, DOI 10.1016/j.neuropsychologia.2014.08.008.
   Thut G, 2006, J NEUROSCI, V26, P9494, DOI 10.1523/JNEUROSCI.0875-06.2006.
   Tye-Murray N., 2015, PSYCHONOMIC IN PRESS.
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185.
   Tye-Murray N, 2013, PSYCHON B REV, V20, P115, DOI 10.3758/s13423-012-0328-5.
   Tye-Murray N, 2011, EAR HEARING, V32, P650, DOI 10.1097/AUD.0b013e31821a4578.
   Tye-Murray Nancy, 2007, Trends Amplif, V11, P233, DOI 10.1177/1084713807307409.
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001.
   Vatakis A, 2008, J VISION, V8, DOI 10.1167/8.9.14.
   Volgushev M, 1998, NEUROSCIENCE, V83, P15, DOI 10.1016/S0306-4522(97)00380-1.
   WATSON CS, 1976, J ACOUST SOC AM, V59, P655, DOI 10.1121/1.380915.
   Wayne RV, 2012, J EXP PSYCHOL-APPL, V18, P419, DOI 10.1037/a0031042.
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034.
   Yi HG, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00768.}},
Number-of-Cited-References = {{97}},
Times-Cited = {{70}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{29}},
Journal-ISO = {{Cortex}},
Doc-Delivery-Number = {{CM5TX}},
Unique-ID = {{ISI:000357752900014}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000356633900003,
Author = {Kleinman, Daniel and Runnqvist, Elin and Ferreira, Victor S.},
Title = {{Single-word predictions of upcoming language during comprehension:
   Evidence from the cumulative semantic interference task}},
Journal = {{COGNITIVE PSYCHOLOGY}},
Year = {{2015}},
Volume = {{79}},
Pages = {{68-101}},
Month = {{JUN}},
Abstract = {{Comprehenders predict upcoming speech and text on the basis of
   linguistic input. How many predictions do comprehenders make for an
   upcoming word? If a listener strongly expects to hear the word
   ``sock{''}, is the word ``shirt{''} partially expected as well, is it
   actively inhibited, or is it ignored? The present research addressed
   these questions by measuring the ``downstream{''} effects of prediction
   on the processing of subsequently presented stimuli using the cumulative
   semantic interference paradigm. In three experiments, subjects named
   pictures (sock) that were presented either in isolation or after
   strongly constraining sentence frames ({''}After doing his laundry, Mark
   always seemed to be missing one...{''}). Naming sock slowed the
   subsequent naming of the picture shirt - the standard cumulative
   semantic interference effect. However, although picture naming was much
   faster after sentence frames, the interference effect was not modulated
   by the context (bare vs. sentence) in which either picture was
   presented. According to the only model of cumulative semantic
   interference that can account for such a pattern of data, this indicates
   that comprehenders pre-activated and maintained the pre-activation of
   best sentence completions (sock) but did not maintain the pre-activation
   of less likely completions (shirt). Thus, comprehenders predicted only
   the most probable completion for each sentence. (C) 2015 Elsevier Inc.
   All rights reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kleinman, D (Corresponding Author), Univ Calif San Diego, Dept Psychol, 9500 Gilman Dr, La Jolla, CA 92093 USA.
   Kleinman, Daniel; Ferreira, Victor S., Univ Calif San Diego, Dept Psychol, La Jolla, CA 92093 USA.
   Runnqvist, Elin, CNRS, Lab Psychol Cognit, UMR 7290, F-13331 Marseille 3, France.
   Runnqvist, Elin, Aix Marseille Univ, F-13331 Marseille 3, France.}},
DOI = {{10.1016/j.cogpsych.2015.04.001}},
ISSN = {{0010-0285}},
EISSN = {{1095-5623}},
Keywords = {{Prediction; Sentence comprehension; Speech production; Word retrieval;
   Semantic interference}},
Keywords-Plus = {{SPREADING-ACTIVATION THEORY; SENTENCE CONTEXTS; BRAIN POTENTIALS;
   LEXICAL SELECTION; EYE-MOVEMENTS; CONSTRAINT; FACILITATION; FREQUENCY;
   PICTURES; GENDER}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology; Psychology, Experimental}},
Author-Email = {{kleinman@gmail.com
   elin\_runnquist@yahoo.es
   vferreira@ucsd.edu}},
ORCID-Numbers = {{Kleinman, Daniel/0000-0002-4821-2294
   Runnqvist, Elin/0000-0002-0032-1168}},
Funding-Acknowledgement = {{NIHUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USA {[}R01 HD051030]; European
   UnionEuropean Union (EU) {[}PIEF-GA-2012-329339];  {[}R01 NIDCD011492];
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH \& HUMAN
   DEVELOPMENTUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health \& Human Development (NICHD) {[}R01HD051030,
   R01HD051030, R01HD051030, R01HD051030, R01HD051030] Funding Source: NIH
   RePORTER; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH
   \&HUMAN DEVELOPMENTUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health \& Human Development (NICHD)
   {[}R01HD051030, R01HD051030, R01HD051030, R01HD051030, R01HD051030]
   Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness \& Other Communication Disorders (NIDCD) {[}R01DC011492,
   R01DC011492, R01DC011492, R01DC011492, R01DC011492, R01DC011492,
   R01DC011492, R01DC011492, R01DC011492, R01DC011492] Funding Source: NIH
   RePORTER}},
Funding-Text = {{D.K. and V.S.F. were supported by the NIH under Grant number R01
   HD051030 (PI: Ferreira), and D.K. was additionally supported by Grant
   number R01 NIDCD011492 (PI: Gollan). E.R. was supported by a
   postdoctoral grant from the People Programme (Marie Curie Actions) of
   the European Union's Seventh Framework Programme (FP7/2007-2013) under
   REA grant agreement no PIEF-GA-2012-329339. We are grateful to Gary
   Oppenheim for helpful discussions, to two anonymous reviewers for speedy
   and helpful feedback on an earlier version of this manuscript, and to
   Sarah Bae, Kristi Cheng, Cameron Hays, Elizabeth Jimenez, Danielle Lew,
   Cheryl Ma, Jessica Ma, Gabriela Meckler, Brittany Nielsen, Shivani
   Patel, and Kurina Wolff for data collection.}},
Cited-References = {{Alario FX, 2010, MEM COGNITION, V38, P57, DOI 10.3758/MC.38.1.57.
   Ashby J, 2005, Q J EXP PSYCHOL-A, V58, P1065, DOI 10.1080/02724980443000476.
   Baayen R., 2008, ANAL LINGUISTIC DATA.
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005.
   Baayen RH, 2010, INT J PSYCHOL RES, V3, P12.
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001.
   Bates E, 2003, PSYCHON B REV, V10, P344, DOI 10.3758/BF03196494.
   Belke E, 2013, J MEM LANG, V69, P228, DOI 10.1016/j.jml.2013.05.008.
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   COHEN J, 1993, BEHAV RES METH INSTR, V25, P257, DOI 10.3758/BF03204507.
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407.
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394.
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Ferreira VS, 2002, J EXP PSYCHOL LEARN, V28, P1187, DOI 10.1037//0278-7393.28.6.1187.
   FISCHLER I, 1979, J VERB LEARN VERB BE, V18, P1, DOI 10.1016/S0022-5371(79)90534-6.
   FISCHLER IS, 1985, MEM COGNITION, V13, P128, DOI 10.3758/BF03197005.
   FORSTER KI, 1981, Q J EXP PSYCHOL-A, V33, P465, DOI 10.1080/14640748108400804.
   Frazer A. K., 2014, P 36 ANN C COGN SCI, P1108.
   Ganis G, 1996, J COGNITIVE NEUROSCI, V8, P89, DOI 10.1162/jocn.1996.8.2.89.
   Griffin ZM, 1998, J MEM LANG, V38, P313, DOI 10.1006/jmla.1997.2547.
   Hagoort P., 2009, COGNITIVE NEUROSCIEN, P819.
   Howard D, 2006, COGNITION, V100, P464, DOI 10.1016/j.cognition.2005.02.006.
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013.
   KROLL JF, 1990, J EXP PSYCHOL LEARN, V16, P747, DOI 10.1037/0278-7393.16.5.747.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Lau E, 2009, BRAIN LANG, V111, P161, DOI 10.1016/j.bandl.2009.08.007.
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1.
   Mahon BZ, 2007, J EXP PSYCHOL LEARN, V33, P503, DOI 10.1037/0278-7393.33.3.503.
   Mulatti C, 2012, PSYCHON B REV, V19, P662, DOI 10.3758/s13423-012-0269-z.
   Myers JL, 1998, DISCOURSE PROCESS, V26, P131, DOI 10.1080/01638539809545042.
   Navarrete E, 2014, J MEM LANG, V76, P253, DOI 10.1016/j.jml.2014.05.003.
   Navarrete E, 2010, ACTA PSYCHOL, V134, P279, DOI 10.1016/j.actpsy.2010.02.009.
   NIGAM A, 1992, J COGNITIVE NEUROSCI, V4, P15, DOI 10.1162/jocn.1992.4.1.15.
   Oppenheim GM, 2010, COGNITION, V114, P227, DOI 10.1016/j.cognition.2009.09.007.
   Piai V, 2014, NEUROPSYCHOLOGIA, V53, P146, DOI 10.1016/j.neuropsychologia.2013.11.014.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   RATCLIFF R, 1993, PSYCHOL BULL, V114, P510, DOI 10.1037/0033-2909.114.3.510.
   Rescorla R. A., 1972, CLASSICAL CONDITION, V2, P64, DOI DOI 10.1101/GR.110528.110.
   ROELOFS A, 1992, COGNITION, V42, P107, DOI 10.1016/0010-0277(92)90041-F.
   Runnqvist E, 2012, J MEM LANG, V66, P850, DOI 10.1016/j.jml.2012.02.007.
   Schnur TT, 2014, J MEM LANG, V75, P27, DOI 10.1016/j.jml.2014.04.006.
   SCHUBERTH RE, 1977, J EXP PSYCHOL HUMAN, V3, P27, DOI 10.1037/0096-1523.3.1.27.
   SCHWANENFLUGEL PJ, 1988, J EXP PSYCHOL LEARN, V14, P344, DOI 10.1037/0278-7393.14.2.344.
   SCHWANENFLUGEL PJ, 1985, J MEM LANG, V24, P232, DOI 10.1016/0749-596X(85)90026-9.
   STANOVICH KE, 1981, J EXP PSYCHOL HUMAN, V7, P658.
   STANOVICH KE, 1979, MEM COGNITION, V7, P77, DOI 10.3758/BF03197588.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401.
   Van Berkum J. J. A., 2009, SEMANTICS PRAGMATICS, P276.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8.
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0.}},
Number-of-Cited-References = {{60}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{25}},
Journal-ISO = {{Cogn. Psychol.}},
Doc-Delivery-Number = {{CL0LJ}},
Unique-ID = {{ISI:000356633900003}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000355041000002,
Author = {Nower, Naushin and Liu, Yang and Unoki, Masashi},
Title = {{Restoration scheme of instantaneous amplitude and phase using Kalman
   filter with efficient linear prediction for speech enhancement}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2015}},
Volume = {{70}},
Pages = {{13-27}},
Month = {{JUN}},
Abstract = {{This paper proposes a restoration scheme for the instantaneous
   amplitudes and phases in sub-bands by using a Kalman filter with linear
   prediction (LP). A few important studies have already proved that the
   phase spectrum in the short-time Fourier transform plays an important
   role in speech enhancement. Thus, the proposed scheme concentrates on
   simultaneously restoring both instantaneous amplitudes and phases. The
   Kalman filter, which is an optimal estimator in this scheme, is used for
   both instantaneous amplitudes and phases in the sub-band representation
   to remove the effect of noise. We found that the effectiveness of the
   Kalman filter depended on accurate estimates of LP coefficients. We
   propose an effective LP training phase to derive gender and content
   independent LP coefficients as central processing for Kalman filtering.
   We carried out objective and subjective tests under various noisy
   conditions to evaluate the effectiveness of the proposed scheme and
   compared it with typical methods. The signal to error ratio (SER),
   perceptual evaluation of speech quality (PESQ), and SNR loss were used
   as objective measures in these simulations. The mean preference score
   was used in subjective evaluations. The results revealed that the
   proposed scheme could effectively improve these objective and subjective
   measures more than those with typical methods. (C) 2015 Elsevier B.V.
   All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Nower, N (Corresponding Author), JAIST, Sch Informat Sci, 1-1 Asahidai, Nomi, Ishikawa 9231292, Japan.
   Nower, Naushin; Liu, Yang; Unoki, Masashi, JAIST, Sch Informat Sci, Nomi, Ishikawa 9231292, Japan.}},
DOI = {{10.1016/j.specom.2015.02.006}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Speech enhancement; Instantaneous amplitude and phase; Kalman filter;
   Gammatone filterbank; Linear prediction}},
Keywords-Plus = {{HIDDEN MARKOV-MODELS; PERCEPTION; ENVELOPE; NOISE}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{naushin@jaist.ac.jp
   yangliu@jaist.ac.jp
   unoki@jaist.ac.jp}},
Funding-Acknowledgement = {{Japan Society for the Promotion of Science - JapanMinistry of Education,
   Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for
   the Promotion of Science; Strategic Information and Communications R \&
   D Promotion Program of the Ministry of Internal Affairs and
   Communications (MK), Japan {[}SCOPE: 131205001]}},
Funding-Text = {{This work was supported by an A3 foresight program made available by the
   Japan Society for the Promotion of Science - Japan. It was also
   partially supported by the Strategic Information and Communications R \&
   D Promotion Program (SCOPE: 131205001) of the Ministry of Internal
   Affairs and Communications (MK), Japan.}},
Cited-References = {{BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   Chen RF, 2012, IEEE T AUDIO SPEECH, V20, P1324, DOI 10.1109/TASL.2011.2177821.
   Cipra T., 1991, TRABAJOS ESTADISTICA.
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112.
   EPHRAIM Y, 1989, IEEE T ACOUST SPEECH, V37, P1846, DOI 10.1109/29.45532.
   EPHRAIM Y, 1992, IEEE T SIGNAL PROCES, V40, P725, DOI 10.1109/78.127947.
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453.
   Fardkhaleghi P, 2010, 2010 5th International Symposium on Telecommunications (IST), P895, DOI 10.1109/ISTEL.2010.5734149.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Kleinschmidt T, 2011, COMPUT SPEECH LANG, V25, P585, DOI 10.1016/j.csl.2010.09.001.
   Le Roux J., 2008, P ISCA WORKSH STAT P, P23.
   Loizou PC, 2011, IEEE T AUDIO SPEECH, V19, P47, DOI 10.1109/TASL.2010.2045180.
   Ma JF, 2011, SPEECH COMMUN, V53, P340, DOI 10.1016/j.specom.2010.10.005.
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095.
   Ming J, 2011, IEEE T AUDIO SPEECH, V19, P822, DOI 10.1109/TASL.2010.2064312.
   Mohammadiha N, 2013, IEEE T AUDIO SPEECH, V21, P2140, DOI 10.1109/TASL.2013.2270369.
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x.
   Nishikawa T, 2003, IEICE T FUND ELECTR, VE86A, P846.
   Nower N., 2014, P IEEE INT C AC SPEE, P4666.
   Paliwal KK, 2005, SPEECH COMMUN, V45, P153, DOI 10.1016/j.specom.2004.08.001.
   Paliwal K, 2012, SPEECH COMMUN, V54, P282, DOI 10.1016/j.specom.2011.09.003.
   Paliwal K, 2011, SPEECH COMMUN, V53, P465, DOI 10.1016/j.specom.2010.12.003.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   Satorra A, 2001, PSYCHOMETRIKA, V66, P507, DOI 10.1007/BF02296192.
   Sawada H, 2013, IEEE T AUDIO SPEECH, V21, P971, DOI 10.1109/TASL.2013.2239990.
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199.
   Shannon B. J., 2006, P INTERSPEECH 2006 I, P1427.
   So S, 2011, SPEECH COMMUN, V53, P818, DOI 10.1016/j.specom.2011.02.001.
   Srinivasan S, 2007, IEEE T AUDIO SPEECH, V15, P441, DOI 10.1109/TASL.2006.881696.
   Swaminathan J., 2010, THESIS PURDUE U.
   Swaminathan J, 2012, J NEUROSCI, V32, P1747, DOI 10.1523/JNEUROSCI.4493-11.2012.
   Unoki M, 1999, SPEECH COMMUN, V27, P261, DOI 10.1016/S0167-6393(98)00077-6.
   Veisi H, 2013, SPEECH COMMUN, V55, P205, DOI 10.1016/j.specom.2012.08.005.
   WANG DL, 1982, IEEE T ACOUST SPEECH, V30, P679, DOI 10.1109/TASSP.1982.1163920.
   Zhang Y, 2013, SPEECH COMMUN, V55, P509, DOI 10.1016/j.specom.2012.09.005.
   Zhao DY, 2007, IEEE T AUDIO SPEECH, V15, P882, DOI 10.1109/TASL.2006.885256.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{CI8SC}},
Unique-ID = {{ISI:000355041000002}},
DA = {{2020-12-06}},
}

@article{ ISI:000445708700004,
Author = {Martinez, David and Lleida, Eduardo and Green, Phil and Christensen,
   Heidi and Ortega, Alfonso and Miguel, Antonio},
Title = {{Intelligibility Assessment and Speech Recognizer Word Accuracy Rate
   Prediction for Dysarthric Speakers in a Factor Analysis Subspace}},
Journal = {{ACM TRANSACTIONS ON ACCESSIBLE COMPUTING}},
Year = {{2015}},
Volume = {{6}},
Number = {{3, 1, SI}},
Month = {{JUN}},
Abstract = {{Automated intelligibility assessments can support speech and language
   therapists in determining the type of dysarthria presented by their
   clients. Such assessments can also help predict how well a person with
   dysarthria might cope with a voice interface to assistive technology.
   Our approach to intelligibility assessment is based on iVectors, a set
   of measures that capture many aspects of a person's speech, including
   intelligibility. The major advantage of iVectors is that they compress
   all acoustic information contained in an utterance into a reduced number
   of measures, and they are very suitable to be used with simple
   predictors. We show that intelligibility assessments work best if there
   is a pre-existing set of words annotated for intelligibility from the
   speaker to be evaluated, which can be used for training our system. We
   discuss the implications of our findings for practice.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Martinez, D (Corresponding Author), Univ Zaragoza, Dept Ingn Elect \& Comunicac, Maria de Luna 1, Zaragoza 50018, Spain.
   Martinez, David; Lleida, Eduardo; Ortega, Alfonso; Miguel, Antonio, Univ Zaragoza, Dept Ingn Elect \& Comunicac, Maria de Luna 1, Zaragoza 50018, Spain.
   Green, Phil; Christensen, Heidi, Univ Sheffield, Dept Comp Sci, Regent Court, Sheffield S1 4DP, S Yorkshire, England.}},
DOI = {{10.1145/2746405}},
Article-Number = {{10}},
ISSN = {{1936-7228}},
EISSN = {{1936-7236}},
Keywords = {{Algorithms; Design; Performance; Intelligibility assessment; ASR
   accuracy prediction; dysarthria; factor analysis; iVectors}},
Keywords-Plus = {{TUTORIAL}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications}},
Author-Email = {{david@unizar.es
   lleida@unizar.es
   p.green@shef.ac.uk
   heidi.christensen@sheffield.ac.uk
   ortega@unizar.es
   amiguel@unizar.es}},
ResearcherID-Numbers = {{Ortega, Alfonso/J-6280-2014
   Green, Phil/AAV-4599-2020
   Miguel, Antonio/B-6044-2017
   Lleida, Eduardo/K-8974-2014
   }},
ORCID-Numbers = {{Ortega, Alfonso/0000-0002-3886-7748
   Miguel, Antonio/0000-0001-5803-4316
   Lleida, Eduardo/0000-0001-9137-4013
   Green, Phil/0000-0001-9103-7287}},
Funding-Acknowledgement = {{Spanish governmentSpanish Government {[}TIN2011-28169-C05-02]; European
   UnionEuropean Union (EU) {[}INNPACTO IPT-2011-1696-390000]; Iris from
   the Seventh Framework Programme for research, technological development,
   and demonstration {[}610986]}},
Funding-Text = {{This work was funded by the Spanish government through project
   TIN2011-28169-C05-02, and by the European Union through projects
   INNPACTO IPT-2011-1696-390000 (FEDER) and Iris, which has received
   funding from the Seventh Framework Programme for research, technological
   development, and demonstration under grant agreement 610986.}},
Cited-References = {{ARMSTRONG JS, 1992, INT J FORECASTING, V8, P69, DOI 10.1016/0169-2070(92)90008-W.
   Bishop Cristopher M., 2006, SPRINGER SERIES INFO, DOI {[}10.1117/1.2819119, DOI 10.1117/1.2819119].
   Bocklet T., 2009, P 3 ADV VOIC FUNCT A, P89.
   Bocklet T, 2012, J VOICE, V26, P390, DOI 10.1016/j.jvoice.2011.04.010.
   Carmichael J., 2007, THESIS.
   Carmichael James, 2004, P INT C SPOK LANG PR.
   Chang CC, 2002, NEURAL COMPUT, V14, P1959, DOI 10.1162/089976602760128081.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Christensen H., 2012, P INTERSPEECH, P1776.
   Darley F., 1975, MOTOR SPEECH DISORDE.
   De Bodt MS, 2002, J COMMUN DISORD, V35, P283, DOI 10.1016/S0021-9924(02)00065-5.
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307.
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x.
   Doyle PC, 1997, J REHABIL RES DEV, V34, P309.
   Drummond S.S., 1993, DYSARTHRIA EXAMINATI.
   Enderby P.M., 1983, FRENCHAY DYSARTHRIA.
   Enderby Pam, 2013, Handb Clin Neurol, V110, P273, DOI 10.1016/B978-0-444-52901-5.00022-8.
   Falk TH, 2012, SPEECH COMMUN, V54, P622, DOI 10.1016/j.specom.2011.03.007.
   Falk TH, 2011, INT CONF ACOUST SPEE, P4480.
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278.
   Green P., 2003, P 8 EUR C SPEECH COM, P1189.
   Hamidi F, 2010, LECT NOTES COMPUT SC, V6179, P605, DOI 10.1007/978-3-642-14097-6\_97.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   Hosom JP, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P924.
   Kain AB, 2007, SPEECH COMMUN, V49, P743, DOI 10.1016/j.specom.2007.05.001.
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1448, DOI 10.1109/TASL.2007.894527.
   Kim H, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1741.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Martinez D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P868.
   Martinez David, 2013, P 14 ANN C INT SPEEC.
   Mengistu Knife T., 2011, P MOD AN VOC EM BIOM.
   Middag C, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3016.
   Middag C, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/629030.
   Moore B. C. J., 2003, INTRO PSYCHOL HEARIN.
   Onwuegbuzie A. J., 2007, ENCY MEASUREMENT STA, P750.
   Paja Milton S., 2012, P 13 ANN C INT SPEEC.
   Paul Douglas B., 1991, P WORKSH SPEECH NAT.
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379.
   Robertson SJ, 1982, DYSARTHRIA PROFILE.
   Sharma H., 2009, INTERSPEECH, P7.
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88.
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002.
   Strand Edythe A., 2004, MIT ENCY COMMUNICATI, P129.
   Van Nuffelen G, 2009, INT J LANG COMM DIS, V44, P716, DOI 10.1080/13682820802342062.}},
Number-of-Cited-References = {{44}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{ACM Trans. Access. Comput.}},
Doc-Delivery-Number = {{VG2GC}},
Unique-ID = {{ISI:000445708700004}},
DA = {{2020-12-06}},
}

@article{ ISI:000353601100012,
Author = {Muralikrishnan, R. and Schlesewsky, Matthias and Bornkessel-Schlesewsky,
   Ina},
Title = {{Animacy-based predictions in language comprehension are robust:
   Contextual cues modulate but do not nullify them}},
Journal = {{BRAIN RESEARCH}},
Year = {{2015}},
Volume = {{1608}},
Pages = {{108-137}},
Month = {{MAY 22}},
Abstract = {{Couldn't a humble coconut hurt a gardener? At least in the first
   instance, the brain seems to assume that it should not: we perceive
   inanimate entities such as coconuts as poor event instigators
   ({''}Actors{''}). Ideally, entities causing a change in another entity
   should be animate and this assumption not only influences event
   perception but also carries over to language comprehension. We present
   three auditory event-related brain potential (ERP) studies on the
   processing of inanimate and animate subjects and objects in simple
   transitive sentences in Tamil. ERP responses were measured at the second
   argument (event participant) in all three studies. Experiment 1 employed
   all possible animacy combinations of Actors and Undergoers (affected
   participants) in Actor- and Undergoerinitial verb-final orders.
   Experiments 2 and 3 employed a fairly novel context design that enabled
   us to compare ERPs evoked by identical auditory material to differing
   contextual expectations: Experiment 2 focussed on constructions in which
   an inanimate Actor acts upon an inanimate Undergoer, whereas Experiment
   3 examined whether and how a preceding context modulates the prediction
   for an ideal Actor. Results showed an N400 effect when the prediction
   for an ideal (animate) Actor following an Undergoer was not met, thus
   further supporting the cross-linguistically robust nature of animacy
   preferences. In addition, though specific contextual cues that are
   indicative of a forthcoming non-ideal Actor may reduce this negativity
   in comparison to when such cues are not available, they nevertheless do
   not nullify it, suggesting that animacy-based predictions are stronger
   than contextual cues in online language comprehension. (C) 2014 Elsevier
   B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Muralikrishnan, R (Corresponding Author), Max Planck Inst Empir Aesthet, Grueneburgweg 14, D-60322 Frankfurt, Germany.
   Muralikrishnan, R., Max Planck Inst Empir Aesthet, D-60322 Frankfurt, Germany.
   Muralikrishnan, R., Max Planck Inst Human Cognit \& Brain Sci, Leipzig, Germany.
   Schlesewsky, Matthias, Johannes Gutenberg Univ Mainz, D-55122 Mainz, Germany.
   Bornkessel-Schlesewsky, Ina, Univ Marburg, Marburg, Germany.
   Bornkessel-Schlesewsky, Ina, Univ S Australia, Adelaide, SA 5001, Australia.}},
DOI = {{10.1016/j.brainres.2014.11.046}},
ISSN = {{0006-8993}},
EISSN = {{1872-6240}},
Keywords = {{ERPs; Sentence processing; Animacy; Tamil; Actor; Predictive processing;
   Contextual cues}},
Keywords-Plus = {{REAL-TIME COMPREHENSION; SENTENCE INTERPRETATION; RELATIVE CLAUSES;
   WORKING-MEMORY; CORTEX; BRAIN; INFORMATION; CATEGORY; SUBJECT; SYSTEMS}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{r.muralikrishnan@aesthetics.mpg.de}},
ORCID-Numbers = {{, R. Muralikrishnan/0000-0001-7103-2497
   Bornkessel-Schlesewsky, Ina/0000-0002-3238-6492}},
Funding-Acknowledgement = {{German Research FoundationGerman Research Foundation (DFG) {[}BO
   2471/3-2]}},
Funding-Text = {{Parts of the research reported here were supported by a grant from the
   German Research Foundation to IBS (BO 2471/3-2). Experiment 1 was
   performed while IBS was at the Max Planck Institute for Human Cognitive
   and Brain Sciences, Leipzig, Germany.}},
Cited-References = {{Aissen J, 2003, NAT LANG LINGUIST TH, V21, P435, DOI 10.1023/A:1024109008573.
   Alday PM, 2014, NEUROINFORMATICS, V12, P143, DOI 10.1007/s12021-013-9198-x.
   Asher RE, 2005, FIGURE OF SPEECH: A FESTSCHRIFT FOR JOHN LAVER, P147.
   Bates E, 2001, ANNU REV PSYCHOL, V52, P369, DOI 10.1146/annurev.psych.52.1.369.
   Bisang W, 2006, TRENDS LINGUIST-STUD, V165, P191.
   Bornkessel I, 2006, PSYCHOL REV, V113, P787, DOI 10.1037/0033-295X.113.4.787.
   Bornkessel-Schlesewsky I., 2015, COMPETING M IN PRESS.
   Bornkessel-Schlesewsky I, 2013, BRAIN LANG, V125, P60, DOI 10.1016/j.bandl.2013.01.010.
   Bornkessel-Schlesewsky I, 2009, LANG LINGUIST COMPAS, V3, P19, DOI 10.1111/j.1749-818x.2008.00099.x.
   Bornkessel-Schlesewsky I, 2008, STUD LANG C, V105, P413.
   Bornkessel-Schlesewsky I, 2009, LINGUA, V119, P1541, DOI 10.1016/j.lingua.2008.03.005.
   Bornkessel-Schlesewsky I, 2008, BRAIN RES REV, V59, P55, DOI 10.1016/j.brainresrev.2008.05.003.
   Caramazza A, 1998, J COGNITIVE NEUROSCI, V10, P1, DOI 10.1162/089892998563752.
   Chao LL, 1999, NAT NEUROSCI, V2, P913.
   Comrie Bernard, 1989, LANGUAGE UNIVERSALS.
   Croft W., 2003, TYPOLOGY UNIVERSALS.
   Dahl O, 2008, LINGUA, V118, P141, DOI 10.1016/j.lingua.2007.02.008.
   FERGUSON CA, 1959, WORD, V15, P325, DOI 10.1080/00437956.1959.11659702.
   Frisch S, 2001, NEUROREPORT, V12, P3391, DOI 10.1097/00001756-200110290-00048.
   Hoeks JCJ, 2004, COGNITIVE BRAIN RES, V19, P59, DOI 10.1016/j.cogbrainres.2003.10.022.
   Huynh H., 1970, J AM STAT ASSOC, V65, P1582, DOI DOI 10.1080/01621459.1970.10481187.
   Jager G, 2007, LANGUAGE, V83, P74, DOI 10.1353/lan.2007.0020.
   Kanwisher N, 1997, J NEUROSCI, V17, P4302.
   Keane E, 2006, LANG SPEECH, V49, P299, DOI 10.1177/00238309060490030101.
   Kerkhofs R, 2007, J COGNITIVE NEUROSCI, V19, P1421, DOI 10.1162/jocn.2007.19.9.1421.
   Kim A, 2005, J MEM LANG, V52, P205, DOI 10.1016/j.jml.2004.10.002.
   Kolk HHJ, 2003, BRAIN LANG, V85, P1, DOI 10.1016/S0093-934X(02)00548-5.
   Kuperberg GR, 2003, COGNITIVE BRAIN RES, V17, P117, DOI 10.1016/S0926-6410(03)00086-7.
   Leube DT, 2001, COGNITIVE BRAIN RES, V12, P425, DOI 10.1016/S0926-6410(01)00068-4.
   LI P, 1993, J MEM LANG, V32, P169, DOI 10.1006/jmla.1993.1010.
   MACWHINNEY B, 1984, J VERB LEARN VERB BE, V23, P127, DOI 10.1016/S0022-5371(84)90093-8.
   Mahon BZ, 2005, COGN NEUROPSYCHOL, V22, P480, DOI 10.1080/02643290442000446.
   Mak WM, 2006, J MEM LANG, V54, P466, DOI 10.1016/j.jml.2006.01.001.
   Mak WM, 2002, J MEM LANG, V47, P50, DOI 10.1006/jmla.2001.2837.
   MANDLER JM, 1992, COGNITIVE DEV, V7, P273, DOI 10.1016/0885-2014(92)90016-K.
   New J, 2007, P NATL ACAD SCI USA, V104, P16598, DOI 10.1073/pnas.0703913104.
   Perani D, 1999, BRAIN, V122, P2337, DOI 10.1093/brain/122.12.2337.
   Philipp M, 2008, BRAIN LANG, V105, P112, DOI 10.1016/j.bandl.2007.09.005.
   Rakison DH, 2001, PSYCHOL BULL, V127, P209, DOI 10.1037//0033-2909.127.2.209.
   Roehm D, 2004, NEUROREPORT, V15, P409, DOI 10.1097/00001756-200403010-00005.
   Scott Graham, 1978, FORE LANGUAGE PAPUA.
   Silverstein M., 1976, GRAMMATICAL CATEGORI.
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002.
   Szewczyk JM, 2011, BRAIN RES, V1368, P208, DOI 10.1016/j.brainres.2010.10.070.
   Traxler MJ, 2005, J MEM LANG, V53, P204, DOI 10.1016/j.jml.2005.02.010.
   Traxler MJ, 2002, J MEM LANG, V47, P69, DOI 10.1006/jmla.2001.2836.
   van Herten M, 2005, COGNITIVE BRAIN RES, V22, P241, DOI 10.1016/j.cogbrainres.2004.09.002.
   Wang LM, 2009, LANG COGNITIVE PROC, V24, P1180, DOI 10.1080/01690960802159937.
   Weckerly J, 1999, PSYCHOPHYSIOLOGY, V36, P559, DOI 10.1017/S0048577299971202.}},
Number-of-Cited-References = {{49}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{Brain Res.}},
Doc-Delivery-Number = {{CG8YH}},
Unique-ID = {{ISI:000353601100012}},
DA = {{2020-12-06}},
}

@article{ ISI:000365719400012,
Author = {Schaedler, Marc Rene and Warzybok, Anna and Hochmuth, Sabine and
   Kollmeier, Birger},
Title = {{Matrix sentence intelligibility prediction using an automatic speech
   recognition system}},
Journal = {{INTERNATIONAL JOURNAL OF AUDIOLOGY}},
Year = {{2015}},
Volume = {{54}},
Number = {{2, SI}},
Pages = {{100-107}},
Month = {{MAY 1}},
Abstract = {{Objective: The feasibility of predicting the outcome of the German
   matrix sentence test for different types of stationary background noise
   using an automatic speech recognition (ASR) system was studied. Design:
   Speech reception thresholds (SRT) of 50\% intelligibility were predicted
   in seven noise conditions. The ASR system used Mel-frequency cepstral
   coefficients as a front-end and employed whole-word Hidden Markov models
   on the back-end side. The ASR system was trained and tested with noisy
   matrix sentences on a broad range of signal-to-noise ratios. Study
   sample: The ASR-based predictions were compared to data from the
   literature (Hochmuth et al, 2015) obtained with 10 native German
   listeners with normal hearing and predictions of the speech
   intelligibility index (SII). Results: The ASR-based predictions showed a
   high and significant correlation (R-2 = 0.95, p < 0.001) with the
   empirical data across different noise conditions, outperforming the
   SII-based predictions which showed no correlation with the empirical
   data (R-2 = 0.00, p = 0.987). Conclusions: The SRTs for the German
   matrix test for listeners with normal hearing in different stationary
   noise conditions could well be predicted based on the acoustical
   properties of the speech and noise signals. Minimum assumptions were
   made about human speech processing already incorporated in a
   reference-free ordinary ASR system.}},
Publisher = {{TAYLOR \& FRANCIS LTD}},
Address = {{4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Schadler, MR (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, D-26111 Oldenburg, Germany.
   Carl von Ossietzky Univ Oldenburg, Med Phys, D-26111 Oldenburg, Germany.
   Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, D-26111 Oldenburg, Germany.}},
DOI = {{10.3109/14992027.2015.1061708}},
ISSN = {{1499-2027}},
EISSN = {{1708-8186}},
Keywords = {{Speech intelligibility predictions; SII; ASR; speech in noise; matrix
   test}},
Keywords-Plus = {{STEADY BACKGROUND-NOISE; MODEL; HEARING; PERCEPTION; LISTENERS; INDEX;
   COMPRESSION; REFLECTIONS; THRESHOLD}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Otorhinolaryngology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Otorhinolaryngology}},
Author-Email = {{marc.r.schaedler@uni-oldenburg.de}},
Funding-Acknowledgement = {{Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG)
   {[}SFB/TRR 31]; Cluster of Excellence Grant `Hearing4all'}},
Funding-Text = {{This work was supported by the Deutsche Forschungsgemeinschaft SFB/TRR
   31 `The active auditory system,' and the Cluster of Excellence Grant
   `Hearing4all'.}},
Cited-References = {{{*}ANSI, 1997, AM NAT STAND METH CA.
   {*}ANSI, 1969, S351969 ANSI STAND S.
   Auditec, 2006, CD101RW2 AUD CD, V2515.
   Bradley JS, 2003, J ACOUST SOC AM, V113, P3233, DOI 10.1121/1.1570439.
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152.
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600.
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   Dreschler WA, 2001, AUDIOLOGY, V40, P148.
   ETSI standard document, 2003, 201108V113 ETSI.
   FLETCHER H, 1950, J ACOUST SOC AM, V22, P89, DOI 10.1121/1.1906605.
   Fraunhofer IDMT, 2014, SIP TOOLB.
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203.
   Hochmuth S, 2015, INT J AUDIOL, V54, P62, DOI 10.3109/14992027.2015.1046502.
   Hochmuth S, 2012, INT J AUDIOL, V51, P536, DOI 10.3109/14992027.2012.670731.
   HOHMANN V, 1995, J ACOUST SOC AM, V97, P1191, DOI 10.1121/1.413092.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   Jorgensen S, 2013, J ACOUST SOC AM, V134, P436, DOI 10.1121/1.4807563.
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502.
   Jurgens T, 2009, J ACOUST SOC AM, V126, P2635, DOI 10.1121/1.3224721.
   Kollmeier B, 2015, INT J AUDIOL, V54, P3, DOI 10.3109/14992027.2015.1020971.
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1689, DOI 10.1121/1.1909094.
   Leijon A, 2002, ACTA ACUST UNITED AC, V88, P423.
   LOCHNER JPA, 1964, J SOUND VIB, V1, P426, DOI 10.1016/0022-460X(64)90057-4.
   Ludvigsen C., 1993, RECENT DEV HEARING I, P81.
   Meyer B., 2009, J ACOUST SOC AM, V129, P388.
   Meyer RM, 2013, ACTA ACUST UNITED AC, V99, P442, DOI 10.3813/AAA.918625.
   Ozimek E, 2010, INT J AUDIOL, V49, P444, DOI 10.3109/14992021003681030.
   Rhebergen KS, 2009, J ACOUST SOC AM, V126, P3236, DOI 10.1121/1.3257225.
   Stadler S., 2007, P INT 2007, P398.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Stone MA, 2012, J ACOUST SOC AM, V132, P317, DOI 10.1121/1.4725766.
   Stone MA, 2011, J ACOUST SOC AM, V130, P2874, DOI 10.1121/1.3641371.
   Wagener K, 1999, Z AUDIOL, V38, P86.
   Wagener K, 1999, Z AUDIOL, V38, P4.
   Wagener K, 1999, Z AUDIOL, V38, P44, DOI DOI 10.3109/00206099909073001.
   Warzybok A, 2015, INT J AUDIOL, V54, P35, DOI 10.3109/14992027.2015.1020969.
   Warzybok A, 2013, J ACOUST SOC AM, V133, P269, DOI 10.1121/1.4768880.
   Wong LLN, 2007, J ACOUST SOC AM, V121, P2350, DOI 10.1121/1.2431338.
   Young S., 2006, CAMBRIDGE U ENG DEP, V2, P2.}},
Number-of-Cited-References = {{39}},
Times-Cited = {{24}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Int. J. Audiol.}},
Doc-Delivery-Number = {{CX5CP}},
Unique-ID = {{ISI:000365719400012}},
DA = {{2020-12-06}},
}

@article{ ISI:000353352100011,
Author = {Strelnikov, Kuzma and Foxton, Jessica and Marx, Mathieu and Barone,
   Pascal},
Title = {{Brain Prediction of Auditory Emphasis by Facial Expressions During
   Audiovisual Continuous Speech}},
Journal = {{BRAIN TOPOGRAPHY}},
Year = {{2015}},
Volume = {{28}},
Number = {{3, SI}},
Pages = {{494-505}},
Month = {{MAY}},
Abstract = {{The visual cues involved in auditory speech processing are not
   restricted to information from lip movements but also include head or
   chin gestures and facial expressions such as eyebrow movements. The fact
   that visual gestures precede the auditory signal implicates that visual
   information may influence the auditory activity. As visual stimuli are
   very close in time to the auditory information for audiovisual
   syllables, the cortical response to them usually overlaps with that for
   the auditory stimulation; the neural dynamics underlying the visual
   facilitation for continuous speech therefore remain unclear. In this
   study, we used a three-word phrase to study continuous speech
   processing. We presented video clips with even (without emphasis)
   phrases as the frequent stimuli and with one word visually emphasized by
   the speaker as the non-frequent stimuli. Negativity in the resulting
   ERPs was detected after the start of the emphasizing articulatory
   movements but before the auditory stimulus, a finding that was confirmed
   by the statistical comparisons of the audiovisual and visual
   stimulation. No such negativity was present in the control visual-only
   condition. The propagation of this negativity was observed between the
   visual and fronto-temporal electrodes. Thus, in continuous speech, the
   visual modality evokes predictive coding for the auditory speech, which
   is analysed by the cerebral cortex in the context of the phrase even
   before the arrival of the corresponding auditory signal.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Strelnikov, K (Corresponding Author), Univ Toulouse, Univ Toulouse 3, CerCo, Toulouse, France.
   Strelnikov, Kuzma; Foxton, Jessica; Marx, Mathieu; Barone, Pascal, Univ Toulouse, Univ Toulouse 3, CerCo, Toulouse, France.
   Strelnikov, Kuzma; Foxton, Jessica; Marx, Mathieu; Barone, Pascal, CHU Purpan, Fac Med Purpan, CNRS, CERCO,UMR 5549, F-31052 Toulouse, France.
   Marx, Mathieu, Hop Purpan, Serv Otorhinolaryngol, Toulouse, France.}},
DOI = {{10.1007/s10548-013-0338-2}},
ISSN = {{0896-0267}},
EISSN = {{1573-6792}},
Keywords = {{Audio-visual speech; Prosody; Mismatch; Predictive coding}},
Keywords-Plus = {{MISMATCH NEGATIVITY; VISUAL INFORMATION; PERCEPTION; ACTIVATION;
   INTEGRATION; MOVEMENTS; CORTEX; PITCH; DISCRIMINATION; OSCILLATIONS}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Clinical Neurology; Neurosciences}},
Author-Email = {{kuzma@cerco.ups-tlse.fr}},
ResearcherID-Numbers = {{Barone, Pascal/A-4008-2009}},
Funding-Acknowledgement = {{Human Frontier Science ProgramHuman Frontier Science Program; DRCI
   Toulouse (Direction de la Recherche Clinique et de l'Innovation);
   ANRFrench National Research Agency (ANR) {[}ANR-11-BSHS2-0008];
   CNRSCentre National de la Recherche Scientifique (CNRS)}},
Funding-Text = {{We thank E. Barbeau for help in the first pilot study and C. Marlot for
   the bibliography. This study was supported by the Human Frontier Science
   Program (to JMF), the DRCI Toulouse (Direction de la Recherche Clinique
   et de l'Innovation to KS and MM), the ANR (ANR Plasmody
   ANR-11-BSHS2-0008 (to BP), and the recurrent funding of the CNRS (to
   BP).}},
Cited-References = {{Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009.
   Barker J. P., 1999, P INT C PHON SCI, P199.
   Barkhuysen P, 2008, J ACOUST SOC AM, V123, P354, DOI 10.1121/1.2816561.
   Barone P, 2011, SPRINGER HANDB AUDIT, V39, P365, DOI 10.1007/978-1-4419-9434-9\_15.
   Besle J, 2005, EXP BRAIN RES, V166, P337, DOI 10.1007/s00221-005-2375-x.
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x.
   Besle J, 2009, HEARING RES, V258, P143, DOI 10.1016/j.heares.2009.06.016.
   Besle J, 2008, J NEUROSCI, V28, P14301, DOI 10.1523/JNEUROSCI.2875-08.2008.
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593.
   Campanella S, 2002, BIOL PSYCHOL, V59, P171, DOI 10.1016/S0301-0511(02)00005-4.
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155.
   Cappe C, 2010, J NEUROSCI, V30, P12572, DOI 10.1523/JNEUROSCI.1099-10.2010.
   Carpenter J, 2000, STAT MED, V19, P1141, DOI 10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F.
   Cave C, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2175, DOI 10.1109/ICSLP.1996.607235.
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064.
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436.
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004.
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155.
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X.
   Colombo L, 2011, CORTEX, V47, P557, DOI 10.1016/j.cortex.2010.03.008.
   Davis C, 2008, BRAIN RES, V1242, P151, DOI 10.1016/j.brainres.2008.04.077.
   de Gelder B, 1999, NEUROSCI LETT, V260, P133, DOI 10.1016/S0304-3940(98)00963-X.
   Donnelly PJ, 2009, J ACOUST SOC AM, V126, pEL128, DOI 10.1121/1.3239464.
   Foxton JM, 2010, COGNITION, V115, P71, DOI 10.1016/j.cognition.2009.11.009.
   Friston KJ, 2008, NEUROIMAGE, V39, P1104, DOI 10.1016/j.neuroimage.2007.09.048.
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300.
   Ghazanfar AA, 2008, J NEUROSCI, V28, P4457, DOI 10.1523/JNEUROSCI.0541-08.2008.
   Guaitella I, 2009, LANG SPEECH, V52, P207, DOI 10.1177/0023830909103167.
   Hadar U, 1984, Adv Neurol, V42, P247.
   HALGREN E, 1995, ELECTROEN CLIN NEURO, V94, P229, DOI 10.1016/0013-4694(95)98475-N.
   Hertrich I, 2007, NEUROPSYCHOLOGIA, V45, P1342, DOI 10.1016/j.neuropsychologia.2006.09.019.
   Jiang JT, 2002, EURASIP J APPL SIG P, V2002, P1174, DOI 10.1155/S1110865702206046.
   Kang E, 2006, NEUROIMAGE, V32, P423, DOI 10.1016/j.neuroimage.2006.03.016.
   Kilian-Hutten N, 2011, NEUROIMAGE, V57, P1601, DOI 10.1016/j.neuroimage.2011.05.043.
   Kimura M, 2012, INT J PSYCHOPHYSIOL, V83, P144, DOI 10.1016/j.ijpsycho.2011.11.010.
   Kislyuk DS, 2008, J COGNITIVE NEUROSCI, V20, P2175, DOI 10.1162/jocn.2008.20152.
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011.
   Li X, 2009, NEUROSCIENCE, V161, P59, DOI 10.1016/j.neuroscience.2009.01.070.
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024.
   Marx M, 2013, 20 IFOS WORLD C SEOU.
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0.
   Mottonen R, 2002, COGNITIVE BRAIN RES, V13, P417, DOI 10.1016/S0926-6410(02)00053-8.
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x.
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026.
   Ponton CW, 2009, BRAIN TOPOGR, V21, P207, DOI 10.1007/s10548-009-0094-5.
   Proverbio AM, 2009, NEUROSCI LETT, V459, P142, DOI 10.1016/j.neulet.2009.05.012.
   Quiroga RQ, 2003, CLIN NEUROPHYSIOL, V114, P376, DOI 10.1016/S1388-2457(02)00365-6.
   Reale RA, 2007, NEUROSCIENCE, V145, P162, DOI 10.1016/j.neuroscience.2006.11.036.
   Ross ED, 2008, BRAIN LANG, V104, P51, DOI 10.1016/j.bandl.2007.04.007.
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024.
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036.
   SAMS M, 1984, PSYCHOPHYSIOLOGY, V21, P434, DOI 10.1111/j.1469-8986.1984.tb00223.x.
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F.
   Scarborough R, 2009, LANG SPEECH, V52, P135, DOI 10.1177/0023830909103165.
   Schroeder CE, 2005, CURR OPIN NEUROBIOL, V15, P454, DOI 10.1016/j.conb.2005.06.008.
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006.
   Schwartz JL, 2013, 12 INT C AUD VIS SPE.
   Stein BE, 1996, J COGNITIVE NEUROSCI, V8, P497, DOI 10.1162/jocn.1996.8.6.497.
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964.
   Stekelenburg JJ, 2009, EXP BRAIN RES, V198, P383, DOI 10.1007/s00221-009-1763-z.
   Strelnikov K, 2008, J NEUROLINGUIST, V21, P1, DOI 10.1016/j.jneuroling.2007.06.001.
   Strelnikov K, 2007, BRAIN COGNITION, V65, P244, DOI 10.1016/j.bandc.2007.04.002.
   Strelnikov K, 2010, BRAIN COGNITION, V72, P449, DOI 10.1016/j.bandc.2009.12.008.
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309.
   Tales A, 1999, NEUROREPORT, V10, P3363, DOI 10.1097/00001756-199911080-00020.
   Ullsperger P, 2006, INT J PSYCHOPHYSIOL, V59, P3, DOI 10.1016/j.ijpsycho.2005.06.007.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.}},
Number-of-Cited-References = {{68}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Brain Topogr.}},
Doc-Delivery-Number = {{CG5RQ}},
Unique-ID = {{ISI:000353352100011}},
DA = {{2020-12-06}},
}

@article{ ISI:000349754400001,
Author = {Borowicz, Adam},
Title = {{A signal subspace approach to spatio-temporal prediction for
   multichannel speech enhancement}},
Journal = {{EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING}},
Year = {{2015}},
Month = {{FEB 10}},
Abstract = {{The spatio-temporal-prediction (STP) method for multichannel speech
   enhancement has recently been proposed. This approach makes it
   theoretically possible to attenuate the residual noise without
   distorting speech. In addition, the STP method depends only on the
   second-order statistics and can be implemented using a simple linear
   filtering framework. Unfortunately, some numerical problems can arise
   when estimating the filter matrix in transients. In such a case, the
   speech correlation matrix is usually rank deficient, so that no solution
   exists. In this paper, we propose to implement the
   spatio-temporal-prediction method using a signal subspace approach. This
   allows for nullifying the noise subspace and processing only the noisy
   signal in the signal-plus-noise subspace. As a result, we are able to
   not only regularize the solution in transients but also to achieve
   higher attenuation of the residual noise. The experimental results also
   show that the signal subspace approach distorts speech less than the
   conventional method.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Borowicz, A (Corresponding Author), Bialystok Tech Univ, Dept Comp Graph \& Digital Media, Fac Comp Sci, Wiejska Str 45A, PL-15351 Bialystok, Poland.
   Bialystok Tech Univ, Dept Comp Graph \& Digital Media, Fac Comp Sci, PL-15351 Bialystok, Poland.}},
DOI = {{10.1186/s13636-015-0051-z}},
Article-Number = {{5}},
ISSN = {{1687-4722}},
Keywords = {{Signal subspace; Spatio-temporal prediction; Speech enhancement}},
Keywords-Plus = {{COLORED NOISE; ALGORITHM}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{a.borowicz@pb.edu.pl}},
ResearcherID-Numbers = {{Borowicz, Adam/K-5188-2017}},
ORCID-Numbers = {{Borowicz, Adam/0000-0003-0320-5530}},
Funding-Acknowledgement = {{Polish National Science Centre {[}DEC-2012/07/D/ST6/02454]}},
Funding-Text = {{This work was supported by the Polish National Science Centre under
   Decision No. DEC-2012/07/D/ST6/02454.}},
Cited-References = {{Affes S, 1997, IEEE T SPEECH AUDI P, V5, P425, DOI 10.1109/89.622565.
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599.
   Benesty J, 2012, SPRBRIEF ELECT, P1, DOI 10.1007/978-3-642-23250-3.
   Benesty J, 2008, SPRINGER TOP SIGN PR, V1, P1.
   Borowicz A, 2012, 2012 P 20 EUR SIGN P.
   Borowicz A, 2011, SPEECH COMMUN, V53, P210, DOI 10.1016/j.specom.2010.09.002.
   Chen JD, 2008, IEEE T AUDIO SPEECH, V16, P481, DOI 10.1109/TASL.2007.914969.
   Cornelis B, 2009, 2009 IEEE INT C AC S.
   EPHRAIM Y, 1995, IEEE T SPEECH AUDI P, V3, P251, DOI 10.1109/89.397090.
   FROST OL, 1972, PR INST ELECTR ELECT, V60, P926, DOI 10.1109/PROC.1972.8817.
   Gannot S, 2001, IEEE T SIGNAL PROCES, V49, P1614, DOI 10.1109/78.934132.
   GRIFFITHS LJ, 1982, IEEE T ANTENN PROPAG, V30, P27, DOI 10.1109/TAP.1982.1142739.
   Habets EAP, 2010, P IWAENC TEL AV ISR.
   HANSEN PC, 1987, BIT, V27, P534, DOI 10.1007/BF01937276.
   Hu Y, 2003, IEEE T SPEECH AUDI P, V11, P334, DOI 10.1109/TSA.2003.814458.
   Huang Y, 2008, IEEE T AUDIO SPEECH, V16, P957, DOI 10.1109/TASL.2008.921754.
   Jabloun F, 2003, IEEE T SPEECH AUDI P, V11, P700, DOI 10.1109/TSA.2003.818031.
   Lev-Ari H, 2003, IEEE SIGNAL PROC LET, V10, P104, DOI 10.1109/LSP.2003.808544.
   Vetter R, 1999, P EUROSPEECH BUD HUN.
   Virette D, 2002, P EUSIPCO, V3, P297.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{EURASIP J. Audio Speech Music Process.}},
Doc-Delivery-Number = {{CB6RN}},
Unique-ID = {{ISI:000349754400001}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000348261700002,
Author = {Norrenbrock, Christoph R. and Hinterleitner, Florian and Heute, Ulrich
   and Moeller, Sebastian},
Title = {{Quality prediction of synthesized speech based on perceptual quality
   dimensions}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2015}},
Volume = {{66}},
Pages = {{17-35}},
Month = {{FEB}},
Abstract = {{Instrumental speech-quality prediction for text-to-speech signals is
   explored in a twofold manner. First, the perceptual quality space of TTS
   is structured by means of three perceptual quality dimensions which are
   derived from multiple auditory tests. Second, quality-prediction models
   are evaluated for each dimension using prosodic and MFCC-based
   measurands. Linear and nonlinear model types are compared under
   cross-validation restrictions, giving detailed insight into
   model-generalizability aspects. Perceptually regularized properties,
   denoted as quality elements, are introduced in order to encode the
   quality-indicative effect of individual signal characteristics. These
   elements integrate a perceptual model reference which is derived in a
   semi-supervised fashion from natural and synthetic speech. The results
   highlight the feasibility of instrumental quality prediction for TTS
   signals provided that broad training material is employed. High
   prediction accuracy, however, requires nonlinear model structures. (C)
   2014 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Norrenbrock, CR (Corresponding Author), Univ Kiel, Digital Signal Proc \& Syst Theory DSS, Tech Fak, Kaiserstr 2, D-24143 Kiel, Germany.
   Norrenbrock, Christoph R.; Heute, Ulrich, Univ Kiel, Digital Signal Proc \& Syst Theory Grp, D-24143 Kiel, Germany.
   Hinterleitner, Florian; Moeller, Sebastian, Tech Univ Berlin, Qual \& Usabil Lab, D-10587 Berlin, Germany.}},
DOI = {{10.1016/j.specom.2014.06.003}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Speech-quality prediction; Synthetic speech perception; Text-to-speech;
   Non-intrusive quality assessment; Perceptual regularization}},
Keywords-Plus = {{SUBJECTIVE EVALUATION; DISCONTINUITIES; SYSTEMS}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{cno@tf.uni-kiel.de
   florian.hinterleitner@tu-berlin.de
   uh@tf.uni-kiel.de
   sebastian.moeller@telekom.de}},
Funding-Acknowledgement = {{German Research Foundation (Deutsche Forschungsgemeinschaft)German
   Research Foundation (DFG) {[}HE 4465/4-1, HE 4465/4-2, MO 1038/11-1, MO
   1038/11-2]}},
Funding-Text = {{This work was funded by the German Research Foundation (Deutsche
   Forschungsgemeinschaft) under Grants HE 4465/4-1, HE 4465/4-2, MO
   1038/11-1, and MO 1038/11-2. We are grateful to Donata Moers, Marc
   Schroder, Guntram Strecha and the organizers of the Blizzard Challenge
   who provided rated TTS samples. Furthermore, we would like to thank
   Friedemann Koster, Kirstin Scholz, Viet Duc Nguyen, and Befkadu Temesgen
   Gebru, and the anonymous reviewers who all contributed to this work.}},
Cited-References = {{{[}Anonymous], 1996, P85 ITUT.
   {[}Anonymous], 2004, P563 ITUT.
   {*}ANSI ATIS, 2006, 01000052006 ANSI ATI.
   BALAKRISHNAN N, 2006, ENCY STAT SCI.
   Boersma P., 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107.
   Boersma P., 2005, PRAAT SOFTWARE SPEEC.
   Cernak M., 2005, P FOR AC BUD HUNG.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Chen J.-D., 1999, P EUR.
   Deller JR, 1993, DISCRETE TIME PROCES.
   Falk TH, 2008, IEEE SIGNAL PROC LET, V15, P781, DOI 10.1109/LSP.2008.2006709.
   Gibbon D., 1998, HDB STANDARDS RESOUR, VIII.
   Grancharov V, 2006, IEEE T AUDIO SPEECH, V14, P1948, DOI 10.1109/TASL.2006.883250.
   Grice M., 1992, MULTILIGUAL SPEECH I.
   Grice M., 1992, MULTILINGUAL SPEECH.
   Hastie T., 2009, ELEMENTS STAT LEARNI.
   Heute U., 2008, ADV DIGITAL SPEECH T.
   Hinterleitner F., 2011, P ESSV AACH GERM.
   Hinterleitner F., 2013, P INTERSPEECH.
   Hinterleitner F., 2012, P IEEE WORKSH SPEECH.
   Hinterleitner F., 2013, P SPEECH SYNTH WORKS.
   Hinterleitner F., 2012, P ESSV COTTB GERM.
   Hinterleitner F., 2011, P 12 ANN C INT SPEEC, P2177.
   Hinterleitner Florian, 2011, P BLIZZ CHALL WORKSH.
   Huang D.-Y., 2011, P APSIPA ASC XIAN CH.
   {*}ITU T, 2001, G712 ITUT.
   {*}ITU T, 2004, P880 ITUT.
   ITU-T, 2001, P862 ITUT.
   Jekosch U, 2005, SIG COM TEC.
   Kim DS, 2005, IEEE T SPEECH AUDI P, V13, P821, DOI 10.1109/TSA.2005.851924.
   King S., 2012, P BLIZZ CHALL WORKSH.
   Klabbers E, 2007, IEEE T AUDIO SPEECH, V15, P949, DOI 10.1109/TASL.2006.885250.
   Klaus H, 1997, ACUSTICA, V83, P124.
   Kohler K.J., 1992, PHONETISCH AKUSTISCH, V26.
   KRAFT V, 1995, ACTA ACUST, V3, P351.
   Mariniak A, 1993, P 3 EUR C SPEECH PRO, P1683.
   Mayo C., 2005, P INTERSPEECH.
   Mayo C, 2011, SPEECH COMMUN, V53, P311, DOI 10.1016/j.specom.2010.10.003.
   Mersdorf J., 2001, THESIS RUHR U BOCHUM.
   Moller S, 2008, ACTA ACUST UNITED AC, V94, P21, DOI {[}10.3813/AAA.918004, 10.2392/AAA.918004].
   Moller S, 2011, IEEE SIGNAL PROC MAG, V28, P18, DOI 10.1109/MSP.2011.942469.
   Moller S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1325.
   Moller S., 2010, QUALITY ENG.
   Norrenbrock C., 2012, P BLIZZ CHALL WORKSH.
   Norrenbrock C., 2012, P ITG C SPEECH COMM.
   Norrenbrock C., 2012, P INTERSPEECH.
   Norrenbrock C., 2011, P INTERSPEECH, P2193.
   Norrenbrock CR, 2012, IEEE SIGNAL PROC LET, V19, P255, DOI 10.1109/LSP.2012.2189562.
   Pisoni D.B., 1997, PROGR SPEECH SYNTHES.
   Precht M., 1993, BIOSTATISTIK 2.
   Quackenbush S., 1988, OBJECTIVE MEASURES S.
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790\_2.
   Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565.
   Seget K., 2007, THESIS CHRISTIAN ALB.
   Sonntag GP, 1998, COMPUT SPEECH LANG, V12, P437, DOI 10.1006/csla.1998.0107.
   Stylianou Y, 2001, INT CONF ACOUST SPEE, P837, DOI 10.1109/ICASSP.2001.941045.
   Taylor P., 2009, TEXT TO SPEECH SYNTH.
   Valentini-Botinhao C., 2011, P INTERSPEECH, P1837.
   van Bezooijen R., 1998, SPOKEN LANGUAGE SYST, P167.
   van Heuven V. J., 1995, SPEECH CODING SYNTHE, P707.
   Vary P., 1998, DIGITALE SPRACHSIGNA.
   Vepa J, 2006, IEEE T AUDIO SPEECH, V14, P1763, DOI 10.1109/TSA.2005.858548.
   Viswanathan M, 2005, COMPUT SPEECH LANG, V19, P55, DOI 10.1016/j.csl.2003.12.001.
   Zwicker E., 1999, PSYCHOACOUSTICS FACT.}},
Number-of-Cited-References = {{64}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{AZ5LE}},
Unique-ID = {{ISI:000348261700002}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380581600090,
Author = {Gallardo, Laura Fernandez and Moeller, Sebastian},
Book-Group-Author = {{ISCA-INT SPEECH COMMUN ASSOC}},
Title = {{Towards the Prediction of Human Speaker Identification Performance from
   Measured Speech Quality}},
Booktitle = {{16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2015), VOLS 1-5}},
Year = {{2015}},
Pages = {{443-447}},
Note = {{16th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2015),
   Dresden, GERMANY, SEP 06-10, 2015}},
Organization = {{NISCAN; TU Berlin; TUBS Sci Mkt; EZ Alibaba Grp; Telekon Innovat Lab;
   Google; Amazon Echo; Facebook; Microsoft; Citrix; Datamall; NXP
   Software; E Sigma; ELRA; European Media Lab GmbH; EML; Nuance;
   Linguwerk; Speech Ocean}},
Abstract = {{Speech communication channels and their components (e.g. codecs) are
   generally designed for optimum perceived speech quality. However,
   transmission channels should also preserve principal speaker-specific
   characteristics that enable acceptable speaker identification
   performance by end listeners. This paper proposes a first step towards
   effective approaches for the prediction of the human speaker
   identification performance from instrumental quality measures.
   Correspondences between speech quality and speaker identification
   accuracy are shown by fitting linear curves to data points involving
   different channel transmissions. Narrowband, wideband, and
   super-wideband channels are considered, with other typically associated
   distortions. Our analyses show that Coloration, one of the perceptual
   quality dimensions, can be a better predictor of the human speaker
   identification performance than overall quality predictions in terms of
   Mean Opinion Scores. This suggests that the speaker specific properties
   of the voice are mainly impaired by the distortion of frequency
   components in the transmission path.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gallardo, LF (Corresponding Author), Univ Canberra, Fac ESTeM, Canberra, ACT 2601, Australia.
   Gallardo, Laura Fernandez; Moeller, Sebastian, Univ Canberra, Fac ESTeM, Canberra, ACT 2601, Australia.
   Gallardo, Laura Fernandez; Moeller, Sebastian, TU Berlin, Telekom Innovat Labs, Qual \& Usabil Lab, Berlin, Germany.}},
ISBN = {{978-1-5108-1790-6}},
Keywords = {{human speaker identification; speech quality; instrumental measures;
   prediction model}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{laura.fernandez-gallardo@telekom.de
   sebastian.moeller@telekom.de}},
Cited-References = {{{[}Anonymous], 2013, ITU T SG12 M CH GEN.
   Beerends J. G., 2005, NEW DIRECTIONS IMPRO.
   Cote N, 2011, T-LAB SER TELECOMMUN, P1, DOI 10.1007/978-3-642-18463-5.
   Fernandez Gallardo Laura, 2012, ITG-Fachbericht, P219.
   Fernandez L. Gallardo, 2014, THESIS.
   Gallardo LF, 2013, INT CONF ACOUST SPEE, P7775, DOI 10.1109/ICASSP.2013.6639177.
   Moller S, 2006, IEEE T AUDIO SPEECH, V14, P1969, DOI 10.1109/TASL.2006.883262.
   Moller S, 2014, 2014 8TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS).
   Rietveld A. C. M., 1991, P 12 INT C PHON SCI, P46.
   Scholz K, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1523.
   Sun H, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P865.
   Taal C. H., 2009, P INTERSPEECH, P1947.
   Waltermann M, 2010, INT CONF ACOUST SPEE, P4654, DOI 10.1109/ICASSP.2010.5495199.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BF3TT}},
Unique-ID = {{ISI:000380581600090}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380581600126,
Author = {Abari, Kalman and Csapo, Tamas Gabor and Toth, Balint Pal and Olaszy,
   Gabor},
Book-Group-Author = {{ISCA-INT SPEECH COMMUN ASSOC}},
Title = {{From text to formants - indirect model for trajectory prediction based
   on a multi-speaker parallel speech database}},
Booktitle = {{16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2015), VOLS 1-5}},
Year = {{2015}},
Pages = {{623-627}},
Note = {{16th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2015),
   Dresden, GERMANY, SEP 06-10, 2015}},
Organization = {{NISCAN; TU Berlin; TUBS Sci Mkt; EZ Alibaba Grp; Telekon Innovat Lab;
   Google; Amazon Echo; Facebook; Microsoft; Citrix; Datamall; NXP
   Software; E Sigma; ELRA; European Media Lab GmbH; EML; Nuance;
   Linguwerk; Speech Ocean}},
Abstract = {{An indirect model is presented, capable of estimating formant
   trajectories from text only (Text-to-Formants, TTF). The result is a
   phonetically correct formant trajectory flow of any virtual speech
   signal, i.e. one that has never been uttered. The focus is on the
   pattern forms inside the given sound, taking into account the sound
   environment (up to quinphone), and not on individual formant value
   measurements. The model is based on a multi-speaker parallel speech
   database with precise manual corrections and a HMM-based formant
   trajectory predictor. The validation of the TTF model shows that formant
   trajectories can be predicted with good accuracy from text. The model
   indirectly gives information about a theoretically possible articulation
   flow of the sentence. Thus it gives a general `formantprint' of the
   language.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Abari, K (Corresponding Author), Univ Debrecen, Debrecen, Hungary.
   Abari, Kalman, Univ Debrecen, Debrecen, Hungary.
   Csapo, Tamas Gabor; Toth, Balint Pal; Olaszy, Gabor, Budapest Univ Technol \& Econ, Dept Telecommu \& Media Informat, Budapest, Hungary.}},
ISBN = {{978-1-5108-1790-6}},
Keywords = {{formant trajectory prediction; HMM; reference formant database; sentence
   pattern; multi-speaker; parallel}},
Keywords-Plus = {{VOWELS}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{abari.kalman@arts.unideb.hu
   csapot@tmit.bme.hu
   toth.b@tmit.bme.hu
   olaszy@tmit.bme.hu}},
ResearcherID-Numbers = {{Csapo, Tamas Gabor/AAH-4175-2020}},
ORCID-Numbers = {{Csapo, Tamas Gabor/0000-0003-4375-7524}},
Cited-References = {{Abari K., 2013, THESIS.
   Abari K., 2011, P 8 MAG SZAM NYELV K, P309.
   Abari K., 2011, P INT, P1262.
   Anumanchipalli G. K., 2010, P SSW 7, V7, P206.
   Boersma P., PRAAT DOING PHONETIC.
   Cai M.-Q., 2014, P INT, P1529.
   Deng L, 2006, INT CONF ACOUST SPEE, P369.
   Hermes DJ, 1998, J SPEECH LANG HEAR R, V41, P73, DOI 10.1044/jslhr.4101.73.
   Hu H., THESIS.
   Jemaa I., 2009, P INT 2009, P1677.
   Lei M., 2011, P INT, P2777.
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396.
   Olaszy G., 2008, PHONETICIAN, V97, P6.
   Olaszy G., 2015, BESZEDKUTATAS, P223.
   Olaszy G., 2013, BESZEDKUTATAS 2013, P261.
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381.
   TALKIN D, 1987, J ACOUST SOC AM S, V1, pS55.
   Toth B., 2010, ACTA CYBERNET, V19, P715.
   Vicsi K., 1998, BESZEDKUTATAS, P163.
   Zen T. Nose, 2007, P ISCA SSW6, P294.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BF3TT}},
Unique-ID = {{ISI:000380581600126}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380581600268,
Author = {Korenevsky, Maxim L. and Smirnov, Andrey B. and Mendelev, Valentin S.},
Book-Group-Author = {{ISCA-INT SPEECH COMMUN ASSOC}},
Title = {{Prediction of Speech Recognition Accuracy for Utterance Classification}},
Booktitle = {{16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2015), VOLS 1-5}},
Year = {{2015}},
Pages = {{1275-1279}},
Note = {{16th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2015),
   Dresden, GERMANY, SEP 06-10, 2015}},
Organization = {{NISCAN; TU Berlin; TUBS Sci Mkt; EZ Alibaba Grp; Telekon Innovat Lab;
   Google; Amazon Echo; Facebook; Microsoft; Citrix; Datamall; NXP
   Software; E Sigma; ELRA; European Media Lab GmbH; EML; Nuance;
   Linguwerk; Speech Ocean}},
Abstract = {{The paper deals with the problem of predicting speech recognition
   quality and filtering poorly recognized utterances in the case when no
   reference transcripts are available. In the proposed system, word error
   rate (WER) predictions for individual utterances are made using
   conditional random fields (CRF), and classification based on a given
   threshold is performed afterwards. We propose using a boosting
   technique, which significantly increases recall for high precision
   values. We also apply Recurrent Neural Networks (RNN) directly to the
   utterance classification task and obtain comparable results but with a
   much simpler system. All experiments were carried out on Russian
   spontaneous conversational speech.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Korenevsky, ML (Corresponding Author), ITMO Univ, St Petersburg, Russia.
   Korenevsky, Maxim L.; Smirnov, Andrey B.; Mendelev, Valentin S., ITMO Univ, St Petersburg, Russia.
   Mendelev, Valentin S., Speech Technol Ctr Ltd, St Petersburg, Russia.
   Korenevsky, Maxim L.; Smirnov, Andrey B., STC Innovat Ltd, St Petersburg, Russia.}},
ISBN = {{978-1-5108-1790-6}},
Keywords = {{word error rate (WER) prediction; conditional random field (CRF);
   precision-recall; boosting; recurrent neural nets}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{korenevsky@speechpro.com
   smirnov-a@speechpro.com
   mendelev@speechpro.com}},
Cited-References = {{{[}Anonymous], 1998, SOUND SYSTEM EQUIPME.
   {[}Anonymous], 1997, METHODS CALCULATION.
   Benbouzid D, 2012, J MACH LEARN RES, V13, P549.
   Chen S., 1998, DARP BROADC NEWS TRA.
   Fish R., 2006, TECH REP.
   Fukutomi T, 2011, INT CONF ACOUST SPEE, P5584.
   Graves A, RNNLIB RECURRENT NEU.
   Graves A., 2009, STUDIES COMPUTATIONA, V385.
   Kobashikawa S, 2014, COMPUT SPEECH LANG, V28, P1287, DOI 10.1016/j.csl.2014.05.001.
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282.
   Levin K, 2014, INTERSPEECH, P1438.
   Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152.
   Ogawa A, 2013, INT CONF ACOUST SPEE, P6832, DOI 10.1109/ICASSP.2013.6638985.
   Ogawa A, 2012, INT CONF ACOUST SPEE, P4925, DOI 10.1109/ICASSP.2012.6289024.
   Pallotta V., 2011, 5 INT WORKSH NEW CHA.
   Pappu A., 2014, 5 INT WORKSH SER SPO, P39.
   Pincus E., 2013, P SIGDIAL C, P132.
   Subramaniam LV, 2009, PROC INT CONF DATA, P1391, DOI 10.1109/ICDE.2009.41.
   van Wijngaarden S, 2012, ACOUST AUST, V40, P134.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BF3TT}},
Unique-ID = {{ISI:000380581600268}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380581600332,
Author = {Moungsri, Decha and Koriyama, Tomoki and Kobayashi, Takao},
Book-Group-Author = {{ISCA-INT SPEECH COMMUN ASSOC}},
Title = {{Duration Prediction Using Multi-Level Model for GPR-Based Speech
   Synthesis}},
Booktitle = {{16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2015), VOLS 1-5}},
Year = {{2015}},
Pages = {{1591-1595}},
Note = {{16th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2015),
   Dresden, GERMANY, SEP 06-10, 2015}},
Organization = {{NISCAN; TU Berlin; TUBS Sci Mkt; EZ Alibaba Grp; Telekon Innovat Lab;
   Google; Amazon Echo; Facebook; Microsoft; Citrix; Datamall; NXP
   Software; E Sigma; ELRA; European Media Lab GmbH; EML; Nuance;
   Linguwerk; Speech Ocean}},
Abstract = {{This paper introduces frame-based Gaussian process regression (GPR) into
   phone/syllable duration modeling for Thai speech synthesis. The GPR
   model is designed for predicting frame level acoustic features using
   corresponding frame information, which includes relative position in
   each unit of utterance structure and linguistic information such as tone
   type and part of speech. Although the GPR-based prediction can be
   applied to a phone duration model, the ase of phone duration model only
   is not always sufficient to generate natural sounding speech.
   Specifically, in some languages including Thai, syllable durations
   affect the perception of sentence structure. In this paper, we propose a
   duration prediction technique using a multi-level model which includes
   syllable and phone levels for prediction. In the technique, first,
   syllable durations are predicted, and then they are used as additional
   contexts in phone{''}Ievel model to generate phone duration for
   synthesizing. Objective and subjective evaluation results show that
   GPR-based modeling with multi-level model for duration prediction
   outperforms the conventional ventional HMM-based speech synthesis.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Moungsri, D (Corresponding Author), Tokyo Inst Technol, Interdisciplinary Grad Sch Sci \& Engn, Tokyo, Japan.
   Moungsri, Decha; Koriyama, Tomoki; Kobayashi, Takao, Tokyo Inst Technol, Interdisciplinary Grad Sch Sci \& Engn, Tokyo, Japan.}},
ISBN = {{978-1-5108-1790-6}},
Keywords = {{Duration prediction; GPR-based speech synthesis; multi-level modeling;
   tonal language}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{moungsri.d.aa@m.titech.ac.jp
   koriyama@ip.titech.ac.jp
   takao.kobayashi@ip.titech.ac.jp}},
Cited-References = {{Chen SH, 2014, IEEE-ACM T AUDIO SPE, V22, P1158, DOI 10.1109/TASLP.2014.2321482.
   Chomphan S., 2007, P INTERSPEECH, P2849.
   Hansakunbuntheung C., 2005, P SNLP, P127.
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5.
   Koriyama Tomoki, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3834, DOI 10.1109/ICASSP.2014.6854319.
   KORIYAMA T, 2015, P ICASSP, P4929.
   Koriyama T., 2013, P INTERSPEECH, P1072.
   Koriyama T, 2014, IEEE J-STSP, V8, P173, DOI 10.1109/JSTSP.2013.2283461.
   Koriyama T, 2013, INT CONF ACOUST SPEE, P8007, DOI 10.1109/ICASSP.2013.6639224.
   Potisuk S, 1996, PHONETICA, V53, P200, DOI 10.1159/000262201.
   Qian Y, 2011, IEEE T AUDIO SPEECH, V19, P1702, DOI 10.1109/TASL.2010.2097248.
   Snelson E., 2007, INT C ART INT STAT, P524.
   Yoshimura T, 1999, P EUR, P2347, DOI DOI 10.1093/IETISY/E90-D.3.692.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BF3TT}},
Unique-ID = {{ISI:000380581600332}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380581600458,
Author = {Wang, Yang and Yang, Minghao and Wen, Zhengqi and Tao, Jianhua},
Book-Group-Author = {{ISCA-INT SPEECH COMMUN ASSOC}},
Title = {{Combining Extreme Learning Machine and Decision Tree for Duration
   Prediction in HMM based Speech Synthesis}},
Booktitle = {{16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2015), VOLS 1-5}},
Year = {{2015}},
Pages = {{2197-2201}},
Note = {{16th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2015),
   Dresden, GERMANY, SEP 06-10, 2015}},
Organization = {{NISCAN; TU Berlin; TUBS Sci Mkt; EZ Alibaba Grp; Telekon Innovat Lab;
   Google; Amazon Echo; Facebook; Microsoft; Citrix; Datamall; NXP
   Software; E Sigma; ELRA; European Media Lab GmbH; EML; Nuance;
   Linguwerk; Speech Ocean}},
Abstract = {{Hidden Markov Model (HMM) based speech synthesis using Decision Tree
   (DT) for duration prediction is known to produce over-averaged rhythm.
   To alleviate this problem, this paper proposes a two level duration
   prediction method together with outlier removal. This method takes
   advantages of accurate regression capability by Extreme Learning Machine
   (ELM) for phone level duration prediction, and the capability of
   distributing state durations by DT for state level duration prediction.
   Experimental results showed that the method decreased RMSE of phone
   duration, increased the fluctuation of syllable duration, and achieved
   63.75\% in preference evaluation. Furthermore, this method does not
   incur laborious manual alignment on training corpus.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, Y (Corresponding Author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   Wang, Yang; Yang, Minghao; Wen, Zhengqi; Tao, Jianhua, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   Tao, Jianhua, Chinese Acad Sci, Beijing Key Lab Mobile Comp \& Pervas Device, Inst Comp Technol, Beijing, Peoples R China.}},
ISBN = {{978-1-5108-1790-6}},
Keywords = {{speech synthesis; duration prediction; extreme learning machine}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{yangwang@nlpr.ia.ac.cn
   mhyang@nlpr.ia.ac.cn
   zqwen@nlpr.ia.ac.cn
   jhtao@nlpr.ia.ac.cn}},
Cited-References = {{Goubanova O, 2008, SPEECH COMMUN, V50, P301, DOI 10.1016/j.specom.2007.10.002.
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001.
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y.
   Ishimatsu Y., SP2001812001 IEICE.
   King S, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.006.
   Latorre J., 2010, P 5 SPEECH PROS WORK.
   Lazaridis A., 2014, SVR VS MLP PHONE DUR.
   Lazaridis A, 2012, COMPUT SPEECH LANG, V26, P274, DOI 10.1016/j.csl.2012.01.009.
   Lazaridis A, 2011, SPEECH COMMUN, V53, P85, DOI 10.1016/j.specom.2010.07.005.
   Lu H, 2009, INT CONF ACOUST SPEE, P4033, DOI 10.1109/ICASSP.2009.4960513.
   Ogbureke U., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P700, DOI 10.1109/ISSPA.2012.6310643.
   Qian Y, 2011, IEEE T AUDIO SPEECH, V19, P1702, DOI 10.1109/TASL.2010.2097248.
   Silen H., 2010, P SPEECH PROS.
   Tokuda K, 2002, IEICE T INF SYST, VE85D, P455.
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820.
   Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852.
   {[}吴义坚 WU Yijian], 2006, {[}中文信息学报, Journal of Chinese Information Processing], V20, P75.
   Yamagishi J, 2008, SPEECH COMMUN, V50, P405, DOI 10.1016/j.specom.2007.12.003.
   Yoshida T, 1998, INTERNATIONAL ELECTRON DEVICES MEETING 1998 - TECHNICAL DIGEST, P29, DOI 10.1109/IEDM.1998.746239.
   Zen H., 2007, P 6 ISCA WORKSH SPEE, P294.
   Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BF3TT}},
Unique-ID = {{ISI:000380581600458}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380581601072,
Author = {Chen, Fei},
Book-Group-Author = {{ISCA-INT SPEECH COMMUN ASSOC}},
Title = {{Improving the Prediction Power of the Speech Transmission Index to
   Account for Non-linear Distortions Introduced by Noise-Reduction
   Algorithms}},
Booktitle = {{16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2015), VOLS 1-5}},
Year = {{2015}},
Pages = {{2573-2577}},
Note = {{16th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2015),
   Dresden, GERMANY, SEP 06-10, 2015}},
Organization = {{NISCAN; TU Berlin; TUBS Sci Mkt; EZ Alibaba Grp; Telekon Innovat Lab;
   Google; Amazon Echo; Facebook; Microsoft; Citrix; Datamall; NXP
   Software; E Sigma; ELRA; European Media Lab GmbH; EML; Nuance;
   Linguwerk; Speech Ocean}},
Abstract = {{Although the speech transmission index (STI) has been shown to predict
   successfully the effects of linear distortions introduced by filtering
   and additive noise, it does not account for non-linear distortions
   present in noise-suppressed speech. In this study, the normalized
   covariance metric (NCM), a STI-based intelligibility measure, was
   modified to reduce the effects of non-linear distortions introduced by
   most noise-suppression algorithms for intelligibility prediction. This
   was done by designing a new definition of the output signal-to-noise
   ratio to compensate the biased estimation of the input SNR prior to the
   noise-suppression processing. The modified NCM measure was evaluated
   with intelligibility scores obtained by normal-hearing listeners in 72
   noisy conditions involving noise-suppressed speech corrupted by four
   different maskers (babble, car, train and street interferences).
   Significantly higher correlation with intelligibility score was obtained
   from the modified NCM measure, in contrast to those from the original
   NCM measure.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Chen, F (Corresponding Author), South Univ Sci \& Technol China, Deptpartment Elect \& Elect Engn, Shenzhen, Peoples R China.
   Chen, Fei, South Univ Sci \& Technol China, Deptpartment Elect \& Elect Engn, Shenzhen, Peoples R China.}},
ISBN = {{978-1-5108-1790-6}},
Keywords = {{Intelligibility prediction; speech-transmission index; noise-suppression
   algorithms}},
Keywords-Plus = {{INTELLIGIBILITY; AUDITORIA}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{fchen@sustc.edu.cn}},
ResearcherID-Numbers = {{Chen, Fei/AAK-6755-2020
   Chen, Fei/G-4674-2018}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Cited-References = {{Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   HOHMANN V, 1995, J ACOUST SOC AM, V97, P1191, DOI 10.1121/1.413092.
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224.
   Hu Y, 2007, J ACOUST SOC AM, V122, P1777, DOI 10.1121/1.2766778.
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kim G, 2011, J ACOUST SOC AM, V130, P1581, DOI 10.1121/1.3619790.
   Loizou PC, 2013, SPEECH ENHANCEMENT T.
   Loizou PC, 2011, J ACOUST SOC AM, V130, P986, DOI 10.1121/1.3605668.
   LU Y, 2010, P IEEE INT C AC SPEE, P4754.
   LUDVIGSEN C, 1993, SCAND AUDIOL, V22, P50.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Quackenbush S., 1988, OBJECTIVE MEASURES S.
   STEENEKEN HJM, 1982, ACUSTICA, V51, P229.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEIGER JH, 1980, PSYCHOL BULL, V87, P245, DOI 10.1037/0033-2909.87.2.245.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BF3TT}},
Unique-ID = {{ISI:000380581601072}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380604800015,
Author = {Ding, Chuang and Xie, Lei and Yan, Jie and Zhang, Weini and Liu, Yang},
Book-Group-Author = {{IEEE}},
Title = {{AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING
   BLSTM-RNN AND EMBEDDING FEATURES}},
Booktitle = {{2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING
   (ASRU)}},
Year = {{2015}},
Pages = {{98-102}},
Note = {{IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),
   Scottsdale, AR, DEC 13-17, 2015}},
Organization = {{IEEE; IEEE Signal Processing Soc; Inst Elect \& Elect Engn}},
Abstract = {{Prosody affects the naturalness and intelligibility of speech. However,
   automatic prosody prediction from text for Chinese speech synthesis is
   still a great challenge and the traditional conditional random fields
   (CRF) based method always heavily relies on feature engineering. In this
   paper, we propose to use neural networks to predict prosodic boundary
   labels directly from Chinese characters without any feature engineering.
   Experimental results show that stacking feed-forward and bidirectional
   long short-term memory (BLSTM) recurrent network layers achieves
   superior performance over the CRF-based method. The embedding features
   learned from raw text further enhance the performance.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ding, C (Corresponding Author), Northwestern Polytech Univ, Sch Comp Sci, Xian, Peoples R China.
   Ding, Chuang; Xie, Lei, Northwestern Polytech Univ, Sch Comp Sci, Xian, Peoples R China.
   Xie, Lei; Yan, Jie; Zhang, Weini; Liu, Yang, Northwestern Polytech Univ, Sch Software \& Microelect, Xian, Peoples R China.}},
ISBN = {{978-1-4799-7291-3}},
Keywords = {{automatic prosody prediction; speech synthesis; neural network; BLSTM;
   embedding features}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{cding@nwpu-aslp.org
   lxie@nwpu-aslp.org
   jyan@nwpu-aslp.org
   wnzhang@nwpu-aslp.org
   yangliu@nwpu-aslp.org}},
Cited-References = {{Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223.
   CHU M, 2001, COMPUT LINGUIST, V6, P61.
   Collobert R, 2011, J MACH LEARN RES, V12, P2493.
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   HORIKAWA S, 1992, IEEE T NEURAL NETWOR, V3, P801, DOI 10.1109/72.159069.
   Jeon JH, 2009, INT CONF ACOUST SPEE, P4565, DOI 10.1109/ICASSP.2009.4960646.
   Jingwei Sun, 2009, Proceedings of the 2009 Fifth International Conference on Natural Computation (ICNC 2009), P602, DOI 10.1109/ICNC.2009.44.
   Koehn P, 2000, INT CONF ACOUST SPEE, P1289, DOI 10.1109/ICASSP.2000.861813.
   Lafferty J.D., 2001, P INT C MACH LEARN, V18, P282.
   Levow G., 2008, P IJCNLP, P217.
   Li Jianfeng, 2004, INT 2004 JEJ ISL KOR, P729.
   Mansur Mairgup, 2013, P 6 IJCNLP, V1, P2.
   Mikolov T., 2013, P NAACL 2013, P746.
   Mikolov T, 2013, ADV NEURAL INFORM PR, P3119, DOI DOI 10.1162/JMLR.2003.3.4-5.951.
   {[}聂鑫 Nie Xin], 2003, {[}中文信息学报, Journal of Chinese Information Processing], V17, P39.
   Pei WZ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P293.
   Rangarajan V., 2007, P NAACL HLT, P1.
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093.
   Sheng Z., 2002, P 1 SIGHAN WORKSH CH, V18, P1.
   Weninger F., 2014, J MACHINE LEARNING R, V15.
   Williams R. J., 1995, BACK PROPAGATION THE, P433.
   Yao Qian, 2010, Proceedings 7th International Symposium on Chinese Spoken Language Processing (ISCSLP 2010), P135, DOI 10.1109/ISCSLP.2010.5684835.
   Zheng X, 2013, EMNLP, P647.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BF3XU}},
Unique-ID = {{ISI:000380604800015}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380433100051,
Author = {Sarkar, Parakrant and Rao, K. Sreenivasa},
Book-Group-Author = {{IEEE}},
Title = {{Data-Driven Pause Prediction for Synthesis of Storytelling Style Speech
   based on Discourse Modes}},
Booktitle = {{2015 IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, COMPUTING AND
   COMMUNICATION TECHNOLOGIES (CONECCT)}},
Year = {{2015}},
Note = {{IEEE International Conference on Electronics Computing and Communication
   Technologies (CONECCT), Bangalore, INDIA, JUL 10-11, 2015}},
Abstract = {{In storytelling style, a storyteller generally uses prosodic variations
   with subtle speech nuances for the better apprehension of the listeners.
   It is achieved by emphasizing prominent words, using various emotions,
   mimicking voices and providing appropriate pauses. This work is a part
   of building the Story Text-to-Speech (TTS) {[}1] synthesis systems in
   Indian Languages, which aims at synthesizing the storytelling style
   speech from the neutral TTS. The neutral speech is converted to
   storytelling style by modifying the specific prosodic parameters (i.e.
   duration, pitch, tempo, intensity and pauses). The main contribution of
   this paper is to model the pause patterns present in storytelling style
   speech based on the modes of discourse: narrative, descriptive and
   dialogue to capture the story-semantic information. Analysis of pause
   patterns are carried out for children stories in Hindi language. We
   analyzed the pause patterns and classified pauses into three different
   categories: short, medium and long pauses for each mode of discourse. A
   three stage data-driven method is proposed to predict the position and
   duration of the pauses. We conducted objective test to evaluate the
   performance of the proposed method at each stage. Also, subjective
   evaluation is carried out on the final output of the Hindi Story-TTS
   system. The subjective evaluation connotes that the subjects have
   perceived an improvement in speech quality in terms of storytelling
   style.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sarkar, P (Corresponding Author), Indian Inst Technol Kharagpur, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
   Sarkar, Parakrant; Rao, K. Sreenivasa, Indian Inst Technol Kharagpur, Sch Informat Technol, Kharagpur 721302, W Bengal, India.}},
ISBN = {{978-1-4799-9985-9}},
Keywords = {{Discourse modes; Storytelling Style; Pause prediction; Speech Synthesis;
   Phrasing; Pause duration}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{parakrantsarkar@gmail.com
   ksrao@iitkgp.ac.in}},
Cited-References = {{Adell J., 2005, PROCESAMIENTO LENGUA, V35.
   Alm C., 2008, TECH REP.
   Black A, 1997, HCRCTR83 U ED.
   Braunschweiler N., 2013, 8 ISCA SPEECH SYNTH, V8, P1.
   Ghosh K, 2012, COMM COM INF SC, V306, P118.
   Harikrishna D. M., 2015, INT C COMP COMM CONT.
   Harikrishna D. M., 2015, 4 INT S NAT LANG PRO.
   Hogg R., 1987, MATH STAT.
   Kim S., 2006, INTERSPEECH 2006.
   King  S., 2011, INTERSPEECH, P2157.
   KING SE, COMMUNICATION.
   Klatt D. H., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1589.
   Krishna N. S., 2004, INTERSPEECH.
   Montao R., 2013, 8 ISCA WORKSH SPEECH, P191.
   Parlikar A., 2012, INTERSPEECH.
   Parlikar Alok, 2011, P INT FLOR IT AUG, P2149.
   Prahallad K., 2007, INTERSPEECH, P2901.
   Rao KS, 2007, COMPUT SPEECH LANG, V21, P282, DOI 10.1016/j.csl.2006.06.003.
   Rijsbergen C.V., 1979, INFORM RETRIEVAL.
   Sarkar P., 2015, 2015 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2015.7157709.
   Sarkar P., 2014, 7 INT C CONT COMP IC, P473.
   Schroder M., 2001, INT J SPEECH TECHNOL, V6, P365.
   Schroder M, 2001, P 7 EUR C SPEECH COM, P561.
   Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041.
   Theune M, 2006, IEEE T AUDIO SPEECH, V14, P1137, DOI 10.1109/TASL.2006.876129.
   Vadapalli A., 2013, 8 ISCA SPEECH SYNTH, P189.
   Vadapalli A, 2014, INTERSPEECH, P41.
   Verma R., 2015, ADV PATT REC ICAPR 2, P1.
   Yoon K, 2006, COMPUT SPEECH LANG, V20, P69, DOI 10.1016/j.csl.2005.01.001.
   Zervas P., 2003, EUROSPEECH.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BF1SM}},
Unique-ID = {{ISI:000380433100051}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380477600146,
Author = {Reddy, Chandan K. A. and Montazeri, Vahid and Rao, Yu and Panahi, Issa
   M. S.},
Book-Group-Author = {{IEEE}},
Title = {{SINGLE CHANNEL SPEECH ENHANCEMENT TECHNIQUE FOR LOW SNR QUASI-PERIODIC
   NOISE BASED ON REDUCED ORDER LINEAR PREDICTION1}},
Booktitle = {{2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING
   (GLOBALSIP)}},
Year = {{2015}},
Pages = {{712-716}},
Note = {{3rd IEEE Global Conference on Signal and Information Processing
   (GlobalSIP), Orlando, FL, DEC 13-16, 2015}},
Organization = {{IEEE; IEEE Signal Proc Soc}},
Abstract = {{In this paper we propose an efficient single microphone (single channel)
   speech enhancement (SE) method for Quasi Stationary noise environment.
   The proposed method estimates the noise by exploiting its quasi-periodic
   nature, followed by a statistical model based method to enhance the
   speech. An efficient reduced-order linear predictive error filtering is
   introduced to increase the signal to noise ratio (SNR) of the noisy
   speech. The proposed method is evaluated experimentally by considering
   the actual recorded Functional Magnetic Resonance Imaging (fMRI)
   machinery noise which is quasi periodic in nature, added in clean
   speech. Objective evaluation of our method shows improvement in both
   quality and intelligibility measures when tested with the sentences
   chosen from IEEE corpus added in broadband quasi periodic fMRI noise.
   The proposed method outperforms the standard statistical model based SE
   technique.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Reddy, CKA (Corresponding Author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.
   Reddy, Chandan K. A.; Montazeri, Vahid; Rao, Yu; Panahi, Issa M. S., Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.}},
ISBN = {{978-1-4799-7591-4}},
Keywords = {{Reduced- order linear prediction; quasi-periodic; single microphone;
   speech enhancement}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Cited-References = {{GRUBER P, 1994, IEEE T SIGNAL PROCES, V42, P552, DOI 10.1109/78.277847.
   HU Y, 2008, T AUDIO SP LANG PROC, V16, P229, DOI DOI 10.1109/TASL.2007.911054.
   Hu K, 2007, INT CONF ACOUST SPEE, P561.
   Hu Y, 2006, INT CONF ACOUST SPEE, P153.
   Kannan G, 2011, IEEE T BIO-MED ENG, V58, P3303, DOI 10.1109/TBME.2010.2096423.
   Kates JM, 2005, IEEE WORK APPL SIG, P53, DOI 10.1109/ASPAA.2005.1540166.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Mansfield P., 2005, MAGNETIC RESONANCE I, V39, P539.
   Proakis J. G., 2007, DIGITAL SIGNAL PROCE.
   Shiran N, 2009, INT WORK QUAL MULTIM, P157, DOI 10.1109/QOMEX.2009.5246960.
   Sierra V., 2008, IEEE T BIOMEDICAL EN.
   Tseng GHC, 2004, P ANN INT IEEE EMBS, V26, P1096.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BF2LH}},
Unique-ID = {{ISI:000380477600146}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380481700027,
Author = {Ehsan, Wajeeha and Jan, Tariqullah},
Book-Group-Author = {{IEEE}},
Title = {{A Novel Approach for Blind Separation and Dereverberation of Speech
   Mixtures using Multiple step Linear Predictive Coding}},
Booktitle = {{2015 INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES (ICET)}},
Year = {{2015}},
Note = {{2015 International Conference on Emerging Technologies (ICET), Peshawar
   Serv Club, Peshawar, PAKISTAN, DEC 19-20, 2015}},
Organization = {{Sarhad Univ Sci \& Informat Technol; CECOS Univ Informat \& Emerging
   Sci; CECOS Univ; Sarhad Univ; IEEE; Higher Educ Commiss; IEEE Power \&
   Energy Soc; IEEE Islamabad Sect; IEEE Peshawar Subsect}},
Abstract = {{A new method for the combination of blind separation and dereverberation
   of speech signals using linear convolutive mixing model is presented.
   The proposed algorithm consists of two parts. In the first part
   pre-filtering process is applied on speech mixtures to predict late
   reverberations by employing long-term multiple-step linear prediction
   (MSLP) and then these late reverberations are mitigated by using
   spectral subtraction (SS) technique. In the second part, a source
   separation technique has been applied consisting of various steps. Here
   in this part, first Independent component analysis (ICA) algorithm is
   used to separate target speech sources from sensor readings using the
   assumptions that sources involved in the mixing process are independent.
   Then by differentiating energy of individual time-frequency signatures
   of the separated target speech signals we compute ideal binary mask
   (IBM). Finally artifacts are suppressed which are normally the basis of
   time varying nature of IBM by means of cepstral smoothing. Simulated
   environment for reverberant mixtures is used to analyse the efficiency
   of our proposed algorithm. Simulations results evaluated in terms of
   signal to noise ratio (SNR) indicate a considerably enhanced quality of
   segregated speech as compared to a previous method.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ehsan, W (Corresponding Author), Univ Engn \& Technol, Dept Elect Engn, Peshawar, Pakistan.
   Ehsan, Wajeeha; Jan, Tariqullah, Univ Engn \& Technol, Dept Elect Engn, Peshawar, Pakistan.}},
ISBN = {{978-1-5090-0436-2}},
Keywords = {{Multiple-step linear prediction (MSLP); dereverberation; ideal binary
   mask (IBM); Independent component analysis (ICA); cepstral smoothing
   (CS); Time-Frequency (T-F)}},
Keywords-Plus = {{NONSTATIONARY SOURCES; ROOM ACOUSTICS; SUPPRESSION; DOMAIN}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Hardware \&
   Architecture; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic}},
Author-Email = {{wajeehaehsankhattak@gmail.com
   tariqullahjan@uetpeshawar.edu.pk}},
Cited-References = {{ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599.
   Araki S, 2003, IEEE T SPEECH AUDI P, V11, P109, DOI 10.1109/TSA.2003.809193.
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   Cichocki A., 2002, ADAPTIVE BLIND SIGNA.
   Delcroix M, 2005, ACOUST SCI TECHNOL, V26, P432, DOI 10.1250/ast.26.432.
   Jan T, 2011, SPEECH COMMUN, V53, P524, DOI 10.1016/j.specom.2011.01.002.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Madhu N, 2008, INT CONF ACOUST SPEE, P45, DOI 10.1109/ICASSP.2008.4517542.
   Oppenheim A. V., 1975, DIGITAL SIGNAL PROCE.
   Parra L, 2000, IEEE T SPEECH AUDI P, V8, P320, DOI 10.1109/89.841214.
   Pedersen MS, 2008, IEEE T NEURAL NETWOR, V19, P475, DOI 10.1109/TNN.2007.911740.
   POLACK JD, 1993, APPL ACOUST, V38, P235, DOI 10.1016/0003-682X(93)90054-A.
   Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6\_12.
   Wang WW, 2005, IEEE T SIGNAL PROCES, V53, P1654, DOI 10.1109/TSP.2005.845433.
   WU M, 2003, P IEEE INT C AC SPEE, V1, P844.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BF2MY}},
Unique-ID = {{ISI:000380481700027}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380516500024,
Author = {Tykhonov, Vvacheslav A. and Kudriavtseva, Nataliia V. and Chmelar, Pavel},
Editor = {{Mustra, M and Tralic, D and Zovkocihlar, B}},
Title = {{Factorization of Speech Signals Parametric Spectra Using Multiplicative
   Linear Prediction Models}},
Booktitle = {{PROCEEDINGS OF ELMAR-2015 57TH INTERNATIONAL SYMPOSIUM ELMAR-2015}},
Year = {{2015}},
Pages = {{93-96}},
Note = {{PROCEEDINGS ELMAR, Zadar, CROATIA, SEP 28-30, 2015}},
Organization = {{Elmar; Ministry Sci Ed Sports Repub Croatia; Ministry Maritime Affairs
   Transport Infrastructure Repub Croatia; Croatian Post Electron Commun
   Agency - HAKOM; HAKOM; Tankerska plovidba d.d.; Town Zadar; OiV; region
   IEEE 8; IEEE CROATIA SECTION; EURASIP; FER; CROATIA; TURISTICKA
   ZAJEDNICA GRADA ZADRA; MARASKA; FALKENSTEINER Hotels Resisences Welcome
   Home}},
Abstract = {{A new approach for a speech signal parametric spectral characterization,
   based on a new factorization method, is proposed in this paper. The
   theoretical basis of the factorization method for multimode speech
   signals spectra is presented in the paper. This method is based on the
   multiplicative polymodels developed by the authors. We also derived
   equations for autoregressive coefficients calculation and for parametric
   power spectrum density of the multiplicative models' calculation. The
   expressions for factorization of spectra of the speech signal's phoneme
   using the multiplicative models are also included in the paper. The
   factorization method for spectral estimations is shown in the examples
   of speech signals parametric spectral estimations.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Tykhonov, VA (Corresponding Author), Kharkiv Natl Univ Radioelect, Kharkov, Ukraine.
   Tykhonov, Vvacheslav A., Kharkiv Natl Univ Radioelect, Kharkov, Ukraine.
   Kudriavtseva, Nataliia V.; Chmelar, Pavel, Univ Pardubice, Dept Elect Engn, Pardubice, Czech Republic.}},
ISBN = {{978-9-5318-4209-9}},
Keywords = {{Linear Prediction Model; Autoregression; Factorization; Power Spectrum
   Density}},
Keywords-Plus = {{SPEAKER IDENTIFICATION}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{nataliia.kudriavtseva@gmail.com}},
Cited-References = {{Faundez-Zanuy M, 2006, SPEECH COMMUN, V48, P1608, DOI 10.1016/j.specom.2006.06.010.
   Gudnason J, 2008, INT CONF ACOUST SPEE, P4821, DOI 10.1109/ICASSP.2008.4518736.
   HAUTAMAKI V, 2010, INTERSPEECH 2010, P1473.
   Kelly John L., 1962, P 4 INT C AC, P1.
   Kudriavtseva N. V., 2014, RADIOELEKTRONIKA 201, P1.
   Kudriavtseva N. V., 2012, IEEE E W DES TEST S, P538.
   Laskowski K, 2009, INT CONF ACOUST SPEE, P4541, DOI 10.1109/ICASSP.2009.4960640.
   Thomas S., 2008, P 16 EUR SIGN PROC C.
   Tykhonov V.A., 2010, APPL RADIOELECTRONIC, V9, P209.
   Tykhonov V.A., 2010, RADIOTEKNIKA J, V162, P140.
   Tykhonov V.A., 1999, RADIOELEKTRONIKA INF, P83.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BF3AO}},
Unique-ID = {{ISI:000380516500024}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000377943800066,
Author = {Casamitjana, Adria and Sundin, Martin and Ghosh, Prasanta and
   Chatterjee, Saikat},
Book-Group-Author = {{IEEE}},
Title = {{BAYESIAN LEARNING FOR TIME-VARYING LINEAR PREDICTION OF SPEECH}},
Booktitle = {{2015 23RD EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO)}},
Series = {{European Signal Processing Conference}},
Year = {{2015}},
Pages = {{325-329}},
Note = {{23rd European Signal Processing Conference (EUSIPCO), Nice, FRANCE, AUG
   31-SEP 04, 2015}},
Organization = {{EURECOM}},
Abstract = {{We develop Bayesian learning algorithms for estimation of time-varying
   linear prediction (TVLP) coefficients of speech. Estimation of TVLP
   coefficients is a naturally underdetermined problem. We consider
   sparsity and subspace based approaches for dealing with the
   corresponding underdetermined system. Bayesian learning algorithms are
   developed to achieve better estimation performance.
   Expectation-maximization (EM) framework is employed to develop the
   Bayesian learning algorithms where we use a combined prior to model a
   driving noise (glottal signal) that has both sparse and dense
   statistical properties. The efficiency of the Bayesian learning
   algorithms is shown for synthetic signals using spectral distortion
   measure and formant tracking of real speech signals.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Casamitjana, A (Corresponding Author), KTH Royal Inst Technol, ACCESS Linneaus Ctr, Stockholm, Sweden.
   Casamitjana, Adria; Sundin, Martin; Chatterjee, Saikat, KTH Royal Inst Technol, ACCESS Linneaus Ctr, Stockholm, Sweden.
   Ghosh, Prasanta, Indian Inst Sci, Dept Elect Engn, Bengaluru, Karnataka, India.}},
ISSN = {{2076-1465}},
ISBN = {{978-0-9928-6263-3}},
Keywords = {{Time-varying linear prediction; sparsity; Bayesian learning;
   expectation-maximization}},
Keywords-Plus = {{NONSTATIONARY SIGNALS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{adriacd@kth.se
   masundi@kth.se
   prasantg@ee.iisc.ernet.in
   sach@kth.se}},
Cited-References = {{Chetupalli S., 2014, AC SPEECH SIGN PROC, P6290.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Giri R., 2014, AC SPEECH SIGN PROC, P3754.
   GRENIER Y, 1983, IEEE T ACOUST SPEECH, V31, P899, DOI 10.1109/TASSP.1983.1164152.
   HALL MG, 1983, SIGNAL PROCESS, V5, P267, DOI 10.1016/0165-1684(83)90074-9.
   LIPORACE LA, 1975, J ACOUST SOC AM, V58, P1288, DOI 10.1121/1.380811.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Markel JD, 1976, LINEAR PREDICTION SP.
   Rudoy D, 2011, IEEE T AUDIO SPEECH, V19, P977, DOI 10.1109/TASL.2010.2073704.
   Sundin M., 2014, SIGN PROC COMM SPCOM, P1.
   Sundin M., 2014, SIGN PROC C EUSIPCO, P1841.
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236.
   TSATSANIS MK, 1993, IEEE T SIGNAL PROCES, V41, P3512, DOI 10.1109/78.258089.
   Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BE9OB}},
Unique-ID = {{ISI:000377943800066}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000364718200009,
Author = {Flanagan, Brendan and Yin, Chengjiu and Suzuki, Takahiko and Hirokawa,
   Sachio},
Editor = {{Zaphiris, P and Ioannou, A}},
Title = {{Prediction of Learner Native Language by Writing Error Pattern}},
Booktitle = {{LEARNING AND COLLABORATION TECHNOLOGIES, LCT 2015}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2015}},
Volume = {{9192}},
Pages = {{87-96}},
Note = {{2nd International Conference on Learning and Collaboration Technologies
   (LCT) Held as Part of 17th International Conference on Human-Computer
   Interaction (HCI International), Los Angeles, CA, AUG 02-07, 2015}},
Abstract = {{The native language of a foreign language learner can have an effect on
   the errors they make because of similarities or differences between the
   two languages. In order to provide effective error prediction and
   correction for non-native English language learners it is important to
   identify their specific characteristic error patterns that are
   influenced by their native language. In this paper, we examine analyzing
   error detection scores to predict the native language of an English
   language learner. 15 categories of error detection scores are combined
   to create an error prediction score vector representation of each
   sentence. The native language is predicted by training an SVM classifier
   with the error vectors. The results are compared to an SVM classifier
   trained with just word representations of the learner writing sentences.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Flanagan, B (Corresponding Author), Kyushu Univ, Grad Sch Informat Sci \& Elect Engn, Fukuoka 812, Japan.
   Flanagan, Brendan, Kyushu Univ, Grad Sch Informat Sci \& Elect Engn, Fukuoka 812, Japan.
   Yin, Chengjiu, Kyushu Univ, Fac Arts \& Sci, Fukuoka 812, Japan.
   Suzuki, Takahiko; Hirokawa, Sachio, Kyushu Univ, Res Inst Informat Technol, Fukuoka 812, Japan.}},
DOI = {{10.1007/978-3-319-20609-7\_9}},
ISSN = {{0302-9743}},
ISBN = {{978-3-319-20609-7; 978-3-319-20608-0}},
Keywords = {{Native language prediction; Writing errors; SVM classifier}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods}},
Author-Email = {{b.flanagan.885@s.kyushu-u.ac.jp
   yin.academic@gmail.com
   suzuki@cc.kyushu-u.ac.jp
   hirokawa@cc.kyushu-u.ac.jp}},
ResearcherID-Numbers = {{Flanagan, Brendan J/B-6234-2016
   Yin, Chengjiu/E-9570-2018
   Flanagan, Brendan/ABF-7586-2020
   Yin, Chengjiu/AAV-3774-2020
   Hirokawa, Sachio/S-3526-2018}},
ORCID-Numbers = {{Flanagan, Brendan J/0000-0001-7644-997X
   Yin, Chengjiu/0000-0003-1492-5250
   Flanagan, Brendan/0000-0001-7644-997X
   Yin, Chengjiu/0000-0003-1492-5250
   Hirokawa, Sachio/0000-0002-8050-1109}},
Cited-References = {{Bestgen Y., 2012, APPROACHING LANGUAGE, P127.
   Brooke J, 2013, 20 YEARS LEARNER COR, P37.
   Flanagan Brendan, 2014, International Journal of Knowledge and Web Intelligence, V5, P21, DOI 10.1504/IJKWI.2014.065063.
   Flanagan B., 2013, ISEEE2013, P733.
   Flanagan B, 2013, INT J DIST EDUC, V11, P63, DOI 10.4018/ijdet.2013100105.
   Flanagan B, 2014, 2014 IIAI 3RD INTERNATIONAL CONFERENCE ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2014), P318, DOI 10.1109/IIAI-AAI.2014.72.
   Flanagan B, 2013, FRONT ARTIF INTEL AP, V254, P174, DOI 10.3233/978-1-61499-262-2-174.
   Graddol D., 2006, ENGLISH NEXT WHY GLO.
   Guo Y., 2007, CONVERGENCE, V40, P117.
   Jarvis S., 2013, NAACL HLT, P111.
   Kochmar E., 2011, THESIS.
   KOPPEL M, 2005, P 11 ACM SIGKDD INT, P624.
   Kroll B, 1990, 2 LANGUAGE WRITING R, P140, DOI {[}DOI 10.1017/CBO9781139524551.014, 10.1017/CBO9781139524551.014].
   Tetreault J., 2013, P 8 WORKSH INN US NL, P48.
   Weltig M. S., 2004, SPAAN FELLOW WORKING, V2, P53.
   Wong Sze-Meng Jojo, 2012, P 2012 JOINT C EMP M, P699.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BD9IF}},
Unique-ID = {{ISI:000364718200009}},
DA = {{2020-12-06}},
}

@article{ ISI:000347683400010,
Author = {Drake, Eleanor and Corley, Martin},
Title = {{Effects in production of word pre-activation during listening: Are
   listener-generated predictions specified at a speech-sound level?}},
Journal = {{MEMORY \& COGNITION}},
Year = {{2015}},
Volume = {{43}},
Number = {{1}},
Pages = {{111-120}},
Month = {{JAN}},
Abstract = {{It has been demonstrated that listener-generated predictions of upcoming
   material can be specified to a phonological level, such that a specific
   word onset is anticipated (e.g., DeLong, Urbach, \& Kutas, Nature
   Neuroscience, 8, 1117-1121, 2005). In the present study, we investigated
   whether such word-form-specific predictions impact picture-naming
   latencies in a manner similar to that observed when a distractor word is
   actually presented. Participants were auditorily presented with
   high-cloze sentence stems, in order to elicit word-form predictions. The
   pictures for naming were presented immediately following the sentence
   stem. We systematically manipulated the phonological relationship
   between the predicted word and the picture name. Across three
   experiments, naming was facilitated when the picture name fully matched
   the predicted word. However, naming was neither facilitated nor
   inhibited when the picture name overlapped phonologically with the
   predicted word. This finding is in contrast to the known effects of
   phonological overlap when a distractor word is heard or read. Our
   findings suggest that words that are internally listener-generated
   (predicted) during comprehension are not robustly specified at a
   speech-sound (phonological) level.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Corley, M (Corresponding Author), Univ Edinburgh, PPLS, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.
   Drake, Eleanor; Corley, Martin, Univ Edinburgh, PPLS, Edinburgh EH8 9JZ, Midlothian, Scotland.}},
DOI = {{10.3758/s13421-014-0451-9}},
ISSN = {{0090-502X}},
EISSN = {{1532-5946}},
Keywords = {{Language comprehension; Language production; Word production; Word
   prediction}},
Keywords-Plus = {{PHONOLOGICAL FACILITATION; INTERFERENCE PARADIGM; SPOKEN PRODUCTION;
   LEXICAL ACCESS; CASCADE MODEL; MOTOR CORTEX; COMPREHENSION; PICTURES;
   EXCITABILITY; COMPETITION}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{Martin.Corley@ed.ac.uk}},
Cited-References = {{Baayen R. H., 2008, ANAL LINGUISTIC DATA, V505.
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001.
   Bates D., 2013, LME4 LINEAR MIXED EF.
   Blackford T, 2012, COGNITION, V123, P84, DOI 10.1016/j.cognition.2011.12.007.
   Brown EC, 2012, NEUROIMAGE, V60, P2335, DOI 10.1016/j.neuroimage.2012.02.040.
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977.
   Damian MF, 2007, J MEM LANG, V57, P195, DOI 10.1016/j.jml.2006.11.001.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x.
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503.
   Goldrick M, 2007, COGNITION, V102, P219, DOI 10.1016/j.cognition.2005.12.010.
   GREENE JO, 1988, HDB STUDY HUMAN COMM, P37.
   Griffin ZM, 1998, J MEM LANG, V38, P313, DOI 10.1006/jmla.1997.2547.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Hirschfeld G, 2008, NEUROREPORT, V19, P1227, DOI 10.1097/WNR.0b013e328309ecd1.
   Humphreys KR, 2010, Q J EXP PSYCHOL, V63, P2289, DOI 10.1080/17470218.2010.509802.
   Janssen N, 2013, LANG COGNITIVE PROC, V28, P672, DOI 10.1080/01690965.2012.746715.
   Jescheniak JD, 2009, EXP PSYCHOL, V56, P56, DOI 10.1027/1618-3169.56.1.56.
   Londei A, 2010, HUM BRAIN MAPP, V31, P567, DOI 10.1002/hbm.20888.
   LUPKER SJ, 1982, CAN J PSYCHOL, V36, P349, DOI 10.1037/h0080652.
   Mahon BZ, 2007, J EXP PSYCHOL LEARN, V33, P503, DOI 10.1037/0278-7393.33.3.503.
   Meyer AS, 2007, MEM COGNITION, V35, P494, DOI 10.3758/BF03193289.
   MEYER AS, 1991, J EXP PSYCHOL LEARN, V17, P1146, DOI 10.1037/0278-7393.17.6.1146.
   Morsella E, 2002, J EXP PSYCHOL LEARN, V28, P555, DOI 10.1037//0278-7393.28.3.555.
   Navarrete E, 2005, J MEM LANG, V53, P359, DOI 10.1016/j.jml.2005.05.001.
   Nozari N, 2011, COGNITIVE PSYCHOL, V63, P1, DOI 10.1016/j.cogpsych.2011.05.001.
   Oppermann F, 2014, PSYCHON B REV, V21, P78, DOI 10.3758/s13423-013-0465-5.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169.
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103.
   R Development Core Team, 2014, R LANG ENV STAT COMP.
   RANEY GE, 1993, J EXP PSYCHOL LEARN, V19, P51, DOI 10.1037/0278-7393.19.1.51.
   Roe K, 2000, MEM COGNITION, V28, P756, DOI 10.3758/BF03198410.
   Rothermich K, 2013, NEUROIMAGE, V70, P89, DOI 10.1016/j.neuroimage.2012.12.013.
   Schiller NO, 2009, NEUROIMAGE, V44, P520, DOI 10.1016/j.neuroimage.2008.09.019.
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603.
   Severens E, 2011, PSYCHOPHYSIOLOGY, V48, P1252, DOI 10.1111/j.1469-8986.2011.01190.x.
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616.
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0.
   Wicha NYY, 2005, LANG COGNITIVE PROC, V20, P553, DOI 10.1080/01690960444000241.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Mem. Cogn.}},
Doc-Delivery-Number = {{AY6NR}},
Unique-ID = {{ISI:000347683400010}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000427402900020,
Author = {Jukic, Ante and Mohammadiha, Nasser and van Waterschoort, Toon and
   Gerkmann, Timo and Doclo, Simon},
Book-Group-Author = {{IEEE}},
Title = {{MULTI-CHANNEL LINEAR PREDICTION-BASED SPEECH DEREVERBERATION WITH
   LOW-RANK POWER SPECTROGRAM APPROXIMATION}},
Booktitle = {{2015 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2015}},
Pages = {{96-100}},
Note = {{40th IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), Brisbane, AUSTRALIA, APR 19-24, 2015}},
Organization = {{IEEE; Inst Elect \& Elect Engineers Signal Proc Soc}},
Abstract = {{In many acoustic conditions the recorded speech signals may be severely
   affected by reverberation, leading to a reduced speech quality and
   intelligibility. In this paper we focus on a blind speech
   dereverberation method based on multi-channel linear prediction (MCLP)
   in the short-time Fourier transform domain, which is typically performed
   in each frequency bin independently without taking into account the
   spectral structure of the speech signal. Since it is widely accepted
   that a speech spectrogram can be well approximated with a low-rank
   matrix, e.g., using a spectral dictionary, in this paper we propose to
   incorporate a low-rank matrix approximation of the speech spectrogram
   into the MCLP-based speech dereverberation. The low-rank approximation
   is obtained using nonnegative matrix factorization with Itakura-Saito
   divergence. Experimental results for several measured acoustic systems
   show that incorporating a low-rank approximation improves the
   dereverberation performance in terms of instrumental speech quality
   measures.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Jukic, A (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, Oldenburg, Germany.
   Jukic, Ante; Mohammadiha, Nasser; Gerkmann, Timo; Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Dept Med Phys \& Acoust, Oldenburg, Germany.
   Jukic, Ante; Mohammadiha, Nasser; Gerkmann, Timo; Doclo, Simon, Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4All, Oldenburg, Germany.
   van Waterschoort, Toon, Katholieke Univ Leuven, Dept Elect Engn, ESAT STADIUS ETC, Leuven, Belgium.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4673-6997-8}},
Keywords = {{speech dereverberation; low-rank approximation; speech enhancement;
   multi-channel linear prediction; nonnegative matrix factorization}},
Keywords-Plus = {{NONNEGATIVE MATRIX FACTORIZATION; NOISE; DIVERGENCE}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{ante.jukic@uni-oldenburg.de}},
ResearcherID-Numbers = {{Gerkmann, Timo/I-3353-2014}},
ORCID-Numbers = {{Gerkmann, Timo/0000-0002-8678-4699}},
Funding-Acknowledgement = {{Marie Curie Initial Training Network DREAMS {[}ITN-GA-2012-316969];
   Research Foundation Flanders (FWO-Vlaanderen)FWO; Cluster of Excellence
   ``Hearing4All{''} - German Research Foundation (DFG)German Research
   Foundation (DFG) {[}1077]}},
Funding-Text = {{This research was supported by the Marie Curie Initial Training Network
   DREAMS (Grant agreement no. ITN-GA-2012-316969), and in part by the
   Research Foundation Flanders (FWO-Vlaanderen) and the Cluster of
   Excellence 1077 ``Hearing4All{''}, funded by the German Research
   Foundation (DFG).}},
Cited-References = {{Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888.
   Cichocki A, 2006, LECT NOTES COMPUT SC, V3889, P32.
   Delcroix M., 2014, P REVERB CHALL WORKS.
   Fevotte C, 2011, NEURAL COMPUT, V23, P2421, DOI 10.1162/NECO\_a\_00168.
   Fevotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Habets EAP, 2009, IEEE SIGNAL PROC LET, V16, P770, DOI 10.1109/LSP.2009.2024791.
   Iwata Y, 2012, INT CONF ACOUST SPEE, P245, DOI 10.1109/ICASSP.2012.6287863.
   Jukic A, 2014, 2014 4TH JOINT WORKSHOP ON HANDS-FREE SPEECH COMMUNICATION AND MICROPHONE ARRAYS (HSCMA), P23, DOI 10.1109/HSCMA.2014.6843244.
   Kinoshita K., 2013, P IEEE WORKSH APPLS.
   Kodrasi I, 2013, IEEE T AUDIO SPEECH, V21, P1879, DOI 10.1109/TASL.2013.2260743.
   Lefevre A, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P313, DOI 10.1109/ASPAA.2011.6082314.
   Mohammadiha N, 2013, IEEE T AUDIO SPEECH, V21, P2140, DOI 10.1109/TASL.2013.2270369.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4.
   Omologo M, 1998, SPEECH COMMUN, V25, P75, DOI 10.1016/S0167-6393(98)00030-2.
   Ozerov A, 2010, IEEE T AUDIO SPEECH, V18, P550, DOI 10.1109/TASL.2009.2031510.
   Schmid D, 2014, IEEE-ACM T AUDIO SPE, V22, P1320, DOI 10.1109/TASLP.2014.2329732.
   Schwartz B., 2014, P INT WORKSH AC ECH.
   Sun Dennis L., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6201, DOI 10.1109/ICASSP.2014.6854796.
   Togami M, 2013, INT CONF ACOUST SPEE, P7447, DOI 10.1109/ICASSP.2013.6639110.
   Togami M, 2013, IEEE T AUDIO SPEECH, V21, P1369, DOI 10.1109/TASL.2013.2250960.
   Wen J. Y. C., 2008, P INT WORKSH AC ECH.
   Wilson K., P INTERSPEECH, P411.
   Yoshioka T, 2012, IEEE T AUDIO SPEECH, V20, P2707, DOI 10.1109/TASL.2012.2210879.
   Yoshioka T, 2009, IEEE T AUDIO SPEECH, V17, P231, DOI 10.1109/TASL.2008.2008042.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BJ7KK}},
Unique-ID = {{ISI:000427402900020}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000427402905007,
Author = {Mishra, Taniya and Kim, Yeon-jun and Bangalore, Srinivas},
Book-Group-Author = {{IEEE}},
Title = {{INTONATIONAL PHRASE BREAK PREDICTION FOR TEXT-TO-SPEECH SYNTHESIS USING
   DEPENDENCY RELATIONS}},
Booktitle = {{2015 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2015}},
Pages = {{4919-4923}},
Note = {{40th IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), Brisbane, AUSTRALIA, APR 19-24, 2015}},
Organization = {{IEEE; Inst Elect \& Elect Engineers Signal Proc Soc}},
Abstract = {{Intonational phrase (IP) break prediction is an important aspect of
   front-end analysis in a text-to-speech system. Standard approaches for
   intonational phrase break prediction rely on the use of linguistic rules
   or more recently, lexicalized data-driven models. Linguistic rules are
   not robust while data-driven models based on lexical identity do not
   generalize across domains. To overcome these challenges, in this paper,
   we explore the use of syntactic features to predict intonational phrase
   breaks. On a test set of over 40 thousand words, while a lexically
   driven IP break prediction model yields an F-score of 0.82, a
   non-lexicalized model that uses part-of-speech tags and dependency
   relations achieves an F-score of 0.81 with added feature of being more
   portable across domains. In this work, we also examine the effect of
   contextual information on prediction performance. Our evaluation shows
   that using a three-token left context in a POS-tag based model results
   in only a 2\% drop in recall compared to a model that uses both a left
   and right context, which suggests the viability of using such a model
   for incremental text-to-speech system.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Mishra, T (Corresponding Author), Interactions, 31 Hayward St, Franklin, MA 02038 USA.
   Mishra, Taniya; Kim, Yeon-jun; Bangalore, Srinivas, Interactions, 31 Hayward St, Franklin, MA 02038 USA.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4673-6997-8}},
Keywords = {{Intonational phrase; phrase breaks; IP prediction; prosody;
   text-analysis}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{tmishra@interactions.net
   ykim@interactions.net
   sbangalore@interactions.net}},
Cited-References = {{Apel J., 2004, K VER NATRL SPRACH K.
   BANGALORE S, 2005, P SNOWB LEARN WORKSH.
   Baumann T., 2012, P INT PORTL US SEPT.
   Black A. W., 1997, EUROSPEECH, P995.
   Bolinger Dwight L., 1989, INTONATION ITS USES.
   Braunschweiler N., 2013, SPEECH SYNTH WORKSH.
   Brierley C., 2011, THESIS.
   Haffner P, 2006, SPEECH COMMUN, V48, P239, DOI 10.1016/j.specom.2005.06.008.
   Hall Johan, 2006, P COLING ACL 2006 MA, P316.
   HIRSCHBERG J, 1996, SPEECH COMMUNICATION.
   Keri V., 2007, INT C NAT LANG PROC, P45.
   Koehn P, 2000, P ICASSP.
   McDonald Ryan, 2013, P ACL.
   Obin N., 2011, INTERSPEECH.
   Rosenberg A., 2009, THESIS.
   Selkirk Elisabeth, 2011, HDB PHONOLOGICAL THE.
   Watson D, 2004, LANG COGNITIVE PROC, V19, P713, DOI 10.1080/01690960444000070.
   Wennerstrom A., 2001, MUSIC EVERYDAY SPEEC.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJ7KK}},
Unique-ID = {{ISI:000427402905007}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000427402905024,
Author = {Zhang, Yu and Yu, Dong and Seltzer, Michael L. and Droppo, Jasha},
Book-Group-Author = {{IEEE}},
Title = {{SPEECH RECOGNITION WITH PREDICTION-ADAPTATION-CORRECTION RECURRENT
   NEURAL NETWORKS}},
Booktitle = {{2015 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2015}},
Pages = {{5004-5008}},
Note = {{40th IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), Brisbane, AUSTRALIA, APR 19-24, 2015}},
Organization = {{IEEE; Inst Elect \& Elect Engineers Signal Proc Soc}},
Abstract = {{We propose the prediction-adaptation-correction RNN (PAC-RNN), in which
   a correction DNN estimates the state posterior probability based on both
   the current frame and the prediction made on the past frames by a
   prediction DNN. The result from the main DNN is fed back to the
   prediction DNN to make better predictions for the future frames. In the
   PAC-RNN, we can consider that, given the new, current frame information,
   the main DNN makes a correction on the prediction made by the prediction
   DNN. Alternatively, it can be viewed as adapting the main DNN's behavior
   based on the prediction DNN's prediction. Experiments on the TIMIT phone
   recognition task indicate that the PAC-RNN outperforms DNN, RNN, and
   LSTM with 2.4\%, 2.1\%, and 1.9\% absolute phone accuracy improvement,
   respectively. We found that incorporating the prediction objective and
   including the recurrent loop are both important to boost the performance
   of the PAC-RNN.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, Y (Corresponding Author), MIT, CSAIL, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Zhang, Yu, MIT, CSAIL, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Yu, Dong; Seltzer, Michael L.; Droppo, Jasha, Microsoft Res, One Microsoft Way, Redmond, WA USA.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4673-6997-8}},
Keywords = {{Deep Neural Network; DNN; Recurrent neural network; RNN;
   Prediction-Adaptation-Correction RNN; PAC-RNN}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{yzhang87@csail.mit.edu
   dongyu@microsoft.com
   mseltzer@microsoft.com
   jdroppo@microsoft.com}},
ORCID-Numbers = {{Droppo, Jasha/0000-0001-6097-0090}},
Cited-References = {{Abdel-Hamid O., 2014, IEEE T AUDIO SPEECH.
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090.
   Deng L., 2014, P INT C AC SPEECH SI.
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742.
   Graves Alex, 2013, P INT C AC SPEECH SI.
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597.
   Huang Y., 2014, P ANN C INT SPEECH C.
   Jaitly N., 2014, P ANN C INT SPEECH C.
   Kalman R.E., 1960, J BASIC ENG, V82, P35, DOI {[}10.1115/1.3662552, DOI 10.1115/1.3662552].
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382.
   Sainath TN, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P315, DOI 10.1109/ASRU.2013.6707749.
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347.
   Sak H., 2014, 15 ANN C INT SPEECH.
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition \& Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899.
   Seide F, 2011, P INTERSPEECH, P437.
   Seltzer M. L., 2013, P INT C AC SPEECH SI.
   Toth L., 2014, P ANN C INT SPEECH C.
   Weng C., 2014, P INT C AC SPEECH SI, P5569.
   Weng C., 2014, P ICASSP.
   Williams R., 1990, NEURAL COMPUT, V2.
   Yu Dong, 2014, TECH REP.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJ7KK}},
Unique-ID = {{ISI:000427402905024}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000427402905043,
Author = {Andersen, Kristian Timm and Elmedyb, Thomas Bo and Moonen, Marc},
Book-Group-Author = {{IEEE}},
Title = {{DELAYLESS SPEECH ENHANCEMENT WITH A VIRTUAL ZERO-PHASE RESPONSE USING A
   PREDICTION OF PERIODIC SIGNAL COMPONENTS}},
Booktitle = {{2015 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2015}},
Pages = {{5098-5102}},
Note = {{40th IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), Brisbane, AUSTRALIA, APR 19-24, 2015}},
Organization = {{IEEE; Inst Elect \& Elect Engineers Signal Proc Soc}},
Abstract = {{In this paper, a delayless speech enhancement scheme with zero phase
   distortion is proposed. It is based on a cascade of adaptive filters
   that predicts periodic components with a significant auto-correlation
   for lags larger than a value D. The adaptive filter is positioned at the
   output of a speech enhancement algorithm, to adjust the phase of the
   periodic components to the noisy signal, and to remove stochastic signal
   components with a significant auto-correlation only for lags smaller
   than D. The stochastic components are enhanced in a separate channel and
   mixed back together with the periodic components to give an output with
   no delay or phase distortion compared to the input signal. Such a scheme
   is useful for low-delay processing where the phase of the signal must be
   preserved, for instance as a front-end for spatial filtering or when the
   output is mixed with another source, such as the direct transmitted
   sound through the vent in an open hearing aid fitting.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Andersen, KT (Corresponding Author), Katholieke Univ Leuven, ESAT STADIUS, Kasteelpk Arenberg 10, B-3001 Leuven, Belgium.
   Andersen, Kristian Timm; Moonen, Marc, Katholieke Univ Leuven, ESAT STADIUS, Kasteelpk Arenberg 10, B-3001 Leuven, Belgium.
   Andersen, Kristian Timm; Elmedyb, Thomas Bo, Widex AS, DK-3540 Lynge, Denmark.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4673-6997-8}},
Keywords = {{low-delay filter bank; zero-phase; real-time prediction; adaptive
   filters; speech enhancement}},
Keywords-Plus = {{FILTER-BANKS}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Cited-References = {{Deller J. R., 2000, I ELECT ELECT ENG.
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453.
   Gerkmann T, 2012, IEEE T AUDIO SPEECH, V20, P1383, DOI 10.1109/TASL.2011.2180896.
   Haykin S.S, 2002, PRENTICE HALL INFORM.
   Hermann D, 2007, INT CONF ACOUST SPEE, P405.
   Lbllmann H. W., 2005, P EUR C SPEECH COMM.
   Lollmann HW, 2008, SIGNALS COMMUN TECHN, P13, DOI 10.1007/978-3-540-70602-1\_2.
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BJ7KK}},
Unique-ID = {{ISI:000427402905043}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000380389200111,
Author = {Sarkar, Parakrant and Rao, K. Sreenivasa},
Book-Group-Author = {{IEEE}},
Title = {{Data-Driven Pause Prediction for Speech Synthesis in Storytelling Style
   Speech}},
Booktitle = {{2015 TWENTY FIRST NATIONAL CONFERENCE ON COMMUNICATIONS (NCC)}},
Series = {{National Conference on Communications NCC}},
Year = {{2015}},
Note = {{21st National Conference on Communications (NCC), Indian Inst Technol,
   Bombay, INDIA, FEB 27-MAR 01, 2015}},
Organization = {{Natl instruments; Tata Consultancy Serv; Samsung; Amitec Innovating
   Technology; Ieee; Ieee Commun Soc; MHRD; Isra; Tektronix; Bharat Elect;
   Indian Inst Tech Bombay}},
Abstract = {{In the storyteller speech, pauses plays a significant role in
   introducing suspense and climax. Pauses are used to emphasize keywords,
   emotion-salient words and separate the phrases in the utterance. The
   objective of this work is to predict the position and duration of the
   pauses in the synthesized speech from the text-to-speech system. We
   analyzed the pause patterns in storyteller speech and classified the
   pauses into three different categories, that is, short, medium and long
   pauses. A data driven three stage pause prediction model is proposed. In
   the first stage, the model is built properly to identify the pause
   position within an utterance using a set of word-level features. In the
   second stage, the pauses are classified into three different categories
   using a set of syllable-level features. In the final stage, a regression
   predictor is trained to predict the pause duration for each category. We
   conducted both objective and subjective tests to evaluate the proposed
   method. The subjective evaluation showed that subjects are perceiving a
   noticeable difference in the synthesized speech using the proposed
   method.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sarkar, P (Corresponding Author), Indian Inst Technol Kharagpur, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
   Sarkar, Parakrant; Rao, K. Sreenivasa, Indian Inst Technol Kharagpur, Sch Informat Technol, Kharagpur 721302, W Bengal, India.}},
ISBN = {{978-1-4799-6619-6}},
Keywords = {{Storytelling style; Pause prediction; Phrasing; Pause Duration; Breaks;
   Non-break; Speech synthesis; silences}},
Keywords-Plus = {{DURATIONS}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{parakrantsarkar@gmail.com
   ksrao@iitkgp.ac.in}},
Cited-References = {{BLACK AW, 1997, HCRCTR83 U ED HUM CO.
   Braunschweiler N., 2013, 8 ISCA SPEECH SYNTH, V8, P1.
   Dhillon R., 2008, J ACOUST SOC AM, V123, P3425, DOI DOI 10.1121/1.2934182.
   Ghosh K, 2012, COMM COM INF SC, V306, P118.
   GOLDMANEISLER F, 1961, LANG SPEECH, V4, P232, DOI 10.1177/002383096100400405.
   HIRSCHBERG J, 2000, PROSODY THEORY EXPT, P335.
   Hogg R., 1987, MATH STAT.
   Klatt D. H., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1589.
   Krishna N. S., 2004, INTERSPEECH.
   Nageshwara Rao M., 2005, P NAT C COMM NCC IIT, P227.
   Parlikar A., 2012, INTERSPEECH.
   Parlikar A, 2012, INT CONF ACOUST SPEE, P4013, DOI 10.1109/ICASSP.2012.6288798.
   Prahallad K., 2007, INTERSPEECH, P2901.
   Prahallad K., 2010, 7 ISCA TUT RES WORKS, P162.
   Prahallad  K., 2006, AC SPEECH SIGN PROC, VI, pI.
   Rao KS, 2007, COMPUT SPEECH LANG, V21, P282, DOI 10.1016/j.csl.2006.06.003.
   Rijsbergen C.V., 1979, INFORM RETRIEVAL.
   Sarkar P., 2014, 7 INT C CONT COMP IC, P473.
   Schroder M., 2001, INT J SPEECH TECHNOL, V6, P365.
   Silverman K., 1992, ICSLP.
   Theune M, 2006, IEEE T AUDIO SPEECH, V14, P1137, DOI 10.1109/TASL.2006.876129.
   Vadapalli A., 2013, 8 ISCA SPEECH SYNTH, P189.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BF1EX}},
Unique-ID = {{ISI:000380389200111}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000395824100032,
Author = {Kalwad, Pramati S. and Pattanaik, Shailja and Chandana, T. L. and Reddy,
   G. Ram Mohana},
Editor = {{Mitra, S and McIntosh, S and Nair, I and Bedi, P and Rajasree, MS}},
Title = {{Language Modelling and English Speech Prediction System to Aid People
   with Stuttering Disorder}},
Booktitle = {{PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING
   AND INFORMATICS (WCI-2015)}},
Year = {{2015}},
Pages = {{191-195}},
Note = {{3rd International Symposium on Women in Computing and Informatics (WCI),
   SCMS Sch Engn \& Technol, Aluva, INDIA, AUG 10-13, 2015}},
Organization = {{ACM India; ACM Comm Women Comp India; ICPS; Assoc Comp Machinery
   Trivandrum Profess Chapter; Int Neural Network Soc India Reg Chapter;
   ACM Cochin Chapter; IWNN}},
Abstract = {{This paper proposes a novel method to predict the speech based on N-Gram
   language model for English Language. It also concentrates on how Speech
   Completion can be combined with stuttering detection to aid people
   suffering from this disorder to overcome psychological and social
   introversion. To the best of our knowledge, such systems exist only in
   Japanese language and hence, this paper is the first to introduce such
   an application for English language. The existing work in Japanese
   language uses a vocabulary tree structure for prediction in contrast to
   the n-gram language model used in this paper. The basic idea of the
   proposed work is to consider the user's speech input for detecting the
   repetition of words as stuttering. If this repetition of words is
   detected then, the next word can be predicted after eliminating the
   repeated word using the n-gram language model and the predicted word can
   be converted back to speech. Using this proposed methodology, we are
   able to achieve a prediction accuracy of 87\% when a 10-fold test is
   carried out.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kalwad, PS (Corresponding Author), Natl Inst Technol Karnataka, Surathkal, Karnataka, India.
   Kalwad, Pramati S.; Pattanaik, Shailja; Chandana, T. L.; Reddy, G. Ram Mohana, Natl Inst Technol Karnataka, Surathkal, Karnataka, India.}},
DOI = {{10.1145/2791405.2791531}},
ISBN = {{978-1-4503-3361-0}},
Keywords = {{N-gram; Stuttering; Prediction}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods}},
Author-Email = {{pramati@gmail.com
   shailjapattanaik@gmail.com
   tlchandana@gmail.com
   profgrmreddy@nitk.ac.in}},
ResearcherID-Numbers = {{Guddeti, Ram Mohana Reddy K/W-9494-2018
   }},
ORCID-Numbers = {{Guddeti, Ram Mohana Reddy/0000-0003-1361-3837}},
Cited-References = {{Akinori Ito, 1996, SPOK LANG ICSLP 96 P, V1, P490.
   Chen Guoliang, 2012, CONS EL COMM NETW CE, P2933.
   Goto Masataka, 2002, P 7 INT C SPOK LANG, P1489.
   Kimura F, 2011, CULT COMP CULT COMP, P183.
   Lesher G. W., 1999, Proceedings of the RESNA'99 Annual Conference. Spotlight on Technology, P52.
   Peter Norvig, BEAUTIFUL DATA, P219.
   Stefanovic M, 2012, TELECOMMUNICATIONS F, P1601.
   Vojtch Stejskal, 2009, 21 IEEE INT C TOOLS, P237.
   ZHANG JB, 2013, COMP ASS ALG DET, P249, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AMR.750-752.249.}},
Number-of-Cited-References = {{9}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH0PF}},
Unique-ID = {{ISI:000395824100032}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000466853902030,
Author = {Wagner, David and Dicks, Joseph and Kristmanson, Paula},
Editor = {{Krainer, K and Vondrova, N}},
Title = {{Students' language repertoires for prediction}},
Booktitle = {{PROCEEDINGS OF THE NINTH CONFERENCE OF THE EUROPEAN SOCIETY FOR RESEARCH
   IN MATHEMATICS EDUCATION (CERME9)}},
Year = {{2015}},
Pages = {{1517-1523}},
Note = {{9th Congress of the
   European-Society-for-Research-in-Mathematics-Education (CERME), Prague,
   CZECH REPUBLIC, FEB 04-08, 2015}},
Organization = {{European Soc Res Math Educ}},
Abstract = {{For communication about prediction (both relating to probability and to
   conjecture), language is by nature recursive - language is an indicator
   of meaning as well as a force that shapes meaning. We describe how this
   recursive nature of language impacted the choices we made in a
   cross-sectional longitudinal study aimed at gaining insight into
   children's language repertoires relating to conjecture. We then use some
   of the data from the project to identify issues relating to interpreting
   data in such a context. Finally, we raise questions about implications
   for educators.}},
Publisher = {{CHARLES UNIV, FAC EDUC}},
Address = {{M D RETTIGOV 4, PRAGUE 1, 116 39, CZECH REPUBLIC}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wagner, D (Corresponding Author), Univ New Brunswick, Fredericton, NB, Canada.
   Wagner, David; Dicks, Joseph; Kristmanson, Paula, Univ New Brunswick, Fredericton, NB, Canada.}},
ISBN = {{978-80-7290-844-8}},
Keywords = {{Language; mathematics education; prediction; conjecture}},
Research-Areas = {{Education \& Educational Research; Mathematics}},
Web-of-Science-Categories  = {{Education, Scientific Disciplines; Mathematics}},
Author-Email = {{dwagner@unb.ca}},
Funding-Acknowledgement = {{Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC)}},
Funding-Text = {{This research was supported by the Social Sciences and Humanities
   Research Council of Canada, as part of a grant entitled ``Students'
   language repertoires for investigating mathematics{''} (Principal
   Investigator: David Wagner).}},
Cited-References = {{Bakker A., 2012, MATH TEACHING MIDDLE, V44, P913.
   Council of Chief State School Officers (CCSSO), 2010, COMM COR STAT STAND.
   Lunney Borden L., 2010, THESIS.
   Neller T. W., 2004, UMAP J, V25, P25.
   New Brunswick Department of Education, 2010, MATH GRAD 6 CURR.
   Rowland T, 2000, PRAGMATICS MATH ED V.
   Shaffer B., 2006, ADV SIGN LANGUAGE DE, P291.
   Swetz F. J., 2009, CULTURALLY RESPONSIV, P11.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM6KH}},
Unique-ID = {{ISI:000466853902030}},
DA = {{2020-12-06}},
}

@article{ ISI:000347019500022,
Author = {Ooi, Kuan Ee Brian and Lech, Margaret and Allen, Nicholas Brian},
Title = {{Prediction of major depression in adolescents using an optimized
   multi-channel weighted speech classification system}},
Journal = {{BIOMEDICAL SIGNAL PROCESSING AND CONTROL}},
Year = {{2014}},
Volume = {{14}},
Pages = {{228-239}},
Month = {{NOV}},
Abstract = {{This study addresses an urgent need for objective measures allowing an
   efficient, early prediction of risk for depression in adolescents. An
   early intervention preventing the onset of clinical depression could
   significantly reduce the social and economic burden of the disease.
   Previous studies have shown that acoustic speech parameters are strong
   indicators of full blown depression symptoms in adults and adolescents.
   The current study investigates the effectiveness of acoustic speech
   analysis and classification in prediction of depression in adolescents
   before the full blown symptoms become apparent. The proposed optimized
   multi-channel weighted speech classification (OMCWSC) method introduces
   a two-stage multi-channel classification procedure. In the first stage,
   each channel of the OMCWSC performs an independent classification based
   on a single type of features (glottal, prosodic and Teager energy
   operator parameters derived from glottal waveform (TEOG)). In the second
   stage, the weighted classification outcomes from all channels are
   combined to deliver the final decision classifying an individual as ``At
   Risk{''} (AR) or ``Not at Risk{''} (NAR) of developing depression
   symptoms within the next 2.5 years. The weight values of the OMCWSC
   system are optimized to maximize the overall system classification
   accuracy. Experiments based on speech recordings collected from 15 AR
   and 15 NAR adolescents showed that while each of the three individual
   channels provided prediction accuracy above the chance level (69\%
   glottal, 63\% prosodic, 67\% TEOG), the adaptive weighting system of the
   proposed OMCWSC procedure led to further improvement of the prediction
   results achieving up to 74\% accuracy and a well-balanced sensitivity to
   specificity ratio of 77\%/70\%. Crown Copyright (C) 2014 Published by
   Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lech, M (Corresponding Author), RMIT Univ, Sch Elect \& Comp Engn, Melbourne, Vic 3001, Australia.
   Ooi, Kuan Ee Brian; Lech, Margaret, RMIT Univ, Sch Elect \& Comp Engn, Melbourne, Vic 3001, Australia.
   Allen, Nicholas Brian, Univ Melbourne, Dept Psychol Sci, Melbourne, Vic 3010, Australia.}},
DOI = {{10.1016/j.bspc.2014.08.006}},
ISSN = {{1746-8094}},
EISSN = {{1746-8108}},
Keywords = {{Multi-channel classification; Prediction of clinical depression;
   Classifier optimization; Weighted features; Decision fusion; Speech
   classification}},
Keywords-Plus = {{CLINICAL DEPRESSION; FLOW; DISORDER; IMPACT; ONSET; RISK}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Biomedical}},
Author-Email = {{margaret.lech@rmit.edu.au}},
ORCID-Numbers = {{Allen, Nicholas/0000-0002-1086-6639}},
Cited-References = {{Adam EK, 2010, PSYCHONEUROENDOCRINO, V35, P921, DOI 10.1016/j.psyneuen.2009.12.007.
   Airas M, 2008, LOGOP PHONIATR VOCO, V33, P49, DOI 10.1080/14015430701855333.
   Alghowinem S, 2013, INTERSPEECH, P2533.
   ALKU P, 1992, SPEECH COMMUN, V11, P109, DOI 10.1016/0167-6393(92)90005-R.
   American Psychiatric Association, 1994, DIAGN STAT MAN MENT.
   Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, P3, DOI 10.1109/4235.585888.
   Barrera A.Z, 2009, INT ENCY DEPRESSION, P447.
   Bernardo J.M., 2001, MEAS SCI TECHNOL, V12, P221, DOI DOI 10.1088/0957-0233/12/2/702.
   Childers D. G, 2000, SPEECH PROCESSING SY.
   Cohn J. F., 2009, AFF COMP INT INT WOR, P1, DOI DOI 10.1109/ACII.2009.5349358.
   Cummins N., 2013, INT 2013 LYON FRANC.
   Cyranowski JM, 2000, ARCH GEN PSYCHIAT, V57, P21, DOI 10.1001/archpsyc.57.1.21.
   Dorado P, 2007, FUND CLIN PHARMACOL, V21, P451, DOI 10.1111/j.1472-8206.2007.00501.x.
   FANT G, 1950, ACOUSTIC THEORY SPEE.
   Field A., 2005, DISCOVERING STAT USI.
   France DJ, 2000, IEEE T BIO-MED ENG, V47, P829, DOI 10.1109/10.846676.
   Fukunaga K., 1990, INTRO STAT PATTERN R.
   Garber J, 2009, JAMA-J AM MED ASSOC, V301, P2215, DOI 10.1001/jama.2009.788.
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T.
   Goldberg D.E., 1989, OPTIMIZATION MACHINE.
   Hansen JHL, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/906789.
   HE L, 2010, INTERSPEECH.
   Henshaw C., 2005, SCREENING PERINATAL.
   HOPS H, 1995, J CLIN CHILD PSYCHOL, V24, P193, DOI 10.1207/s15374424jccp2402\_7.
   Kaiser J. F., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P149, DOI 10.1109/ICASSP.1993.319457.
   KAISER JF, 1990, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.1990.115702.
   Khosla S., 2008, CURR OPIN OTHOLARYNG, V16.
   Khosla S, 2007, ANN OTO RHINOL LARYN, V116, P217, DOI 10.1177/000348940711600310.
   Khosla S, 2009, LARYNGOSCOPE, V119, P216, DOI 10.1002/lary.20026.
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671.
   Kuppens P, 2012, EMOTION, V12, P283, DOI 10.1037/a0025046.
   Lech M., 2014, MENTAL HLTH INFORM.
   Lech M., 2013, MENTAL HLTH INFORM.
   Lech M., 2005, GESTS INT T COMPUTER, V12, P51.
   Low LSA, 2011, IEEE T BIO-MED ENG, V58, P574, DOI 10.1109/TBME.2010.2091640.
   Low LSA, 2010, INT CONF ACOUST SPEE, P5154, DOI 10.1109/ICASSP.2010.5495018.
   MARAGOS P, 1993, IEEE T SIGNAL PROCES, V41, P3024, DOI 10.1109/78.277799.
   Moore E, 2004, P ANN INT IEEE EMBS, V26, P17.
   Moore E, 2008, IEEE T BIO-MED ENG, V55, P96, DOI 10.1109/TBME.2007.900562.
   MRAZEK PJ, 1994, FRONTIERS PREVENTIVE.
   Munoz R. F., 2008, HDB DEPRESSION, P533.
   Munoz R. F., 1993, PREVENTION DEPRESSIO.
   Ooi K.E.B., 2011, IMAGE ANAL MULTIMED.
   Ooi KEB, 2012, INT CONF ACOUST SPEE, P4613, DOI 10.1109/ICASSP.2012.6288946.
   Ooi KEB, 2013, IEEE T BIO-MED ENG, V60, P497, DOI 10.1109/TBME.2012.2228646.
   Ozdas A, 2004, IEEE T BIO-MED ENG, V51, P1530, DOI 10.1109/TBME.2004.827544.
   Quatieri TF, 2001, DISCRETE TIME SPEECH.
   ROBERTS RE, 1991, J AM ACAD CHILD PSY, V30, P58, DOI 10.1097/00004583-199101000-00009.
   Sawyer MG, 2000, MENTAL HLTH YOUNG PE.
   Scherer S., 2013, INTERSPEECH.
   Sheerber L, 2001, CLIN CHILD FAM PSYCH.
   Sturim D., 2011, INTERSPEECH.
   TEAGER HM, 1980, IEEE T ACOUST SPEECH, V28, P599, DOI 10.1109/TASSP.1980.1163453.
   Theodoridis S., 1998, PATTERN RECOGNITION.
   Weise T, 2009, GLOBAL OPTIMIZATION.
   Whittle S, 2011, DEV PSYCHOPATHOL, V23, P115, DOI 10.1017/S0954579410000684.
   Yap MBH, 2008, CHILD DEV, V79, P1415, DOI 10.1111/j.1467-8624.2008.01196.x.
   Young S.J., 1993, HTK HIDDEN MARKOV MO.
   Zhou GJ, 2001, IEEE T SPEECH AUDI P, V9, P201, DOI 10.1109/89.905995.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Biomed. Signal Process. Control}},
Doc-Delivery-Number = {{AX6FW}},
Unique-ID = {{ISI:000347019500022}},
DA = {{2020-12-06}},
}

@article{ ISI:000335754700023,
Author = {Stolt, Suvi and Matomaki, Jaakko and Lind, Annika and Lapinleimu, Helena
   and Haataja, Leena and Lehtonen, Liisa},
Title = {{The prevalence and predictive value of weak language skills in children
   with very low birth weight - a longitudinal study}},
Journal = {{ACTA PAEDIATRICA}},
Year = {{2014}},
Volume = {{103}},
Number = {{6}},
Pages = {{651-658}},
Month = {{JUN}},
Abstract = {{AimPrevious findings regarding the prevalence and predictive value of
   weak language skills in preterm children with very low birth weight
   (VLBW) are unclear. This study analysed the prevalence of weak language
   skills, the predictive value of early weak language skills on later weak
   language skills, and the sensitivity and specificity of cognitive scores
   for identifying concurrent weak language skills in a longitudinal sample
   of VLBW children (n=141) and their full-term controls (n=146).
   MethodsData on language skills and cognitive development were gathered
   at two and five years of age. Weak language skills were defined by the
   10th percentile value of the controls.
   ResultsIn VLBW children, the prevalence of weak language skills varied
   between 16\% and 18\% at 2 years of age (controls: 8 to 10\%) and
   between 20\% and 27\% at 5 years of age (controls: 10\%). Early weak
   language skills predicted later weak language skills in VLBW children.
   Cognitive scores were specific, but their sensitivity for identifying
   concurrent weak language skills was low.
   ConclusionThe prevalence of weak language skills in VLBW children
   increased during the follow-up period and was higher than the controls.
   Language-sensitive methods should be used in the clinical follow-up of
   VLBW children.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Stolt, S (Corresponding Author), Univ Turku, Dept Behav Sci \& Philosophy, Assistentinkatu 7 Publicum, Turku 20014, Finland.
   Stolt, Suvi; Lind, Annika, Univ Turku, Dept Behav Sci \& Philosophy, Turku 20014, Finland.
   Matomaki, Jaakko; Lind, Annika; Lapinleimu, Helena; Lehtonen, Liisa, Turku Univ Hosp, Dept Pediat, FIN-20520 Turku, Finland.
   Matomaki, Jaakko; Lind, Annika; Lapinleimu, Helena; Haataja, Leena; Lehtonen, Liisa, Univ Turku, Turku 20014, Finland.
   Haataja, Leena, Turku Univ Hosp, Dept Pediat Neurol, FIN-20520 Turku, Finland.}},
DOI = {{10.1111/apa.12607}},
ISSN = {{0803-5253}},
EISSN = {{1651-2227}},
Keywords = {{Cognitive development; Language development; Predictive value of early
   language; Very low birth weight children; Very preterm children}},
Keywords-Plus = {{PRETERM CHILDREN; BORN; RISK; AGE; OUTCOMES}},
Research-Areas = {{Pediatrics}},
Web-of-Science-Categories  = {{Pediatrics}},
Author-Email = {{suvi.stolt@utu.fi}},
ResearcherID-Numbers = {{Stolt, Suvi/V-5060-2018
   Haataja, Leena/G-1160-2016
   }},
ORCID-Numbers = {{Stolt, Suvi/0000-0002-6029-5459
   Haataja, Leena/0000-0002-8057-6194
   Lehtonen, Liisa/0000-0001-8925-2594}},
Funding-Acknowledgement = {{Academy of FinlandAcademy of Finland}},
Funding-Text = {{The present study was supported by the Academy of Finland. This study is
   part of the PIPARI study. The members of the PIPARI study group are Satu
   Ekblad, Eeva Ekholm, Leena Haataja, Mira Huhtala, Pentti Kero, Riikka
   Korja, Harry Kujari, Helena Lapinleimu, Liisa Lehtonen, Marika Leppanen,
   Hanna Manninen, Jaakko Matomaki, Jonna Maunu, Petriina Munck, Pekka
   Niemi, Pertti Palo, Riitta Parkkola, Jorma Piha, Annika Lind, Liisi
   Rautava, Paivi Rautava, Milla Ylijoki, Hellevi Rikalainen, Katriina
   Saarinen, Matti Sillanpaa, Suvi Stolt, Anniina Valiaho, Paivi
   Tuomikoski-Koiranen, Timo Tuovinen and Tuula Aarimaa.}},
Cited-References = {{Aylward G. P, 2010, NEURODEVELOPMENTAL O, P164.
   Barre N, 2011, J PEDIATR-US, V158, P766, DOI 10.1016/j.jpeds.2010.10.032.
   Bayley N., 1993, BAYLEY SCALES INFANT.
   Caskey M, 2011, PEDIATRICS, V128, P910, DOI 10.1542/peds.2011-0609.
   Dennis M, 2009, J INT NEUROPSYCH SOC, V15, P331, DOI 10.1017/S1355617709090481.
   FENSON L, 1994, MONOGR SOC RES CHILD, V59, pR5.
   Foster-Cohen S, 2007, J CHILD LANG, V34, P655, DOI 10.1017/S0305000907008070.
   Kadesjo B, 2004, EUR CHILD ADOLES PSY, V13, P3, DOI 10.1007/s00787-004-3002-2.
   Korkman M, 2004, EUR CHILD ADOLES PSY, V13, P31, DOI 10.1007/s00787-004-3005-z.
   Korkman M, 2007, NEPSY 2.
   Korkman M, 2012, ACTA PAEDIATR, V101, P946, DOI 10.1111/j.1651-2227.2012.02733.x.
   Lind A, 2011, DEV MED CHILD NEUROL, V53, P256, DOI 10.1111/j.1469-8749.2010.03828.x.
   Luoma L, 1998, DEV MED CHILD NEUROL, V40, P380.
   Lyytinen P, 2005, ANN DYSLEXIA, V55, P166, DOI 10.1007/s11881-005-0010-y.
   Lyytinen P, 1999, VARHAISEN KOMMUNIKAA.
   Ment LR, 2003, JAMA-J AM MED ASSOC, V289, P705, DOI 10.1001/jama.289.6.705.
   Munck P, 2012, PEDIATRICS, V129, P503, DOI 10.1542/peds.2011-1566.
   Rescorla L, 2002, J SPEECH LANG HEAR R, V45, P360, DOI 10.1044/1092-4388(2002/028).
   Sansavini A, 2010, EARLY HUM DEV, V86, P765, DOI 10.1016/j.earlhumdev.2010.08.014.
   Siegel LS, 1995, INFANT BEHAV DEV, V18, P483, DOI 10.1016/0163-6383(95)90037-3.
   Stolt S, 2013, J CHILD LANG, V40, P336, DOI 10.1017/S0305000911000456.
   Stolt S, 2009, J COMMUN DISORD, V42, P107, DOI 10.1016/j.jcomdis.2008.10.002.
   Luu TM, 2011, PEDIATRICS, V128, P313, DOI 10.1542/peds.2010-2655.
   van Noort-van der Spek IL, 2012, PEDIATRICS, V129, P745, DOI 10.1542/peds.2011-1728.
   Wechsler D, 1995, WECHSLERIN ALYKKYYST.
   Wolke D, 1999, DEV MED CHILD NEUROL, V41, P94, DOI 10.1017/S0012162299000201.
   Woodward LJ, 2009, ARCH DIS CHILD-FETAL, V94, pF339, DOI 10.1136/adc.2008.146282.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{Acta Paediatr.}},
Doc-Delivery-Number = {{AG9QQ}},
Unique-ID = {{ISI:000335754700023}},
DA = {{2020-12-06}},
}

@article{ ISI:000348196300014,
Author = {Hayiou-Thomas, Marianna E. and Dale, Philip S. and Plomin, Robert},
Title = {{Language Impairment From 4 to 12 Years: Prediction and Etiology}},
Journal = {{JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH}},
Year = {{2014}},
Volume = {{57}},
Number = {{3}},
Pages = {{850-864}},
Month = {{JUN}},
Abstract = {{Purpose: The authors of this article examined the etiology of
   developmental language impairment (LI) at 4 and 12 years of age, as well
   as the relationship between the 2.
   Method: Phenotypic and quantitative genetic analyses using longitudinal
   data from the Twins Early Development Study (Oliver \& Plomin, 2007)
   were conducted. A total of 2,923 pairs of twins (1,075 monozygotic
   {[}MZ]; 975 dizygotic same sex {[}DZss]; and 873 dizygotic opposite sex
   {[}DZos]) provided data at 4 and 12 years. At 4 years, (a) psychometric
   LI was defined on the basis of a low parent-reported expressive
   vocabulary score (-1.25 SDs; 226 MZand 115 DZss probands for genetic
   analysis); and (b) parent referral was defined as having seen a medical
   professional or speech-language pathologist following parental concern
   (112 MZ and 104 DZss probands). The 12-year language measure was a
   composite of 4 web-administered receptive language tests.
   Results: (a) Psychometric LI at 4 years is more predictive than parent
   referral of poor language performance at age 12 years, and (b) parent
   referral is substantially and significantly more heritable than
   psychometric LI.
   Conclusions: Parents' concern about their child's language development
   seems to be the marker of a more heritable disorder than poor expressive
   language skills alone. However, the language difficulties that arouse
   parental concern in preschool children, although more heritable, are not
   predictive of language difficulties in early adolescence. Rather, poor
   expressive language skills at age 4 years, psychometrically defined, are
   a better predictor than parent referral of continuing language
   difficulties at age 12 years.}},
Publisher = {{AMER SPEECH-LANGUAGE-HEARING ASSOC}},
Address = {{10801 ROCKVILLE PIKE, ROCKVILLE, MD 20852-3279 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hayiou-Thomas, ME (Corresponding Author), Univ York, York YO10 5DD, N Yorkshire, England.
   Hayiou-Thomas, Marianna E., Univ York, York YO10 5DD, N Yorkshire, England.
   Dale, Philip S., Univ New Mexico, Albuquerque, NM 87131 USA.
   Plomin, Robert, Kings Coll London, London WC2R 2LS, England.}},
DOI = {{10.1044/2013\_JSLHR-L-12-0240}},
ISSN = {{1092-4388}},
EISSN = {{1558-9102}},
Keywords = {{language impairment; etiology; genetics; longitudinal; prediction}},
Keywords-Plus = {{TWINS EARLY DEVELOPMENT; MULTIPLE-REGRESSION ANALYSIS; LATE-TALKING
   TODDLERS; ENVIRONMENTAL-INFLUENCES; GENETIC INFLUENCES; BEHAVIOR
   PROBLEMS; READING OUTCOMES; YOUNG ADULTHOOD; EARLY-CHILDHOOD; SPEECH}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation}},
Author-Email = {{emma.hayiou-thomas@york.ac.uk}},
ResearcherID-Numbers = {{Dale, Philip S/A-2254-2009
   }},
ORCID-Numbers = {{Dale, Philip S/0000-0002-7697-8510
   Plomin, Robert/0000-0002-0756-3629
   Hayiou-Thomas, Emma/0000-0003-1163-2671}},
Funding-Acknowledgement = {{UK Medical Research CouncilMedical Research Council UK (MRC)
   {[}G0901245, G0500079]; Medical Research CouncilMedical Research Council
   UK (MRC) {[}G0901245, G19/2, G0500079] Funding Source: researchfish}},
Funding-Text = {{We gratefully acknowledge the ongoing contribution of the participants
   in the Twins Early Development Study (TEDS) and their families. TEDS is
   supported by a programme grant {[}G0901245; and previously G0500079]
   from the UK Medical Research Council.}},
Cited-References = {{Beitchman JH, 1996, J AM ACAD CHILD PSY, V35, P804, DOI 10.1097/00004583-199606000-00021.
   Bishop DVM, 2008, GENES BRAIN BEHAV, V7, P365, DOI 10.1111/j.1601-183X.2007.00360.x.
   BISHOP DVM, 1987, J SPEECH HEAR DISORD, V52, P156, DOI 10.1044/jshd.5202.156.
   Bishop DVM, 2003, J SPEECH LANG HEAR R, V46, P561, DOI 10.1044/1092-4388(2003/045).
   BISHOP DVM, 1995, DEV MED CHILD NEUROL, V37, P56.
   Botting N, 2001, J CHILD PSYCHOL PSYC, V42, P1013, DOI 10.1111/1469-7610.00799.
   Byrne B, 2006, J RES READ, V29, P33, DOI 10.1111/j.1467-9817.2006.00291.x.
   Castles A, 1999, J EXP CHILD PSYCHOL, V72, P73, DOI 10.1006/jecp.1998.2482.
   Dale PS, 2010, J SPEECH LANG HEAR R, V53, P982, DOI 10.1044/1092-4388(2009/09-0108).
   Dale PS, 2003, J SPEECH LANG HEAR R, V46, P544, DOI 10.1044/1092-4388(2003/044).
   DEFRIES JC, 1988, ACTA GENET MED GEMEL, V37, P205, DOI 10.1017/S0001566000003810.
   DEFRIES JC, 1985, BEHAV GENET, V15, P467, DOI 10.1007/BF01066239.
   DeThorne LS, 2006, J SPEECH LANG HEAR R, V49, P1280, DOI 10.1044/1092-4388(2006/092).
   DeThorne LS, 2012, J SPEECH LANG HEAR R, V55, P739, DOI 10.1044/1092-4388(2011/11-0014).
   Dionne G, 2003, CHILD DEV, V74, P394, DOI 10.1111/1467-8624.7402005.
   Dollaghan C. A., 2007, HDB EVIDENCE BASED P.
   Dunn D. M., 1997, PEABODY PICTURE VOCA.
   Dworzynski K, 2007, INT J LANG COMM DIS, V42, P273, DOI 10.1080/13682820600939002.
   Fenson L., 1994, MONOGRAPHS SOC RES C, V59.
   Gough P. B., 1986, REM SPEC EDUC, V7, P1, DOI {[}DOI 10.1177/074193258600700104, 10.1177/074193258600700104].
   HAMMILL DD, 1994, TEST ADOLESCENT ADUL.
   Haworth CMA, 2007, TWIN RES HUM GENET, V10, P554, DOI 10.1375/twin.10.4.554.
   Haworth CMA, 2013, TWIN RES HUM GENET, V16, P117, DOI 10.1017/thg.2012.91.
   Haworth CMA, 2009, J CHILD PSYCHOL PSYC, V50, P1318, DOI 10.1111/j.1469-7610.2009.02114.x.
   Hayiou-Thomas M. E., 2012, DEVELOPMENTAL SCI, V15, P1.
   Hayiou-Thomas ME, 2006, J CHILD LANG, V33, P339, DOI 10.1017/S0305000906007331.
   Hayiou-Thomas ME, 2010, J SPEECH LANG HEAR R, V53, P311, DOI 10.1044/1092-4388(2009/07-0145).
   Hoekstra RA, 2007, LEARN INDIVID DIFFER, V17, P97, DOI 10.1016/j.lindif.2007.05.005.
   Law J, 2008, J SPEECH LANG HEAR R, V51, P739, DOI 10.1044/1092-4388(2008/052).
   LEWIS BA, 1992, J SPEECH HEAR RES, V35, P1086, DOI 10.1044/jshr.3505.1086.
   Nippold M. A., 2007, LATER LANGUANGE DEV.
   Oliver B, 2004, J CHILD LANG, V31, P609, DOI 10.1017/S0305000904006221.
   Oliver BR, 2007, TWIN RES HUM GENET, V10, P96, DOI 10.1375/twin.10.1.96.
   Pennington BF, 2009, ANNU REV PSYCHOL, V60, P283, DOI 10.1146/annurev.psych.60.110707.163548.
   Pickles A, 1998, BEHAV GENET, V28, P243, DOI 10.1023/A:1021615228995.
   Plomin R, 2008, BEHAV GENETICS.
   Price T S, 2000, Twin Res, V3, P129, DOI 10.1375/twin.3.3.129.
   Purcell S, 2001, DEVELOPMENTAL SCI, V4, P195, DOI 10.1111/1467-7687.00165.
   Rescorla L, 2005, J SPEECH LANG HEAR R, V48, P459, DOI 10.1044/1092-4388(2005/031).
   Rescorla L, 2002, J SPEECH LANG HEAR R, V45, P360, DOI 10.1044/1092-4388(2002/028).
   Rescorla L., 2013, LATE TALKERS LANGUAG.
   Samuelsson S, 2005, J EDUC PSYCHOL, V97, P705, DOI 10.1037/0022-0663.97.4.705.
   Sham P, 1998, STAT HUMAN GENETICS.
   SILVA PA, 1983, DEV MED CHILD NEUROL, V25, P783.
   Spinath FM, 2004, CHILD DEV, V75, P445, DOI 10.1111/j.1467-8624.2004.00685.x.
   Stothard SE, 1998, J SPEECH LANG HEAR R, V41, P407, DOI 10.1044/jslhr.4102.407.
   Tomblin JB, 2003, J SPEECH LANG HEAR R, V46, P1283, DOI 10.1044/1092-4388(2003/100).
   Tomblin JB, 1998, J SPEECH LANG HEAR R, V41, P188, DOI 10.1044/jslhr.4101.188.
   Trouton A, 2002, TWIN RES, V5, P444, DOI 10.1375/136905202320906255.
   Vernes SC, 2008, NEW ENGL J MED, V359, P2337, DOI 10.1056/NEJMoa0802828.
   Walker A., 2001, LIVING BRITAIN 2000.
   Wechsler D, 1992, WECHSLER INTELLIGENC.
   Wiig E., 1989, TEST LANGUAGE COMPET.
   Williams K, 1997, EXPRESSIVE VOCABULAR.
   Zhang XY, 2000, AM J SPEECH-LANG PAT, V9, P345, DOI 10.1044/1058-0360.0904.345.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{15}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{J. Speech Lang. Hear. Res.}},
Doc-Delivery-Number = {{AZ4MS}},
Unique-ID = {{ISI:000348196300014}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000334128100017,
Author = {Tripoliti, Elina and Limousin, Patricia and Foltynie, Tom and
   Candelario, Joseph and Aviles-Olmos, Iciar and Hariz, Marwan I. and
   Zrinzo, Ludvic},
Title = {{Predictive factors of speech intelligibility following subthalamic
   nucleus stimulation in consecutive patients with Parkinson's disease}},
Journal = {{MOVEMENT DISORDERS}},
Year = {{2014}},
Volume = {{29}},
Number = {{4}},
Pages = {{532-538}},
Month = {{APR}},
Abstract = {{Speech changes after bilateral subthalamic nucleus deep brain
   stimulation (STN-DBS) can be variable, with the majority of patients
   experiencing speech deterioration over time. The aim of this study was
   to describe the perceptual characteristics of speech following chronic
   STN-DBS and to analyze clinical and surgical factors that could predict
   speech change. Fifty-four consecutive patients (34 men; mean age +/-
   standard deviation (SD), 58.8 +/- 6.3 years; mean +/- SD disease
   duration, 12.5 +/- 4.7 years; mean +/- SD levodopa equivalent, 1556 +/-
   671 mg/day; mean +/- SD Unified Parkinson's Disease Rating Scale motor
   part (UPDRS-III) off-medication score, 48.1 +/- 17.9 {[}range, 20-89];
   and mean +/- SD UPDRS-III on-medication score, 12.4 +/- 7.8 {[}range,
   2-31]) participated in this study. They were assessed before and at 1
   year after surgery using the Assessment of Intelligibility for the
   Dysarthric Speech, the perceptual scale from Darley et al., and the
   UPDRS-III. Speech intelligibility deteriorated on average by 14.4\% (P =
   0.0006) after 1 year of STN-DBS when off-medication and by 12.3\% (P =
   0.001) when on-medication. The effect on speech was not linked to age at
   surgery, unlike the effect on motor outcome. The most significant
   predictive factors for deterioration of speech intelligibility when
   patients were off-medication/on-stimulation were lower preoperative
   speech intelligibility on-medication, longer disease duration, and
   medially placed left hemisphere active electrode contact. Speech change
   after STN-DBS is variable and multifactorial. Consistent preoperative
   speech evaluation would help inform patients about the possible effects
   of surgery. Appropriate consideration of speech deficits might assist
   surgical targeting, particularly of the left electrode. (c) 2014
   International Parkinson and Movement Disorder Society}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tripoliti, E (Corresponding Author), UCL, Unit Funct Neurosurg, Inst Neurol, Box 146,Queen Sq, London WC1N 3BG, England.
   Tripoliti, Elina; Candelario, Joseph; Aviles-Olmos, Iciar; Zrinzo, Ludvic, UCL, Unit Funct Neurosurg, Inst Neurol, London WC1N 3BG, England.
   Limousin, Patricia; Foltynie, Tom; Hariz, Marwan I., UCL, Sobell Dept Motor Neurosci \& Movement Disorders, Inst Neurol, London WC1N 3BG, England.
   Hariz, Marwan I., UCL, Natl Hosp Neurol \& Neurosurg, Inst Neurol, London WC1N 3BG, England.}},
DOI = {{10.1002/mds.25816}},
ISSN = {{0885-3185}},
EISSN = {{1531-8257}},
Keywords = {{predictive factors; deep brain stimulation; speech; Parkinson's disease}},
Keywords-Plus = {{DEEP BRAIN-STIMULATION; MOTOR CORTEX; ELECTRODE POSITION; HEMISPHERIC
   LATERALIZATION; ELECTRICAL-STIMULATION; NETWORKS; MOVEMENT; LEVODOPA}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Clinical Neurology}},
Author-Email = {{e.tripoliti@ucl.ac.uk}},
ResearcherID-Numbers = {{Aviles-Olmos, Iciar/E-3065-2018}},
ORCID-Numbers = {{Aviles-Olmos, Iciar/0000-0002-1645-7406}},
Funding-Acknowledgement = {{Sainsbury Monument Trust; Parkinson's Appeal for Deep Brain Stimulation;
   NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKEUnited States
   Department of Health \& Human ServicesNational Institutes of Health
   (NIH) - USANIH National Institute of Neurological Disorders \& Stroke
   (NINDS) {[}R56NS040902] Funding Source: NIH RePORTER}},
Funding-Text = {{The Unit of Functional Neurosurgery, UCL Institute of Neurology, is
   supported by the Sainsbury Monument Trust and Parkinson's Appeal for
   Deep Brain Stimulation.}},
Cited-References = {{AGID Y, 1991, LANCET, V337, P1321, DOI 10.1016/0140-6736(91)92989-F.
   Ahlberg E, 2011, PARKINSONS DIS-US, V2011, DOI 10.4061/2011/540158.
   Astrom M, 2010, STEREOT FUNCT NEUROS, V88, P224, DOI 10.1159/000314357.
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911.
   Charles PD, 2002, NEUROLOGY, V59, P932, DOI 10.1212/WNL.59.6.932.
   Darley F., 1975, MOTOR SPEECH DISORDE.
   Duffy JR, 2007, MOTOR SPEECH DISORDE.
   Fasano A, 2010, BRAIN, V133, P2664, DOI 10.1093/brain/awq221.
   Guehl D, 2006, EUR J NEUROL, V13, P963, DOI 10.1111/j.1468-1331.2006.01405.x.
   Hariz MI, 2003, STEREOT FUNCT NEUROS, V80, P96, DOI 10.1159/000075167.
   Hariz MI, 2000, MOVEMENT DISORD, V15, P136, DOI 10.1002/1531-8257(200001)15:1<136::AID-MDS1021>3.0.CO;2-5.
   Holl EM, 2010, NEUROSURGERY, V67, DOI 10.1227/NEU.0b013e3181f7422a.
   Kleiner-Fisman G, 2004, MOVEMENT DISORD, V19, P1209, DOI 10.1002/mds.20151.
   Krack P, 2003, NEW ENGL J MED, V349, P1925, DOI 10.1056/NEJMoa035275.
   Limousin P, 1998, NEW ENGL J MED, V339, P1105, DOI 10.1056/NEJM199810153391603.
   LOGEMANN JA, 1978, J SPEECH HEAR DISORD, V43, P47, DOI 10.1044/jshd.4301.47.
   Merola A, 2011, BRAIN, V134, P2074, DOI 10.1093/brain/awr121.
   METTER EJ, 1986, J COMMUN DISORD, V19, P347, DOI 10.1016/0021-9924(86)90026-2.
   Morel A., 2007, STEREOTACTIC ATLAS H.
   Nakajima T, 2011, STEREOT FUNCT NEUROS, V89, P318, DOI 10.1159/000330379.
   Paek SH, 2008, NEUROSURGERY, V63, P925, DOI 10.1227/01.NEU.0000334045.43940.FB.
   Paek SH, 2011, J KOREAN MED SCI, V26, P1344, DOI 10.3346/jkms.2011.26.10.1344.
   Piboolnurak P, 2007, MOVEMENT DISORD, V22, P990, DOI 10.1002/mds.21482.
   Pinto S, 2004, LANCET NEUROL, V3, P547, DOI 10.1016/S1474-4422(04)00854-3.
   Plaha P, 2006, BRAIN, V129, P1732, DOI 10.1093/brain/awl127.
   Plowman-Prine EK, 2009, NEUROREHABILITATION, V24, P131, DOI 10.3233/NRE-2009-0462.
   Riecker A, 2000, NEUROREPORT, V11, P1997, DOI 10.1097/00001756-200006260-00038.
   Riecker A, 2005, NEUROLOGY, V64, P700, DOI 10.1212/01.WNL.0000152156.90779.89.
   Santens P, 2003, BRAIN LANG, V87, P253, DOI 10.1016/S0093-934X(03)00142-1.
   SELBY G, 1968, J NEUROL SCI, V6, P517, DOI 10.1016/0022-510X(68)90034-8.
   Simonyan K, 2013, NEUROIMAGE, V70, P21, DOI 10.1016/j.neuroimage.2012.12.042.
   Simonyan K, 2012, BRAIN LANG, V122, P142, DOI 10.1016/j.bandl.2011.12.009.
   Simonyan K, 2012, CEREB CORTEX, V22, P417, DOI 10.1093/cercor/bhr120.
   Simonyan K, 2009, J NEUROSCI, V29, P14912, DOI 10.1523/JNEUROSCI.4897-09.2009.
   Sowman PF, 2009, J NEUROPHYSIOL, V102, P159, DOI 10.1152/jn.90894.2008.
   Tommasi G, 2008, J NEUROL NEUROSUR PS, V79, P813, DOI 10.1136/jnnp.2007.117507.
   Tripoliti E, 2011, NEUROLOGY, V76, P80, DOI 10.1212/WNL.0b013e318203e7d0.
   Tripoliti E, 2008, MOVEMENT DISORD, V23, P2377, DOI 10.1002/mds.22296.
   Velasco F, 2001, NEUROSURGERY, V49, P293, DOI 10.1097/00006123-200108000-00009.
   Wang E, 2003, CLIN LINGUIST PHONET, V17, P283, DOI 10.1080/0269920031000080064.
   Watkins KE, 2008, BRAIN, V131, P50, DOI 10.1093/brain/awm241.
   Welter ML, 2002, BRAIN, V125, P575, DOI 10.1093/brain/awf050.
   Wildgruber D, 2001, NEUROIMAGE, V13, P101, DOI 10.1006/nimg.2000.0672.
   Witt K, 2013, BRAIN, V136, P2109, DOI 10.1093/brain/awt151.
   Wodarg F, 2012, MOVEMENT DISORD, V27, P874, DOI 10.1002/mds.25006.
   Yelnik J, 2003, J NEUROSURG, V99, P89, DOI 10.3171/jns.2003.99.1.0089.
   Yorkston K., 1984, ASSESSMENT INTELLIGI.}},
Number-of-Cited-References = {{47}},
Times-Cited = {{42}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Mov. Disord.}},
Doc-Delivery-Number = {{AE6TC}},
Unique-ID = {{ISI:000334128100017}},
DA = {{2020-12-06}},
}

@article{ ISI:000335101100003,
Author = {Bendixen, Alexandra and Scharinger, Mathias and Strauss, Antje and
   Obleser, Jonas},
Title = {{Prediction in the service of comprehension: Modulated early brain
   responses to omitted speech segments}},
Journal = {{CORTEX}},
Year = {{2014}},
Volume = {{53}},
Pages = {{9-26}},
Month = {{APR}},
Abstract = {{Speech signals are often compromised by disruptions originating from
   external (e.g., masking noise) or internal (e.g., inaccurate
   articulation) sources. Speech comprehension thus entails detecting and
   replacing missing information based on predictive and restorative neural
   mechanisms. The present study targets predictive mechanisms by
   investigating the influence of a speech segment's predictability on
   early, modality-specific electrophysiological responses to this
   segment's omission. Predictability was manipulated in simple physical
   terms in a single-word framework (Experiment 1) or in more complex
   semantic terms in a sentence framework (Experiment 2). In both
   experiments, final consonants of the German words Lachs ({[}laks],
   salmon) or Latz ({[}lats], bib) were occasionally omitted, resulting in
   the syllable La ({[}lab no semantic meaning), while brain responses were
   measured with multi-channel electroencephalography (EEG). In both
   experiments, the occasional presentation of the fragment La elicited a
   larger omission response when the final speech segment had been
   predictable. The omission response occurred similar to 125-165 msec
   after the expected onset of the final segment and showed characteristics
   of the omission mismatch negativity (MMN), with generators in auditory
   cortical areas. Suggestive of a general auditory predictive mechanism at
   work, this main observation was robust against varying source of
   predictive information or attentional allocation, differing between the
   two experiments. Source localization further suggested the omission
   response enhancement by predictability to emerge from left superior
   temporal gyrus and left angular gyrus in both experiments, with
   additional experiment-specific contributions. These results are
   consistent with the existence of predictive coding mechanisms in the
   central auditory system, and suggestive of the general predictive
   properties of the auditory system to support spoken word recognition.
   (C) 2014 Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER MASSON, CORP OFF}},
Address = {{65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bendixen, A (Corresponding Author), Carl von Ossietzky Univ Oldenburg, Dept Psychol, Ammerlander Heerstr 114-118, D-26129 Oldenburg, Germany.
   Bendixen, Alexandra, Univ Leipzig, Inst Psychol, D-04109 Leipzig, Germany.
   Bendixen, Alexandra, Carl von Ossietzky Univ Oldenburg, Dept Psychol, Auditory Psychophysiol Lab, Cluster Excellence Hearing4a11,European Med Sch, D-26129 Oldenburg, Germany.
   Scharinger, Mathias; Strauss, Antje; Obleser, Jonas, Max Planck Inst Human Cognit \& Brain Sci, Max Planck Res Grp Auditory Cognit, Leipzig, Germany.}},
DOI = {{10.1016/j.cortex.2014.01.001}},
ISSN = {{0010-9452}},
EISSN = {{1973-8102}},
Keywords = {{Predictive coding; Semantic expectation; Auditory processing; Omission
   mismatch negativity (MMN); Source localization}},
Keywords-Plus = {{MISMATCH NEGATIVITY MMN; EVENT-RELATED POTENTIALS; AUDITORY SENSORY
   MEMORY; HIGHER-ORDER PROCESSES; TEMPORAL WINDOW; LANGUAGE COMPREHENSION;
   PHONEMIC RESTORATION; SELECTIVE-ATTENTION; SENTENCE CONTEXT; SILENT
   PAUSES}},
Research-Areas = {{Behavioral Sciences; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Behavioral Sciences; Neurosciences; Psychology, Experimental}},
Author-Email = {{alexandra.bendixen@uni-oldenburg.de}},
ResearcherID-Numbers = {{Bendixen, Alexandra/B-3922-2010
   Obleser, Jonas/C-9891-2011}},
ORCID-Numbers = {{Obleser, Jonas/0000-0002-7619-0459}},
Funding-Acknowledgement = {{Max Planck Society through a Max Planck Research group; DFGGerman
   Research Foundation (DFG); German Research Foundation {[}Deutsche
   Forschungsgemeinschaft, DFG]German Research Foundation (DFG) {[}SCH
   375/20-1]}},
Funding-Text = {{M.S., A.S. and J.O. are funded by the Max Planck Society through a Max
   Planck Research group grant to J.O. A.B. is funded by the DFG Cluster of
   Excellence 1077 ``Hearing4all{''}. Data collection of Experiment 2 was
   supported by the German Research Foundation {[}Deutsche
   Forschungsgemeinschaft, DFG, SCH 375/20-1]. SCDs were calculated and
   plotted with the aid of a plug-in for EEGlab (Delorme \& Makeig, 2004)
   written by Andreas Widmann, University of Leipzig, Germany. VARETA
   source localization was performed with scripts provided by Nelson
   Trujillo-Barreto, University of Havana, Cuba. The authors thank
   Christina Otto and Julia Merrill for help during stimulus preparation,
   Elizabeth Kelly for proofreading the manuscript, Erich Schroger for the
   opportunity to conduct the measurements of Experiment 2, as well as Ina
   Koch and Julia Steinbrack for assistance in data acquisition.}},
Cited-References = {{Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003.
   Baldeweg T, 2006, TRENDS COGN SCI, V10, P93, DOI 10.1016/j.tics.2006.01.010.
   Baldeweg T, 2007, J PSYCHOPHYSIOL, V21, P204, DOI 10.1027/0269-8803.21.34.204.
   Bendixen A, 2007, J COGNITIVE NEUROSCI, V19, P1664, DOI 10.1162/jocn.2007.19.10.1664.
   Bendixen A, 2012, INT J PSYCHOPHYSIOL, V83, P120, DOI 10.1016/j.ijpsycho.2011.08.003.
   Bendixen A, 2009, J NEUROSCI, V29, P8447, DOI 10.1523/JNEUROSCI.1493-09.2009.
   Besson M, 1997, BIOL PSYCHOL, V46, P3, DOI 10.1016/S0301-0511(96)05215-5.
   Bosch-Bayard J, 2001, CLIN ELECTROENCEPHAL, V32, P47, DOI 10.1177/155005940103200203.
   Boulenger V, 2011, BRAIN LANG, V116, P51, DOI 10.1016/j.bandl.2010.09.011.
   Chatrian G. E., 1985, American Journal of EEG Technology, V25, P83.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   Cornell SA, 2011, BRAIN RES, V1394, P79, DOI 10.1016/j.brainres.2011.04.001.
   COWAN N, 1993, J EXP PSYCHOL LEARN, V19, P909, DOI 10.1037/0278-7393.19.4.909.
   COWAN N, 1984, PSYCHOL BULL, V96, P341, DOI 10.1037/0033-2909.96.2.341.
   Davenport T, 2011, BRAIN RES, V1418, P70, DOI 10.1016/j.brainres.2011.07.039.
   Delong KA, 2011, PSYCHOPHYSIOLOGY, V48, P1203, DOI 10.1111/j.1469-8986.2011.01199.x.
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009.
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308.
   EVANS AC, 1993, NUCLEAR SCIENCE SYMPOSIUM \& MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1813, DOI 10.1109/NSSMIC.1993.373602.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Folstein JR, 2008, PSYCHOPHYSIOLOGY, V45, P152, DOI 10.1111/j.1469-8986.2007.00602.x.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Garrido MI, 2008, NEUROIMAGE, V42, P936, DOI 10.1016/j.neuroimage.2008.05.018.
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029.
   Grimm S, 2007, RESTOR NEUROL NEUROS, V25, P241.
   Groppe DM, 2010, BRAIN RES, V1361, P54, DOI 10.1016/j.brainres.2010.09.003.
   Haenschel C, 2005, J NEUROSCI, V25, P10494, DOI 10.1523/JNEUROSCI.1227-05.2005.
   Hasting AS, 2008, EUR J NEUROSCI, V27, P1561, DOI 10.1111/j.1460-9568.2008.06103.x.
   Hasting AS, 2007, J COGNITIVE NEUROSCI, V19, P386, DOI 10.1162/jocn.2007.19.3.386.
   Herrmann B, 2009, NEUROIMAGE, V48, P590, DOI 10.1016/j.neuroimage.2009.06.082.
   Horvath J, 2007, NEUROBIOL AGING, V28, P964, DOI 10.1016/j.neurobiolaging.2006.05.002.
   Horvath J, 2010, NEUROREPORT, V21, P537, DOI 10.1097/WNR.0b013e3283398094.
   Hughes HC, 2001, NEUROIMAGE, V13, P1073, DOI 10.1006/nimg.2001.0766.
   Jaaskelainen IP, 2004, P NATL ACAD SCI USA, V101, P6809, DOI 10.1073/pnas.0303760101.
   Jacobsen T, 2003, AUDIOL NEURO-OTOL, V8, P338, DOI 10.1159/000073518.
   Jacobsen T, 2001, PSYCHOPHYSIOLOGY, V38, P723, DOI 10.1017/S0048577201000993.
   Janata P, 2001, BRAIN TOPOGR, V13, P169, DOI 10.1023/A:1007803102254.
   Jomori I, 2009, NEUROSCI RES, V65, P187, DOI 10.1016/j.neures.2009.06.015.
   Kappenman ES, 2010, PSYCHOPHYSIOLOGY, V47, P888, DOI 10.1111/j.1469-8986.2010.01009.x.
   Kraemer DJM, 2005, NATURE, V434, P158, DOI 10.1038/434158a.
   Kujala T, 2007, BIOL PSYCHOL, V74, P1, DOI 10.1016/j.biopsycho.2006.06.001.
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Laufer I, 2009, NEUROIMAGE, V44, P546, DOI 10.1016/j.neuroimage.2008.09.010.
   Leaver AM, 2009, J NEUROSCI, V29, P2477, DOI 10.1523/JNEUROSCI.4921-08.2009.
   MacGregor LJ, 2010, NEUROPSYCHOLOGIA, V48, P3982, DOI 10.1016/j.neuropsychologia.2010.09.024.
   Mattys SL, 2005, PSYCHOL SCI, V16, P958, DOI 10.1111/j.1467-9280.2005.01644.x.
   May PJC, 2010, PSYCHOPHYSIOLOGY, V47, P66, DOI 10.1111/j.1469-8986.2009.00856.x.
   McGettigan C, 2012, TRENDS COGN SCI, V16, P269, DOI 10.1016/j.tics.2012.04.006.
   Michel CM, 2004, CLIN NEUROPHYSIOL, V115, P2195, DOI 10.1016/j.clinph.2004.06.001.
   Muller-Gass A, 2002, INT J PSYCHOPHYSIOL, V46, P177, DOI 10.1016/S0167-8760(02)00111-3.
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026.
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x.
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9.
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0.
   Naatanen R, 2004, CLIN NEUROPHYSIOL, V115, P140, DOI 10.1016/j.clinph.2003.04.001.
   NAATANEN R, 1989, NEUROSCI LETT, V98, P217, DOI 10.1016/0304-3940(89)90513-2.
   Naatanen R, 1997, TRENDS COGN SCI, V1, P44, DOI 10.1016/S1364-6613(97)01013-9.
   Nousak JMK, 1996, COGNITIVE BRAIN RES, V4, P305, DOI 10.1016/S0926-6410(96)00068-7.
   NOVAK GP, 1990, ELECTROEN CLIN NEURO, V75, P255, DOI 10.1016/0013-4694(90)90105-S.
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007.
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128.
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7.
   Otten M, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-89.
   PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6.
   Pihko E, 1997, NEUROREPORT, V8, P911, DOI 10.1097/00001756-199703030-00019.
   Pulvermuller F, 2007, J COGNITIVE NEUROSCI, V19, P971, DOI 10.1162/jocn.2007.19.6.971.
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004.
   Raij T, 1997, BRAIN RES, V745, P134, DOI 10.1016/S0006-8993(96)01140-7.
   Renoult L, 2012, CLIN NEUROPHYSIOL, V123, P741, DOI 10.1016/j.clinph.2011.08.025.
   Russeler J, 2001, NEUROSCI LETT, V308, P33, DOI 10.1016/S0304-3940(01)01977-2.
   Sabri M, 2001, COGNITIVE BRAIN RES, V12, P171, DOI 10.1016/S0926-6410(01)00026-X.
   SAMS M, 1984, PSYCHOPHYSIOLOGY, V21, P434, DOI 10.1111/j.1469-8986.1984.tb00223.x.
   Samuel A, 1996, LANG COGNITIVE PROC, V11, P647, DOI 10.1080/016909696387051.
   SanMiguel I, 2013, J NEUROSCI, V33, P8633, DOI 10.1523/JNEUROSCI.5821-12.2013.
   Scharinger M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040953.
   Schroger E, 1997, TRENDS COGN SCI, V1, P45.
   Schroger E, 2007, J PSYCHOPHYSIOL, V21, P138, DOI 10.1027/0269-8803.21.34.138.
   Schroger E, 1996, NEUROREPORT, V7, P3005, DOI 10.1097/00001756-199611250-00041.
   Schroger E, 2005, ACTA ACUST UNITED AC, V91, P490.
   Seghier ML, 2013, NEUROSCIENTIST, V19, P43, DOI 10.1177/1073858412440596.
   Shtyrov Y, 2004, EUR J NEUROSCI, V19, P1083, DOI 10.1111/j.0953-816X.2004.03126.x.
   Sivonen P, 2006, BRAIN RES, V1121, P177, DOI 10.1016/j.brainres.2006.08.123.
   Sivonen P, 2006, NEUROSCI LETT, V408, P220, DOI 10.1016/j.neulet.2006.09.001.
   SRINIVASAN R, 2005, EVENT RELATED POTENT, P167.
   Steinberg J, 2010, J COGNITIVE NEUROSCI, V22, P2174, DOI 10.1162/jocn.2009.21408.
   Stickney GS, 2001, J ACOUST SOC AM, V109, P1157, DOI 10.1121/1.1340643.
   Strauss A, 2013, J COGNITIVE NEUROSCI, V25, P1383, DOI 10.1162/jocn\_a\_00389.
   Tavano A, 2012, NEUROIMAGE, V60, P2300, DOI 10.1016/j.neuroimage.2012.02.041.
   TERVANIEMI M, 1994, BIOL PSYCHOL, V38, P157, DOI 10.1016/0301-0511(94)90036-1.
   Todorovic A, 2011, J NEUROSCI, V31, P9118, DOI 10.1523/JNEUROSCI.1425-11.2011.
   Trujillo-Barreto NJ, 2004, NEUROIMAGE, V21, P1300, DOI 10.1016/j.neuroimage.2003.11.008.
   Tse CY, 2006, NEUROIMAGE, V29, P314, DOI 10.1016/j.neuroimage.2005.07.013.
   Valdes-Sosa P, 2000, BIOMAG 96: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON BIOMAGNETISM, VOLS I \& II, P373.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015.
   Vespignani F, 2010, J COGNITIVE NEUROSCI, V22, P1682, DOI 10.1162/jocn.2009.21293.
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012.
   Wacongne C, 2011, P NATL ACAD SCI USA, V108, P20754, DOI 10.1073/pnas.1117807108.
   Walker L J, 2001, J Am Acad Audiol, V12, P348.
   Wang L, 2012, FRONT PSYCHOL, V3, DOI {[}10.3389/fpsyg.2012.00187, 10.3389/fpsyg.2012.00438].
   Winkler I, 1998, NEUROREPORT, V9, P3809, DOI 10.1097/00001756-199812010-00008.
   Winkler I, 1996, BRAIN RES, V742, P239, DOI 10.1016/S0006-8993(96)01008-6.
   Winkler I, 1998, NEUROREPORT, V9, P495, DOI 10.1097/00001756-199802160-00025.
   Winkler I, 1996, J COGNITIVE NEUROSCI, V8, P403, DOI 10.1162/jocn.1996.8.5.403.
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147.
   Worsley KJ, 1996, HUM BRAIN MAPP, V4, P74, DOI 10.1002/(SICI)1097-0193(1996)4:1<74::AID-HBM5>3.0.CO;2-M.
   Yabe H, 1997, NEUROREPORT, V8, P1971, DOI 10.1097/00001756-199705260-00035.
   Yabe H, 1998, PSYCHOPHYSIOLOGY, V35, P615, DOI 10.1017/S0048577298000183.
   Yabe H, 2001, COGNITIVE BRAIN RES, V12, P39, DOI 10.1016/S0926-6410(01)00027-1.
   ZWISLOCKI JJ, 1969, J ACOUST SOC AM, V46, P431, DOI 10.1121/1.1911708.}},
Number-of-Cited-References = {{115}},
Times-Cited = {{26}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{22}},
Journal-ISO = {{Cortex}},
Doc-Delivery-Number = {{AG0JF}},
Unique-ID = {{ISI:000335101100003}},
DA = {{2020-12-06}},
}

@article{ ISI:000332951800003,
Author = {Yang, Jae-Mo and Kang, Hong-Goo},
Title = {{Online Speech Dereverberation Algorithm Based on Adaptive Multichannel
   Linear Prediction}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2014}},
Volume = {{22}},
Number = {{3}},
Pages = {{608-619}},
Month = {{MAR}},
Abstract = {{This paper proposes a real-time acoustic channel equalization method
   that uses an adaptive multichannel linear prediction technique. In
   general, multichannel equalization algorithms can eliminate
   reverberation if they meet the following specific conditions including:
   the co-primeness between channels and sufficient filter length. It also
   requires the characteristic of correct channel information, however, it
   is difficult to estimate accurate acoustic channels in a practical
   system. The proposed method utilizes a theoretically perfect channel
   equalization algorithm and considers problems that may arise in the
   actual system. Linear-predictive multi-input equalization (LIME) is also
   an appropriate attempt at blind dereverberation by assuring the
   theoretical basis. However, a huge computational cost is incurred by
   calculating the large dimensions of a covariance matrix and its
   inversion. The proposed equalizer is developed as a multichannel linear
   prediction (MLP) oriented structure with a new formula that is optimized
   to time-varying acoustical room environments. Moreover, experimental
   results show that the proposed method works well even if the channel
   characteristics of each microphone are similar. The results of
   experiments using various room impulse response (RIR) models, including
   both the synthesized and real room environments, show that the proposed
   method is superior to conventional methods.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yang, JM (Corresponding Author), Yonsei Univ, Sch Elect \& Elect Engn, Seoul 120749, South Korea.
   Yang, Jae-Mo; Kang, Hong-Goo, Yonsei Univ, Sch Elect \& Elect Engn, Seoul 120749, South Korea.}},
DOI = {{10.1109/TASLP.2013.2294578}},
ISSN = {{2329-9290}},
Keywords = {{Acoustic channel equalization; adaptive filter; dereverberation;
   multichannel linear prediction}},
Keywords-Plus = {{NEAR-COMMON ZEROS; SYSTEM-IDENTIFICATION; EQUALIZATION; ENVIRONMENTS;
   DIVERSITY}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{jaemo2879@dsp.yonsei.ac.kr
   hgkang@yonsei.ac.kr}},
Cited-References = {{Chong E. K., 2004, INTRO OPTIMIZATION.
   Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698.
   Gillespie BW, 2001, INT CONF ACOUST SPEE, P3701, DOI 10.1109/ICASSP.2001.940646.
   Gillespie BW, 2002, INT CONF ACOUST SPEE, P557.
   Habets EAP, 2007, INT CONF ACOUST SPEE, P901.
   Habets E. A. P., 2007, THESIS TU EINDHOVEN.
   Haykin S., 2003, ADAPTIVE FILTER THEO.
   HUGHES CP, 2004, ZEROS RANDOM POLYNOM.
   Jeub M., 2010, P 20 INT C AC.
   Khong AWH, 2008, INT CONF ACOUST SPEE, P389, DOI 10.1109/ICASSP.2008.4517628.
   Kinoshita K, 2006, INT CONF ACOUST SPEE, P817.
   Kodrasi I, 2012, INT CONF ACOUST SPEE, P537, DOI 10.1109/ICASSP.2012.6287935.
   Leung SH, 2005, IEEE T SIGNAL PROCES, V53, P3141, DOI 10.1109/TSP.2005.851110.
   Lin X, 2012, IEEE T AUDIO SPEECH, V20, P888, DOI 10.1109/TASL.2011.2168208.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Mosayyebpour S, 2012, IEEE T AUDIO SPEECH, V20, P1617, DOI 10.1109/TASL.2012.2186804.
   Nakatani T, 2010, IEEE T AUDIO SPEECH, V18, P1717, DOI 10.1109/TASL.2010.2052251.
   Okamoto T, 2012, APPL ACOUST, V73, P50, DOI 10.1016/j.apacoust.2011.07.004.
   Paleologu C, 2008, IEEE SIGNAL PROC LET, V15, P597, DOI 10.1109/LSP.2008.2001559.
   Ram I., 2008, P EUR SIGN PROC C EU.
   Rombouts S., 1998, MATH9804133 ARXIV.
   Triki M., 2005, P IWAENC.
   TRIKI M, 2006, INT CONF ACOUST SPEE, P97.
   Yoshioka T, 2009, INT CONF ACOUST SPEE, P3733, DOI 10.1109/ICASSP.2009.4960438.
   Zhang W., 2009, EUR SIGN PROC C EUSI, P1427.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{AD0VH}},
Unique-ID = {{ISI:000332951800003}},
DA = {{2020-12-06}},
}

@article{ ISI:000332614900013,
Author = {Jensen, Jesper and Taal, Cees H.},
Title = {{Speech Intelligibility Prediction Based on Mutual Information}},
Journal = {{IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2014}},
Volume = {{22}},
Number = {{2}},
Pages = {{430-440}},
Month = {{FEB}},
Abstract = {{This paper deals with the problem of predicting the average
   intelligibility of noisy and potentially processed speech signals, as
   observed by a group of normal hearing listeners. We propose a model
   which performs this prediction based on the hypothesis that
   intelligibility is monotonically related to the mutual information
   between critical-band amplitude envelopes of the clean signal and the
   corresponding noisy/processed signal. The resulting intelligibility
   predictor turns out to be a simple function of the mean-square error
   (mse) that arises when estimating a clean critical- band amplitude using
   a minimum mean-square error (mmse) estimator based on the
   noisy/processed amplitude. The proposed model predicts that speech
   intelligibility cannot be improved by any processing of noisy
   critical-band amplitudes. Furthermore, the proposed intelligibility
   predictor performs well (rho > 0.95) in predicting the intelligibility
   of speech signals contaminated by additive noise and potentially
   non-linearly processed using time-frequency weighting.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jensen, J (Corresponding Author), Oticon AS, DK-2765 Smorum, Denmark.
   Jensen, Jesper, Oticon AS, DK-2765 Smorum, Denmark.
   Jensen, Jesper, Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.
   Taal, Cees H., Leiden Univ, Med Ctr, ENT Dept, NL-2300 RA Leiden, Netherlands.}},
DOI = {{10.1109/TASLP.2013.2295914}},
ISSN = {{2329-9290}},
EISSN = {{2329-9304}},
Keywords = {{Instrumental measures; noise reduction; objective distortion measures;
   speech enhancement; speech intelligibility prediction}},
Keywords-Plus = {{OBJECTIVE MEASURES; NOISE; MODULATION; ENVELOPE; MASKING}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{jsj@oticon.dk
   cees.taal@philips.com}},
Cited-References = {{Allen JB, 2005, AUDITORY SIGNAL PROCESSINGP: PHYSIOLOGY, PSYCHOACOUSTICS, AND MODELS, P314.
   {[}Anonymous], 1969, S35 ANSI.
   {[}Anonymous], 1995, S35 ANSI.
   {[}Anonymous], 2003, IEC6026816.
   BIALEK W, 1993, PHYSICA A, V200, P581, DOI 10.1016/0378-4371(93)90563-J.
   Boldt Jesper B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1849.
   Brillinger DR, 2001, TIME SERIES DATA ANA.
   Bronkhorst AW, 2000, ACUSTICA, V86, P117.
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929.
   Christiansen C, 2010, SPEECH COMMUN, V52, P678, DOI 10.1016/j.specom.2010.03.004.
   Cover T. M., 1991, ELEMENTS INFORM THEO.
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959.
   Dau T, 1997, J ACOUST SOC AM, V102, P2892, DOI 10.1121/1.420344.
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   HOHMANN V, 1995, J ACOUST SOC AM, V97, P1191, DOI 10.1121/1.413092.
   HOUTGAST T, 1971, ACUSTICA, V25, P355.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Hu K, 2007, INT CONF ACOUST SPEE, P561.
   Jensen J, 2012, IEEE T AUDIO SPEECH, V20, P92, DOI 10.1109/TASL.2011.2157685.
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502.
   Kapur JN, 1990, MAXIMUM ENTROPY MODE.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673.
   Koopman J., 2007, P 8 EFAS C 10 DGA C.
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1689, DOI 10.1121/1.1909094.
   Leijon A, 2007, HEARING - FROM SENSORY PROCESSING TO PERCEPTION, P525, DOI 10.1007/978-3-540-73009-5\_56.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   LUDVIGSEN C, 1993, SCAND AUDIOL, V22, P50.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915.
   Martin R., 2001, P INT WORKSH AC ECH, P167.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal C. H., 2010, P INT WORKSH AC ECH.
   Taal C. H., 2009, P INTERSPEECH, P1947.
   Taal CH, 2011, J ACOUST SOC AM, V130, P3013, DOI 10.1121/1.3641373.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Taghia J, 2012, INT CONF ACOUST SPEE, P65, DOI 10.1109/ICASSP.2012.6287818.
   Therrien C. W., 1992, DISCRETE RANDOM SIGN.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{24}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{IEEE-ACM Trans. Audio Speech Lang.}},
Doc-Delivery-Number = {{AC6ES}},
Unique-ID = {{ISI:000332614900013}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000330036400004,
Author = {Drugman, Thomas},
Title = {{Maximum Phase Modeling for Sparse Linear Prediction of Speech}},
Journal = {{IEEE SIGNAL PROCESSING LETTERS}},
Year = {{2014}},
Volume = {{21}},
Number = {{2}},
Pages = {{185-189}},
Month = {{FEB}},
Abstract = {{Linear prediction (LP) is an ubiquitous analysis method in speech
   processing. Various studies have focused on sparse LP algorithms by
   introducing sparsity constraints into the LP framework. Sparse LP has
   been shown to be effective in several issues related to speech modeling
   and coding. However, all existing approaches assume the speech signal to
   be minimum-phase. Because speech is known to be mixed-phase, the
   resulting residual signal contains a persistent maximum-phase component.
   The aim of this paper is to propose a novel technique which incorporates
   a modeling of the maximum-phase contribution of speech, and can be
   applied to any filter representation. The proposed method is shown to
   significantly increase the sparsity of the LP residual signal and to be
   effective in two illustrative applications: speech polarity detection
   and excitation modeling.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Drugman, T (Corresponding Author), Univ Mons, TCTS Lab, B-7000 Mons, Belgium.
   Univ Mons, TCTS Lab, B-7000 Mons, Belgium.}},
DOI = {{10.1109/LSP.2013.2296944}},
ISSN = {{1070-9908}},
EISSN = {{1558-2361}},
Keywords = {{Linear prediction; maximum phase; residual excitation; sparsity; speech
   processing}},
Keywords-Plus = {{STABILITY}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{thomas.drugman@umons.ac.be}},
Funding-Acknowledgement = {{FNRSFonds de la Recherche Scientifique - FNRS}},
Funding-Text = {{Manuscript received November 21, 2013; revised December 19, 2013;
   accepted December 23, 2013. Date of current version January 07, 2014.
   This work was supported by the FNRS. The associate editor coordinating
   the review of this manuscript and approving it for publication was Prof.
   Constantine L. Kotropoulos.}},
Cited-References = {{Boyd S., 2004, CONVEX OPTIMIZATION.
   Bozkurt B., 2004, P ICLSP.
   Candes E., 2005, L1 MAGIC RECOVERY SP.
   CYBENKO G, 1980, SIAM J SCI STAT COMP, V1, P303, DOI 10.1137/0901021.
   Drugman T., 2011, P INTERSPEECH.
   Drugman T., 2009, ISCA WORKSH NONL SPE.
   Drugman T. D. T., 2009, P INTERSPEECH.
   Drugman T, 2013, IEEE SIGNAL PROC LET, V20, P387, DOI 10.1109/LSP.2013.2249661.
   Drugman T, 2012, IEEE T AUDIO SPEECH, V20, P994, DOI 10.1109/TASL.2011.2170835.
   Drugman T, 2012, IEEE T AUDIO SPEECH, V20, P968, DOI 10.1109/TASL.2011.2169787.
   Drugman T, 2012, COMPUT SPEECH LANG, V26, P20, DOI 10.1016/j.csl.2011.03.003.
   Drugman T, 2011, SPEECH COMMUN, V53, P855, DOI 10.1016/j.specom.2011.02.004.
   Fant G., 1985, STL QPSR, V4, P1, DOI DOI 10.1016/0167-6393(89)90001-0.
   Gardner WR, 1997, IEEE T SPEECH AUDI P, V5, P1, DOI 10.1109/89.554263.
   Garofolo J. S., 1993, DARPA TIMIT ACOUSTIC.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457.
   Hurley N, 2009, IEEE T INFORM THEORY, V55, P4723, DOI 10.1109/TIT.2009.2027527.
   Jolliffe I., 2005, PRINCIPAL COMPONENT.
   Khanagha V, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-3.
   KNOCKAERT L, 1992, IEEE T INFORM THEORY, V38, P1483, DOI 10.1109/18.149499.
   Kominek J., 2004, P 5 ISCA SPEECH SYNT, P223.
   MA CX, 1993, SPEECH COMMUN, V12, P69, DOI 10.1016/0167-6393(93)90019-H.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Quatieri T. F., 2002, DISCRETE TIME SPEECH.
   Rickard S, 2004, C INF SCI SYST.
   Tokuda K., 1994, P ICLSP.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Signal Process. Lett.}},
Doc-Delivery-Number = {{294HR}},
Unique-ID = {{ISI:000330036400004}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000349765600089,
Author = {Shiota, Satoshi and Wang, Longbiao and Odani, Kyohei and Kai, Atsuhiko
   and Li, Weifeng},
Editor = {{Dong, M and Tao, J and Li, H and Zheng, TF and Lu, Y}},
Title = {{Distant-talking speech recognition using multi-channel LMS and
   multiple-step linear prediction}},
Booktitle = {{2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING
   (ISCSLP)}},
Year = {{2014}},
Pages = {{384+}},
Note = {{9th International Symposium on Chinese Spoken Language Processing
   (ISCSLP), SINGAPORE, SEP 12-14, 2014}},
Organization = {{Chinese \& Oriental Language Informat Proc Soc; Int Speech Commun Assoc;
   Inst Infocomm Res; ISCA Special Interest Grp Chinese Spoken Language
   Proc; Natl Conf Man Machine Speed Commun China; IEEE Singapore SMC
   Chapter; IEEE}},
Abstract = {{Previously, dereverberation methods based on generalized spectral
   subtraction (GSS) using multi-channel least mean squares (MCLMS) and
   multiple-step linear prediction (MSLP) have been proposed. Bath methods
   have in common to estimate the late reverberation characteristics
   blindly, to suppress the late reverberation by spectral subtraction.
   Speech recognition performances of both methods are changing according
   to length of late reverberation to be estimated. In this paper, we
   investigated effect of estimated length of late reverberation on
   distant-talking speech recognition. Moreover, we proposed method to
   combine MCLMS and MSLP. As a result, MCLMS-based dereverberation method
   is effective to reduce in the long reverberation with approximately 200
   ms and MS LP dereverberation is effective for the short reverberation
   with approximately 100 ins. The proposed method of ``MSLP+MCLMS{''}
   (that is, MCLMS is applied after MSLP) outperformed than all other
   dereverberation methods.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Shiota, S (Corresponding Author), Nagaoka Univ Technol, Nagaoka, Niigata 9402188, Japan.
   Shiota, Satoshi; Wang, Longbiao, Nagaoka Univ Technol, Nagaoka, Niigata 9402188, Japan.
   Odani, Kyohei; Kai, Atsuhiko, Shizuoka Univ, Hamamatsu, Shizuoka 4328561, Japan.
   Li, Weifeng, Tsinghua Univ, Shenzhen 100084, Peoples R China.}},
ISBN = {{978-1-4799-4219-0}},
Keywords = {{speech recognition; reverberant speech; multi-channel LMS; multiple-step
   linear prediction; generalized spectral subtraction}},
Keywords-Plus = {{ALGORITHM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{s\_shiota@stn.nagaokaut.ac.jp
   wang@vos.nagaokaut.ac.jp
   kai@sys.eng.shizuoka.ac.jp}},
Funding-Acknowledgement = {{Tateisi Science and Technology Foundation}},
Funding-Text = {{This work was partially supported by a research grant from the Tateisi
   Science and Technology Foundation.}},
Cited-References = {{Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698.
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530.
   HABETS E, 2005, P 30 IEEE INT C AC S, P173.
   Huang YT, 2005, IEEE SIGNAL PROC LET, V12, P173, DOI 10.1109/LSP.2004.842286.
   Hughes TB, 1999, IEEE T SPEECH AUDI P, V7, P346, DOI 10.1109/89.759045.
   Ishii T., 2013, P INTERSPEECH, P3512.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   Lee A., 2001, P EUR C SPEECH COMM, P1691.
   Li WF, 2013, INT CONF ACOUST SPEE, P7117, DOI 10.1109/ICASSP.2013.6639043.
   Maganti H, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P570.
   Nakamura S., 2000, P LREC, P965.
   Nishiura T, 2008, P INTERSPEECH 2008 S, P968.
   Nugraha A., 2014, EURASIP J ADV SIG PR, V2014, p{[}13, 1].
   Odani K, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1250.
   Sadjadi SO, 2011, INT CONF ACOUST SPEE, P5448.
   Sehr A, 2010, IEEE T AUDIO SPEECH, V18, P1676, DOI 10.1109/TASL.2010.2050511.
   Wang L, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1032.
   Wang L., 2006, EURASIP J APPL SIG P, V2006, P1.
   Wang L., 2005, P EUROSPEECH 2005, P2661.
   Wang LB, 2007, INT CONF ACOUST SPEE, P817.
   Wang LB, 2007, SPEECH COMMUN, V49, P501, DOI 10.1016/j.specom.2007.04.004.
   Wang LB, 2013, INT CONF ACOUST SPEE, P7224, DOI 10.1109/ICASSP.2013.6639065.
   Wang LB, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-12.
   Wang LB, 2011, IEICE T INF SYST, VE94D, P659, DOI 10.1587/transinf.E94.D.659.
   Wu MY, 2006, IEEE T AUDIO SPEECH, V14, P774, DOI 10.1109/TSA.2005.858066.
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BC0WX}},
Unique-ID = {{ISI:000349765600089}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000349765600128,
Author = {Liu, Shanfeng and Wen, Zhengqi and Li, Ya and Tao, Jianghua and Liu, Bin},
Editor = {{Dong, M and Tao, J and Li, H and Zheng, TF and Lu, Y}},
Title = {{Context Features Based Pre-Selection and Weight Prediction in
   Concatenation Speech Synthesis System}},
Booktitle = {{2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING
   (ISCSLP)}},
Year = {{2014}},
Pages = {{506-510}},
Note = {{9th International Symposium on Chinese Spoken Language Processing
   (ISCSLP), SINGAPORE, SEP 12-14, 2014}},
Organization = {{Chinese \& Oriental Language Informat Proc Soc; Int Speech Commun Assoc;
   Inst Infocomm Res; ISCA Special Interest Grp Chinese Spoken Language
   Proc; Natl Conf Man Machine Speed Commun China; IEEE Singapore SMC
   Chapter; IEEE}},
Abstract = {{How to generate natural-sounding synthesized speech has been challenging
   all the researchers in speech synthesis area. Experiments show that
   speech concatenated by units selected from large speech corpus has a
   better performance. However how to limit the searching space and predict
   weights when calculating target cost is an important problem. This paper
   presents a detailed hierarchical pre-selection method to limit the
   searching of space. After three layers of pre-selection, a set of units
   are selected as the candidate units. In order to ensure the continuity
   in the duration, the prediction model is used in the hierarchical
   pre-selection. Meanwhile, M5P algorithm which is combined with decision
   tree and regression is presented in this paper to predict weights needed
   in target cost calculation. Experimental result shows that these two
   approaches can generate high quality speech.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Liu, SF (Corresponding Author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.
   Liu, Shanfeng; Wen, Zhengqi; Li, Ya; Tao, Jianghua; Liu, Bin, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.}},
ISBN = {{978-1-4799-4219-0}},
Keywords = {{concatenation speech synthesis; hierarchical pre-selection; weight
   prediction}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{sfliu@nlpr.ia.ac.cn
   zqwen@nlpr.ia.ac.cn
   yli@nlpr.ia.ac.cn
   jhtao@nlpr.ia.ac.cn
   liubin@nlpr.ia.ac.cn}},
Cited-References = {{Blouin C, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON SPEECH SYNTHESIS, P231.
   Blouin C, 2003, AC SPEECH SIGN PROC, V1.
   DUTOIT T, 1994, INT CONF ACOUST SPEE, P565.
   Gimenez de los Galanes F M, 1994, AC SPEECH SIGN PROC, V1.
   Hunt AJ, 1996, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.1996.541110.
   Iwahashi N., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P65, DOI 10.1109/ICASSP.1992.226119.
   Ling Z H, 2002, INT S CHIN SPOK LANG.
   Ling Z.-H., 2006, INTERSPEECH.
   Liu S F, 2014, INTERSPEECH 20 UNPUB.
   Ran Zhang, 2013, OR COCOSDA HELD JOIN, P1.
   SAGISAKA Y, 1992, P ICSLP, P483.
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820.
   Webster G, 2010, SPEECH PROSODY UNPUB.
   Yu J, 2007, AC SPEECH SIGN PROC, V4.
   Zhao Y, 2006, AC SPEECH SIGN PROC, V1, pI.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BC0WX}},
Unique-ID = {{ISI:000349765600128}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000350149800037,
Author = {Hayashida, Kohei and Nakayama, Masato and Nishiur, Takanobu and
   Yamashita, Yoichi},
Editor = {{NevesSilva, R and Tshirintzis, GA and Uskov, V and Howlett, RJ and Jain, LC}},
Title = {{Gaussian Mixture Model Learning for Desired Speech Discrimination Based
   on Kurtosis of Linear Prediction Residual Signals}},
Booktitle = {{SMART DIGITAL FUTURES 2014}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2014}},
Volume = {{262}},
Pages = {{367-376}},
Note = {{KES International Conference on Smart Digital Futures (SDF), Chania,
   GREECE, JUN 18-20, 2014}},
Organization = {{KES}},
Abstract = {{Desired/undesired speech discrimination is as important as
   speech/non-speech discrimination to achieve useful applications such as
   speech interfaces and teleconferencing systems. Conventional methods for
   voice activity detection (VAD) utilize the directional information of
   sound sources to distinguish desired from undesired speech. However,
   these methods have to use multiple microphones to estimate the
   directions of sound sources. Here, we propose a new method that uses a
   single microphone to discriminate desired from undesired speech. We
   assumed that the desired talkers would be close to the microphone, so
   the proposed method discriminates close/distant-talking speech from
   observed signals with a Gaussian mixture model that was constructed by
   the kurtosis of the linear prediction (LP) residual signals in advance.
   The experimental results revealed that the proposed method could
   distinguish close-talking speech from distant-talking speech within a
   10\% equal error rate (EER) in ordinary reverberant environments.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hayashida, K (Corresponding Author), Ritsumeikan Univ, Grad Sch Informat Sci \& Engn, 1-1-1 Nojihigashi, Kusatsu, Shiga 5258577, Japan.
   Hayashida, Kohei, Ritsumeikan Univ, Grad Sch Informat Sci \& Engn, Kusatsu, Shiga 5258577, Japan.
   Nakayama, Masato; Nishiur, Takanobu; Yamashita, Yoichi, Ritsumeikan Univ, Colleage Informat Sci \& Engn, Kusatsu, Shiga 5258577, Japan.}},
DOI = {{10.3233/978-1-61499-405-3-367}},
ISSN = {{0922-6389}},
ISBN = {{978-1-61499-405-3; 978-1-61499-404-6}},
Keywords = {{Close/distant talker discrimination; kurtosis; linear prediction
   residual signal; Gaussian mixture model}},
Keywords-Plus = {{MAXIMUM-LIKELIHOOD; EM ALGORITHM; LOCALIZATION; VOICE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{cm012063@ed.ritsumei.ac.jp}},
Cited-References = {{Benyassine A, 1997, IEEE COMMUN MAG, V35, P64, DOI 10.1109/35.620527.
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x.
   ETSI Standard, 2007, 202050 ETSI ES, P1.
   Gillespie BW, 2001, INT CONF ACOUST SPEE, P3701, DOI 10.1109/ICASSP.2001.940646.
   GUO YM, 2012, 2012 IEEE INT C AC, P4901.
   Hioka Y, 2011, IEEE T AUDIO SPEECH, V19, P2374, DOI 10.1109/TASL.2011.2134091.
   Huang KL, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P126, DOI 10.1109/ISCSLP.2012.6423514.
   Kitaoka N, 2009, ACOUST SCI TECHNOL, V30, P363, DOI 10.1250/ast.30.363.
   Nakayama M, 2013, INT CONF ACOUST SPEE, P423, DOI 10.1109/ICASSP.2013.6637682.
   Pourmohammad A, 2012, IEEE SYST J, V6, P455, DOI 10.1109/JSYST.2011.2176766.
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034.
   Rubio JE, 2007, INT CONF ACOUST SPEE, P385.
   Valin JM, 2007, ROBOT AUTON SYST, V55, P216, DOI 10.1016/j.robot.2006.08.004.
   YANG M, 1994, IEEE T INSTRUM MEAS, V43, P861, DOI 10.1109/19.368084.
   Yegnanarayana B, 2000, IEEE T SPEECH AUDI P, V8, P267, DOI 10.1109/89.841209.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BC1JJ}},
Unique-ID = {{ISI:000350149800037}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000348926100044,
Author = {HaCohen-Kerner, Yaakov and Applebaum, Asaf and Bitterman, Jacob},
Editor = {{Przepiorkowski, A and Ogrodniczuk, M}},
Title = {{Experiments with Language Models for Word Completion and Prediction in
   Hebrew}},
Booktitle = {{ADVANCES IN NATURAL LANGUAGE PROCESSING}},
Series = {{Lecture Notes in Artificial Intelligence}},
Year = {{2014}},
Volume = {{8686}},
Pages = {{450-462}},
Note = {{9th International Conference on Natural Language Processing (NLP),
   Warsaw, POLAND, SEP 17-19, 2014}},
Organization = {{Polish Acad Sci, Inst Comp Sci}},
Abstract = {{In this paper, we describe various language models (LMs) and
   combinations created to support word prediction and completion in
   Hebrew. We define and apply 5 general types of LMs: (1) Basic LMs
   (unigrams, bigrams, trigrams, and quadgrams), (2) Backoff LMs, (3) LMs
   Integrated with tagged LMs, (4) Interpolated LMs, and (5) Interpolated
   LMs Integrated with tagged LMs. 16 specific implementations of these LMs
   were compared using 3 types of Israeli web newspaper corpora. The
   foremost keystroke saving results were achieved with LMs of the most
   complex variety, the Interpolated LMs Integrated with tagged LMs.
   Therefore, we conclude that combining all strengths by creating a
   synthesis of all four basic LMs and the tagged LMs leads to the best
   results.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{HaCohen-Kerner, Y (Corresponding Author), Jerusalem Coll Technol, Lev Acad Ctr, Dept Comp Sci, 21 Havaad Haleumi St,POB 16031, IL-9116001 Jerusalem, Israel.
   HaCohen-Kerner, Yaakov; Applebaum, Asaf; Bitterman, Jacob, Jerusalem Coll Technol, Lev Acad Ctr, Dept Comp Sci, IL-9116001 Jerusalem, Israel.}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-10888-9; 978-3-319-10887-2}},
Keywords = {{Hebrew; Keystroke savings; Language models; Word completion; Word
   prediction}},
Keywords-Plus = {{KEYBOARD}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications}},
Author-Email = {{kerner@jct.ac.il
   asaf.app@gmail.com
   Jacobitterman@gmail.com}},
Cited-References = {{Adler M., 2007, THESIS BENGURION U I.
   Adler M., 2008, LREC 2008.
   Anson D, 2006, ASSIST TECHNOL, V18, P146, DOI 10.1080/10400435.2006.10131913.
   Badaskar S., 2008, IJCNLP, VII, P817.
   Beukelman D., 2008, AUGMENTATIVE ALTERNA, P77.
   Beukelman D. R., 2005, AUGMENTATIVE ALTERNA.
   Beyerlein P, 1998, INT CONF ACOUST SPEE, P481, DOI 10.1109/ICASSP.1998.674472.
   Calculator S., 2004, TECHNICAL REPORT.
   Carlberger A., 1997, P ACL WORKSH NAT LAN, P23.
   Carlberger J., 1997, THESIS ROYAL I TECHN.
   Darragh J. J., 1991, Interacting with Computers, V3, P27, DOI 10.1016/0953-5438(91)90004-L.
   DARRAGH JJ, 1990, COMPUTER, V23, P41, DOI 10.1109/2.60879.
   Fossett B., 2009, HDB DEV DISABILITIES, P330.
   Goldberg Y., 2008, ACL, P746.
   HaCohen-Kerner Y, 2012, LECT NOTES COMPUT SC, V7608, P237, DOI 10.1007/978-3-642-34109-0\_25.
   Kimelfeld B, 2007, LECT NOTES COMPUT SC, V4518, P253.
   Kirchhoff K, 2006, COMPUT SPEECH LANG, V20, P589, DOI 10.1016/j.csl.2005.10.001.
   Li J., 2005, P 7 INT ACM SIGACCES, P121.
   McMahon J.G.G., 1994, THESIS QUEENS U BELF.
   Morris C, 1992, Assist Technol, V4, P51.
   Netzer Y., 2008, ISAAC.
   NEWELL A., 1998, NAT LANG ENG, V41, P1, DOI DOI 10.1017/S135132499800182X.
   Shein F., 2001, TECHN PERS DIS C LOS.
   Swiffin A. L., 1985, Proceedings of the Eighth Annual Conference on Rehabilitation Technology. Technology - A Bridge to Independence, P197.
   Tam C, 2009, ASSIST TECHNOL, V21, P105, DOI 10.1080/10400430903175473.
   Trnka K., 2009, ACM T ACCESS COMPUT, V1, P1, DOI DOI 10.1145/1497302.1497307.
   Trnka K., 2008, ACL 2008, P261.
   Wandmacher T., 2007, P ACL SIGDAT JOINT C, P503.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BC0DJ}},
Unique-ID = {{ISI:000348926100044}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000346153100051,
Author = {Quintero, R. and Almeida, J. and Llorca, D. F. and Sotelo, M. A.},
Book-Group-Author = {{IEEE}},
Title = {{Pedestrian Path Prediction using Body Language Traits}},
Booktitle = {{2014 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS}},
Series = {{IEEE Intelligent Vehicles Symposium}},
Year = {{2014}},
Pages = {{317-323}},
Note = {{IEEE Intelligent Vehicles Symposium (IV), Dearborn, MI, JUN 08-11, 2014}},
Organization = {{IEEE; IEEE Intelligent Transportat Syst Soc}},
Abstract = {{Driver Assistance Systems have achieved a high level of maturity in the
   latest years. As an example of that, sophisticated pedestrian protection
   systems are already available in a number of commercial vehicles from
   several OEMs. However, accurate pedestrian path prediction is needed in
   order to go a step further in terms of safety and reliability, since it
   can make the difference between effective and non-effective
   intervention. In this paper, we consider the three-dimensional
   pedestrian body language in order to perform path prediction in a
   probabilistic framework. For this purpose, the different body parts and
   joints are detected using stereo vision. We propose the use of GPDM
   (Gaussian Process Dynamical Models) for reducing the high dimensionality
   of the input feature vector (composed by joints and displacement
   vectors) in the 3D pose space and for learning the pedestrian dynamics
   in a latent space. Experimental results show that accurate path
   prediction can be achieved at a time horizon of approximate to 0.8 s.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Quintero, R (Corresponding Author), Univ Alcala de Henares, Dept Comp Engn, E-28801 Alcala De Henares, Spain.
   Quintero, R.; Llorca, D. F.; Sotelo, M. A., Univ Alcala de Henares, Dept Comp Engn, E-28801 Alcala De Henares, Spain.
   Almeida, J., Univ Aveiro, Dept Mech Engn, Aveiro, Portugal.}},
ISSN = {{1931-0587}},
ISBN = {{978-1-4799-3637-3}},
Keywords = {{Pedestrian Path Prediction; Prediction of Intentions; Pedestrian
   Protection Systems; ADAS; Vision}},
Keywords-Plus = {{MODELS}},
Research-Areas = {{Computer Science; Transportation}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Transportation Science \&
   Technology}},
Author-Email = {{raul.quintero@aut.uah.es
   almeida.j@ua.pt
   llorca@aut.uah.es
   sotelo@aut.uah.es}},
ResearcherID-Numbers = {{Fernandez-Llorca, David/K-2613-2012
   Sotelo, Miguel Angel/A-8663-2013}},
ORCID-Numbers = {{Fernandez-Llorca, David/0000-0003-2433-7110
   Sotelo, Miguel Angel/0000-0001-8809-2103}},
Funding-Acknowledgement = {{Spanish Ministry of Economy {[}ONDA-FP TRA2011-27712-0O2-02]; Portuguese
   FCTPortuguese Foundation for Science and Technology
   {[}SFRH/BD/73181/2010]}},
Funding-Text = {{This work was supported by the Spanish Ministry of Economy under Grant
   ONDA-FP TRA2011-27712-0O2-02 and the Portuguese FCT under Grant
   SFRH/BD/73181/2010.}},
Cited-References = {{Boers Y, 2003, IEE P-RADAR SON NAV, V150, P344, DOI 10.1049/ip-rsn:20030741.
   Chun-Chieh Lee, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P1785, DOI 10.1109/ICMLC.2011.6017007.
   CMU, CMU GRAPH LAB MOT CA.
   Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155.
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260.
   Farmer ME, 2002, INT C PATT RECOG, P20, DOI 10.1109/ICPR.2002.1048226.
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167.
   Geiger A., 2012, C COMP VIS PATT REC.
   Geronimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122.
   Girshick R. B., DISCRIMINATIVELY TRA.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Keller Christoph G., 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P386, DOI 10.1007/978-3-642-23123-0\_39.
   Keller C. G., 2014, IEEE T INTE IN PRESS, V15.
   Kohler S, 2013, IEEE INTEL TRANSP SY, V5, P87, DOI 10.1109/MITS.2013.2276939.
   Lawrence ND, 2004, ADV NEUR IN, V16, P329.
   Llorca DF, 2012, TRANSPORT RES C-EMER, V25, P226, DOI 10.1016/j.trc.2012.06.006.
   MOLLER M, 1990, PB339 U AARH COMP SC.
   References M., 2003, STRATEGIES TERMS VUL.
   Schmidt S, 2009, TRANSPORT RES F-TRAF, V12, P300, DOI 10.1016/j.trf.2009.02.003.
   Urtasun R., 2006, P 2006 IEEE COMP SOC, V1, P238, DOI DOI 10.1109/CVPR.2006.15.
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167.
   Yao A., 2011, ADV NEURAL INFORM PR, P1359.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{20}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BB7ZN}},
Unique-ID = {{ISI:000346153100051}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000343655304103,
Author = {Tanaka, Kou and Toda, Tomoki and Neubig, Graham and Sakti, Sakriani and
   Nakamura, Satoshi},
Book-Group-Author = {{IEEE}},
Title = {{AN EVALUATION OF EXCITATION FEATURE PREDICTION IN A HYBRID APPROACH TO
   ELECTROLARYNGEAL SPEECH ENHANCEMENT}},
Booktitle = {{2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2014}},
Note = {{IEEE International Conference on Acoustics, Speech and Signal Processing
   (ICASSP), Florence, ITALY, MAY 04-09, 2014}},
Organization = {{IEEE; IEEE Signal Proc Soc}},
Abstract = {{We implement removing micro-prosody with low-pass filtering and avoiding
   Unvoiced/Voiced (U/V) prediction as part of a hybrid approach to improve
   statistical excitation prediction in electrolaryngeal (EL) speech
   enhancement. An electrolarynx is a device that artificially generates
   excitation sounds to enable laryngectomees to produce EL speech.
   Although proficient laryngectomees can produce quite intelligible EL
   speech, it sounds very unnatural due to the mechanical excitation
   produced by the device. Moreover, the excitation sounds produced by the
   device often leak outside, adding noise to EL speech. To address these
   issues, in our previous work, we proposed a hybrid method using a noise
   reduction method for enhancing spectral parameters and voice conversion
   method for predicting excitation parameters. In this paper, we evaluate
   the effect of removing micro-prosody with low-pass filtering and
   avoiding U/V prediction in the hybrid enhancement process.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Tanaka, K (Corresponding Author), Nara Inst Sci \& Technol, Grad Sch Informat Sci, Nara, Japan.
   Tanaka, Kou; Toda, Tomoki; Neubig, Graham; Sakti, Sakriani; Nakamura, Satoshi, Nara Inst Sci \& Technol, Grad Sch Informat Sci, Nara, Japan.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-2893-4}},
Keywords = {{speaking aid; electrolaryngeal speech; hybrid approach; statistical
   excitation prediction; unvoiced/voiced information}},
Keywords-Plus = {{VOICE CONVERSION}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Cited-References = {{Basha S. K., 2012, P NAT C COMM KHAR IN, P516.
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   Doi H., 2013, THESIS NAIST.
   Doi H, 2011, INT CONF ACOUST SPEE, P5136.
   Kain A, 1998, INT CONF ACOUST SPEE, P285, DOI 10.1109/ICASSP.1998.674423.
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5.
   Kawahara H., 2001, P 2 MAVEBA SEP.
   Liu HJ, 2006, IEEE T BIO-MED ENG, V53, P865, DOI 10.1109/TBME.2006.872821.
   Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007.
   Ohtani Y, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2266.
   Sakurai A, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P817, DOI 10.1109/ICSLP.1996.607726.
   Sharifzadeh HR, 2010, IEEE T BIO-MED ENG, V57, P2448, DOI 10.1109/TBME.2010.2053369.
   Sim BL, 1998, IEEE T SPEECH AUDI P, V6, P328, DOI 10.1109/89.701361.
   Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472.
   Tanaka K, 2013, INTERSPEECH, P3066.
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344.
   Toda T, 2012, IEEE T AUDIO SPEECH, V20, P2505, DOI 10.1109/TASL.2012.2205241.
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820.
   Yu K, 2011, IEEE T AUDIO SPEECH, V19, P1071, DOI 10.1109/TASL.2010.2076805.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BB5BJ}},
Unique-ID = {{ISI:000343655304103}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000342920600016,
Author = {Guy, Stephen and Schwitter, Rolf},
Editor = {{Davis, B and Kaljurand, K and Kuhn, T}},
Title = {{Architecture of a Web-Based Predictive Editor for Controlled Natural
   Language Processing}},
Booktitle = {{CONTROLLED NATURAL LANGUAGE, CNL 2014}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2014}},
Volume = {{8625}},
Pages = {{167-178}},
Note = {{4th International Workshop on Controlled Natural Language (CNL), Natl
   Univ Ireland, Galway, IRELAND, AUG 20-22, 2014}},
Abstract = {{In this paper, we describe the architecture of a web-based predictive
   text editor being developed for the controlled natural language PENG
   ASP. This controlled language can be used to write non-monotonic
   specifications that have the same expressive power as Answer Set
   Programs. In order to support the writing process of these
   specifications, the predictive text editor communicates asynchronously
   with the controlled natural language processor that generates lookahead
   categories and additional auxiliary information for the author of a
   specification text. The text editor can display multiple sets of
   lookahead categories simultaneously for different possible sentence
   completions, anaphoric expressions, and supports the addition of new
   content words to the lexicon.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Guy, S (Corresponding Author), Macquarie Univ, Dept Comp, Sydney, NSW 2109, Australia.
   Guy, Stephen; Schwitter, Rolf, Macquarie Univ, Dept Comp, Sydney, NSW 2109, Australia.}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-10223-8}},
Keywords = {{controlled natural language processing; predictive editor; web-based
   authoring tools; answer set programming}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods}},
Author-Email = {{Stephen.Guy@mq.edu.au
   Rolf.Schwitter@mq.edu.au}},
ORCID-Numbers = {{Schwitter, Rolf/0000-0001-8998-7005}},
Cited-References = {{Brewka G., 2011, COMMUNICATIONS ACM, V54.
   Franconi E., 2011, P 24 INT WORKSH DESC.
   Freeman E., 2004, HEAD 1 DESIGN PATTER, P526.
   Fuchs NE, 2008, LECT NOTES COMPUT SC, V5224, P104.
   Gebser M, 2012, SYNTHESIS LECT ARTIF, V6, P1, DOI DOI 10.2200/S00457ED1V01Y201211AIM019.
   Gebser M, 2011, AI COMMUN, V24, P107, DOI 10.3233/AIC-2011-0491.
   Kamp Hans, 1993, DISCOURSE LOGIC.
   Kuhn T., 2008, P AUSTR LANG TECHN A, P46.
   Lierler Y., 2013, P 10 INT C COMP SEM, P340.
   Lifschitz V., 2008, P 23 AAAI C ART INT, V8, P1594.
   Power R, 2012, LECT NOTES COMPUT SC, V7427, P44, DOI 10.1007/978-3-642-32612-7\_4.
   Schwarz RB, 2003, PROCESSING AND PROPERTIES OF STRUCTURAL NANOMATERIALS, P141.
   SCHWITTER R., 2010, P 23 INT C COMP LING, V23-27, P1113.
   Schwitter R, 2013, THEOR PRACT LOG PROG, V13, P487, DOI 10.1017/S1471068413000306.
   Sommerville I., 2011, SOFTWARE ENG, P155.
   Tennant H. R., 1983, 21st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, P151.
   van Eijck J, 2011, ELSEV INSIGHT, P181, DOI 10.1016/B978-0-444-53726-3.00003-7.
   White C., 2009, P ALTA 2009 SYDN AUS, P80.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BB3OD}},
Unique-ID = {{ISI:000342920600016}},
DA = {{2020-12-06}},
}

@article{ ISI:000340046100003,
Author = {Poljac, Edita and Dahlslatt, Kristoffer and Bekkering, Harold},
Title = {{Shared predictive decision-making mechanisms in action and language}},
Journal = {{LANGUAGE COGNITION AND NEUROSCIENCE}},
Year = {{2014}},
Volume = {{29}},
Number = {{4}},
Pages = {{424-434}},
Abstract = {{Anticipatory eye movements are reported in studies on motor control as
   well as on language comprehension, implying that this major orienting
   system is involved in generating goal-directed behaviour within the
   action and the language domain. The cognitive contribution of these
   anticipatory eye movements to language and motor control, however, is
   still not well understood. This study investigated whether anticipatory
   eye movements reflect the working of a predictive mechanism that is
   shared between action and language and if so, whether the predictions
   are based primarily on an anticipation of the next discrete event
   (movement or word), or rather represent a semantic understanding of the
   end goal of the whole event (action or sentence). To this end, we
   designed two highly comparable paradigms with complex action sequences -
   one relying more strongly on the action and the other on the language
   system. The data demonstrated a pattern of predictive looks in our
   action observation paradigm that was similar to that observed in the
   visual world paradigm. These findings provide empirical evidence for the
   idea of a shared predictive mechanism that allows for fluent behaviour
   in action and language. Moreover, the pattern in both paradigms was such
   that it demonstrated an increase in predictive looks in the final action
   step. This finding implies that the predictive mechanism accumulates
   semantic information relevant for our overall (motor or linguistic)
   behavioural goals, rather than just predicting discrete events when
   making decisions about complex action sequences. Such a predictive
   mechanism facilitates understanding of complex situations, allowing for
   efficient and adaptive interaction with our environment.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Poljac, E (Corresponding Author), Univ Oxford, Dept Expt Psychol, S Parks Rd, Oxford OX1 3UD, England.
   Poljac, Edita, Univ Oxford, Dept Expt Psychol, Oxford OX1 3UD, England.
   Poljac, Edita; Dahlslatt, Kristoffer; Bekkering, Harold, Radboud Univ Nijmegen, Dept Cognit Psychol, NL-6525 ED Nijmegen, Netherlands.}},
DOI = {{10.1080/01690965.2013.791702}},
ISSN = {{2327-3798}},
EISSN = {{2327-3801}},
Keywords = {{action observation; language comprehension; anticipatory eye movements
   and predictions; semantics}},
Keywords-Plus = {{EYE-HAND COORDINATION; INTERNAL-MODELS; MOVEMENTS; COMPREHENSION;
   INDUCTION; SELECTION; LOOKING; MEMORY; SCENE}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Behavioral Sciences;
   Linguistics; Psychology, Experimental}},
Author-Email = {{e.poljac@donders.ru.nl}},
ResearcherID-Numbers = {{Bekkering, Harold/A-6357-2009
   Poljac, Edita/J-3233-2012}},
Funding-Acknowledgement = {{Rubicon Grant from the Netherlands Organisation for Scientific Research
   (NWO)Netherlands Organization for Scientific Research (NWO)
   {[}446-09-024]; VICI Grant from the Netherlands Organisation for
   Scientific Research (NWO)Netherlands Organization for Scientific
   Research (NWO) {[}453-05-001]}},
Funding-Text = {{This work was supported by a Rubicon Grant (446-09-024) to the first
   author and a VICI Grant (453-05-001) to the last author from the
   Netherlands Organisation for Scientific Research (NWO).}},
Cited-References = {{Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 2009, COGNITION, V111, P55, DOI 10.1016/j.cognition.2008.12.005.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   BALLARD DH, 1995, J COGNITIVE NEUROSCI, V7, P66, DOI 10.1162/jocn.1995.7.1.66.
   Butz MV, 2007, LECT NOTES ARTIF INT, V4520, P1.
   Carmi R, 2006, VISION RES, V46, P4333, DOI 10.1016/j.visres.2006.08.019.
   Cavanagh P, 2011, VISION RES, V51, P1538, DOI 10.1016/j.visres.2011.01.015.
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X.
   Craighero L, 2011, COGNITION, V120, P26, DOI 10.1016/j.cognition.2011.02.011.
   Cuijpers RH, 2006, NEURAL NETWORKS, V19, P311, DOI 10.1016/j.neunet.2006.02.004.
   De Maeght S, 2004, PSYCHOL RES-PSYCH FO, V68, P97, DOI 10.1007/s00426-003-0148-3.
   Deubel H, 1996, VISION RES, V36, P1827, DOI 10.1016/0042-6989(95)00294-4.
   Elliott D, 2010, PSYCHOL BULL, V136, P1023, DOI 10.1037/a0020958.
   EPELBOIM J, 1995, VISION RES, V35, P3401, DOI 10.1016/0042-6989(95)00080-X.
   Flanagan JR, 2003, NATURE, V424, P769, DOI 10.1038/nature01861.
   Foerster RM, 2011, J VISION, V11, DOI 10.1167/11.7.9.
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787.
   Gallese V, 2007, PHILOS T R SOC B, V362, P659, DOI 10.1098/rstb.2006.2002.
   Gallese V, 2008, SOC NEUROSCI-UK, V3, P317, DOI 10.1080/17470910701563608.
   Gehring WJ, 2011, GENOME BIOL EVOL, V3, P1053, DOI 10.1093/gbe/evr061.
   Glenberg AM, 2012, CORTEX, V48, P905, DOI 10.1016/j.cortex.2011.04.010.
   Griffin ZM, 2000, PSYCHOL SCI, V11, P274, DOI 10.1111/1467-9280.00255.
   HALDER G, 1995, SCIENCE, V267, P1788, DOI 10.1126/science.7892602.
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003.
   Imamizu H, 2009, PSYCHOL RES-PSYCH FO, V73, P527, DOI 10.1007/s00426-009-0235-1.
   Johansson RS, 2001, J NEUROSCI, V21, P6917.
   Kaas JH, 2008, BRAIN RES BULL, V75, P384, DOI 10.1016/j.brainresbull.2007.10.009.
   Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8.
   KEELE SW, 1968, J EXP PSYCHOL, V77, P155, DOI 10.1037/h0025754.
   Kilner James M, 2007, Cogn Process, V8, P159, DOI 10.1007/s10339-007-0170-2.
   Knoeferle P, 2005, COGNITION, V95, P95, DOI 10.1016/j.cognition.2004.03.002.
   Knoeferle P, 2007, J MEM LANG, V57, P519, DOI 10.1016/j.jml.2007.01.003.
   Knoeferle P, 2006, COGNITIVE SCI, V30, P481, DOI 10.1207/s15516709cog0000\_65.
   Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935.
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4.
   Ondobaka S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00579.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Prinz W, 2006, CORTEX, V42, P515, DOI 10.1016/S0010-9452(08)70389-7.
   Richardson DC, 2005, COGNITIVE SCI, V29, P1045, DOI 10.1207/s15516709cog0000\_29.
   Rizzolatti G, 2001, NAT REV NEUROSCI, V2, P661, DOI 10.1038/35090060.
   Rosander K, 2011, NEUROPSYCHOLOGIA, V49, P2911, DOI 10.1016/j.neuropsychologia.2011.06.018.
   Rotman G, 2006, J NEUROPHYSIOL, V96, P1358, DOI 10.1152/jn.00227.2006.
   Sailer U, 2005, J NEUROSCI, V25, P8833, DOI 10.1523/JNEUROSCI.2658-05.2005.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Tatler BW, 2011, J VISION, V11, DOI 10.1167/11.5.5.
   van Elk M, 2008, NEUROIMAGE, V43, P808, DOI 10.1016/j.neuroimage.2008.07.057.}},
Number-of-Cited-References = {{46}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Lang. Cogn. Neurosci.}},
Doc-Delivery-Number = {{AM7KO}},
Unique-ID = {{ISI:000340046100003}},
DA = {{2020-12-06}},
}

@article{ ISI:000333424000010,
Author = {Duta, Nicolae},
Title = {{Natural Language Understanding and Prediction: from Formal Grammars to
   Large Scale Machine Learning}},
Journal = {{FUNDAMENTA INFORMATICAE}},
Year = {{2014}},
Volume = {{131}},
Number = {{3-4}},
Pages = {{425-440}},
Abstract = {{Scientists have long dreamed of creating machines humans could interact
   with by voice. Although one no longer believes Turing's prophecy that
   machines will be able to converse like humans in the near future, real
   progress has been made in the voice and text-based human-machine
   interaction. This paper is a light introduction and survey of some
   deployed natural language systems and technologies and their historical
   evolution. We review two fundamental problems involving natural
   language: the language prediction problem and the language understanding
   problem. While describing in detail all these technologies is beyond our
   scope, we do comment on some aspects less discussed in the literature
   such as language prediction using huge models and semantic labeling
   using Marcus contextual grammars.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Duta, N (Corresponding Author), Microsoft NERD Ctr, One Mem Dr, Cambridge, MA 02142 USA.
   Duta, Nicolae, Microsoft, New England Res \& Dev Ctr, Cambridge, MA USA.}},
DOI = {{10.3233/FI-2014-1023}},
ISSN = {{0169-2968}},
EISSN = {{1875-8681}},
Keywords = {{Natural language understanding; language modeling; language prediction}},
Keywords-Plus = {{RECOGNITION; MODELS}},
Research-Areas = {{Computer Science; Mathematics}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Mathematics, Applied}},
Author-Email = {{niduta@microsoft.com}},
Cited-References = {{Agarwal G., 2010, WWW, P1.
   Arisoy Ebru, 2012, P NAACL HLT 2012 WOR, P20.
   Beesley K. R., 2003, FINITE STATE MORPHOL.
   Bellegarda JR, 2004, SPEECH COMMUN, V42, P93, DOI 10.1016/j.specom.2003.08.002.
   Bortnikov Edward, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P13, DOI 10.1007/978-3-642-28997-2\_2.
   Brill E, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P286, DOI 10.3115/1075218.1075255.
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552.
   Bulyko I., 2007, ACM T SPEECH LANGUAG, V5.
   Burns M., 2012, NUANCE SUPERCHARGES.
   Celikyilmaz A, 2012, IEEE W SP LANG TECH, P216, DOI 10.1109/SLT.2012.6424225.
   Charniak E., 2004, EARS RT 04 WORKSH YO.
   Chelba C., P INT, P2242.
   Chelba C., 2012, LARGE SCALE LANGUAGE.
   Chelba C, 2012, INT CONF ACOUST SPEE, P4129, DOI 10.1109/ICASSP.2012.6288827.
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113.
   Dean Jeffrey, 2004, OSDI 04 6 S OP SYST.
   Dowding J., 1993, P ARPA WORKSH HUM LA.
   Duffy J., PC MAGAZINE.
   Duta N., EARS TECHN WORKSH EU.
   Duta N., 2008, P INT 2008 BRISB AUS.
   Duta N, 2006, IEEE T AUDIO SPEECH, V14, P1745, DOI 10.1109/TASL.2006.878268.
   Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X.
   Gupta N, 2006, IEEE T AUDIO SPEECH, V14, P213, DOI 10.1109/TSA.2005.854085.
   Imielinski T, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P184, DOI 10.1109/ICSC.2009.31.
   Jelinek F., 2001, STAT METHODS SPEECH.
   Kirchhoff K., 2003, P ICASSP 2003, VI, P344.
   Kneser R., P ICASSP 1995, P181.
   Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586.
   Marcus S, 1998, COMPUT LINGUIST, V24, P245.
   MILLER S, 1994, P ANN M ASS COMP LIN.
   Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6.
   Mori S., 1999, WILEY MICRO.
   Natarajan P., 2002, P INT C SPOK LANG PR.
   Parameswaran A., 2012, TECHNICAL REPORT.
   Pasca M., 2006, P 21 NAT C ART INT, V2, P1400.
   Paun Gh., 1997, MARCUS CONTEXTUAL GR.
   PIERACCINI R, 1992, SPEECH AND NATURAL LANGUAGE, P67.
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821.
   Price P. J., 1990, P DARPA WORKSH SPEEC.
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083.
   Rubinstein Y. D., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P49.
   Seneff S., 1992, Computational Linguistics, V18, P61.
   SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P1, DOI 10.1016/S0019-9958(64)90223-2.
   Stolcke A., 1998, P DARPA BROADC NEWS, P270.
   Tur G., 2011, SPOKEN LANGUAGE UNDE.
   Turing A. M., 1950, MIND, V59, P433, DOI {[}10.1093/mind/lix.236.433, DOI 10.1093/MIND/LIX.236.433].
   Wang Y., 2011, SPOKEN LANGUAGE UNDE.
   Wang YY, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU `03, P577, DOI 10.1109/ASRU.2003.1318504.
   Ward W., 1998, P DARPA BROADC NEWS, P270.
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000.}},
Number-of-Cited-References = {{50}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Fundam. Inform.}},
Doc-Delivery-Number = {{AD7EE}},
Unique-ID = {{ISI:000333424000010}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000366525200077,
Author = {Mathew, Lani Rachel and Anselam, Ancy S. and Pillai, Sakuntala S.},
Book-Group-Author = {{IEEE}},
Title = {{A Study of Low Bit-Rate Linear Prediction Based Speech Coders for Indian
   Dialects}},
Booktitle = {{2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION
   AND COMPUTATIONAL TECHNOLOGIES (ICCICCT)}},
Year = {{2014}},
Pages = {{403-408}},
Note = {{International Conference on Control, Instrumentation, Communication and
   Computational Technologies (ICCICCT), Kanyakumari, INDIA, JUL 10-11,
   2014}},
Organization = {{IEEE Elect Devices Soc; Noorul Islam Ctr Higher Educ, Dept Elect \&
   Instrumenta Engn}},
Abstract = {{Speech coders based on the linear prediction model are widely in use
   today. This paper describes the algorithms of low bit-rate vocoders,
   viz. Code-Excited Linear Prediction (CELP) and Mixed Excitation Linear
   Prediction (MELP) and their performance for Indian dialects. A Linux
   platform has been used for execution of the vocoders. Mean Opinion Score
   testing has been performed with speech samples of Indian dialects and
   Indian-accented English. Waveform analysis has been done using Praat
   software. Results show that CELP which operates at a higher bit rate of
   4.8 kb/s gives better quality output. MELP speech output is intelligible
   and suited for very low bit-rate (2.4 kb/s) applications. The results
   also highlight the need for better codebook tuning in Indian dialects.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Mathew, LR (Corresponding Author), Mar Baselios Coll Engn \& Technol, Dept Elect \& Commun, Thiruvananthapuram 695015, Kerala, India.
   Mathew, Lani Rachel; Anselam, Ancy S.; Pillai, Sakuntala S., Mar Baselios Coll Engn \& Technol, Dept Elect \& Commun, Thiruvananthapuram 695015, Kerala, India.}},
ISBN = {{978-1-4799-4190-2}},
Keywords = {{Vocoder; linear prediction; code excited; low delay; mixed excitation;
   CELP; MELP; Praat; Linux}},
Research-Areas = {{Automation \& Control Systems; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Telecommunications}},
Author-Email = {{lanirachel@gmail.com
   ancy\_anselam@yahoo.co.in
   sakuntala.pillai@gmail.com}},
Cited-References = {{Bhagat D., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P547, DOI 10.1109/CSNT.2012.124.
   Chassaing R., 2008, DIGITAL SIGNAL PROCE.
   Chu W. C., 2003, SPEECH CODING ALGORI.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Mathew L., 2014, INT J ENG TRENDS TEC, V10, P554.
   Mathew L., 2014, IEEE C ADV COM UNPUB.
   McCree A, 1996, INT CONF ACOUST SPEE, P200, DOI 10.1109/ICASSP.1996.540325.
   Schroeder M. R., 1985, P IEEE INT C AC SPEE, V10, P937, DOI DOI 10.1109/ICASSP.1985.1168147.
   Tandel Milind, 2011, 3 INT C EL COMP TECH, V6, P86.}},
Number-of-Cited-References = {{9}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BE0PL}},
Unique-ID = {{ISI:000366525200077}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000364936400056,
Author = {Abhiram, B. and Prathosh, A. P. and Ramakrishnan, A. G.},
Book-Group-Author = {{IEEE}},
Title = {{A fast algorithm for speech polarity detection using long-term linear
   prediction}},
Booktitle = {{2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS
   (SPCOM)}},
Series = {{International Conference on Signal Processing and Communications SPCOM}},
Year = {{2014}},
Note = {{International Conference on Signal Processing and Communications
   (SPCOM), Bangalore, INDIA, JUL 22-25, 2014}},
Abstract = {{Speech polarity detection is a crucial first step in many speech
   processing techniques. In this paper, an algorithm is proposed that
   improvises the existing technique using the skewness of the voice source
   (VS) signal. Here, the integrated linear prediction residual (ILPR) is
   used as the VS estimate, which is obtained using linear prediction on
   long-term frames of the low-pass filtered speech signal. This excludes
   the unvoiced regions from analysis and also reduces the computation.
   Further, a modified skewness measure is proposed for decision, which
   also considers the magnitude of the skewness of the ILPR along with its
   sign. With the detection error rate (DER) as the performance metric, the
   algorithm is tested on 8 large databases and its performance
   (DER=0.20\%) is found to be comparable to that of the best technique
   (DER=0.06\%) on both clean and noisy speech. Further, the proposed
   method is found to be ten times faster than the best technique.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Abhiram, B (Corresponding Author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
   Abhiram, B.; Prathosh, A. P.; Ramakrishnan, A. G., Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.}},
ISSN = {{2474-9168}},
EISSN = {{2474-915X}},
ISBN = {{978-1-4799-4665-5}},
Keywords = {{speech polarity detection; voice source; integrated linear prediction
   residual; long-term linear prediction; weighted skewness}},
Keywords-Plus = {{EPOCH EXTRACTION}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{abhiram@ee.iisc.ernet.in
   prathoshap@ee.iisc.ernet.in
   ramkiag@ee.iisc.ernet.in}},
ResearcherID-Numbers = {{Ganesan, Ramakrishnan Angarai/B-8317-2013}},
ORCID-Numbers = {{Ganesan, Ramakrishnan Angarai/0000-0002-3646-1955}},
Cited-References = {{Ananthapadmanabha T. V, 1984, 25 STLQPSR DEP SPEEC, V2-3, P1.
   Burkhardt Felix, 2005, INTERSPEECH, P1517.
   Ding W, 1998, INT CONF ACOUST SPEE, P857, DOI 10.1109/ICASSP.1998.675400.
   Drugman T, 2013, COGN COMPUT, V5, P442, DOI 10.1007/s12559-012-9167-y.
   Drugman T, 2013, IEEE SIGNAL PROC LET, V20, P387, DOI 10.1109/LSP.2013.2249661.
   Fant G., 1985, STL QPSR, V4, P1, DOI DOI 10.1016/0167-6393(89)90001-0.
   Hunt AJ, 1996, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.1996.541110.
   Kominek J., 2004, P 5 ISCA SPEECH SYNT, P223.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Muralishankar R, 2004, SPEECH COMMUN, V42, P143, DOI 10.1016/j.specom.2003.05.001.
   Murty KSR, 2008, IEEE T AUDIO SPEECH, V16, P1602, DOI 10.1109/TASL.2008.2004526.
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875.
   Prathosh AP, 2013, IEEE T AUDIO SPEECH, V21, P2471, DOI 10.1109/TASL.2013.2273717.
   Ramakrishnan A. G., CHARACTERIZATI UNPUB.
   Rohan Kumar Das, COMBINING SOUR UNPUB.
   Saratxaga I, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1095.
   Schluter R, 2001, INT CONF ACOUST SPEE, P133, DOI 10.1109/ICASSP.2001.940785.
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BD9LX}},
Unique-ID = {{ISI:000364936400056}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000410571300015,
Author = {Javed, Shazia and Ahmad, Noor Atinah},
Book-Group-Author = {{IEEE}},
Title = {{Adaptive Total Least Squares Based Speech Prediction}},
Booktitle = {{PROCEEDINGS OF THE 2014 6TH INTERNATIONAL CONFERENCE ON INFORMATION
   TECHNOLOGY AND MULTIMEDIA (ICIM)}},
Series = {{International Conference on Information Technology \& Multimedia}},
Year = {{2014}},
Pages = {{78-82}},
Note = {{6th International Conference on Information Technology and Multimedia
   (ICIM), Univ Tenaga Nas, Putrajaya, MALAYSIA, NOV 18-20, 2014}},
Organization = {{Univ Tenaga Nas, Coll Informat Technol}},
Abstract = {{In this paper, an instantaneous total error based adaptive linear
   predictor is presented for linear predictive coding (LPC) of speech
   signals. In LPC, the speech signal is predicted by a linear combination
   of delayed input signals that are contaminated by noise. For this
   reason, total least mean squares (T-LMS) algorithm is used to decode the
   noisy input signals and to predict a speech signal. A compressed speech
   prediction is done when the mean squares total error is minimized,
   showing the efficiency of T-LMS based LPC model. Experimental results
   are recorded for different values of signal to noise ratio (SNR) of the
   input signals, and a comparative study is presented with instantaneous
   error squares based adaptive filter. These results show the preference
   of proposed predictor over the other.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Javed, S (Corresponding Author), Univ Sains Malaysia, Sch Math Sci, George Town 11800, Malaysia.
   Javed, Shazia; Ahmad, Noor Atinah, Univ Sains Malaysia, Sch Math Sci, George Town 11800, Malaysia.}},
ISSN = {{2372-1588}},
ISBN = {{978-1-4799-5423-0}},
Keywords = {{Linear predictive coding; adaptive filter; total least squares}},
Keywords-Plus = {{ALGORITHMS}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical \& Electronic}},
Author-Email = {{shaziafateh@hotmail.com
   atinah@cs.usm.my}},
ResearcherID-Numbers = {{Ahmad, Noor Atinah/ABB-9133-2020}},
ORCID-Numbers = {{Ahmad, Noor Atinah/0000-0002-4249-7305}},
Funding-Acknowledgement = {{Universiti Sains Malaysia by FRGS}},
Funding-Text = {{The authors would like to acknowledge the financial support, of the
   Universiti Sains Malaysia by FRGS grant.}},
Cited-References = {{Atal BS, 2006, IEEE SIGNAL PROC MAG, V23, P154, DOI 10.1109/MSP.2006.1598091.
   Benesty J., 2008, SPRINGER HDB SPEECH, P111, DOI {[}10.1007/978-3-540-49127-9\_7, DOI 10.1007/978-3-540-49127-9\_7].
   Bradbury Jeremy, 2000, LINEAR PREDICTIVE CO.
   DAVILA CE, 1994, IEEE T SIGNAL PROCES, V42, P268, DOI 10.1109/78.275601.
   Dunne BE, 2000, CONF REC ASILOMAR C, P1762, DOI 10.1109/ACSSC.2000.911290.
   Farhang-Boroujeny B., 1998, ADAPTIVE FILTERS THE.
   Feng DZ, 2004, IEEE T SIGNAL PROCES, V52, P2729, DOI 10.1109/TSP.2004.834260.
   GOLUB GH, 1980, SIAM J NUMER ANAL, V17, P883, DOI 10.1137/0717073.
   Haykin S., 1991, ADAPTIVE FILTER THEO.
   Javed S, 2014, AIP CONF PROC, V1605, P233, DOI 10.1063/1.4887594.
   Javed S, 2014, SCI WORLD J, DOI 10.1155/2014/625280.
   Kreyszig E., 1989, INTRO FUNCTIONAL ANA, V1.
   RAHMAN MA, 1987, IEEE T ACOUST SPEECH, V35, P1440, DOI 10.1109/TASSP.1987.1165059.
   van Huffel S, 1991, TOTAL LEAST SQUARES, V9.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BI2ZE}},
Unique-ID = {{ISI:000410571300015}},
DA = {{2020-12-06}},
}

@article{ ISI:000326351800002,
Author = {Wold, Astri Heen},
Title = {{Accuracy of teachers' predictions of language minority and majority
   students' language comprehension}},
Journal = {{LANGUAGE AND EDUCATION}},
Year = {{2013}},
Volume = {{27}},
Number = {{6}},
Pages = {{498-525}},
Month = {{NOV 1}},
Abstract = {{The classroom is an important context of second language learning for
   language minority children. Teachers are responsible for creating good
   learning opportunities by securing language use well adjusted to the
   children's level of comprehension. Thus, teachers should have realistic
   expectations of this. The purpose of the research is to increase
   knowledge of the classroom as a language learning setting by exploring
   the accuracy of teachers' evaluations of their students' language
   comprehension and possible biases in their evaluations of language
   minority compared to majority students. A total of 205 students from 13
   different classes and their main teachers from five different schools in
   Norway participated in the research. The students were tested for
   vocabulary and grammatical comprehension of Norwegian, and their
   teachers were asked to predict how each child would score on each test
   item. The language minority children gained lower scores than the
   majority children, a difference also predicted by their teachers. The
   accuracy of teachers' predictions was higher for language majority than
   minority children, however. This difference seems to be directly
   affected by the language minority/majority status of the child. The
   teachers were, furthermore, most accurate when predicting the
   comprehension scores of the students they believed to be high
   performers.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wold, AH (Corresponding Author), Univ Oslo, Dept Psychol, Oslo, Norway.
   Univ Oslo, Dept Psychol, Oslo, Norway.}},
DOI = {{10.1080/09500782.2012.736519}},
ISSN = {{0950-0782}},
EISSN = {{1747-7581}},
Keywords = {{language comprehension; language minority students; second language
   acquisition; teacher expectation; teacher bias}},
Keywords-Plus = {{EXPECTATIONS; LEARNERS; ABILITY; GAP}},
Research-Areas = {{Education \& Educational Research; Linguistics}},
Web-of-Science-Categories  = {{Education \& Educational Research; Linguistics; Language \& Linguistics}},
Author-Email = {{a.h.wold@psykologi.uio.no}},
Cited-References = {{August D., 2005, LEARNING DISABILITIE, V20, DOI {[}DOI 10.1111/J.1540-5826.2005.00120.X, 10.1111/j.1540-5826.2005.00120.x].
   Baker C., 2006, FDN BILINGUAL ED BIL.
   Baron R. M., 1985, TEACHER EXPECTANCIES, P251.
   Bezemer J., 2004, LANGUAGE TEACHING LE.
   Bishop D. V. M., 2009, TEST RECEPTION GRAMM.
   BISHOP DV, 1989, TEST RECEPTION GRAMM.
   Bishop DV, 2003, TEST RECEPTION GRAMM.
   Carlo MS, 2004, READ RES QUART, V39, P188, DOI 10.1598/RRQ.39.2.3.
   Cummins J., 1984, BILINGUALISM SPECIAL.
   Cummins J., 2000, LANGUAGE POWER PEDAG.
   Daugstad Gunnlaug, 2006, GRENSELOS KJAERLIGHE.
   Dunn L.M., 1997, BRIT PICTURE VOCABUL.
   Dunn LM, 1997, PEABODY PICTURE VOCA.
   Dusek J. B., 1983, J EDUC PSYCHOL, V75, P326.
   DUSEK JB, 1985, TEACHER EXPECTANCIES.
   EGAN O, 1985, AM EDUC RES J, V22, P25, DOI 10.2307/1162985.
   FERGUSON CA, 1971, PIDGINIZATION CREOLI, P141.
   Ferguson RF, 2003, URBAN EDUC, V38, P460, DOI 10.1177/0042085903038004006.
   FILLMORE LW, 1989, TEACHABILITY LANGUAG, P311.
   FILLMORE LW, 1985, INPUT 2 LANGUAGE ACQ, P17.
   Fladberg K. L., 2011, DAGSAVISEN      0331, V31.
   Fladberg K. L., 2011, DAGSAVISEN      0404.
   Gass S. M., 1985, INPUT 2 LANGUAGE ACQ, P149.
   GOOD TL, 1987, J TEACH EDUC, V38, P32, DOI 10.1177/002248718703800406.
   HALLER EJ, 1985, AM EDUC RES J, V22, P465, DOI 10.2307/1163135.
   HOGE RD, 1984, J EDUC PSYCHOL, V76, P777, DOI 10.1037/0022-0663.76.5.777.
   HOGG MICHAEL A., 1988, SOCIAL IDENTIFICATIO.
   Krashen S., 1985, INPUT HYPOTHESIS ISS.
   Lervag A, 2010, J CHILD PSYCHOL PSYC, V51, P612, DOI 10.1111/j.1469-7610.2009.02185.x.
   LIE S, 1991, J MULTILING MULTICUL, V12, P363, DOI 10.1080/01434632.1991.9994470.
   Lyster S.-A. H., 2010, SPESIALPEDAGOGIKK, V74, P35.
   Monsrud M. B., 2010, SPESIALPEDAGOGIKK, V74, P44.
   Nergard T. B., 2006, AFTENPOSTEN AFT 0508.
   Norsk Som Laeringssprak (NSL), 2011, PED PSYK TJEN.
   NOU, 2010, MANGF MESTR FLERSP 7, V7.
   PEARSON BZ, 1993, LANG LEARN, V43, P93, DOI 10.1111/j.1467-1770.1993.tb00174.x.
   RIST RC, 1970, HARVARD EDUC REV, V40, P411, DOI 10.17763/haer.40.3.h0m026p670k618q3.
   Rommetveit R., 2008, SPRAK INDIVIDUELL PS.
   Rommetveit Ragnar, 1992, DIALOGICAL ALTERNATI, P19.
   ROSENTHA.R, 1966, PSYCHOL REP, V19, P115, DOI 10.2466/pr0.1966.19.1.115.
   Rosenthal R., 1992, PYGMALION CLASSROOM.
   ROSENTHAL R, 1985, TEACHER EXPECTANCIES, P37.
   Ryen Else, 2010, NORSK SOM ANDRESPRAK, V26, P67.
   Snow C., 1977, TALKING CHILDREN LAN.
   Tahir M., 2009, DAGSAVISEN      0603.
   TAJFEL H, 1963, BRIT J PSYCHOL, V54, P101, DOI 10.1111/j.2044-8295.1963.tb00865.x.
   Tajfel H, 1981, HUMAN GROUPS SOCIAL.
   Tenenbaum HR, 2007, J EDUC PSYCHOL, V99, P253, DOI 10.1037/0022-0663.99.2.253.
   Thomas W. P., 2002, STATE ED STANDARD, V3, P30.
   Thorud E, 2010, INT MIGRATION 2009 2.
   Wold A. H., 2008, MED SPRAKLIGE MINORI, P195.
   Wold A. H., 2008, SPRAKVANSKER TEORETI, P121.
   Wold A. H., 1993, NORSK PEDAGOGISK TID, V77, P17.
   Wold Astri, 2005, LANGUAGE ED, V19, P513.
   Wong Fillmore L., 1983, TESOL 82 PACIFIC PER, P203.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Lang. Educ.}},
Doc-Delivery-Number = {{243XN}},
Unique-ID = {{ISI:000326351800002}},
DA = {{2020-12-06}},
}

@article{ ISI:000326213300008,
Author = {Dikker, Suzanne and Pylkkanen, Liina},
Title = {{Predicting language: MEG evidence for lexical preactivation}},
Journal = {{BRAIN AND LANGUAGE}},
Year = {{2013}},
Volume = {{127}},
Number = {{1}},
Pages = {{55-64}},
Month = {{OCT}},
Abstract = {{It is widely assumed that prediction plays a substantial role in
   language processing. However, despite numerous studies demonstrating
   that contextual information facilitates both syntactic and
   lexical-semantic processing, there exists no direct evidence pertaining
   to the neural correlates of the prediction process itself. Using
   magnetoencephalography (MEG), this study found that brain activity was
   modulated by whether or not a specific noun could be predicted, given a
   picture prime. Specifically, before the noun was presented, predictive
   contexts triggered enhanced activation in left mid-temporal cortex
   (implicated in lexical access), ventro-medial prefrontal cortex
   (previously associated with top-down processing), and visual cortex
   (hypothesized to index the preactivation of predicted form features),
   successively. This finding suggests that predictive language processing
   recruits a top-down network where predicted words are activated at
   different levels of representation, from more `abstract'
   lexical-semantic representations in temporal cortex, all the way down to
   visual word form features. The same brain regions that exhibited
   enhanced activation for predictive contexts before the onset of the noun
   showed effects of congruence during the target word. To our knowledge,
   this study is one of the first to directly investigate the anticipatory
   stage of predictive language processing. (C) 2012 Elsevier Inc. All
   rights reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dikker, S (Corresponding Author), Weill Cornell Med Coll, Sackler Inst Dev Psychobiol, New York, NY USA.
   Dikker, Suzanne, Weill Cornell Med Coll, Sackler Inst Dev Psychobiol, New York, NY USA.
   Dikker, Suzanne; Pylkkanen, Liina, NYU, Dept Psychol, New York, NY 10003 USA.
   Pylkkanen, Liina, NYU, Dept Linguist, New York, NY 10003 USA.}},
DOI = {{10.1016/j.bandl.2012.08.004}},
ISSN = {{0093-934X}},
EISSN = {{1090-2155}},
Keywords = {{Language processing; Prediction; Top-down processing; Lexical-semantic
   processing; Magnetoencephalography; Visual cortex; Lexical priming}},
Keywords-Plus = {{EVENT-RELATED POTENTIALS; PREFRONTAL CORTEX; VISUAL-CORTEX;
   RESPONSE-INHIBITION; NEURAL MECHANISMS; SENTENCE; BRAIN; WORD; EEG;
   COMPREHENSION}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences \&
   Neurology; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental}},
Author-Email = {{suzanne.dikker@nyu.edu}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}BCS-0545186]; Whitehead Fellowship for Junior Faculty Biomedical and
   Biological Sciences}},
Funding-Text = {{This research was supported by the National Science Foundation Grant
   BCS-0545186 (LP) and the Whitehead Fellowship for Junior Faculty
   Biomedical and Biological Sciences (LP). We further wish to thank three
   anonymous reviewers for their insightful comments.}},
Cited-References = {{Albright TD, 2002, ANNU REV NEUROSCI, V25, P339, DOI 10.1146/annurev.neuro.25.112701.142900.
   Alink A, 2010, J NEUROSCI, V30, P2960, DOI 10.1523/JNEUROSCI.3730-10.2010.
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Bar M, 2006, P NATL ACAD SCI USA, V103, P449, DOI 10.1073/pnas.0507062103.
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Bastiaansen MCM, 2005, J COGNITIVE NEUROSCI, V17, P530, DOI 10.1162/0898929053279469.
   Bemis DK, 2011, J NEUROSCI, V31, P2801, DOI 10.1523/JNEUROSCI.5003-10.2011.
   Brennan J, 2008, BRAIN LANG, V106, P132, DOI 10.1016/j.bandl.2008.04.003.
   Brennan J, 2010, LANG COGNITIVE PROC, V25, P777, DOI 10.1080/01690961003616840.
   Brown JW, 2005, SCIENCE, V307, P1118, DOI 10.1126/science.1105783.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   Bueti D, 2010, J NEUROSCI, V30, P4343, DOI 10.1523/JNEUROSCI.2254-09.2010.
   Carlsson K, 2000, J COGNITIVE NEUROSCI, V12, P691, DOI 10.1162/089892900562318.
   Cavanagh JF, 2010, NEUROIMAGE, V49, P3198, DOI 10.1016/j.neuroimage.2009.11.080.
   Davidson DJ, 2007, BRAIN RES, V1158, P81, DOI 10.1016/j.brainres.2007.04.082.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.ne.18.030195.001205.
   Desimone R, 1996, P NATL ACAD SCI USA, V93, P13494, DOI 10.1073/pnas.93.24.13494.
   Dikker S., 2011, BRAIN LANGUAGE.
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751.
   Dikker S, 2009, COGNITION, V110, P293, DOI 10.1016/j.cognition.2008.09.008.
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565.
   Enns JT, 2008, TRENDS COGN SCI, V12, P327, DOI 10.1016/j.tics.2008.06.001.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005.
   Gregoriou GG, 2009, SCIENCE, V324, P1207, DOI 10.1126/science.1171402.
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006.
   Hald LA, 2006, BRAIN LANG, V96, P90, DOI 10.1016/j.bandl.2005.06.007.
   Kirmizi-Alsan E, 2006, BRAIN RES, V1104, P114, DOI 10.1016/j.brainres.2006.03.010.
   Lamme VAF, 2003, TRENDS COGN SCI, V7, P12, DOI 10.1016/S1364-6613(02)00013-X.
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532.
   Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434.
   Liang HL, 2002, NEUROREPORT, V13, P2011, DOI 10.1097/00001756-200211150-00004.
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167.
   Mosher JC, 1998, IEEE T BIO-MED ENG, V45, P1342, DOI 10.1109/10.725331.
   Pantev Christo, 1995, Brain Topography, V7, P321, DOI 10.1007/BF01195258.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pylkkanen L, 2007, J COGNITIVE NEUROSCI, V19, P1905, DOI 10.1162/jocn.2007.19.11.1905.
   Pylkkanen L, 2003, TRENDS COGN SCI, V7, P187, DOI 10.1016/S1364-6613(03)00092-5.
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580.
   Ridderinkhof KR, 2004, BRAIN COGNITION, V56, P129, DOI 10.1016/j.bandc.2004.09.016.
   Simmons W. K., 2005, CEREB CORTEX, V15, P1570.
   Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008.
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107.
   Stokes M, 2009, J NEUROSCI, V29, P1565, DOI 10.1523/JNEUROSCI.4657-08.2009.
   Summerfield C, 2005, NEUROIMAGE, V24, P692, DOI 10.1016/j.neuroimage.2004.09.012.
   Summerfield C., 2006, SCIENCE, P314.
   Summerfield C, 2008, NEURON, V59, P336, DOI 10.1016/j.neuron.2008.05.021.
   Summerfield C, 2009, TRENDS COGN SCI, V13, P403, DOI 10.1016/j.tics.2009.06.003.
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   von Stein A, 2000, P NATL ACAD SCI USA, V97, P14748, DOI 10.1073/pnas.97.26.14748.
   West WC, 2002, COGNITIVE BRAIN RES, V13, P363, DOI 10.1016/S0926-6410(01)00129-X.
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0.
   Willems RM, 2008, J COGNITIVE NEUROSCI, V20, P1235, DOI 10.1162/jocn.2008.20085.
   Wood JN, 2003, NAT REV NEUROSCI, V4, P139, DOI 10.1038/nrn1033.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{66}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{34}},
Journal-ISO = {{Brain Lang.}},
Doc-Delivery-Number = {{242BV}},
Unique-ID = {{ISI:000326213300008}},
DA = {{2020-12-06}},
}

@article{ ISI:000324336100005,
Author = {Besada, Juan A. and Frontera, Guillermo and Crespo, Jesus and Casado,
   Enrique and Lopez-Leones, Javier},
Title = {{Automated Aircraft Trajectory Prediction Based on Formal Intent-Related
   Language Processing}},
Journal = {{IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS}},
Year = {{2013}},
Volume = {{14}},
Number = {{3}},
Pages = {{1067-1082}},
Month = {{SEP}},
Abstract = {{This paper proposes a new paradigm for the formulation of aircraft
   trajectory computation and prediction processes. Under this paradigm, an
   aircraft trajectory can be expressed at different levels of detail using
   a set of novel intent-related formal languages. These languages can be
   used for describing different aspects of aircraft motion or the
   resulting predicted trajectory, ranging from high-level restrictions
   imposed on the trajectory to details on how the aircraft will be
   operated at any specific instant. After defining the complete hierarchy
   of these formal languages, the concept of trajectory language processing
   engine is introduced. Every engine can perform automated modifications
   over a trajectory specified at different levels or at the same level
   considering the language hierarchy. Finally, several engine examples are
   described, and a complete trajectory computation process is built as an
   engine composed through the smart interconnection of several engines.
   Examples of executions of these automated processes are also included.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Besada, JA (Corresponding Author), Univ Politecn Madrid, E-28040 Madrid, Spain.
   Besada, Juan A.; Frontera, Guillermo; Crespo, Jesus, Univ Politecn Madrid, E-28040 Madrid, Spain.
   Casado, Enrique; Lopez-Leones, Javier, Boeing Res \& Technol Europe, Madrid, Spain.}},
DOI = {{10.1109/TITS.2013.2252343}},
ISSN = {{1524-9050}},
EISSN = {{1558-0016}},
Keywords = {{Flight specification; formal languages; trajectory-based operations;
   trajectory prediction; trajectory synchronization}},
Keywords-Plus = {{OPTIMIZATION; AVOIDANCE; GUIDANCE}},
Research-Areas = {{Engineering; Transportation}},
Web-of-Science-Categories  = {{Engineering, Civil; Engineering, Electrical \& Electronic;
   Transportation Science \& Technology}},
Author-Email = {{besada@grpss.ssr.upm.es
   guillermo.frontera@grpss.ssr.upm.es
   jcrespo@grpss.ssr.upm.es
   Enrique.Casado@boeing.com
   javier.lopezleones@boeing.com}},
ResearcherID-Numbers = {{Besada, Juan/A-3969-2011
   }},
ORCID-Numbers = {{Besada, Juan/0000-0002-4330-4050
   Frontera, Guillermo/0000-0001-8903-559X}},
Funding-Acknowledgement = {{Spanish Ministry of Science and Innovation through ATLANTIDA project;
   Spanish Ministry of Science and Innovation through ADAM project; Spanish
   Ministry of Economy and Competitiveness {[}CYCIT TEC2011-28626]; Spanish
   Ministry of Education under FPU Grant {[}AP2009-0246]}},
Funding-Text = {{This work was supported in part by the Spanish Ministry of Science and
   Innovation through the ATLANTIDA and ADAM projects, by the Spanish
   Ministry of Economy and Competitiveness under Grant CYCIT TEC2011-28626,
   and by the Spanish Ministry of Education under FPU Grant AP2009-0246.
   The Associate Editor for this paper was C. Wu.}},
Cited-References = {{Alonso-Ayuso A, 2011, IEEE T INTELL TRANSP, V12, P47, DOI 10.1109/TITS.2010.2061971.
   {[}Anonymous], 2008, 42419 ARINC.
   {[}Anonymous], 2008, USER MANUAL BASE AIR.
   Brenan KE, 1996, CLASSICS APPL MATH.
   Devasia S, 2011, IEEE T INTELL TRANSP, V12, P422, DOI 10.1109/TITS.2010.2093574.
   Grabbe S, 2009, J GUID CONTROL DYNAM, V32, P810, DOI 10.2514/1.40300.
   Hu XB, 2004, ENG APPL ARTIF INTEL, V17, P897, DOI 10.1016/j.engappai.2004.08.015.
   ICAO, 2007, 4444 ICAO.
   Innocenti M, 2004, J GUID CONTROL DYNAM, V27, P715, DOI 10.2514/1.2651.
   Jackson M, 2009, NEW ORLEANS REV, V35, P13.
   Jacobsen M, 2010, J AIRCRAFT, V47, P1256, DOI 10.2514/1.47109.
   Jardin M. R., 2003, P 5 US EUR AIR TRAFF, P27.
   Jorris TR, 2008, J GUID CONTROL DYNAM, V31, P543, DOI 10.2514/1.32354.
   Konyak M. A., 2008, P AIAA GUID NAV CONT, P1.
   Lecchini A., 2005, P IFAC WORLD C, V16, P2024.
   Leclaire C., 1995, CITRAC COMMON INTERF.
   Leones J. Lopez, Eur. Patent Appl., Patent No. {[}11 382 020.3., 113820203].
   Leones J. Lopez, 2011, Patent No. {[}EP 2 482 269 A1, 2482269].
   Lopes A. P., 2009, P 24 INT BATT HYBR F, P1, DOI DOI 10.1109/PTC.2009.5282155.
   Lopez-Leones J., 2007, P 26 IEEE DIG AV SYS.
   Lopez-Leones J., 2008, THESIS U GLASGOW GLA.
   Lymperopoulos I, 2010, J GUID CONTROL DYNAM, V33, P347, DOI 10.2514/1.46190.
   Milam M. B., 2003, THESIS CALTECH PASAD.
   Next Gen, NEXT GEN AIR TRANSP.
   Patel RB, 2011, J GUID CONTROL DYNAM, V34, P218, DOI 10.2514/1.49518.
   Roberson B., 2007, BOEING COMMERCIAL AE, P23.
   Slattery R, 1997, J GUID CONTROL DYNAM, V20, P232, DOI 10.2514/2.4056.
   Soler M, 2010, J GUID CONTROL DYNAM, V33, P985, DOI 10.2514/1.47458.
   Visser H. G., 1994, LT769 DELFT U TECHN.
   WALLER MC, 1990, PROC NAECON IEEE NAT, P574, DOI 10.1109/NAECON.1990.112828.
   Whang IH, 2002, IEEE T AERO ELEC SYS, V38, P1116, DOI 10.1109/TAES.2002.1039430.
   Zhang C., 2010, P ICINA.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{22}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{IEEE Trans. Intell. Transp. Syst.}},
Doc-Delivery-Number = {{217DE}},
Unique-ID = {{ISI:000324336100005}},
DA = {{2020-12-06}},
}

@article{ ISI:000320880900001,
Author = {Ramirez, Miguel Arjona},
Title = {{Intra-Predictive Switched Split Vector Quantization of Speech Spectra}},
Journal = {{IEEE SIGNAL PROCESSING LETTERS}},
Year = {{2013}},
Volume = {{20}},
Number = {{8}},
Pages = {{791-794}},
Month = {{AUG}},
Abstract = {{Vector quantization (VQ) of speech spectral vectors has been improved by
   techniques such as split VQ (SVQ), vector transforms and direction
   switching. This letter proposes Intra-Predictive Switched SVQ (IPSSVQ)
   with direction switching by a Gaussian Mixture Model (GMM), using at the
   frame level the prediction-based lower-triangular transform (PLT), which
   has lower complexity than the Karhunen-Loeve transform (KLT). It is
   shown that equivalent results to GMM KLT SSVQ may be obtained in the
   quantization of line spectral frequency (LSF) vectors from wideband
   speech signals, such as transparent coding throughout the range from 46
   bit/frame to 41 bit/frame, with about three-fourths as much operational
   complexity.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ramirez, MA (Corresponding Author), Univ Sao Paulo, Escola Politecn, Dept Elect Syst Engn, BR-05508 Sao Paulo, Brazil.
   Univ Sao Paulo, Escola Politecn, Dept Elect Syst Engn, BR-05508 Sao Paulo, Brazil.}},
DOI = {{10.1109/LSP.2013.2267391}},
ISSN = {{1070-9908}},
EISSN = {{1558-2361}},
Keywords = {{Vector quantization; intra-predictive quantization; prediction-based
   lower-triangular transform; Karhunen-Loeve transform; line spectral
   frequencies}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{miguel@lps.usp.br}},
ResearcherID-Numbers = {{Ramirez, Miguel Arjona/O-1738-2019
   Arjona Ramirez, Miguel/A-3890-2008}},
ORCID-Numbers = {{Ramirez, Miguel Arjona/0000-0002-7107-0888
   Arjona Ramirez, Miguel/0000-0002-7107-0888}},
Funding-Acknowledgement = {{Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPq)National Council for Scientific and Technological Development
   (CNPq) {[}307633/2011-0]; Fundacao de Amparo a Pesquisa do Estado de Sao
   Paulo (FAPESP)Fundacao de Amparo a Pesquisa do Estado de Sao Paulo
   (FAPESP) {[}2012/24789-0]}},
Funding-Text = {{This work was supported by the Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq) under Grant 307633/2011-0 and by the
   Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) under
   Grant 2012/24789-0. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Mathew Magimai
   Doss.}},
Cited-References = {{ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679.
   Bessette B, 2002, IEEE T SPEECH AUDI P, V10, P620, DOI 10.1109/TSA.2002.804299.
   Biundo G., 2002, P 3 COST 276 WORKSH, V1, P114.
   Chatterjee Saikat, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P1054, DOI 10.1109/ISSPIT.2007.4458124.
   GARDNER WR, 1995, IEEE T SPEECH AUDI P, V3, P367, DOI 10.1109/89.466658.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Lee Y, 2011, IEEE SIGNAL PROC LET, V18, P415, DOI 10.1109/LSP.2011.2154331.
   LOOKABAUGH TD, 1989, IEEE T INFORM THEORY, V35, P1020, DOI 10.1109/18.42217.
   MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340.
   Norden F, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P157.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   Phoong SM, 2000, IEEE T SIGNAL PROCES, V48, P1947, DOI 10.1109/78.847781.
   Ramisch M, 2011, P 38 EPS C PLASM PHY, P1.
   So S., 2005, P EUR C SPEECH COMM, P2705.
   So S, 2007, DIGIT SIGNAL PROCESS, V17, P138, DOI 10.1016/j.dsp.2005.08.005.
   Subramaniam AD, 2003, IEEE T SPEECH AUDI P, V11, P130, DOI 10.1109/TSA.2003.809192.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Signal Process. Lett.}},
Doc-Delivery-Number = {{170UW}},
Unique-ID = {{ISI:000320880900001}},
DA = {{2020-12-06}},
}

@article{ ISI:000331038600001,
Author = {Gambi, Chiara and Pickering, Martin J.},
Title = {{Prediction and imitation in speech}},
Journal = {{FRONTIERS IN PSYCHOLOGY}},
Year = {{2013}},
Volume = {{4}},
Month = {{JUN 21}},
Abstract = {{It has been suggested that intra - and inter speaker variability in
   speech are correlated. Interlocutors have been shown to converge on
   various phonetic dimensions. In addition, speakers imitate the phonetic
   properties of voices they are exposed to in shadowing, repetition, and
   even passive listening tasks. We review three theoretical accounts of
   speech imitation and convergence phenomena: (i) the Episodic Theory (ET)
   of speech perception and production (Goldinger; 1998); (ii) the Motor
   Theory (MT) of speech perception (Liberman and Whalen, 2000; Galantucci
   et al., 2006); (iii) Communication Accommodation Theory (CAT Giles and
   Coupland, 1991; Giles et al., 1991). We argue that no account is able to
   explain all the available evidence. In particular, there is a need to
   integrate low-level, mechanistic accounts (like ET and MT), and
   higher-level accounts (like CAT). We propose that this is possible
   within the framework of an integrated theory of production and
   comprehension (Pickering and Garrod, 2013). Similarly to both ET and MT,
   this theory assumes panty between production and perception. Uniquely,
   however, it posits that listeners simulate speakers' utterances by
   computing forward-model predictions at many different levels, which are
   then compared to the incoming phonetic input. In our account phonetic
   imitation can be achieved via the same mechanism that is responsible for
   sensonmotor adaptation; i.e., the correction of prediction errors. In
   addition, the model assumes that the degree to which sensory prediction
   errors lead to motor adjustments is context-dependent. The notion of
   context subsumes both the preceding linguistic input and non-linguistic
   attributes of the situation (e g., the speaker's and listener's social
   identities, their conversational roles, the listener's intention to
   imitate).}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gambi, C (Corresponding Author), Univ Edinburgh, Dept Psychol, 7 George Sq, Edinburgh EH8 9JZ, Midlothian, Scotland.
   Gambi, Chiara; Pickering, Martin J., Univ Edinburgh, Dept Psychol, Edinburgh EH8 9JZ, Midlothian, Scotland.}},
DOI = {{10.3389/fpsyg.2013.00340}},
Article-Number = {{340}},
ISSN = {{1664-1078}},
Keywords = {{imitation; convergence; forward models; simulation; prediction error}},
Keywords-Plus = {{PHONETIC CONVERGENCE; FUNDAMENTAL-FREQUENCY; PERCEPTUAL ADAPTATION;
   LANGUAGE PRODUCTION; MOTOR CONTROL; WORDS; ACCOMMODATION; COMPREHENSION;
   INTEGRATION; ACTIVATION}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary}},
Author-Email = {{c.gambi@sms.ed.ac.uk}},
ResearcherID-Numbers = {{Gambi, Chiara/J-2361-2018
   }},
ORCID-Numbers = {{Gambi, Chiara/0000-0002-1568-7779
   Pickering, Martin/0000-0002-2005-049X}},
Cited-References = {{Adank P, 2010, PSYCHOL SCI, V21, P1903, DOI 10.1177/0956797610389192.
   Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   ANDERSON AH, 1991, LANG SPEECH, V34, P351, DOI 10.1177/002383099103400404.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Aruffo C, 2012, PSYCHON B REV, V19, P66, DOI 10.3758/s13423-011-0176-8.
   Babel M, 2012, LANG SPEECH, V55, P231, DOI 10.1177/0023830911417695.
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001.
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400.
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003.
   Bosshardt HG, 1997, J PSYCHOLINGUIST RES, V26, P425, DOI 10.1023/A:1025030120016.
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005.
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276.
   Brouwer S, 2010, J ACOUST SOC AM, V128, pEL32, DOI 10.1121/1.3448022.
   D'Ausilio A, 2011, NEUROPSYCHOLOGIA, V49, P3670, DOI 10.1016/j.neuropsychologia.2011.09.022.
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914.
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Fowler CA, 2003, J MEM LANG, V49, P396, DOI 10.1016/S0749-596X(03)00072-X.
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2.
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857.
   Galantucci B, 2009, ATTEN PERCEPT PSYCHO, V71, P1138, DOI 10.3758/APP.71.5.1138.
   Gallois C, 2005, THEORIZING INTERCULT, P121.
   Gentilucci M, 2007, NEUROPSYCHOLOGIA, V45, P608, DOI 10.1016/j.neuropsychologia.2006.04.004.
   GILES H, 1973, ANTHROPOL LINGUIST, V15, P87.
   Giles H., 1991, CONTEXTS ACCOMMODATI.
   Giles Howard, 1991, LANGUAGE CONTEXTS CO.
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251.
   Goldinger SD, 2004, PSYCHON B REV, V11, P716, DOI 10.3758/BF03196625.
   Gregory SW, 1996, J PERS SOC PSYCHOL, V70, P1231, DOI 10.1037/0022-3514.70.6.1231.
   Grush R, 2004, BEHAV BRAIN SCI, V27, P377, DOI 10.1017/S0140525X04000093.
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001.
   Hesslow G, 2002, TRENDS COGN SCI, V6, P242, DOI 10.1016/S1364-6613(02)01913-7.
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158.
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103.
   Honorof DN, 2011, J PHONETICS, V39, P18, DOI 10.1016/j.wocn.2010.10.007.
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213.
   Jarick M, 2008, EXP BRAIN RES, V189, P221, DOI 10.1007/s00221-008-1416-7.
   Kappes J, 2009, BRAIN LANG, V111, P140, DOI 10.1016/j.bandl.2009.08.008.
   Kerzel D, 2000, J EXP PSYCHOL HUMAN, V26, P634, DOI 10.1037//0096-1523.26.2.634.
   Kim Midam, 2011, Lab Phonol, V2, P125.
   Kutas M., 2011, PREDICTIONBRAIN US, DOI {[}DOI 10.1093/ACPROF:OSO/9780195395518.003.0065, 10.1093/acprof:oso/9780195395518.003.0065].
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003.
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6.
   Mainwaring S, 2003, SPAT COGN COMPUT, V3, P3, DOI DOI 10.1207/S15427633SCC0301\_2.
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X.
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004.
   Miller RM, 2010, ATTEN PERCEPT PSYCHO, V72, P1614, DOI 10.3758/APP.72.6.1614.
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002.
   Namy LL, 2002, J LANG SOC PSYCHOL, V21, P422, DOI 10.1177/026192702237958.
   NATALE M, 1975, J PERS SOC PSYCHOL, V32, P790, DOI 10.1037/0022-3514.32.5.790.
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007.
   Nye PW, 2003, J PHONETICS, V31, P63, DOI 10.1016/S0095-4470(02)00072-4.
   Pardo JS, 2012, LANG LINGUIST COMPAS, V6, P753, DOI 10.1002/lnc3.367.
   Pardo JS, 2013, DISCOURSE PROCESS, V50, P276, DOI 10.1080/0163853X.2013.778168.
   Pardo JS, 2012, J PHONETICS, V40, P190, DOI 10.1016/j.wocn.2011.10.001.
   Pardo JS, 2010, ATTEN PERCEPT PSYCHO, V72, P2254, DOI 10.3758/APP.72.8.2254.
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495.
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169.
   Pitt MA, 2012, LANG COGNITIVE PROC, V27, P1225, DOI 10.1080/01690965.2011.619370.
   Pope J, 2007, LANGUAGE, V83, P615, DOI 10.1353/lan.2007.0117.
   Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551.
   Sanchez K, 2010, J SPEECH LANG HEAR R, V53, P262, DOI 10.1044/1092-4388(2009/08-0247).
   Schober M.F., 2009, SPATIAL LANGUAGE DIA, P23, DOI DOI 10.1093/ACPROF:OSO/9780199554201.003.0003.
   SCHOBER MF, 1993, COGNITION, V47, P1, DOI 10.1016/0010-0277(93)90060-9.
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890.
   Simpson AP, 2001, J ACOUST SOC AM, V109, P2153, DOI 10.1121/1.1356020.
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166.
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wilson M, 2005, PSYCHOL BULL, V131, P460, DOI 10.1037/0033-2909.131.3.460.
   Wolpert DM, 2001, CURR BIOL, V11, pR729, DOI 10.1016/S0960-9822(01)00432-8.
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238.}},
Number-of-Cited-References = {{79}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{25}},
Journal-ISO = {{Front. Psychol.}},
Doc-Delivery-Number = {{AA4BH}},
Unique-ID = {{ISI:000331038600001}},
OA = {{DOAJ Gold, Green Published, Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000318671801153,
Author = {Lau, Ellen and Weber, Kirsten and Delaney-Busch, Nate and Ustine,
   Candida and Fanucci, Kristina and Hamalainen, Matti and Kuperberg, Gina
   R.},
Title = {{Spatiotemporal Imaging of Language Reveals Dissociations Between
   Prediction Generation and Belief Updating in Schizophrenia}},
Journal = {{BIOLOGICAL PSYCHIATRY}},
Year = {{2013}},
Volume = {{73}},
Number = {{9, S}},
Meeting = {{843}},
Pages = {{269S-270S}},
Month = {{MAY 1}},
Note = {{68th Annual Scientific Meeting of the Society-of-Biological-Psychiatry,
   San Francisco, CA, MAY 16-18, 2013}},
Organization = {{Soc Biol Psychiat}},
Publisher = {{ELSEVIER SCIENCE INC}},
Address = {{STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA}},
Type = {{Meeting Abstract}},
Language = {{English}},
Affiliation = {{Lau, Ellen; Weber, Kirsten; Delaney-Busch, Nate; Ustine, Candida; Fanucci, Kristina; Kuperberg, Gina R., Tufts Univ, Dept Psychol, Boston, MA 02111 USA.
   Lau, Ellen; Weber, Kirsten; Delaney-Busch, Nate; Ustine, Candida; Fanucci, Kristina; Hamalainen, Matti; Kuperberg, Gina R., Massachusetts Gen Hosp, Dept Psychiat, Boston, MA 02114 USA.
   Lau, Ellen; Weber, Kirsten; Delaney-Busch, Nate; Ustine, Candida; Fanucci, Kristina; Hamalainen, Matti; Kuperberg, Gina R., Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Boston, MA 02114 USA.
   Lau, Ellen; Kuperberg, Gina R., Univ Maryland, Dept Linguist, College Pk, MD 20742 USA.}},
ISSN = {{0006-3223}},
EISSN = {{1873-2402}},
Keywords = {{schizophrenia; language; prediction error; fMRI; MEG/ERP}},
Research-Areas = {{Neurosciences \& Neurology; Psychiatry}},
Web-of-Science-Categories  = {{Neurosciences; Psychiatry}},
ResearcherID-Numbers = {{Weber, Kirsten/U-5244-2018
   Hamalainen, Matti S/C-8507-2013}},
ORCID-Numbers = {{Weber, Kirsten/0000-0001-8192-2207
   }},
Number-of-Cited-References = {{0}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Biol. Psychiatry}},
Doc-Delivery-Number = {{140RE}},
Unique-ID = {{ISI:000318671801153}},
DA = {{2020-12-06}},
}

@article{ ISI:000317942900011,
Author = {Chen, Fei and Hazrati, Oldooz and Loizou, Philipos C.},
Title = {{Predicting the intelligibility of reverberant speech for cochlear
   implant listeners with a non-intrusive intelligibility measure}},
Journal = {{BIOMEDICAL SIGNAL PROCESSING AND CONTROL}},
Year = {{2013}},
Volume = {{8}},
Number = {{3}},
Pages = {{311-314}},
Month = {{MAY}},
Abstract = {{Reverberation is known to reduce the temporal envelope modulations
   present in the signal and affect the shape of the modulation spectrum. A
   non-intrusive intelligibility measure for reverberant speech is proposed
   motivated by the fact that the area of the modulation spectrum decreases
   with increasing reverberation. The proposed measure is based on the
   average modulation area computed across four acoustic frequency bands
   spanning the signal bandwidth. High correlations (r = 0.98) were
   observed with sentence intelligibility scores obtained by cochlear
   implant listeners. Proposed measure outperformed other measures
   including an intrusive speech-transmission index based measure. (c) 2012
   Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chen, F (Corresponding Author), Univ Hong Kong, Prince Philip Dent Hosp, Div Speech \& Hearing Sci, 34 Hosp Rd, Hong Kong, Hong Kong, Peoples R China.
   Chen, Fei, Univ Hong Kong, Div Speech \& Hearing Sci, Hong Kong, Hong Kong, Peoples R China.
   Hazrati, Oldooz; Loizou, Philipos C., Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.}},
DOI = {{10.1016/j.bspc.2012.11.007}},
ISSN = {{1746-8094}},
Keywords = {{Intelligibility prediction; Non-intrusive measure; Envelope modulation
   reduction}},
Keywords-Plus = {{TRANSMISSION INDEX; HEARING-AIDS; NOISE; QUALITY}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Biomedical}},
Author-Email = {{feichen1@hku.hk}},
ResearcherID-Numbers = {{Chen, Fei/AAK-6755-2020
   Chen, Fei/G-4674-2018}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Funding-Acknowledgement = {{Faculty Research Fund, Faculty of Education, The University of Hong
   Kong; Seed Funding for Basic Research, The University of Hong
   KongUniversity of Hong Kong; National Institute of Deafness and other
   Communication Disorders, NIHUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness \& Other Communication Disorders (NIDCD) {[}R01 DC010494];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health \& Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness \& Other
   Communication Disorders (NIDCD) {[}R01DC010494, R01DC010494,
   R01DC010494, R01DC010494, R01DC010494, R01DC010494, R01DC010494] Funding
   Source: NIH RePORTER}},
Funding-Text = {{This research was supported by Faculty Research Fund, Faculty of
   Education, The University of Hong Kong, by Seed Funding for Basic
   Research, The University of Hong Kong, and by grant no. R01 DC010494
   from the National Institute of Deafness and other Communication
   Disorders, NIH. The authors would like to thank Dr. Tiago H. Falk for
   providing the MATLAB implementation of the SRMR measure.}},
Cited-References = {{Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052.
   Hazrati O, 2012, INT J AUDIOL, V51, P437, DOI 10.3109/14992027.2012.658972.
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224.
   Kokkinakis K, 2011, J ACOUST SOC AM, V129, P3221, DOI 10.1121/1.3559683.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   NABELEK AK, 1974, J SPEECH HEAR RES, V17, P724, DOI 10.1044/jshr.1704.724.
   Neuman AC, 2010, EAR HEARING, V31, P336, DOI 10.1097/AUD.0b013e3181d3d514.
   Payton KL, 1999, J ACOUST SOC AM, V106, P3637, DOI 10.1121/1.428216.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEIGER JH, 1980, PSYCHOL BULL, V87, P245, DOI 10.1037/0033-2909.87.2.245.
   Van den Bogaert T, 2009, J ACOUST SOC AM, V125, P360, DOI 10.1121/1.3023069.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{21}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Biomed. Signal Process. Control}},
Doc-Delivery-Number = {{130TL}},
Unique-ID = {{ISI:000317942900011}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000318261700001,
Author = {Szewczyk, Jakub M. and Schriefers, Herbert},
Title = {{Prediction in language comprehension beyond specific words: An ERP study
   on sentence comprehension in Polish}},
Journal = {{JOURNAL OF MEMORY AND LANGUAGE}},
Year = {{2013}},
Volume = {{68}},
Number = {{4}},
Pages = {{297-314}},
Month = {{MAY}},
Abstract = {{Recently, several ERP studies have shown that the human language
   comprehension system anticipates words that are highly likely
   continuations of a given text. However, it remains an open issue whether
   the language comprehension system can also make predictions that go
   beyond a specific word. Here, we address the question of whether readers
   predict broad semantically defined classes of words. Event-related brain
   potentials were recorded, while native Polish speakers read short
   stories for comprehension. The stories were setting up a context that
   was very strongly biasing towards either an animate or an inanimate
   direct object noun in the story-final sentence. At the same time, the
   context was highly predictive for a specific direct object noun or not
   predictive for a specific direct object noun. The noun that was actually
   presented either did fit the animacy bias of the context or did not fit.
   The noun was preceded by an adjective. Polish has four classes of
   grammatical gender in the singular: feminine, neuter, masculine-animate,
   and masculine-inanimate. The prenominal adjective agrees with the direct
   object noun with respect to case and, in the case of masculine-animate
   and masculine-inanimate nouns, with respect to the in-/animacy of the
   noun. This allowed us to probe, at the adjective, whether the
   comprehension system predicts the in-/animacy of the direct object noun.
   Prediction-inconsistent adjectives elicited a negativity relative to
   prediction-consistent adjectives. This negativity was of the same size
   for contexts biasing towards a specific noun and for contexts not
   biasing towards a specific noun. These findings show that the
   comprehension system can predict semantically defined classes of words.
   (C) 2012 Elsevier Inc. All rights reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Szewczyk, JM (Corresponding Author), Inst Psychol, Al Mickiewicza 3, PL-31120 Krakow, Poland.
   Szewczyk, Jakub M., Jagiellonian Univ, Inst Psychol, Krakow, Poland.
   Schriefers, Herbert, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, Nijmegen, Netherlands.}},
DOI = {{10.1016/j.jml.2012.12.002}},
ISSN = {{0749-596X}},
EISSN = {{1096-0821}},
Keywords = {{Prediction; Gender agreement; Event-related potentials; N400}},
Keywords-Plus = {{GRAMMATICAL GENDER; UPCOMING WORDS; EYE-MOVEMENTS; TIME-COURSE; SEMANTIC
   INTEGRATION; BRAIN POTENTIALS; RELATIVE CLAUSES; AGREEMENT; CONTEXT;
   SPANISH}},
Research-Areas = {{Linguistics; Psychology}},
Web-of-Science-Categories  = {{Linguistics; Psychology; Psychology, Experimental}},
Author-Email = {{jakub.szewczyk@uj.edu.pl}},
ResearcherID-Numbers = {{Schriefers, Herbert/D-8532-2012
   }},
ORCID-Numbers = {{Szewczyk, Jakub/0000-0003-4464-082X}},
Funding-Acknowledgement = {{Ministry of Science and Higher Education of the Polish Government
   {[}N/N106/2677/33]; Foundation for Polish ScienceFoundation for Polish
   Science}},
Funding-Text = {{This research was supported by Grant N/N106/2677/33 from the Ministry of
   Science and Higher Education of the Polish Government to Jakub Szewczyk,
   and by a stipend to Jakub Szewczyk from the Foundation for Polish
   Science subsidy to Zofia Wodniecka (FOCUS program).}},
Cited-References = {{Aitchison J., 2003, WORD MIND INTRO MENT.
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   BALOTA DA, 1985, COGNITIVE PSYCHOL, V17, P364, DOI 10.1016/0010-0285(85)90013-1.
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Barber H, 2004, ON-LINE STUDY OF SENTENCE COMPREHENSION, P309.
   Barber H, 2005, J COGNITIVE NEUROSCI, V17, P137, DOI 10.1162/0898929052880101.
   Bornkessel-Schlesewsky I, 2008, BRAIN RES REV, V59, P55, DOI 10.1016/j.brainresrev.2008.05.003.
   Caramazza A, 1998, J COGNITIVE NEUROSCI, V10, P1, DOI 10.1162/089892998563752.
   Chomsky N., 1965, ASPECTS THEORY SYNTA.
   Corbett Greville G., 1991, GENDER.
   Cover T.M., 2006, ELEMENTS INFORM THEO.
   Dahl O., 2000, GENDER GRAMMAR COG 1.
   DeLong K. A., 2009, THESIS U CALIFORNIA.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   FORSTER KI, 1981, Q J EXP PSYCHOL-A, V33, P465, DOI 10.1080/14640748108400804.
   Grzegorczykowa R, 1998, GRAMATYKA WSPOLCZESN.
   Hockett Charles F., 1958, COURSE MODERN LINGUI.
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   KATZ JJ, 1963, LANGUAGE, V39, P170, DOI 10.2307/411200.
   Knoeferle P, 2005, COGNITION, V95, P95, DOI 10.1016/j.cognition.2004.03.002.
   Kuperberg GR, 2007, BRAIN RES, V1146, P23, DOI 10.1016/j.brainres.2006.12.063.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Lamers MJ, 2006, BMC NEUROSCI, V7, DOI 10.1186/1471-2202-7-23.
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676.
   Mak WM, 2006, J MEM LANG, V54, P466, DOI 10.1016/j.jml.2006.01.001.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   McRae K, 2005, MEM COGNITION, V33, P1174, DOI 10.3758/BF03193221.
   McRae K, 1998, J MEM LANG, V38, P283, DOI 10.1006/jmla.1997.2543.
   Merchant J., SYNTAX INT IN PRESS.
   Molinaro N, 2008, BRAIN RES, V1228, P161, DOI 10.1016/j.brainres.2008.06.064.
   Nagorko A, 1996, ZARYS GRAMATYKI POLS.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Otten M, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-89.
   Otten M, 2009, BRAIN RES, V1291, P92, DOI 10.1016/j.brainres.2009.07.042.
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   PRZEPIORKOWSKI A, 2004, IPI PAN CORPUS PRELI.
   Roland D, 2012, COGNITION, V122, P267, DOI 10.1016/j.cognition.2011.11.011.
   SCHWANENFLUGEL PJ, 1988, J EXP PSYCHOL LEARN, V14, P344, DOI 10.1037/0278-7393.14.2.344.
   SEIDENBERG MS, 1982, COGNITIVE PSYCHOL, V14, P489, DOI 10.1016/0010-0285(82)90017-2.
   Sussman RS, 2003, LANG COGNITIVE PROC, V18, P143, DOI 10.1080/01690960143000498.
   Szewczyk JM, 2011, BRAIN RES, V1368, P208, DOI 10.1016/j.brainres.2010.10.070.
   Traxler MJ, 2002, J MEM LANG, V47, P69, DOI 10.1006/jmla.2001.2836.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van de Meerendonk N, 2010, J COGNITIVE NEUROSCI, V22, P67, DOI 10.1162/jocn.2008.21170.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   WARRINGTON EK, 1984, BRAIN, V107, P829, DOI 10.1093/brain/107.3.829.
   Weckerly J, 1999, PSYCHOPHYSIOLOGY, V36, P559, DOI 10.1017/S0048577299971202.
   Wicha NYY, 2005, LANG COGNITIVE PROC, V20, P553, DOI 10.1080/01690960444000241.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8.
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0.
   Wlotko EW, 2007, NEUROPSYCHOLOGIA, V45, P3001, DOI 10.1016/j.neuropsychologia.2007.05.013.
   ZWITSERLOOD P, 1989, COGNITION, V32, P25, DOI 10.1016/0010-0277(89)90013-9.}},
Number-of-Cited-References = {{61}},
Times-Cited = {{54}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{29}},
Journal-ISO = {{J. Mem. Lang.}},
Doc-Delivery-Number = {{135BT}},
Unique-ID = {{ISI:000318261700001}},
DA = {{2020-12-06}},
}

@article{ ISI:000315703800010,
Author = {Rothermich, Kathrin and Kotz, Sonja A.},
Title = {{Predictions in speech comprehension: fMRI evidence on the meter-semantic
   interface}},
Journal = {{NEUROIMAGE}},
Year = {{2013}},
Volume = {{70}},
Pages = {{89-100}},
Month = {{APR 15}},
Abstract = {{When listening to speech we not only form predictions about what is
   coming next, but also when something is coming. For example, metric
   stress may be utilized to predict the next salient speech event (i.e.
   the next stressed syllable) and in turn facilitate speech comprehension.
   However, speech comprehension can also be facilitated by semantic
   context, that is, which content word is likely to appear next In the
   current fMRI experiment we investigated (1) the brain networks that
   underlie metric and semantic predictions by means of prediction errors,
   (2) how semantic processing is influenced by a metrically regular or
   irregular sentence context, and (3) whether task demands influence both
   processes. The results are three-fold: First, while metrically
   incongruent sentences activated a bilateral fronto-striatal network,
   semantically incongruent trials led to activation of fronto-temporal
   areas. Second, metrically regular context facilitated speech
   comprehension in the left-fronto-temporal language network. Third,
   attention directed to metric or semantic aspects in speech engaged
   different subcomponents of the left inferior frontal gyrus (IFG). The
   current results suggest that speech comprehension relies on different
   forms of prediction, and extends known speech comprehension networks to
   subcortical sensorimotor areas. (c) 2012 Elsevier Inc. All rights
   reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kotz, SA (Corresponding Author), Max Planck Inst Human Cognit \& Brain Sci, Stephanstr 1A, D-04103 Leipzig, Germany.
   Rothermich, Kathrin, Univ Montreal, Int Lab Brain Mus \& Sound Res BRAMS, Stn Ctr Ville, Montreal, PQ H3C 3J7, Canada.
   Rothermich, Kathrin; Kotz, Sonja A., Max Planck Inst Human Cognit \& Brain Sci, Res Grp Subcort Contribut Comprehens, Dept Neuropsychol, D-04103 Leipzig, Germany.}},
DOI = {{10.1016/j.neuroimage.2012.12.013}},
ISSN = {{1053-8119}},
EISSN = {{1095-9572}},
Keywords = {{fMRI; Speech comprehension; Prediction; Facilitation}},
Keywords-Plus = {{EVENT-RELATED FMRI; LINKING BASAL GANGLIA; FUNCTIONAL NEUROANATOMY;
   CORTICAL ORGANIZATION; LANGUAGE PRODUCTION; SOURCE MEMORY; BRAIN; TIME;
   PERCEPTION; MOTOR}},
Research-Areas = {{Neurosciences \& Neurology; Radiology, Nuclear Medicine \& Medical
   Imaging}},
Web-of-Science-Categories  = {{Neurosciences; Neuroimaging; Radiology, Nuclear Medicine \& Medical
   Imaging}},
Author-Email = {{kotz@cbs.mpg.de}},
ResearcherID-Numbers = {{Rothermich, Kathrin/Z-5320-2019}},
Cited-References = {{Ackermann H, 2001, NEUROREPORT, V12, P4087, DOI 10.1097/00001756-200112210-00045.
   Ackermann H, 2008, TRENDS NEUROSCI, V31, P265, DOI 10.1016/j.tins.2008.02.011.
   Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742.
   Akkal D, 2007, J NEUROSCI, V27, P10659, DOI 10.1523/JNEUROSCI.3134-07.2007.
   Aleman A, 2005, CEREB CORTEX, V15, P221, DOI 10.1093/cercor/bhh124.
   ALEXANDER GE, 1986, ANNU REV NEUROSCI, V9, P357, DOI 10.1146/annurev.ne.09.030186.002041.
   Badre D, 2005, NEURON, V47, P907, DOI 10.1016/j.neuron.2005.07.023.
   Badre D, 2009, NAT REV NEUROSCI, V10, P659, DOI 10.1038/nrn2667.
   Bamiou DE, 2006, NEUROLOGY, V67, P614, DOI 10.1212/01.wnl.0000230197.40410.db.
   Bengtsson SL, 2009, CORTEX, V45, P62, DOI 10.1016/j.cortex.2008.07.002.
   Bookheimer S, 2002, ANNU REV NEUROSCI, V25, P151, DOI 10.1146/annurev.neuro.25.112701.142946.
   BRADY JP, 1969, BEHAV RES THER, V7, P197, DOI 10.1016/0005-7967(69)90033-3.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   Buhusi CV, 2005, NAT REV NEUROSCI, V6, P755, DOI 10.1038/nrn1764.
   Burton H, 2003, J NEUROPHYSIOL, V90, P1965, DOI 10.1152/jn.00279.2003.
   Cason N, 2012, NEUROPSYCHOLOGIA, V50, P2652, DOI 10.1016/j.neuropsychologia.2012.07.018.
   Chapin HL, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00224.
   Chen JL, 2008, CEREB CORTEX, V18, P2844, DOI 10.1093/cercor/bhn042.
   Christensen TA, 2008, NEUROREPORT, V19, P1101, DOI 10.1097/WNR.0b013e3283060a9d.
   Coull JT, 2008, CURR OPIN NEUROBIOL, V18, P137, DOI 10.1016/j.conb.2008.07.011.
   Coull JT, 2004, COGNITIVE BRAIN RES, V21, P216, DOI 10.1016/j.cogbrainres.2004.02.011.
   Craig AD, 2009, PHILOS T R SOC B, V364, P1933, DOI 10.1098/rstb.2009.0008.
   CROSSON B, 1985, BRAIN LANG, V25, P257, DOI 10.1016/0093-934X(85)90085-9.
   Cusack R, 2003, NEUROIMAGE, V18, P127, DOI 10.1006/nimg.2002.1281.
   CUTLER A, 1988, J EXP PSYCHOL HUMAN, V14, P113, DOI 10.1037/0096-1523.14.1.113.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743.
   Domahs U, 2008, PHONOLOGY, V25, P1, DOI 10.1017/S0952675708001383.
   Endress AD, 2010, COGNITIVE PSYCHOL, V61, P177, DOI 10.1016/j.cogpsych.2010.05.001.
   ESSENS PJ, 1985, PERCEPT PSYCHOPHYS, V37, P1, DOI 10.3758/BF03207132.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Fiez JA, 1997, HUM BRAIN MAPP, V5, P79, DOI 10.1002/(SICI)1097-0193(1997)5:2<79::AID-HBM1>3.3.CO;2-M.
   Friederici AD, 2002, J PSYCHOLINGUIST RES, V31, P45, DOI 10.1023/A:1014376204525.
   Friederici AD, 2003, CEREB CORTEX, V13, P170, DOI 10.1093/cercor/13.2.170.
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011.
   Friederici AD, 2010, HUM BRAIN MAPP, V31, P448, DOI 10.1002/hbm.20878.
   Friston KJ, 1998, NEUROIMAGE, V7, P30, DOI 10.1006/nimg.1997.0306.
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015.
   Geiser E, 2008, J COGNITIVE NEUROSCI, V20, P541, DOI 10.1162/jocn.2008.20029.
   Geiser E, 2012, J NEUROSCI, V32, P6177, DOI 10.1523/JNEUROSCI.5153-11.2012.
   Golumbic E.M.Z., 2012, BRAIN LANG.
   GOW DW, 1993, J PSYCHOLINGUIST RES, V22, P545.
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893.
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004.
   Hasson U, 2012, TRENDS COGN SCI, V16, P114, DOI 10.1016/j.tics.2011.12.007.
   Heim S, 2003, COGNITIVE BRAIN RES, V16, P285, DOI 10.1016/S0926-6410(02)00284-7.
   Herrero MT, 2002, CHILD NERV SYST, V18, P386, DOI 10.1007/s00381-002-0604-1.
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7.
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113.
   Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032.
   HOUK JC, 1995, CEREB CORTEX, V5, P95, DOI 10.1093/cercor/5.2.95.
   INASE M, 1994, NEUROSCI LETT, V180, P135, DOI 10.1016/0304-3940(94)90505-3.
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716.
   Keppel G., 1982, DESIGN ANAL RES HDB.
   Ketteler D, 2008, NEUROIMAGE, V39, P2002, DOI 10.1016/j.neuroimage.2007.10.023.
   Klein E, 2011, BEHAV BRAIN FUNCT, V7, DOI 10.1186/1744-9081-7-15.
   Kosillo P, 2010, BRAIN STRUCT FUNCT, V214, P623, DOI 10.1007/s00429-010-0267-8.
   Kotz SA, 2005, BRAIN LANG, V95, P70, DOI 10.1016/j.bandl.2005.07.039.
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005.
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010.
   Kuperberg GR, 2000, J COGNITIVE NEUROSCI, V12, P321, DOI 10.1162/089892900562138.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119.
   Lee CS, 2004, COGNITION, V93, P225, DOI 10.1016/j.cognition.2003.10.012.
   LEE JH, 1995, MAGN RESON MED, V34, P308, DOI 10.1002/mrm.1910340305.
   Lewis JW, 2000, CEREB CORTEX, V10, P873, DOI 10.1093/cercor/10.9.873.
   Lidji P, 2011, PSYCHON B REV, V18, P1035, DOI 10.3758/s13423-011-0163-0.
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040.
   Lundstrom BN, 2005, NEUROIMAGE, V27, P824, DOI 10.1016/j.neuroimage.2005.05.008.
   Macmillan N. A., 2005, DETECTION THEORY USE.
   Magne C., 2010, P SPEECH PROS 2010 C.
   MARTIN JG, 1972, PSYCHOL REV, V79, P487, DOI 10.1037/h0033467.
   McClelland J. L., 1986, PARALLEL DISTRIBUTED, VII, P58.
   McIntosh GC, 1997, J NEUROL NEUROSUR PS, V62, P22, DOI 10.1136/jnnp.62.1.22.
   Menenti L, 2009, J COGNITIVE NEUROSCI, V21, P2358, DOI 10.1162/jocn.2008.21163.
   Meyer M, 2002, HUM BRAIN MAPP, V17, P73, DOI 10.1002/hbm.10042.
   Miezin FM, 2000, NEUROIMAGE, V11, P735, DOI 10.1006/nimg.2000.0568.
   Mutschler I, 2009, NEUROSCI LETT, V457, P66, DOI 10.1016/j.neulet.2009.03.101.
   Nadeau SE, 1997, BRAIN LANG, V58, P355, DOI 10.1006/brln.1997.1707.
   Newman AJ, 2001, J PSYCHOLINGUIST RES, V30, P339, DOI 10.1023/A:1010499119393.
   Ni W, 2000, J COGNITIVE NEUROSCI, V12, P120, DOI 10.1162/08989290051137648.
   Norris DG, 2000, JMRI-J MAGN RESON IM, V11, P445, DOI 10.1002/(SICI)1522-2586(200004)11:4<445::AID-JMRI13>3.0.CO;2-T.
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128.
   Otten LJ, 2001, CEREB CORTEX, V11, P1150, DOI 10.1093/cercor/11.12.1150.
   Patel A.D., 2008, MUSIC LANGUAGE BRAIN.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   PITT MA, 1990, J EXP PSYCHOL HUMAN, V16, P564, DOI 10.1037/0096-1523.16.3.564.
   Port RF, 2003, J PHONETICS, V31, P599, DOI 10.1016/j.wocn.2003.08.001.
   Quene H, 2005, PHONETICA, V62, P1, DOI 10.1159/000087222.
   Rissman J, 2003, J COGNITIVE NEUROSCI, V15, P1160, DOI 10.1162/089892903322598120.
   Rossell SL, 2003, NEUROPSYCHOLOGIA, V41, P550, DOI 10.1016/S0028-3932(02)00181-1.
   Rothermich K, 2012, NEUROPSYCHOLOGIA, V50, P232, DOI 10.1016/j.neuropsychologia.2011.10.025.
   Rothermich K, 2010, NEUROREPORT, V21, P580, DOI 10.1097/WNR.0b013e32833a7da7.
   Ruschemeyer SA, 2005, HUM BRAIN MAPP, V25, P266, DOI 10.1002/hbm.20098.
   Saint-Cyr JA, 2003, J INT NEUROPSYCH SOC, V9, P103, DOI 10.1017/S1355617703910125.
   Schmidt-Kassow M., 2007, MPI SERIES COGNITIVE.
   Schmidt-Kassow M, 2008, BRAIN RES, V1226, P144, DOI 10.1016/j.brainres.2008.06.017.
   Schmidt-Kassow M, 2009, J COGNITIVE NEUROSCI, V21, P1693, DOI 10.1162/jocn.2008.21153.
   Schwartze M, 2012, NEUROIMAGE, V60, P290, DOI 10.1016/j.neuroimage.2011.11.089.
   SHIELDS JL, 1974, J EXP PSYCHOL, V102, P250, DOI 10.1037/h0035855.
   Singer T, 2009, TRENDS COGN SCI, V13, P334, DOI 10.1016/j.tics.2009.05.001.
   Slotnick SD, 2003, COGNITIVE BRAIN RES, V17, P75, DOI 10.1016/S0926-6410(03)00082-X.
   Swick D, 2011, NEUROIMAGE, V56, P1655, DOI 10.1016/j.neuroimage.2011.02.070.
   Trainor LJ, 2002, PSYCHON B REV, V9, P335, DOI 10.3758/BF03196290.
   UGURBIL K, 1993, MAGN RESON QUART, V9, P259.
   Vermeiren A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031595.
   Wahl M, 2008, NEURON, V59, P695, DOI 10.1016/j.neuron.2008.07.011.
   Wallentin M, 2008, HUM BRAIN MAPP, V29, P524, DOI 10.1002/hbm.20413.
   Wendelken C., 2011, HUM BRAIN MAPP.
   Wheatley T., 2005, J COGNITIVE NEUROSCI, V17, P12.
   WORSLEY KJ, 1995, NEUROIMAGE, V2, P173, DOI 10.1006/nimg.1995.1023.
   Yoshida KA, 2010, COGNITION, V115, P356, DOI 10.1016/j.cognition.2010.01.005.
   Zarate JM, 2005, ANN NY ACAD SCI, V1060, P404, DOI 10.1196/annals.1360.058.
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767.
   Zhao JJ, 2008, NEUROIMAGE, V43, P624, DOI 10.1016/j.neuroimage.2008.07.025.
   Zhuang J, 2011, J COGNITIVE NEUROSCI, V23, P3778, DOI 10.1162/jocn\_a\_00046.
   Zurowski B, 2002, NEUROIMAGE, V15, P45, DOI 10.1006/nimg.2001.0968.}},
Number-of-Cited-References = {{117}},
Times-Cited = {{35}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{51}},
Journal-ISO = {{Neuroimage}},
Doc-Delivery-Number = {{100LX}},
Unique-ID = {{ISI:000315703800010}},
DA = {{2020-12-06}},
}

@article{ ISI:000317320800009,
Author = {Brunelliere, Angele and Soto-Faraco, Salvador},
Title = {{The speakers' accent shapes the listeners' phonological predictions
   during speech perception}},
Journal = {{BRAIN AND LANGUAGE}},
Year = {{2013}},
Volume = {{125}},
Number = {{1}},
Pages = {{82-93}},
Month = {{APR}},
Abstract = {{This study investigates the specificity of predictive coding in spoken
   word comprehension using event-related potentials (ERPs). We measured
   word-evoked ERPs in Catalan speakers listening to semantically
   constraining sentences produced in their native regional accent
   (Experiment 1) or in a non-native accent (Experiment 2). Semantically
   anomalous words produced long-lasting negative shift (N400) starting as
   early as 250 ms, thus reflecting phonological as well as semantic
   mismatch. Semantically expected but phonologically unexpected
   (non-native forms embedded in a native context) produced only an early
   (similar to 250 ms) negative difference. In contrast, this phonological
   expectancy effect failed for native albeit phonologically unexpected
   target words embedded in a non-native context. These results suggest
   phonologically precise expectations when operating over native input,
   whilst phonologically less specified expectations in a non-native
   context. Our findings shed light on contextual influence during word
   recognition, suggesting that word form prediction based on context is
   sensitive and adaptive to phonological variability. (c) 2013 Elsevier
   Inc. All rights reserved.}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Brunelliere, A (Corresponding Author), Univ Lille 3, Unite Rech Sci Cognit \& Affect, BP 149, F-59653 Villeneuve Dascq, France.
   Brunelliere, Angele, Univ Lille 3, Unite Rech Sci Cognit \& Affect, F-59653 Villeneuve Dascq, France.
   Soto-Faraco, Salvador, Univ Pompeu Fabra, ICREA, Barcelona, Spain.
   Soto-Faraco, Salvador, Univ Pompeu Fabra, Dept Tecnol Informacio \& Comunicac, Barcelona, Spain.}},
DOI = {{10.1016/j.bandl.2013.01.007}},
ISSN = {{0093-934X}},
EISSN = {{1090-2155}},
Keywords = {{Predictive mechanisms; Phonological variability; Spoken-word
   comprehension; Event-related potentials}},
Keywords-Plus = {{SPOKEN-WORD RECOGNITION; LANGUAGE COMPREHENSION; SEMANTIC INTEGRATION;
   BRAIN POTENTIALS; LEXICAL ACCESS; TIME-COURSE; SENTENCES; SPANISH;
   GENDER; IDENTIFICATION}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences \&
   Neurology; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental}},
Author-Email = {{angele.brunelliere@univ-lille3.fr}},
ResearcherID-Numbers = {{Consolider Ingenio 2010, BRAINGLOT/D-1235-2009
   SOTO-FARACO, SALVADOR/B-8400-2011
   }},
ORCID-Numbers = {{SOTO-FARACO, SALVADOR/0000-0002-4799-3762
   Brunelliere, Angele/0000-0002-1913-5613}},
Funding-Acknowledgement = {{Spanish Ministry of Science and InnovationSpanish Government
   {[}PSI2010-15426, CSD2007-00012]; Comissionat per a Universitats i
   Recerca del DIUE-Generalitat de CatalunyaGeneralitat de Catalunya
   {[}SGR2009-092]; European Research CouncilEuropean Research Council
   (ERC) {[}StG-2010263145]; Center for Biomedical Imaging of Geneva;
   Center for Biomedical Imaging of Lausanne; ICREAICREA Funding Source:
   Custom}},
Funding-Text = {{This research was supported by the Spanish Ministry of Science and
   Innovation (PSI2010-15426 and Consolider INGENIO CSD2007-00012),
   Comissionat per a Universitats i Recerca del DIUE-Generalitat de
   Catalunya (SGR2009-092), and the European Research Council
   (StG-2010263145). ERP analyses were performed with the Cartool software
   (supported by the Center for Biomedical Imaging of Geneva and Lausanne).
   We would like to thank Nara Ikumi for her help in acquiring the ERP data
   and in constructing and recording the sentences. We are grateful to the
   three anonymous reviewers for their helpful comments.}},
Cited-References = {{Alarcos E., 1953, ARCHIVUM, VIII, p{[}135, 11].
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   Baldeweg T, 2006, TRENDS COGN SCI, V10, P93, DOI 10.1016/j.tics.2006.01.010.
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403.
   CONNOLLY JF, 1992, BRAIN LANG, V43, P1, DOI 10.1016/0093-934X(92)90018-A.
   CONNOLLY JF, 1990, BRAIN LANG, V39, P302, DOI 10.1016/0093-934X(90)90016-A.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   FRAUENFELDER UH, 1987, COGNITION, V25, P1, DOI 10.1016/0010-0277(87)90002-3.
   Friston KJ, 2009, NEURAL NETWORKS, V22, P1093, DOI 10.1016/j.neunet.2009.07.023.
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622.
   Giles H., 1991, CONTEXTS ACCOMMODATI, P1, DOI {[}DOI 10.1017/CBO9780511663673, DOI 10.1017/CBO9780511663673.001].
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251.
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166.
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823.
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn\_a\_00103.
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Liberman A. M., 1962, P SPEECH COMM SEM, V2.
   MARSLENWILSON W, 1984, ATTENTION PERFORM, V10, P125.
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X.
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0.
   Morton J., 1979, STRUCTURES PROCESSES, P108.
   NATALE M, 1975, J PERS SOC PSYCHOL, V32, P790, DOI 10.1037/0022-3514.32.5.790.
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720.
   PERRIN F, 1987, ELECTROEN CLIN NEURO, V66, P75, DOI 10.1016/0013-4694(87)90141-6.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Rafel i Fontanals J., 1998, DICCIONARI FREQUENCI.
   Stevens K. N., 1967, MODELS PERCEPTION SP, P88.
   TANENHAUS MK, 1987, COGNITION, V25, P213, DOI 10.1016/0010-0277(87)90010-2.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054.
   van den Brink D, 2004, J COGNITIVE NEUROSCI, V16, P1068, DOI 10.1162/0898929041502670.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8.
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{20}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{24}},
Journal-ISO = {{Brain Lang.}},
Doc-Delivery-Number = {{122LY}},
Unique-ID = {{ISI:000317320800009}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000316215300004,
Author = {Sanchez-Garcia, Carolina and Enns, James T. and Soto-Faraco, Salvador},
Title = {{Cross-modal prediction in speech depends on prior linguistic experience}},
Journal = {{EXPERIMENTAL BRAIN RESEARCH}},
Year = {{2013}},
Volume = {{225}},
Number = {{4}},
Pages = {{499-511}},
Month = {{APR}},
Abstract = {{The sight of a speaker's facial movements during the perception of a
   spoken message can benefit speech processing through online predictive
   mechanisms. Recent evidence suggests that these predictive mechanisms
   can operate across sensory modalities, that is, vision and audition.
   However, to date, behavioral and electrophysiological demonstrations of
   cross-modal prediction in speech have considered only the speaker's
   native language. Here, we address a question of current debate, namely
   whether the level of representation involved in cross-modal prediction
   is phonological or pre-phonological. We do this by testing participants
   in an unfamiliar language. If cross-modal prediction is predominantly
   based on phonological representations tuned to the phonemic categories
   of the native language of the listener, then it should be more effective
   in the listener's native language than in an unfamiliar one. We tested
   Spanish and English native speakers in an audiovisual matching paradigm
   that allowed us to evaluate visual-to-auditory prediction, using
   sentences in the participant's native language and in an unfamiliar
   language. The benefits of cross-modal prediction were only seen in the
   native language, regardless of the particular language or participant's
   linguistic background. This pattern of results implies that cross-modal
   visual-to-auditory prediction during speech processing makes strong use
   of phonological representations, rather than low-level spatiotemporal
   correlations across facial movements and sounds.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Soto-Faraco, S (Corresponding Author), Univ Pompeu Fabra, CBC, Dept Tecnol Informacio \& Comunicac, C Roc Boronat 138, Barcelona 08018, Spain.
   Sanchez-Garcia, Carolina; Soto-Faraco, Salvador, Univ Pompeu Fabra, CBC, Dept Tecnol Informacio \& Comunicac, C Roc Boronat 138, Barcelona 08018, Spain.
   Enns, James T., Univ British Columbia, Dept Psychol, Vancouver, BC, Canada.
   Soto-Faraco, Salvador, ICREA, Barcelona, Spain.}},
DOI = {{10.1007/s00221-012-3390-3}},
ISSN = {{0014-4819}},
EISSN = {{1432-1106}},
Keywords = {{Audiovisual speech; Speech perception; Predictive coding; Multisensory
   integration}},
Keywords-Plus = {{HEARING LIPS; VISUAL SPEECH; PERCEPTION; LANGUAGE; INFORMATION;
   INTEGRATION; OSCILLATIONS; 2ND-LANGUAGE; BILINGUALS; ACTIVATION}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{Salvador.Soto@icrea.cat}},
ResearcherID-Numbers = {{Consolider Ingenio 2010, BRAINGLOT/D-1235-2009
   Enns, James T/O-7583-2017
   SOTO-FARACO, SALVADOR/B-8400-2011}},
ORCID-Numbers = {{Enns, James T/0000-0002-3676-8316
   SOTO-FARACO, SALVADOR/0000-0002-4799-3762}},
Funding-Acknowledgement = {{ICREAICREA Funding Source: Custom}},
Cited-References = {{Abercrombie D., 1967, ELEMENTS GEN PHONETI.
   Altieri NA, 2011, J ACOUST SOC AM, V130, P1, DOI 10.1121/1.3593376.
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810.
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009.
   Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220.
   Bernstein L., 1998, HEARING EYE, P211.
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546.
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011.
   Bernstein LE, 2005, BLACKW HBK LINGUIST, P79, DOI 10.1002/9780470757024.ch4.
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x.
   Best C. T., 1995, SPEECH PERCEPTION LI, P171.
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701.
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5.
   Bubic A, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00025.
   Calvert G. A., 2004, HDB MULTISENSORY PRO.
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436.
   Dambacher M, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005047.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379.
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x.
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503.
   Fowler C. A., 2004, HDB MULTISENSORY PRO, P189.
   Grant KW, 2001, J ACOUST SOC AM, V109, P2272, DOI 10.1121/1.1362687.
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668.
   GREEN KP, 1991, J EXP PSYCHOL HUMAN, V17, P278, DOI 10.1037/0096-1523.17.1.278.
   GREEN KP, 1998, HEARING EYE, V2, P3.
   Kim J, 2003, PERCEPTION, V32, P111, DOI 10.1068/p3466.
   Levelt WJM, 2001, P NATL ACAD SCI USA, V98, P13464, DOI 10.1073/pnas.231459498.
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109.
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279.
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6.
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830.
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067).
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753.
   Massaro DW, 1998, MIT PRESS BRADFORD B.
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0.
   Navarra J, 2005, J EXP PSYCHOL HUMAN, V31, P912, DOI 10.1037/0096-1523.31.5.912.
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5.
   Navarra J, 2010, BRAIN RES, V1323, P84, DOI 10.1016/j.brainres.2010.01.059.
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357.
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005.
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383.
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160.
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106.
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0.
   Rosenblum LD, 2005, BLACKW HBK LINGUIST, P51, DOI 10.1002/9780470757024.ch3.
   Sams M, 2005, COGNITIVE BRAIN RES, V23, P429, DOI 10.1016/j.cogbrainres.2004.11.006.
   Sanchez-Garcia C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025198.
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002.
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006.
   SCHWARTZ JL, 1998, HEARING EYE, V2, P85.
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4.
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x.
   Siva N., 1995, J ACOUST SOC AM, V98, P2983.
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147.
   Skipper JI, 2009, CURR BIOL, V19, P661, DOI 10.1016/j.cub.2009.02.051.
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006.
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012.
   Soto-Faraco S, 2012, MULTISENSORY DEV, P207, DOI DOI 10.1093/ACPROF:OSO/9780199586059.003.0009.
   Soto-Faraco S, 2007, PERCEPT PSYCHOPHYS, V69, P218, DOI 10.3758/BF03193744.
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964.
   Strange W, 1978, PERCEPTION EXPERIENC, V1, P129, DOI {[}DOI 10.1007/978-1-4684-2619-9\_5, 10.1007/978-1-4684-2619-9\_5].
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309.
   Summerfield Q, 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102.
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308.
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686.
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988.
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509.
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249.}},
Number-of-Cited-References = {{73}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{21}},
Journal-ISO = {{Exp. Brain Res.}},
Doc-Delivery-Number = {{107KJ}},
Unique-ID = {{ISI:000316215300004}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000315493900009,
Author = {Pitas, Charalampos N. and Panagopoulos, Athanasios D. and Constantinou,
   Philip},
Title = {{Speech and Video Telephony Quality Characterization and Prediction of
   Live Contemporary Mobile Communication Networks}},
Journal = {{WIRELESS PERSONAL COMMUNICATIONS}},
Year = {{2013}},
Volume = {{69}},
Number = {{1}},
Pages = {{153-174}},
Month = {{MAR}},
Abstract = {{Quality of Service (QoS) characterization and prediction is of utmost
   importance in contemporary operating cellular communications networks.
   Measurements data of speech and video telephony have been collected
   using modern experimental equipment. More specifically, key performance
   indicators of radio, speech and video quality are evoked. The objective
   of our study is to critically investigate the performance of speech and
   video telephony at live cellular networks correlating significant QoS
   parameters from radio and the service side. Simple non-linear regression
   models are also proposed for speech and video quality prediction.
   Finally, the paper represents the splendid positive influences of the
   continuous performance evaluation for the optimization of the mobile
   networks. There are also briefly given guidelines for mobile networks
   benchmarking.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Panagopoulos, AD (Corresponding Author), Natl Tech Univ Athens, Sch Elect \& Comp Engn, Mobile Radiocommun Lab, Div Informat Transmiss Syst \& Mat Technol, 8 Iroon Polytech Str, GR-15773 Athens, Greece.
   Pitas, Charalampos N.; Panagopoulos, Athanasios D.; Constantinou, Philip, Natl Tech Univ Athens, Sch Elect \& Comp Engn, Mobile Radiocommun Lab, Div Informat Transmiss Syst \& Mat Technol, GR-15773 Athens, Greece.}},
DOI = {{10.1007/s11277-012-0566-x}},
ISSN = {{0929-6212}},
Keywords = {{Cellular radio networks; Radio coverage; Speech quality; Video quality;
   QoS prediction; Optimization; Benchmarking}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Author-Email = {{chpitas@mobile.ntua.gr
   thpanag@ece.ntua.gr
   fkonst@mobile.ntua.gr}},
ResearcherID-Numbers = {{Pitas, Charalampos/F-1317-2015
   Panagopoulos, Athanasios/P-8713-2018}},
ORCID-Numbers = {{Pitas, Charalampos/0000-0001-8058-1535
   Panagopoulos, Athanasios/0000-0003-4716-3328}},
Funding-Acknowledgement = {{General Secretariat of Research and Technology, Ministry of Development,
   GreeceGreek Ministry of Development-GSRT}},
Funding-Text = {{The experimental equipment was acquired by Mobile Radiocommunications
   Laboratory, NTUA, in 2008 during 05-AKM Omega N-95 project funded by the
   General Secretariat of Research and Technology, Ministry of Development,
   Greece. The authors would like to thank Mr. Arthur Tollenaar and
   SwissQual A. G., Switzerland, for the provision of live network
   drive-test data regarding of video telephony service. We also thank
   Adapt-IT S. A., Greece, for providing us the vehicle for the experiment.}},
Cited-References = {{{[}Anonymous], 2008, J246 ITUT.
   {[}Anonymous], 2007, EL COMM COMM ECC EUR.
   {[}Anonymous], 2009, 126071 ETSI TS.
   {[}Anonymous], 2009, GSM UMTS MOBILE COMM.
   {[}Anonymous], 102250 ETSI TS 1.
   {[}Anonymous], 2010, P863 ITUT.
   {[}Anonymous], 2010, 126290 ETSI TS.
   {[}Anonymous], 2000, 300726 ETSI EN.
   {[}Anonymous], 2004, P563 ITUT.
   {[}Anonymous], 1999, RXQUAL VOIC QUAL, V102.
   {[}Anonymous], 2008, VAL OBJ MOD MULT QUA.
   {[}Anonymous], 2009, 102493 ETSI TR.
   {[}Anonymous], 2010, DIVR BENCHM.
   {[}Anonymous], 2009, 126190 ETSI TS.
   Cotanis I., 2006, PESQ ALGORITHM SOLUT.
   ECC, 2008, EL COMM COMM ECC EUR.
   {*}ETSI, 2007, 102506 ETSI TR.
   Goudarzi M, 2009, MEASUREMENT OF SPEECH, AUDIO AND VIDEO QUALITY IN NETWORKS, P3.
   Holma H., 2009, LTE UMTS OFDMA SC FD.
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522.
   {*}ITU T, 2003, P8621 ITUT.
   ITU-T, 2001, P862 ITUT.
   ITU-T Recommendation, 2008, J247 ITUT.
   Khan A., 2009, INT J ADV NETWORKS S, V2, P144.
   Khan A, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/608138.
   Masaaki I., 1986, KAIZEN KEY JAPANS CO.
   Nipp O., 2007, P 16 IST MOB WIR COM, P1.
   OHM JR, 1999, BILDSIGNALVERARBEITU.
   Pitas C. N., 2009, JOINT WORKSH COST210.
   Pitas C. N., 2010, 9 INT C MEAS SPEECH.
   Pyzdek T, 2009, 6 SIGMA HDB.
   Rohani B., 2008, 8 INT C MEAS SPEECH.
   Sun LF, 2006, IEEE T MULTIMEDIA, V8, P809, DOI 10.1109/TMM.2006.876279.
   Vlachodimitropoulos K., 2007, 18 ANN IEEE INT S PE.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Wirel. Pers. Commun.}},
Doc-Delivery-Number = {{097SN}},
Unique-ID = {{ISI:000315493900009}},
DA = {{2020-12-06}},
}

@article{ ISI:000316809800026,
Author = {Ooi, Kuan Ee Brian and Lech, Margaret and Allen, Nicholas B.},
Title = {{Multichannel Weighted Speech Classification System for Prediction of
   Major Depression in Adolescents}},
Journal = {{IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING}},
Year = {{2013}},
Volume = {{60}},
Number = {{2}},
Pages = {{497-506}},
Month = {{FEB}},
Abstract = {{Early identification of adolescents at high imminent risk for clinical
   depression could significantly reduce the burden of the disease. This
   study demonstrated that acoustic speech analysis and classification can
   be used to determine early signs of major depression in adolescents, up
   to two years before they meet clinical diagnostic criteria for the
   full-blown disorder. Individual contributions of four different types of
   acoustic parameters {[}prosodic, glottal, Teager's energy operator
   (TEO), and spectral] to depression-related changes of speech
   characteristics were examined. A new computational methodology for the
   early prediction of depression in adolescents was developed and tested.
   The novel aspect of this methodology is in the introduction of
   multichannel classification with a weighted decision procedure. It was
   observed that single-channel classification was effective in predicting
   depression with a desirable specificity-to-sensitivity ratio and
   accuracy higher than chance level only when using glottal or prosodic
   features. The best prediction performance was achieved with the new
   multichannel method, which used four features (prosodic, glottal, TEO,
   and spectral). In the case of the person-based approach with two sets of
   weights, the new multichannel method provided a high accuracy level of
   73\% and the sensitivity-to-specificity ratio of 79\%/67\% for
   predicting future depression.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ooi, KEB (Corresponding Author), RMIT Univ, Sch Elect \& Comp Engn, Melbourne, Vic 3001, Australia.
   Ooi, Kuan Ee Brian; Lech, Margaret, RMIT Univ, Sch Elect \& Comp Engn, Melbourne, Vic 3001, Australia.
   Allen, Nicholas B., Univ Melbourne, Orygen Youth Hlth Res Ctr, Melbourne, Vic 3010, Australia.
   Allen, Nicholas B., Univ Melbourne, Dept Psychol Sci, Melbourne, Vic 3010, Australia.}},
DOI = {{10.1109/TBME.2012.2228646}},
ISSN = {{0018-9294}},
EISSN = {{1558-2531}},
Keywords = {{Clinical depression; decision fusion; optimal weighting; prediction of
   depression; risk for depression; speech classification}},
Keywords-Plus = {{CLINICAL DEPRESSION; EMOTIONAL INERTIA; ONSET; RISK; FLOW}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Biomedical}},
Author-Email = {{k.ooi@student.rmit.edu.au
   margaret.lech@rmit.edu.au
   nba@unimelb.edu.au}},
ORCID-Numbers = {{Allen, Nicholas/0000-0002-1086-6639}},
Cited-References = {{Airas M, 2008, LOGOP PHONIATR VOCO, V33, P49, DOI 10.1080/14015430701855333.
   ALKU P, 1992, SPEECH COMMUN, V11, P109, DOI 10.1016/0167-6393(92)90005-R.
   Barrera A.Z, 2009, INT ENCY DEPRESSION, P447.
   Bernardo J.M., 2001, MEAS SCI TECHNOL, V12, P221, DOI DOI 10.1088/0957-0233/12/2/702.
   Boersma P., 1993, P I PHONETIC SCI, V17, P97.
   Childers D. G, 2000, SPEECH PROCESSING SY.
   Cyranowski JM, 2000, ARCH GEN PSYCHIAT, V57, P21, DOI 10.1001/archpsyc.57.1.21.
   Dorado P, 2007, FUND CLIN PHARMACOL, V21, P451, DOI 10.1111/j.1472-8206.2007.00501.x.
   Ellis L.K., 2001, BIENN M SOC RES CHIL.
   Field A., 2005, DISCOVERING STAT USI.
   France DJ, 2000, IEEE T BIO-MED ENG, V47, P829, DOI 10.1109/10.846676.
   Fukunaga K., 1990, INTRO STAT PATTERN R.
   Garber J, 2009, JAMA-J AM MED ASSOC, V301, P2215, DOI 10.1001/jama.2009.788.
   Hansen JHL, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/906789.
   He L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2346.
   Henshaw C., 2005, SCREENING PERINATAL.
   HOPS H, 1995, J CLIN CHILD PSYCHOL, V24, P193, DOI 10.1207/s15374424jccp2402\_7.
   Kaiser J. F., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P149, DOI 10.1109/ICASSP.1993.319457.
   KAISER JF, 1990, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.1990.115702.
   Kuppens P, 2012, EMOTION, V12, P283, DOI 10.1037/a0025046.
   Kuppens P, 2010, PSYCHOL SCI, V21, P984, DOI 10.1177/0956797610372634.
   Low LSA, 2011, IEEE T BIO-MED ENG, V58, P574, DOI 10.1109/TBME.2010.2091640.
   Moore E, 2004, P ANN INT IEEE EMBS, V26, P17.
   Moore E, 2008, IEEE T BIO-MED ENG, V55, P96, DOI 10.1109/TBME.2007.900562.
   Moses P., 1954, VOICE NEUROSIS.
   Mrazek P., 1994, REDUCING RISK MENTAL.
   Munoz R. F., 1993, PREVENTIVE DEPRESSIO.
   Munoz R. F., 2008, HDB DEPRESSION, P533.
   NMH Communications, 2001, MENT NEUR DIS FACT S.
   Ooi K. E. B., 2011, 12 INT WORKSH IM AN.
   Ozdas A, 2004, IEEE T BIO-MED ENG, V51, P1530, DOI 10.1109/TBME.2004.827544.
   Quatieri T. F., 2002, DISCRETE TIME SPEECH.
   Schuller B., 2007, P INTERSPEECH, P2253.
   Sheeber L, 2001, CLIN CHILD FAM PSYCH, V4, P19, DOI 10.1023/A:1009524626436.
   TEAGER HM, 1980, IEEE T ACOUST SPEECH, V28, P599, DOI 10.1109/TASSP.1980.1163453.
   Theodoridis S., 1998, PATTERN RECOGNITION.
   Whittle S, 2011, DEV PSYCHOPATHOL, V23, P115, DOI 10.1017/S0954579410000684.
   Young S.J., 1993, HTK HIDDEN MARKOV MO.
   Zhou GJ, 2001, IEEE T SPEECH AUDI P, V9, P201, DOI 10.1109/89.905995.}},
Number-of-Cited-References = {{39}},
Times-Cited = {{30}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{IEEE Trans. Biomed. Eng.}},
Doc-Delivery-Number = {{115KA}},
Unique-ID = {{ISI:000316809800026}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000338689600174,
Author = {Su, Zhaoan and Xiu, Chundi},
Editor = {{Xu, P and Wang, Y and Su, Y and Hao, L}},
Title = {{Speech Coding Algorithm withDynamic Weighted Inter-frame Linear
   Prediction}},
Booktitle = {{ADVANCES IN APPLIED SCIENCE AND INDUSTRIAL TECHNOLOGY, PTS 1 AND 2}},
Series = {{Advanced Materials Research}},
Year = {{2013}},
Volume = {{798-799}},
Pages = {{769-772}},
Note = {{International Forum on Materials Science and Industrial Technology
   (IFMSIT 2013), Qingdao, PEOPLES R CHINA, AUG 30-SEP 01, 2013}},
Organization = {{Qingdao Univ; Qingdao Sci Culture Commun Co Ltd}},
Abstract = {{A new multi-frame joint quantization algorithm with dynamic weighted
   inter-frame linear prediction based on mixed excitation linear
   prediction(MELP) is proposed in this paper. Inencoding stage, a
   super-frame consists of three adjacent single-frames. Fourier magnitudes
   and aperiodic jitter flag are eliminated. The otherparameters are
   jointlyquantized. LSF of the first and third frame are quantized as a
   20-dimensional vector.According to the BPVsof super-frame,pitchis
   quantized with codebooks of dynamic size. In decoding stage, parameters
   are indexed from corresponding codebook. The LSFof middle frame are
   predicted from the first and third frame. The weighted factors keep
   changing in accordance with the BPVs of adjacent five frames.Results
   show thatthe reconstruction accuracy of LSFis significantly
   improvedusing dynamic weighted inter-frame linear prediction.
   Meanwhilethe coding bit rateis reduced to 0.6 kbps.}},
Publisher = {{TRANS TECH PUBLICATIONS LTD}},
Address = {{LAUBLSRUTISTR 24, CH-8717 STAFA-ZURICH, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Su, ZA (Corresponding Author), Beihang Univ, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
   Su, Zhaoan; Xiu, Chundi, Beihang Univ, Beijing 100191, Peoples R China.}},
DOI = {{10.4028/www.scientific.net/AMR.798-799.769}},
ISSN = {{1022-6680}},
ISBN = {{978-3-03785-841-7}},
Keywords = {{speech coding; multi-frame joint quantization; dynamic; weighted linear
   prediction; codebook size}},
Research-Areas = {{Materials Science}},
Web-of-Science-Categories  = {{Materials Science, Multidisciplinary}},
Author-Email = {{zhaoan\_su@163.com
   xcd@buaa.edu.cn}},
Cited-References = {{Li Q, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P1580, DOI 10.1109/CISP.2012.6469908.
   Xu M, ICSP 2010 9 INT C SI, P514.
   Zou Feng, 2006, INT C COMM TECH, P1.}},
Number-of-Cited-References = {{3}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BA8UC}},
Unique-ID = {{ISI:000338689600174}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000334921600352,
Author = {Chen, Fei and Guan, Tian},
Book-Group-Author = {{IEEE}},
Title = {{Non-intrusive Intelligibility Prediction for Mandarin Speech in Noise}},
Booktitle = {{2013 IEEE INTERNATIONAL CONFERENCE OF IEEE REGION 10 (TENCON)}},
Series = {{TENCON IEEE Region 10 Conference Proceedings}},
Year = {{2013}},
Note = {{IEEE International Conference of Region 10 (TENCON), Xian, PEOPLES R
   CHINA, OCT 22-25, 2013}},
Organization = {{IEEE Reg 10; IEEE Xian Sect; IEEE Hong Kong Sect; Natl Nat Sci Fdn
   China; NW Polytechn Univ; Xian Jiaotong Univ; Xidian Univ; Changan Univ;
   Innovat Grp Natl Nat Sci Fdn}},
Abstract = {{Most existing intelligibility indices require access to the input
   (clean) reference signal to predict speech intelligibility in noise. In
   some real-world applications, however, only the noise-masked speech is
   available, rendering existing indices of little use. The present study
   assessed the performance of an intelligibility measure that could be
   used to predict non-intrusively (i.e., with no access to the clean input
   signal) speech intelligibility in noise using only information extracted
   from the noise-masked speech envelopes. The proposed intelligibility
   measure (denoted as ModA) was computed by integrating the area of the
   modulation spectrum (within 0.5 Hz to 10 Hz) of the noise-masked
   envelopes extracted in four acoustic bands. The ModA measure was
   evaluated with intelligibility scores obtained by normal-hearing
   listeners presented with Mandarin sentences corrupted by three types of
   maskers. High correlation (r=0.90) was obtained between ModA values and
   listener's intelligibility scores, suggesting that the
   modulation-spectrum area could be potentially used as a simple but
   efficient predictor of speech intelligibility in noisy conditions.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Chen, F (Corresponding Author), Univ Hong Kong, Div Speech \& Hearing Sci, Hong Kong, Hong Kong, Peoples R China.
   Chen, Fei, Univ Hong Kong, Div Speech \& Hearing Sci, Hong Kong, Hong Kong, Peoples R China.
   Guan, Tian, Tsinghua Univ, Grad Sch Shenzhen, Shenzhen, Peoples R China.}},
ISSN = {{2159-3442}},
ISBN = {{978-1-4799-2825-5; 978-1-4799-2827-9}},
Keywords = {{Non-intrusive intelligibility index; intelligibility prediction}},
Keywords-Plus = {{QUALITY; INDEX}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
ResearcherID-Numbers = {{Chen, Fei/G-4674-2018
   Chen, Fei/AAK-6755-2020}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Funding-Acknowledgement = {{Faculty Research Fund, Faculty of Education, The University of Hong
   Kong; National Natural Science Foundation of ChinaNational Natural
   Science Foundation of China (NSFC) {[}31271056]}},
Funding-Text = {{This research was supported by Faculty Research Fund, Faculty of
   Education, The University of Hong Kong, by Seed Funding for Basic
   Research. This work was also supported Grant 31271056 from National
   Natural Science Foundation of China.}},
Cited-References = {{ANSI, 1997, S351997 ANSI.
   Chen F., 2012, BIOMED SIGNAL PROCES, V8, P311.
   Chen F, 2012, J MED BIOL ENG, V32, P189, DOI {[}10.5405/jmbe.885, 10.5405/jmbe.892].
   Chen F, 2011, J ACOUST SOC AM, V129, P3281, DOI 10.1121/1.3570957.
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836.
   Dubbelboer F, 2008, J ACOUST SOC AM, V124, P3937, DOI 10.1121/1.3001713.
   Elhilali M, 2003, SPEECH COMMUN, V41, P331, DOI 10.1016/S0167-6393(02)00134-6.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052.
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224.
   ITU-T P. 563, 2004, P563 ITUT.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kim DS, 2005, IEEE T SPEECH AUDI P, V13, P821, DOI 10.1109/TSA.2005.851924.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEIGER JH, 1980, PSYCHOL BULL, V87, P245, DOI 10.1037/0033-2909.87.2.245.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BA3VD}},
Unique-ID = {{ISI:000334921600352}},
DA = {{2020-12-06}},
}

@article{ ISI:000333679500002,
Author = {Angel Martin-Pascual, Miguel and Andreu-Sanchez, Celia},
Title = {{Memory-prediction framework theory and cognits in language's origin and
   cortical organization}},
Journal = {{ONOMAZEIN}},
Year = {{2013}},
Number = {{28}},
Pages = {{14-28}},
Abstract = {{Traditionally, language was regarded as an example of a cultural and a
   social phenomenon, as opposed to a natural or a biological one. This
   distinction of culturally acquired (nurture) against the naturally
   (nature) reflects, in fact, the previous gap between the two cultures of
   human and natural sciences that Snow tried to solve since 1951. Today it
   is considered that the language has a deep biological basis with
   well-established evidence in the scientific community. For the assertion
   that the power of language depends on the genes, it is needed a more
   comprehensive understanding of human cognition where language would be
   integrated with other neurogenetic cognitive processes and
   neurophysiological interaction between humanity and reality.}},
Publisher = {{PONTIFICIA UNIV CATOLICA CHILE, FAC LETRAS}},
Address = {{AV VICUNA MACKENNA 4860, SANTIAGO, 00000, CHILE}},
Type = {{Article}},
Language = {{Spanish}},
Affiliation = {{Martin-Pascual, MA (Corresponding Author), Univ Autonoma Barcelona, Grp Invest Neurocom Neurociencia \& Comunicac, Dept Comunicac Audiovisual \& Publicidad, Fac Ciencias Comunicac, E-08193 Barcelona, Spain.
   Angel Martin-Pascual, Miguel; Andreu-Sanchez, Celia, Univ Autonoma Barcelona, Grp Invest Neurocom Neurociencia \& Comunicac, Dept Comunicac Audiovisual \& Publicidad, Fac Ciencias Comunicac, E-08193 Barcelona, Spain.}},
DOI = {{10.7764/onomazein.28.8}},
ISSN = {{0717-1285}},
EISSN = {{0718-5758}},
Keywords = {{genetics of language; cognits; hierarchical temporal memory;
   memory-prediction framework theory}},
Research-Areas = {{Linguistics}},
Web-of-Science-Categories  = {{Linguistics; Language \& Linguistics}},
Author-Email = {{miguelangel.martin@uab.cat
   celia.andreu@uab.cat}},
ResearcherID-Numbers = {{Andreu-Sanchez, Celia/A-1454-2011
   Martin-Pascual, Miguel Angel/A-1451-2011}},
Cited-References = {{Bach-Y-Rita P, 2004, ANN NY ACAD SCI, V1013, P83, DOI 10.1196/annals.1305.006.
   Baker Mark C., 1996, POLYSYNTHESIS PARAME.
   BENITEZ-BURRACO Antonio, 2009, LUDUS VITALIS, VXVII.
   Buxhoeveden DP, 2002, BRAIN, V125, P935, DOI 10.1093/brain/awf110.
   CAVALLI-SFORZA Luigi, 1996, GENI POPOLI LINGUE.
   Changizi MA, 2006, AM NAT, V167, pE117, DOI 10.1086/502806.
   Chater N, 2009, P NATL ACAD SCI USA, V106, P1015, DOI 10.1073/pnas.0807191106.
   CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334.
   Dawkins R., 1989, SELFISH GENE.
   DILEEP G, 2008, THESIS STANFORD U.
   Edelman GM, 2006, 2 NATURE BRAIN SCI H.
   Feldman JA, 2005, ARTIF INTELL, V169, P181, DOI 10.1016/j.artint.2005.10.010.
   Fisher S.E., 1998, NATURE GENETICS, V18.
   Fisher SE, 2006, COGNITION, V101, P270, DOI 10.1016/j.cognition.2006.04.004.
   Fuster JM, 2003, CORTEX MIND UNIFYING.
   FUSTER Joaquin, 2006, LECT 8 12 IBM RES AL.
   George D, 2005, IEEE IJCNN, P1812.
   GOPNIK M, 1990, NATURE, V344, P715, DOI 10.1038/344715a0.
   GREENFIELD PM, 1991, BEHAV BRAIN SCI, V14, P531, DOI 10.1017/S0140525X00071235.
   HAGOORT Peter, 2005, TRENDS COGN SCI, V6, P78.
   Hawkins J., 2004, INTELLIGENCE.
   Hawkins J., 2011, HIERARCHICAL TEMPORA.
   Lai CSL, 2001, NATURE, V413, P519, DOI 10.1038/35097076.
   LONGA Victor Manuel, 2003, METODE.
   LORENZO Guillermo, 2009, LUDUS VITALIS, VXVII, P32.
   Milner D., 2006, VISUAL BRAIN ACTION.
   Mountcastle V., 1998, PERCEPTUAL NEUROSCIE.
   Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701.
   Mountcastle VB., 1978, MINDFUL BRAIN.
   MOUNTCASTLE Vernon Benjamin, 2003, CEREB CORTEX, V13, P1.
   NOE Alva, 2009, OUT OUR HEADS WHY AR.
   PINKER S, 1991, SCIENCE, V253, P530, DOI 10.1126/science.1857983.
   PINKER Steven, 2011, TELL TALE BRAIN.
   PINKER Steven, 2006, 3 CULTURE.
   Ramachandran V.S., 2000, 3 CULTURE.
   Ramachandran VS, 2006, SCI AM, V295, P62, DOI 10.1038/scientificamerican1106-62.
   RAMACHANDRAN VS, 1995, NATURE, V377, P489, DOI 10.1038/377489a0.
   RAMOS-ZUNIGA Rodrigo, 2011, MASTER INT PSICOBIOL.
   Richards R. J., 1987, DARWIN EMERGENCE EVO.
   Sacks O., 2010, MINDS EYE.
   SALAS Margarita, 2003, GENETICA LENGUAJE TE.
   SERRANO Sebastian, 2003, METODE.
   von Melchner L, 2000, NATURE, V404, P871, DOI 10.1038/35009102.
   Wilson EO, 1978, HUMAN NATURE.}},
Number-of-Cited-References = {{44}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Onomazein}},
Doc-Delivery-Number = {{AE0TQ}},
Unique-ID = {{ISI:000333679500002}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000329611507118,
Author = {Hermansky, Hynek and Variani, Ehsan and Peddinti, Vijayaditya},
Book-Group-Author = {{IEEE}},
Title = {{MEAN TEMPORAL DISTANCE: PREDICTING ASR ERROR FROM TEMPORAL PROPERTIES OF
   SPEECH SIGNAL}},
Booktitle = {{2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2013}},
Pages = {{7423-7426}},
Note = {{IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), Vancouver, CANADA, MAY 26-31, 2013}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Extending previous work on prediction of phoneme recognition error from
   unlabeled data that were corrupted by unpredictable factors, the current
   work investigates a simple but effective method of estimating ASR
   performance by computing a function M(Delta t), which represents the
   mean distance between speech feature vectors evaluated over certain
   finite time interval, determined as a function of temporal distance
   Delta t between the vectors. It is shown that M(Delta t) is a function
   of signal-to-noise ratio of speech signal. Comparing M(Delta t) curves,
   derived on data used for training of the classifier, and on test
   utterances, allows for predicting error on the test data. Another
   interesting observation is that M(Delta t) remains approximately
   constant, as temporal separation Delta t exceeds certain critical
   interval (about 200 ms), indicating the extent of coarticulation in
   speech sounds.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hermansky, H (Corresponding Author), Johns Hopkins Univ, Ctr Language \& Speech Proc, Baltimore, MD 21218 USA.
   Hermansky, Hynek; Variani, Ehsan; Peddinti, Vijayaditya, Johns Hopkins Univ, Ctr Language \& Speech Proc, Baltimore, MD 21218 USA.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-0356-6}},
Keywords = {{error-rate prediction on unknown data; phoneme classification; automatic
   recognition of speech}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{hynek@jhu.edu
   variani@jhu.edu
   vijay.p@jhu.edu}},
Cited-References = {{Badiezadegan S., 2011, P INTERSPEECH, P4780.
   Hermansky H., 1996, REPORT WS 1996.
   Mesgarani N., 2011, P INTERSPEECH, P2329.
   Mesgarani N, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P318.
   Scheffers MK, 2000, J EXP PSYCHOL HUMAN, V26, P141, DOI 10.1037/0096-1523.26.1.141.
   Smith JD, 2005, CURR DIR PSYCHOL SCI, V14, P19, DOI 10.1111/j.0963-7214.2005.00327.x.
   Varga A., 1992, NOISEX 92 STUDY EFFE.
   Variani E., 2012, P INTERSPEECH.
   Variani E., 2013, MULTISTREAM RECOGNIT.}},
Number-of-Cited-References = {{9}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJQ19}},
Unique-ID = {{ISI:000329611507118}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000329611507199,
Author = {Falk, Tiago H. and Cosentino, Stefano and Santos, Joao and Suelzle,
   David and Parsa, Vijay},
Book-Group-Author = {{IEEE}},
Title = {{NON-INTRUSIVE OBJECTIVE SPEECH QUALITY AND INTELLIGIBILITY PREDICTION
   FOR HEARING INSTRUMENTS IN COMPLEX LISTENING ENVIRONMENTS}},
Booktitle = {{2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2013}},
Pages = {{7820-7824}},
Note = {{IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), Vancouver, CANADA, MAY 26-31, 2013}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{A non-intrusive objective speech quality and intelligibility measure
   tailored to hearing restoration instruments is proposed and evaluated in
   complex listening environments. The measure builds upon the
   previously-proposed ``speech-to-reverberation modulation energy
   ratio{''} (SRMR) by incorporating hearing impairment percepts, such as
   hearing loss thresholds and altered modulation frequency selectivity.
   Performance is assessed using speech data corrupted by additive noise,
   reverberation, and noise-plus-reverberation which were subjectively
   rated by cochlear implant and hearing aid users. Experimental results
   show that the developed measures outperform the original SRMR metric for
   hearing impaired listeners and achieve performance levels inline with
   existing intrusive quality and intelligibility metrics, but with the
   advantage of not requiring access to a clean reference signal. As such,
   the measure may be used to develop quality-or intelligibility-aware
   speech enhancement algorithms for advanced hearing restoration
   instruments.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Falk, TH (Corresponding Author), Univ Quebec, INRS EMT, Montreal, PQ H3C 3P8, Canada.
   Falk, Tiago H.; Santos, Joao, Univ Quebec, INRS EMT, Montreal, PQ H3C 3P8, Canada.
   Cosentino, Stefano, UCL, Ear Inst, London WC1E 6BT, England.
   Suelzle, David; Parsa, Vijay, Univ Western Ontario, Dept Elect \& Comp Engn, London, ON N6A 3K7, Canada.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-0356-6}},
Keywords = {{Cochlear implant devices; hearing aids; quality measurement;
   intelligibility prediction; reverberation}},
Keywords-Plus = {{NOISE; MODEL}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
ORCID-Numbers = {{Santos, Joao Felipe/0000-0003-3934-3943
   Falk, Tiago/0000-0002-5739-2514}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of CanadaCGIAR; Ontario
   Research Fund}},
Funding-Text = {{The authors would like to thank the Natural Sciences and Engineering
   Research Council of Canada and the Ontario Research Fund for the
   financial support, Dr. Oldooz Hazrati for sharing the CI database and
   Prof. Philipos Loizou (in memoriam) for his expert advise during earlier
   stages of this work}},
Cited-References = {{Arai T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2490, DOI 10.1109/ICSLP.1996.607318.
   Beerends J., 2008, 124 AES CONV.
   Chen F, 2011, EAR HEARING, V32, P331, DOI 10.1097/AUD.0b013e3181ff3515.
   Cosentino S., 2012, INT C INF SCI SIGN P, P4710.
   Ewert SD, 2000, J ACOUST SOC AM, V108, P1181, DOI 10.1121/1.1288665.
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247.
   Falk TH, 2010, IEEE T INSTRUM MEAS, V59, P978, DOI 10.1109/TIM.2009.2024697.
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T.
   Hazrati O., 2012, INT J AUDIOL.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   Kates JM, 2010, J AUDIO ENG SOC, V58, P363.
   Kates JM, 2005, IEEE WORK APPL SIG, P53, DOI 10.1109/ASPAA.2005.1540166.
   Keymanesh A., 2012, INT J AUDIOLOGY.
   Kokkinakis K, 2011, J ACOUST SOC AM, V129, P3221, DOI 10.1121/1.3559683.
   Kressner AA, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P209, DOI 10.1109/ASPAA.2011.6082343.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   MERKS I, 2006, HEAR REV, V13, P53.
   Moller S, 2011, IEEE SIGNAL PROC MAG, V28, P18, DOI 10.1109/MSP.2011.942469.
   Parsa V., 2001, 111 AES CONV.
   PAVLOVIC CV, 1986, J ACOUST SOC AM, V80, P50, DOI 10.1121/1.394082.
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009.
   Rohdenburg T., 2008, ITG C VOIC COMM, P1.
   Santos J., 2012, INTERSPEECH.
   Yang LP, 2005, J ACOUST SOC AM, V117, P1001, DOI 10.1121/1.1852873.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BJQ19}},
Unique-ID = {{ISI:000329611507199}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000329611508070,
Author = {Jensen, Tobias Lindstrom and Giacobello, Daniele and Christensen, Mads
   Graesboll and Jensen, Soren Holdt and Moonen, Marc},
Book-Group-Author = {{IEEE}},
Title = {{REAL-TIME IMPLEMENTATIONS OF SPARSE LINEAR PREDICTION FOR SPEECH
   PROCESSING}},
Booktitle = {{2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Series = {{International Conference on Acoustics Speech and Signal Processing
   ICASSP}},
Year = {{2013}},
Pages = {{8184-8188}},
Note = {{IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP), Vancouver, CANADA, MAY 26-31, 2013}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Employing sparsity criteria in linear prediction of speech has been
   proven successful for several analysis and coding purposes. However,
   sparse linear prediction comes at the expenses of a much higher
   computational burden and numerical sensitivity compared to the
   traditional minimum variance approach. This makes sparse linear
   prediction difficult to deploy in real-time systems. In this paper, we
   present a step towards real-time implementation of the sparse linear
   prediction problem using hand-tailored interior-point methods. Using
   compiled implementations the sparse linear prediction problems
   corresponding to a frame size of 20 ms can be solved on a standard PC in
   approximately 2 ms and orders faster than with general purpose software.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Jensen, TL (Corresponding Author), Aalborg Univ, Dept Elect Syst, Aalborg, Denmark.
   Jensen, Tobias Lindstrom; Jensen, Soren Holdt, Aalborg Univ, Dept Elect Syst, Aalborg, Denmark.}},
ISSN = {{1520-6149}},
ISBN = {{978-1-4799-0356-6}},
Keywords = {{Sparse linear prediction; convex optimization; real-time implementation;
   speech analysis}},
Keywords-Plus = {{OPTIMIZATION}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{tlj@es.aau.dk
   giacobello@broadcom.com
   mgc@create.aau.dk
   shj@es.aau.dk
   marc.moonen@esat.kuleuven.be}},
ResearcherID-Numbers = {{Giacobello, Daniele/AAI-3724-2020
   Christensen, Mads G/I-4132-2018
   Jensen, Tobias Lindstrom/L-3096-2015
   Giacobello, Daniele/J-7962-2013}},
ORCID-Numbers = {{Giacobello, Daniele/0000-0001-8708-8604
   Christensen, Mads G/0000-0003-3586-7969
   Jensen, Tobias Lindstrom/0000-0003-4262-0577
   Giacobello, Daniele/0000-0001-8708-8604}},
Funding-Acknowledgement = {{The Danish Council for Strategic ResearchDanske Strategiske
   Forskningsrad (DSF) {[}09-067056]}},
Funding-Text = {{The work of T. L. Jensen is supported by The Danish Council for
   Strategic Research under grant number 09-067056.}},
Cited-References = {{Alipoor G, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P454, DOI 10.1109/TSP.2012.6256335.
   Andersen ED, 2003, MATH PROGRAM, V95, P249, DOI 10.1007/s10107-002-0349-3.
   Boyd S., 2004, CONVEX OPTIMIZATION.
   Defraene B, 2012, IEEE T AUDIO SPEECH, V20, P2657, DOI 10.1109/TASL.2012.2210875.
   DENOEL E, 1985, IEEE T ACOUST SPEECH, V33, P1397, DOI 10.1109/TASSP.1985.1164759.
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100.
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969.
   Giacobello Daniele, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2524.
   Giacobello D, 2012, IEEE T AUDIO SPEECH, V20, P1644, DOI 10.1109/TASL.2012.2186807.
   Grant M, 2011, CVX MATLAB SOFTWARE.
   Hansen J. H. L., 1987, DISCRETE TIME PROCES, DOI Englewood Cliffs, NJ, USA.
   Itakura F., 1968, P 6 INT C AC, pC17.
   KNOCKAERT L, 1992, IEEE T INFORM THEORY, V38, P1483, DOI 10.1109/18.149499.
   Larsen T., 2011, JACKET GPU POWERED M.
   LEE CH, 1988, IEEE T ACOUST SPEECH, V36, P642, DOI 10.1109/29.1574.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Mattingley J, 2012, OPTIM ENG, V13, P1, DOI 10.1007/s11081-011-9176-9.
   Mattingley J, 2010, IEEE SIGNAL PROC MAG, V27, P50, DOI 10.1109/MSP.2010.936020.
   Murthi MN, 1998, INT CONF ACOUST SPEE, P369, DOI 10.1109/ICASSP.1998.674444.
   Nesterov Y., 1994, INTERIOR POINT POLYN.
   Nocedal J., 1999, NUMERICAL OPTIMIZATI.
   RABINER LR, 1972, IEEE T ACOUST SPEECH, VAU20, P280, DOI 10.1109/TAU.1972.1162395.
   Stoica P., 2005, SPECTRAL ANAL SIGNAL.
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766.
   Vandenberghe L, 2010, CVXOPT LINEAR QUADRA.
   Wright S.J., 1997, PRIMAL DUAL INTERIOR.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BJQ19}},
Unique-ID = {{ISI:000329611508070}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000326679200162,
Author = {Irshad, Azeem and Salman, Muhammad},
Book-Group-Author = {{IEEE}},
Title = {{State-space approach to linear predictive coding of speech - A
   comparative assessment}},
Booktitle = {{PROCEEDINGS OF THE 2013 IEEE 8TH CONFERENCE ON INDUSTRIAL ELECTRONICS
   AND APPLICATIONS (ICIEA)}},
Series = {{IEEE Conference on Industrial Electronics and Applications}},
Year = {{2013}},
Pages = {{886-890}},
Note = {{8th IEEE Conference on Industrial Electronics and Applications (ICIEA),
   Swinburne Univ Technol, Melbourne, AUSTRALIA, JUN 19-21, 2013}},
Organization = {{IEEE; IEEE Ind Elect Chapter Singapore Sect; IEEE Ind Elect Soc; IEEE
   Ind Elect Chapter; IEEE Victorian Sect}},
Abstract = {{Speech coders are fundamental component in telecommunication and
   multimedia infrastructure. Several systems like, mobile telephony, voice
   over internet protocol (VOIP), audio conferencing etc., rely on
   efficient speech coding. Speech coders strive to provide low-bit rate
   maintaining the same speech quality and intelligibility. Linear
   predictive coding uses spectral properties of the speech to
   ``optimize{''} the coder's performance for human ear. In this paper we
   perform a comparative assessment of speech coding performance of some
   state-space filters to give designers an insight into capabilities of
   these filters. The filters considered are Kalman filter, state-space
   recursive least-squares (SSRLS) and SSRLS with adaptive memory
   (SS-RLSWAM). The results of RLS and LMS are also quoted. The performance
   is judged in terms of perceptual evaluation of speech quality (PESQ) and
   prediction gain.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Irshad, A (Corresponding Author), Natl Univ Sci \& Technol, Coll Elect \& Mech Engn, Islamabad, Pakistan.
   Irshad, Azeem; Salman, Muhammad, Natl Univ Sci \& Technol, Coll Elect \& Mech Engn, Islamabad, Pakistan.}},
ISSN = {{2156-2318}},
ISBN = {{978-1-4673-6322-8; 978-1-4673-6320-4}},
Keywords = {{Speech coding; Kalman Filter; SSRLS; SSRL-SWAM; linear predictive coding}},
Keywords-Plus = {{RECURSIVE LEAST-SQUARES}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{azeemirshad84@yahoo.com
   salmanmasaud@ceme.nust.edu.pk}},
ResearcherID-Numbers = {{Salman, Muhammad/AAZ-1636-2020
   }},
ORCID-Numbers = {{Salman, Muhammad/0000-0003-2699-6400
   Irshad, Azeem/0000-0002-8356-2257}},
Cited-References = {{Adoul J., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1957.
   Atal B. S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P614.
   Atal B. S., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P1681.
   ATAL BS, 1982, IEEE T COMMUN, V30, P600, DOI 10.1109/TCOM.1982.1095501.
   Bar-Shalom Y, 2002, ESTIMATION APPL TRAC.
   Chu W., 2004, COMMUNICATIONS TECHN.
   Hasegawa-Johnson M., 2003, SPEECH CODING FUNDAM, DOI DOI 10.1002/0471219282.E0T156.
   Haykin S., 2002, ADAPTIVE FILTER THEO.
   Hu Y., 2006, ICASSP 2006 P, V1.
   ITU-T, 2001, P862 ITUT.
   ITU-T Rec P. 862.2, 2005, P8622 ITUT.
   Kalman R.E., 1960, J BASIC ENG, V82, P35, DOI {[}10.1115/1.3662552, DOI 10.1115/1.3662552].
   Kleijn W. B., 1991, IEEE Global Telecommunications Conference. GLOBECOM `91. Countdown to the New Millennium. Featuring a Mini-Theme on: Personal Communications Services (PCS). Conference Record (Cat. No.91CH2980-1), P1879, DOI 10.1109/GLOCOM.1991.188688.
   KLEIJN WB, 1995, INT CONF ACOUST SPEE, P508, DOI 10.1109/ICASSP.1995.479640.
   Kondoz A. M., 2004, DIGITAL SPEECH CODIN.
   Malik MB, 2006, SIGNAL PROCESS, V86, P1365, DOI 10.1016/j.sigpro.2005.02.024.
   Malik MB, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P305.
   Malik MB, 2004, SIGNAL PROCESS, V84, P1709, DOI 10.1016/j.sigpro.2004.05.022.
   Malik MB, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P645.
   Oppenheim A. V., 2009, DISCRETE TIME SIGNAL.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BHU17}},
Unique-ID = {{ISI:000326679200162}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000395050000080,
Author = {Hinterleitner, Florian and Norrenbrock, Christoph R. and Moeller,
   Sebastian and Heute, Ulrich},
Editor = {{Bimbot, F and Cerisara, C and Fougeron, C and Gravier, G and Lamel, L and Pellegrino, F and Perrier, P}},
Title = {{Predicting the Quality of Text-To-Speech Systems from a Large-Scale
   Feature Set}},
Booktitle = {{14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5}},
Series = {{Interspeech}},
Year = {{2013}},
Pages = {{383-387}},
Note = {{14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013), Lyon,
   FRANCE, AUG 25-29, 2013}},
Organization = {{Int Speech Commun Assoc; europa org; amazon; Microsoft; Google; TcL
   SYTRAL; European Language Resources Assoc; ouaero; imaginove; VOCAPIA
   res; acapela; speech ocean; ALDEBARAN; orange; vecsys; IBM Res; Raytheon
   BBN Technol; voxygen}},
Abstract = {{We extract 1495 speech features from 2 subjectively evaluated
   text-to-speech (TTS) databases. These features are extracted from pitch,
   loudness, MFCCs, spectrals, formants, and intensity. The speech material
   is synthesized using up to 15 different TTS systems, some of them with
   up to 8 different voices. We develop quality predictors for TTS signals
   following two different approaches to handle the huge set of speech
   features: a three-step feature selection followed by a stepwise multiple
   linear regression and an approach based on support vector machines. The
   predictors are cross-validated via 3-fold cross validation (CV) and
   leave-one-test-out (LOTO) CV. Due to the high number of features we
   apply a strict CV method where the partitioning is realized prior to the
   feature scaling and feature selection steps. In comparison we also
   follow a semi-strict approach where the partitioning effectively takes
   place after these steps. In the 3-fold CV case we achieve correlations
   as high as .75 for strict CV and .89 for semi-strict CV. The more
   ambitious LOTO CV yields correlations around .80 for the male speakers
   whereas the results for the female voices show the need for improvement.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hinterleitner, F (Corresponding Author), TU Berlin, Qual \& Usabil Lab, Berlin, Germany.
   Hinterleitner, Florian; Moeller, Sebastian, TU Berlin, Qual \& Usabil Lab, Berlin, Germany.
   Norrenbrock, Christoph R.; Heute, Ulrich, CAU Kiel, Digital Signal Proc \& Syst Theory, Kiel, Germany.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-62993-443-3}},
Keywords = {{quality prediction; text-to-speech (TTS); cross-validation}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{florian.hinterleitner@tu-berlin.de
   cno@tf.uni-kiel.de
   sebastian.moeller@telekom.de
   uh@tf.uni-kiel.de}},
Funding-Acknowledgement = {{Deutsche Forschungsgemeinschaft (DFG)German Research Foundation (DFG)
   {[}MO 1038/11-1, HE 4465/4-1]}},
Funding-Text = {{The present study was supported by the Deutsche Forschungsgemeinschaft
   (DFG), grants MO 1038/11-1 and HE 4465/4-1.}},
Cited-References = {{{[}Anonymous], 1994, METH SUBJ PERF ASS Q.
   Bins J., 2001, P 8 IEEE INT C COMP.
   Chan D., 1995, P 4 EUR C SPEECH COM, V1, P867.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Falk TH, 2008, IEEE SIGNAL PROC LET, V15, P781, DOI 10.1109/LSP.2008.2006709.
   Hastie T., 2009, ELEMENTS STAT LEARNI.
   Hinterleitner F., 2012, P 23 K EL SPRACHS ES.
   Hinterleitner F., 2011, P 12 ANN C INT SPEEC, P2177.
   Hinterleitner F, 2012, IEEE W SP LANG TECH, P240, DOI 10.1109/SLT.2012.6424229.
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129.
   Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621.
   Macqueen JB, 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1007/S11665-016-2173-6.
   Minker W., 2010, SPOKEN DIALOGUE SYST.
   Moller S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1325.
   Norrenbrock C., 2012, P BLIZZ CHALL WORKSH.
   Norrenbrock C. R., 2012, P 13 ANN C INT SPEEC.
   Norrenbrock CR, 2012, IEEE SIGNAL PROC LET, V19, P255, DOI 10.1109/LSP.2012.2189562.
   Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BH0HX}},
Unique-ID = {{ISI:000395050000080}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000395050000248,
Author = {Jensen, Jesper and Taal, Cees H.},
Editor = {{Bimbot, F and Cerisara, C and Fougeron, C and Gravier, G and Lamel, L and Pellegrino, F and Perrier, P}},
Title = {{Prediction of Intelligibility of Noisy and Time-Frequency Weighted
   Speech based on Mutual Information Between Amplitude Envelopes}},
Booktitle = {{14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5}},
Series = {{Interspeech}},
Year = {{2013}},
Pages = {{1173-1177}},
Note = {{14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013), Lyon,
   FRANCE, AUG 25-29, 2013}},
Organization = {{Int Speech Commun Assoc; europa org; amazon; Microsoft; Google; TcL
   SYTRAL; European Language Resources Assoc; ouaero; imaginove; VOCAPIA
   res; acapela; speech ocean; ALDEBARAN; orange; vecsys; IBM Res; Raytheon
   BBN Technol; voxygen}},
Abstract = {{This paper deals with the problem of predicting the average
   intelligibility of noisy and potentially processed speech signals, as
   observed by a group of normal hearing listeners. We propose a prediction
   model based on the hypothesis that intelligibility is monotonically
   related to the the amount of Shannon information the critical-band
   amplitude envelopes of the noisy/processed signal convey about the
   corresponding clean signal envelopes. The resulting intelligibility
   predictor turns out to be a simple function of the correlation between
   noisy/processed and clean amplitude envelopes. The proposed predictor
   performs well (p > 0.95) in predicting the intelligibility of speech
   signals contaminated by additive noise and potentially non-linearly
   processed using time-frequency weighting.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Jensen, J (Corresponding Author), Oticon AS, Smorum, Denmark.
   Jensen, Jesper, Oticon AS, Smorum, Denmark.
   Jensen, Jesper, Aalborg Univ, Aalborg, Denmark.
   Taal, Cees H., Leiden Univ, Med Ctr, Leiden, Netherlands.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-62993-443-3}},
Keywords = {{Intelligibility prediction; Mutual information; Auditory model;
   Time-frequency weighting; Single -channel noise reduction}},
Keywords-Plus = {{OBJECTIVE MEASURES; INDEX; SENTENCES}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{jsj@oticon.dk
   c.h.taal@lumc.nl}},
Cited-References = {{{*}AM NAT STAND I, 1969, S35 ANSI.
   American National Standards Institute N. Y, 1995, S35 ANSI.
   {[}Anonymous], 2003, IEC6026816.
   BIALEK W, 1993, PHYSICA A, V200, P581, DOI 10.1016/0378-4371(93)90563-J.
   Boldt J.B., 2009, P EUSIPCO, P1849.
   Brillinger DR, 2001, TIME SERIES DATA ANA.
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929.
   COVER T, 1991, WILEY SERIES COMMUNI.
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   HOHMANN V, 1995, J ACOUST SOC AM, V97, P1191, DOI 10.1121/1.413092.
   HOUTGAST T, 1971, ACUSTICA, V25, P355.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673.
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1689, DOI 10.1121/1.1909094.
   LUDVIGSEN C, 1993, SCAND AUDIOL, V22, P50.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915.
   Martin R., 2001, P INT WORKSH AC ECH, P167.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal C. H., 2010, P INT WORKSH AC ECH.
   Taal C. H., 2009, P INTERSPEECH, P1947.
   Taal CH, 2011, J ACOUST SOC AM, V130, P3013, DOI 10.1121/1.3641373.
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881.
   Taghia J, 2012, INT CONF ACOUST SPEE, P65, DOI 10.1109/ICASSP.2012.6287818.
   Therrien C. W., 1992, DISCRETE RANDOM SIGN.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH0HX}},
Unique-ID = {{ISI:000395050000248}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000395050000250,
Author = {Li, Junfeng and Chen, Fei and Akagi, Masato and Yan, Yonghong},
Editor = {{Bimbot, F and Cerisara, C and Fougeron, C and Gravier, G and Lamel, L and Pellegrino, F and Perrier, P}},
Title = {{Comparative investigation of objective speech intelligibility prediction
   measures for noise-reduced signals in Mandarin and Japanese}},
Booktitle = {{14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5}},
Series = {{Interspeech}},
Year = {{2013}},
Pages = {{1183-1186}},
Note = {{14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013), Lyon,
   FRANCE, AUG 25-29, 2013}},
Organization = {{Int Speech Commun Assoc; europa org; amazon; Microsoft; Google; TcL
   SYTRAL; European Language Resources Assoc; ouaero; imaginove; VOCAPIA
   res; acapela; speech ocean; ALDEBARAN; orange; vecsys; IBM Res; Raytheon
   BBN Technol; voxygen}},
Abstract = {{In this paper, eight state-of-the-art objective speech intelligibility
   prediction measures are comparatively investigated for noisy signals
   before and after noise-reduction processing between Mandarin and
   Japanese. Clean speech signals (Chinese words and Japanese words) were
   first corrupted by three types of noise at two signal-to-noise ratios
   and then processed by normal-hearing listeners for recognition, whose
   intelligibility was subsequently predicted by objective measures.
   Further investigations were conducted for objective measures in
   predicting speech intelligibility of noise-reduced signals between
   subjective evaluation scores and objective prediction results, and of
   noisy signals before and after noise-reduction processing, in terms of
   correlation analysis and prediction errors. Results showed that the
   majority of objective measures behave differently for Mandarin and
   Japanese in predicting the subjective ratings, and the STOI measure
   consistently provided the best ability in predicting the effect on
   speech intelligibility of the noise-reduction processing for both
   Mandarin and Japanese.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Li, JF (Corresponding Author), Chinese Acad Sci, Inst Acoust, Beijing, Peoples R China.
   Li, Junfeng; Yan, Yonghong, Chinese Acad Sci, Inst Acoust, Beijing, Peoples R China.
   Chen, Fei, Univ Hong Kong, Div Speech \& Hearing Sci, Hong Kong, Hong Kong, Peoples R China.
   Akagi, Masato, Japan Adv Inst Sci \& Technol, Sch Informat Sci, Nomi, Japan.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-62993-443-3}},
Keywords = {{Speech intelligibility; objective intelligibility prediction; noise
   reduction}},
Keywords-Plus = {{INDEX}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
ResearcherID-Numbers = {{Chen, Fei/AAK-6755-2020
   Chen, Fei/G-4674-2018
   Akagi, Masato/ABD-4043-2020}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X
   }},
Funding-Acknowledgement = {{National 973 ProgramNational Basic Research Program of China
   {[}2013CB329302]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}10925419, 90920302,
   61072124, 11074275, 11161140319, 91120001]; Strategic Priority Research
   Program of the Chinese Academy of SciencesChinese Academy of Sciences
   {[}XDA06030100, XDA06030500]; National 863 ProgramNational High
   Technology Research and Development Program of China {[}2012AA012503]}},
Funding-Text = {{This work is partially supported by the National 973 Program
   (2013CB329302), the National Natural Science Foundation of China (Nos.
   10925419, 90920302, 61072124, 11074275, 11161140319, 91120001), the
   Strategic Priority Research Program of the Chinese Academy of Sciences
   (Grant Nos. XDA06030100, XDA06030500) and the National 863 Program (No.
   2012AA012503).}},
Cited-References = {{Amano S, 2009, SPEECH COMMUN, V51, P76, DOI 10.1016/j.specom.2008.07.002.
   ANSI, 1997, S351997 ANSI.
   Boldt J.B., 2009, P EUSIPCO, P1849.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1698, DOI 10.1121/1.1909096.
   Li JF, 2011, J ACOUST SOC AM, V129, P3291, DOI 10.1121/1.3571422.
   Liu WM, 2006, INT CONF ACOUST SPEE, P1225.
   Ma D., 2004, ACOUSTIC MANUAL.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Taal C., 2011, IEEE T AUDIO SPEECH, P2125.
   Trask R., 1998, KEY CONCEPTS LANGUAG, P15.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH0HX}},
Unique-ID = {{ISI:000395050000250}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000395050000353,
Author = {Patil, Hemant A. and Patel, Tanvina B.},
Editor = {{Bimbot, F and Cerisara, C and Fougeron, C and Gravier, G and Lamel, L and Pellegrino, F and Perrier, P}},
Title = {{Nonlinear Prediction of Speech Signal using Volterra-Wiener Series}},
Booktitle = {{14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5}},
Series = {{Interspeech}},
Year = {{2013}},
Pages = {{1686-1690}},
Note = {{14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013), Lyon,
   FRANCE, AUG 25-29, 2013}},
Organization = {{Int Speech Commun Assoc; europa org; amazon; Microsoft; Google; TcL
   SYTRAL; European Language Resources Assoc; ouaero; imaginove; VOCAPIA
   res; acapela; speech ocean; ALDEBARAN; orange; vecsys; IBM Res; Raytheon
   BBN Technol; voxygen}},
Abstract = {{Linear Prediction (LP) analysis has.proven to be very effective and
   successful in speech analysis and speech synthesis applications. This
   may be due to the fact that LP analysis captures implicitly the
   time-varying vocal tract area function. However, it captures only the
   second-order statistical relationships and only the linear dependencies
   in the sequence of samples of speech signals (and not the higher-order
   relations), as a result of which the LP residual is also intelligible.
   This paper studies the effectiveness of nonlinear prediction (NLP) of
   the speech signal by using the state-of-the-art Volterra-Wiener series
   and uses a novel chaotic titration method to analyze the chaotic
   characteristics of the residual obtained by both the LP and NLP methods.
   The experimental results demonstrate that the proposed NLP approach
   gives less prediction error, relatively flat residual spectrum, less
   PESQ score (i.e., objective evaluation of MOS to a certain extent) and
   less chaoticity than its LP counterpart. Finally, the L-I norm and L-2
   norm of NLP residual was found be relatively less than LP residual for
   five instances of voiced and unvoiced regions extracted from speakers of
   TIMIT database.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Patil, HA (Corresponding Author), DA IICT, Gandhinagar 382007, India.
   Patil, Hemant A.; Patel, Tanvina B., DA IICT, Gandhinagar 382007, India.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-62993-443-3}},
Keywords = {{Linear prediction; nonlinear prediction; residual; Volterra-Wiener
   series; chaotic titration; noise limit}},
Keywords-Plus = {{NETWORKS; MODEL}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{hemant\_patil@daiict.ac.in
   tanvina\_bhupendrabhai\_patel@daiict.ac.in}},
Cited-References = {{AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705.
   Ananthapadmanaba T, 1982, SPEECH COMMUN, V1, P167.
   ANANTHAPADMANABHA TV, 1979, IEEE T ACOUST SPEECH, V27, P309, DOI 10.1109/TASSP.1979.1163267.
   Barahona M, 1996, NATURE, V381, P215, DOI 10.1038/381215a0.
   Don RH, 1990, NONLINEAR DIGITAL FI.
   Frechet M, 1910, ANN SCI ECOLE NORM S, V27</IT, P193.
   Garafolo J. S., 1988, GETTING STARTED DARP.
   HAKIM NZ, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS \& COMPUTERS, VOLS 1 AND 2, P1128, DOI 10.1109/ACSSC.1991.186623.
   KORENBERG MJ, 1988, ANN BIOMED ENG, V16, P123, DOI 10.1007/BF02367385.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Marmarelis VZ, 1997, IEEE T NEURAL NETWOR, V8, P1421, DOI 10.1109/72.641465.
   MARTIN S, 1980, VOLTERRA WIENER THEO.
   Mathews V., 2000, POLYNOMIAL SIGNAL PR.
   Patil A. H., 2012, INT C SIGN PROC COMM, P1, DOI 10.1109/SPCOM.2012.6289991.
   Patil H.A., 2010, P 6 INT S COD GEN OP, P1.
   Pinto J, 2009, INT CONF ACOUST SPEE, P1813, DOI 10.1109/ICASSP.2009.4959958.
   Poon CS, 2001, P NATL ACAD SCI USA, V98, P7107, DOI 10.1073/pnas.131173198.
   Quatieri T. F., 2002, DISCRETE TIME SPEECH.
   Rabiner L., 2010, FUNDAMENTALS SPEECH.
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023.
   Rousset J, 1998, P INT JOINT C NEUR N, P128.
   Savoji MH, 2006, P 11 INT C SPEECH CO, P367.
   SCHROEDER MR, 1985, P IEEE ICASSP TAMP F, V10, P937.
   Stegmayer G, 2004, IEEE IJCNN, P2907.
   TAO C, 2004, ACOUST SCI TECH, V25, P50.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.
   Yegnanarayana B, 2000, IEEE T SPEECH AUDI P, V8, P267, DOI 10.1109/89.841209.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH0HX}},
Unique-ID = {{ISI:000395050000353}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000395050000407,
Author = {Pohjalainen, Jouni and Alku, Paavo},
Editor = {{Bimbot, F and Cerisara, C and Fougeron, C and Gravier, G and Lamel, L and Pellegrino, F and Perrier, P}},
Title = {{Extended Weighted Linear Prediction Using the Autocorrelation Snapshot -
   A Robust Speech Analysis Method and its Application to Recognition of
   Vocal}},
Booktitle = {{14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5}},
Series = {{Interspeech}},
Year = {{2013}},
Pages = {{1930-1934}},
Note = {{14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013), Lyon,
   FRANCE, AUG 25-29, 2013}},
Organization = {{Int Speech Commun Assoc; europa org; amazon; Microsoft; Google; TcL
   SYTRAL; European Language Resources Assoc; ouaero; imaginove; VOCAPIA
   res; acapela; speech ocean; ALDEBARAN; orange; vecsys; IBM Res; Raytheon
   BBN Technol; voxygen}},
Abstract = {{Temporally weighted linear predictive methods have recently been
   successfully used for robust feature extraction in speech and speaker
   recognition. This paper introduces their general formulation, where
   various efficient temporal weighting functions can be included in the
   optimization of the all-pole coefficients of a linear predictive model.
   Temporal weighting is imposed by multiplying elements of instantaneous
   autocorrelation ``snapshot{''} matrices computed from speech data. With
   this novel autocorrelation-snapshot formulation of weighted linear
   prediction, it is demonstrated that different temporal aspects of speech
   can be emphasized in order to enhance robustness of feature extraction
   in speech emotion recognition.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Pohjalainen, J (Corresponding Author), Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.
   Pohjalainen, Jouni; Alku, Paavo, Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-62993-443-3}},
Keywords = {{linear prediction; spectrum analysis; speech emotion recognition}},
Keywords-Plus = {{FEATURES}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{jouni.pohjalainen@aalto.fi
   paavo.alku@aalto.fi}},
ResearcherID-Numbers = {{Alku, Paavo/E-2400-2012
   }},
ORCID-Numbers = {{Alku, Paavo/0000-0002-8173-9418}},
Funding-Acknowledgement = {{Academy of FinlandAcademy of Finland {[}256961]; EC FP7 project
   Simple4All {[}287678]}},
Funding-Text = {{This work was supported by Academy of Finland (256961) and the EC FP7
   project Simple4All (287678).}},
Cited-References = {{Alku P., 2012, P INTERSPEECH.
   BURKHARDT F, 2005, P INTERSPEECH.
   Chi TS, 2012, J AMB INTEL HUM COMP, V3, P47, DOI 10.1007/s12652-011-0088-5.
   de Wet F., 2000, P ICASSP.
   Huang X, 2001, SPOKEN LANGUAGE PROC.
   Katsavounidis I, 1994, IEEE SIGNAL PROC LET, V1, P144, DOI 10.1109/97.329844.
   Keronen S., 2011, P INTERSPEECH.
   MA CX, 1993, SPEECH COMMUN, V12, P69, DOI 10.1016/0167-6393(93)90019-H.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Pohjalainen J., 2010, P INTERSPEECH.
   Pohjalainen J., 2009, P INTERSPEECH.
   Pylkkonen J., 2012, P INTERSPEECH.
   Rabiner L. R., 1978, DIGITAL PROCESSING S.
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649.
   Schuller B., 2008, P INTERSPEECH.
   TAWARI A, 2010, P INT C PATT REC IST.
   Theodoridis S., 2003, PATTERN RECOGNITION.
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013.
   Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH0HX}},
Unique-ID = {{ISI:000395050000407}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000395050001227,
Author = {Moeller, Sebastian and Kelaidi, Emilia and Koester, Friedemann and Cote,
   Nicolas and Bauer, Patrick and Fingscheidt, Tim and Schlien, Thomas and
   Pulakka, Hannu and Alku, Paavo},
Editor = {{Bimbot, F and Cerisara, C and Fougeron, C and Gravier, G and Lamel, L and Pellegrino, F and Perrier, P}},
Title = {{Speech Quality Prediction for Artificial Bandwidth Extension Algorithms}},
Booktitle = {{14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5}},
Series = {{Interspeech}},
Year = {{2013}},
Pages = {{3406-3410}},
Note = {{14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013), Lyon,
   FRANCE, AUG 25-29, 2013}},
Organization = {{Int Speech Commun Assoc; europa org; amazon; Microsoft; Google; TcL
   SYTRAL; European Language Resources Assoc; ouaero; imaginove; VOCAPIA
   res; acapela; speech ocean; ALDEBARAN; orange; vecsys; IBM Res; Raytheon
   BBN Technol; voxygen}},
Abstract = {{During the transition period from narrowband to wideband speech
   transmission services, Artificial Bandwidth Extension (ABE) algorithms
   are able to reduce the perceptual degradation of narrowband-transmitted
   speech signals by extending the audio bandwidth. In this paper, we
   analyze whether the resulting speech quality can be predicted reliably
   with instrumental models. Estimations from the new ITU standard POLQA,
   its predecessor WB-PESQ and the diagnostic DIAL model are compared to
   subjective listener judgments. This comparison reveals that the
   instrumental measures are not fully able to cope with ABE-processed
   speech, particularly in predicting ABE rank orders reliably. Reasons for
   this finding and corresponding diagnoses are discussed.}},
Publisher = {{ISCA-INT SPEECH COMMUNICATION ASSOC}},
Address = {{C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Moller, S (Corresponding Author), TU Berlin, Telekom Innovat Labs, Qual \& Usabil Lab, Berlin, Germany.
   Moeller, Sebastian; Kelaidi, Emilia; Koester, Friedemann, TU Berlin, Telekom Innovat Labs, Qual \& Usabil Lab, Berlin, Germany.
   Cote, Nicolas, Inst Elect Microelect \& Nanotechnol, ISEN Dept, Lille, France.
   Bauer, Patrick; Fingscheidt, Tim, Tech Univ Carolo Wilhelmina Braunschweig, Inst Commun Technol, Braunschweig, Germany.
   Schlien, Thomas, Rhein Westfal TH Aachen, Inst Nachrichtengerate \& Datenverarbeitung, Aachen, Germany.
   Pulakka, Hannu; Alku, Paavo, Aalto Univ, Dept Signal Proc \& Acoust, Espoo, Finland.
   Pulakka, Hannu, Nokia Smart Devices, Espoo, Finland.}},
ISSN = {{2308-457X}},
ISBN = {{978-1-62993-443-3}},
Keywords = {{speech quality; artificial bandwidth extension; instrumental quality
   prediction; speech transmission; diagnosis}},
Keywords-Plus = {{BAND}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{sebastian.moeller@telekom.de
   kelaidi.aimilia.23@gmail.com
   friedemann.koester@telekom.de
   nicolas.cote@isen.fr
   patrick.bauer@tu-bs.de
   t.fingscheidt@tu-bs.de
   schlien@ind.rwth-aachen.de
   hannu.pulakka@aalto.fi
   paavo.alku@aalto.fi}},
ResearcherID-Numbers = {{Alku, Paavo/E-2400-2012
   }},
ORCID-Numbers = {{Alku, Paavo/0000-0002-8173-9418}},
Cited-References = {{Bauer P., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1839.
   Bauer Patrick, 2012, ITG-Fachbericht, P275.
   Bauer P., 2010, P IEEE INT S CONS EL.
   Cote N, 2011, T-LAB SER TELECOMMUN, P1, DOI 10.1007/978-3-642-18463-5.
   Gibbon D., 1992, 2589 ESPRIT U BIEL.
   Heese F., 2012, P GERM ANN C AC DAGA.
   Jax P., 2003, SIGNAL PROCESSING IE, V83.
   Kontio J, 2007, IEEE T AUDIO SPEECH, V15, P873, DOI 10.1109/TASL.2006.885934.
   Laaksonen L., 2005, P IEEE INT C AC SPEE.
   Moller S, 2006, IEEE T AUDIO SPEECH, V14, P1969, DOI 10.1109/TASL.2006.883262.
   Moller S., 2000, ASSESSMENT PREDICTIO.
   Pham T.V., 2010, P INT C COMM EL ICCE.
   Pulakka H, 2008, IEEE T AUDIO SPEECH, V16, P1124, DOI 10.1109/TASL.2008.925149.
   Raake A., 2006, SPEECH QUALITY VOIP.
   Waltermann M, 2010, ACTA ACUST UNITED AC, V96, P1090, DOI 10.3813/AAA.918370.
   Waltermann M., 2010, P IEEE INT C AC SPEE.
   Waltermann M, 2013, DIMENSION BASED QUAL.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH0HX}},
Unique-ID = {{ISI:000395050001227}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000349857500112,
Author = {Despotovic, Vladimir and Peric, Zoran},
Book-Group-Author = {{IEEE}},
Title = {{Design of Nonlinear Predictors for Adaptive Predictive Coding of Speech
   Signals}},
Booktitle = {{2013 21ST TELECOMMUNICATIONS FORUM (TELFOR)}},
Year = {{2013}},
Pages = {{490+}},
Note = {{21st Telecommunications Forum (TELFOR), Belgrade, SERBIA, NOV 26-28,
   2013}},
Organization = {{IEEE; Telecommunicat Soc; Univ Belgrade, Sch Elect Engn; IEEE Commun
   Soc, Serbia \& Montenegro COM Chapter; IEEE Reg 8; Telekom Srbija;
   VLATACOM d o o; ERICSSON; HUAWEI; Int Business Machines d o o; Minist
   Educ, Sci \& Technol Dev; Minist Foreign \& Internal Trade \&
   Telecommunicat; Nokia Solut \& Networks Serbia; Publ PTT Enterprise
   SRBIJA; Republ Agcy Elect Commun Serbia; Serbian Natl Register Internet
   Domain Names; Serbia \& Montenegro Air Traf Serv; Teri Engn; BIT
   Projekt; IBIS INSTRUMENTS; IEEE Serbia \& Montenegro Sect; INTRACOM
   TELEKOM; ROHDE \& SCHWARZ Osterreich Ges m b H; VIP MOBILE; APEX Solut
   Technol; MDS Informaticki Inzenjering}},
Abstract = {{Linear predictive coding is probably the most frequently used technique
   in speech signal processing. Its main advantage comes from the analogy
   of the simplified vocal tract model with speech production system.
   However, this neglects nonlinearities in the speech production process.
   The paper deals with nonlinear prediction of speech based on truncated
   Volterra series. Long-term one-tap Volterra predictor is designed in
   order to decrease computational complexity. Further improvements are
   obtained using frame/subframe structure and fractional delay.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Despotovic, V (Corresponding Author), Univ Belgrade, Tech Fac Bor, Vojske Jugoslavije 12, Bor 19210, Serbia.
   Despotovic, Vladimir, Univ Belgrade, Tech Fac Bor, Vojske Jugoslavije 12, Bor 19210, Serbia.
   Peric, Zoran, Univ Nis, Fac Elect Engn, Nish, Serbia.}},
ISBN = {{978-1-4799-1420-3}},
Keywords = {{Nonlinear speech processing; Pitch period; Prediction; Volterra series}},
Keywords-Plus = {{FILTERS}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{vdespotovic@tf.bor.ac.rs
   zoran.peric@elfak.ni.ac.rs}},
ORCID-Numbers = {{Peric, Zoran/0000-0002-8267-9541}},
Cited-References = {{Alipoor G, 2011, EUR T TELECOMMUN, V22, P81, DOI 10.1002/ett.1440.
   Chikouche D., 2006, ASIAN J INFORM TECHN, V5, P1219.
   Chu W. C., 2003, SPEECH CODING ALGORI.
   Collis WB, 1997, PROCEEDINGS OF THE IEEE SIGNAL PROCESSING WORKSHOP ON HIGHER-ORDER STATISTICS, P39, DOI 10.1109/HOST.1997.613483.
   Deng L., 2003, SIGNAL PROCESSING CO.
   Despotovic V., 2012, P 10 ITG S SPEECH CO, P26.
   Despotovic V, 2012, ELMAR PROC, P231.
   Despotovic V, 2012, IEEE T AUDIO SPEECH, V20, P1069, DOI 10.1109/TASL.2011.2169788.
   Diniz P. S. R., 2013, ADAPTIVE FILTERING A.
   Du KL, 2010, WIRELESS COMMUNICATI.
   Faundez-Zanuy M., 2002, Control and Intelligent Systems, V30, P1.
   Giacobello D., 2010, THESIS.
   Holambe R. S., 2012, SPRINGERBRIEFS ELECT.
   Kroon P., 1991, Advances in Speech Coding, P321.
   Kubin G., 1995, SPEECH CODING SYNTHE.
   Laakso TI, 1996, IEEE SIGNAL PROC MAG, V13, P30, DOI 10.1109/79.482137.
   MEDAN Y, 1991, IEEE T SIGNAL PROCES, V39, P40, DOI 10.1109/78.80763.
   Mumolo E., 1994, Signal Processing VII, Theories and Applications. Proceedings of EUSIPCO-94. Seventh European Signal Processing Conference, P387.
   Ogunfunmi T, 2007, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-0-387-68630-1.
   Paleologu C, 2008, IEEE SIGNAL PROC LET, V15, P597, DOI 10.1109/LSP.2008.2001559.
   RAMACHANDRAN RP, 1989, IEEE T ACOUST SPEECH, V37, P467, DOI 10.1109/29.17527.
   Ramamurthy K. N., 2011, SYNRTHESIS LECT ALGO.
   Richard G., 1997, PROGR SPEECH SYNTHES, P41.
   Savoji MH, 2006, P 11 INT C SPEECH CO, P367.
   Schnell K., 2007, P ISCA ITRW NONL SPE, P116.
   TEAGER HM, 1990, NATO ADV SCI I D-BEH, V55, P241.
   TEAGER HM, 1980, IEEE T ACOUST SPEECH, V28, P599, DOI 10.1109/TASSP.1980.1163453.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.
   Zeller M, 2011, IEEE T SIGNAL PROCES, V59, P1449, DOI 10.1109/TSP.2010.2101066.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BC0ZC}},
Unique-ID = {{ISI:000349857500112}},
DA = {{2020-12-06}},
}

@inproceedings{ ISI:000393046008029,
Author = {Ren Zhepo and Li Zhijian and Wu Xiaojun and Ou Xiaobo},
Book-Group-Author = {{IEEE}},
Title = {{Nonlinear Bi-directional Prediction Model of Speech Signals Based on
   Genetic Programming}},
Booktitle = {{2013 32ND CHINESE CONTROL CONFERENCE (CCC)}},
Series = {{Chinese Control Conference}},
Year = {{2013}},
Pages = {{7971-7975}},
Note = {{32nd Chinese Control Conference (CCC), Xian, PEOPLES R CHINA, JUL 26-28,
   2013}},
Organization = {{Syst Engn Soc China; NW Polytechn Univ; Chinese Assoc Automat, Tech Comm
   Control Theory; Chinese Acad Sci, Acad Math \& Syst Sci; China Soc Ind
   \& Appl Math; Xian Jiaotong Univ; Xian Univ Technol; IEEE Control Syst
   Soc; Soc Instrument \& Control Engineers Japan; Inst Control Robot \&
   Syst Korea}},
Abstract = {{Based on the linear prediction theory, This paper proposes a nonlinear
   bi-directional prediction model for speech signals. After the data
   preprocessing, an improved GP is used to construct bi-directional
   prediction model of each frame. Then by the analysis of these models,
   the normalized nonlinear bi-directional prediction model is obtained. In
   the experiments, the DUPSO algorithm is used to optimize the parameters.
   By comparing the SNR and MMSE with the linear prediction model, the
   superiority of the proposed nonlinear bi-directional prediction model is
   proved.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{Chinese}},
Affiliation = {{Wu, XJ (Corresponding Author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   Ren Zhepo; Li Zhijian; Wu Xiaojun; Ou Xiaobo, Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   Wu Xiaojun, Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.}},
ISSN = {{2161-2927}},
Keywords = {{Speech Signals; Genetic Programming; Nonlinear Bi-directional
   Prediction; DUPSO algorithm}},
Research-Areas = {{Automation \& Control Systems}},
Web-of-Science-Categories  = {{Automation \& Control Systems}},
Author-Email = {{rzpyhg@163.com
   xjwu@nwpu.edu.cn}},
Cited-References = {{Al-kazemi B, 2002, IEEE C EVOL COMPUTAT, P489, DOI 10.1109/CEC.2002.1006283.
   George N. V., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P560.
   Kokkinos I, 2005, IEEE T SPEECH AUDI P, V13, P1098, DOI 10.1109/TSA.2005.852982.
   Koza JR, 1992, GENETIC PROGRAMMING.
   Tsanas A, 2011, J R SOC INTERFACE, V8, P842, DOI 10.1098/rsif.2010.0456.}},
Number-of-Cited-References = {{5}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG9CG}},
Unique-ID = {{ISI:000393046008029}},
DA = {{2020-12-06}},
}

@article{ ISI:000209640500003,
Author = {Kuhn, Tobias},
Title = {{A Principled Approach to Grammars for Controlled Natural Languages and
   Predictive Editors}},
Journal = {{JOURNAL OF LOGIC LANGUAGE AND INFORMATION}},
Year = {{2013}},
Volume = {{22}},
Number = {{1}},
Pages = {{33-70}},
Month = {{JAN}},
Abstract = {{Controlled natural languages (CNL) with a direct mapping to formal logic
   have been proposed to improve the usability of knowledge representation
   systems, query interfaces, and formal specifications. Predictive editors
   are a popular approach to solve the problem that CNLs are easy to read
   but hard to write. Such predictive editors need to be able to ``look
   ahead{''} in order to show all possible continuations of a given
   unfinished sentence. Such lookahead features, however, are difficult to
   implement in a satisfying way with existing grammar frameworks,
   especially if the CNL supports complex nonlocal structures such as
   anaphoric references. Here, methods and algorithms are presented for a
   new grammar notation called Codeco, which is specifically designed for
   controlled natural languages and predictive editors. A parsing approach
   for Codeco based on an extended chart parsing algorithm is presented. A
   large subset of Attempto Controlled English has been represented in
   Codeco. Evaluation of this grammar and the parser implementation shows
   that the approach is practical, adequate and efficient.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kuhn, T (Corresponding Author), Yale Univ, Sch Med, Dept Pathol, New Haven, CT 06510 USA.
   Kuhn, Tobias, Yale Univ, Sch Med, Dept Pathol, New Haven, CT 06510 USA.}},
DOI = {{10.1007/s10849-012-9167-z}},
ISSN = {{0925-8531}},
EISSN = {{1572-9583}},
Keywords = {{Anaphoric references; Attempto Controlled English; Chart parsing;
   Controlled natural languages; Predictive editors}},
Research-Areas = {{Computer Science; Linguistics; Science \& Technology - Other Topics;
   Philosophy}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Language \& Linguistics; Logic; Philosophy}},
Author-Email = {{kuhntobias@gmail.com}},
ResearcherID-Numbers = {{Kuhn, Tobias/B-6810-2013}},
ORCID-Numbers = {{Kuhn, Tobias/0000-0002-1267-0234}},
Cited-References = {{Adriaens G., 1992, P COLING 92 NANT, P595.
   Angelov K., 2010, CNL, V5972, P82.
   BACKUS JW, 1963, COMMUN ACM, V6, P1, DOI 10.1145/366193.366201.
   Bernstein A, 2006, LECT NOTES COMPUT SC, V4273, P144.
   CHOMSKY N, 1980, LINGUIST INQ, V11, P1.
   Clark P, 2007, K-CAP'07: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P63.
   COLE R, 1997, SURVEY STATE ART HUM.
   COVINGTON M, 1994, NATURAL LANGUAGE PRO.
   Dahl V, 1997, LOGIC PROGRAMM, P256.
   Dimitrova V, 2008, LECT NOTES COMPUT SC, V5318, P1, DOI 10.1007/978-3-540-88564-1\_1.
   EARLEY J, 1970, COMMUN ACM, V13, P94, DOI 10.1145/362007.362035.
   Franconi E., 2011, P 24 INT WORKSH DESC.
   Fuchs N. E., 1990, P 8 INT WORKSH LOG P.
   Fuchs NE, 2008, LECT NOTES COMPUT SC, V5224, P104.
   Funk A, 2007, LECT NOTES COMPUT SC, V4825, P142.
   Gazdar G., 1989, NATURAL LANGUAGE PRO.
   Gazdar Gerald, 1985, GEN PHRASE STRUCTURE.
   GRUNE D, 2008, PARSING TECHNIQUES P.
   Harrison Phil, 2005, P 18 INT FLOR ART IN, P506.
   HOBBS JR, 1978, LINGUA, V44, P311, DOI 10.1016/0024-3841(78)90006-2.
   Johnson M., 1986, 11th International Conference on Computational Linguistics. Proceedings of Coling `86, P669.
   Johnson S. C., 1975, 32 BELL LAB.
   JOSHI AK, 1975, J COMPUT SYST SCI, V10, P136, DOI 10.1016/S0022-0000(75)80019-5.
   Kaplan Ronald M., 1982, MENTAL REPRESENTATIO, P173.
   KNUTH DE, 1964, COMMUN ACM, V7, P735, DOI 10.1145/355588.365140.
   Kuhn T., 2009, P 5 INT WORKSH SEM W, V543.
   Kuhn T., 2012, CORPORA IN PRESS, V7.
   Kuhn T., 2010, THESIS U ZURICH.
   Kuhn T., SEMANTIC WE IN PRESS.
   Kuhn T., 2008, P AUSTR LANG TECHN A, P46.
   Kuhn T., 2009, CEUR WORKSHOP P, V464.
   Kuhn T., 2012, LNCS, V7175, P95.
   Kuhn T, 2007, LECT NOTES COMPUT SC, V4524, P299.
   Lappin S., 1994, Computational Linguistics, V20, P535.
   Martin P, 2002, LECT NOTES ARTIF INT, V2393, P77.
   MUECKSTEIN EM, 1985, CSC 85, P176.
   Ogden C. K., 1932, PSYCHE MINIATURES GE.
   PEREIRA F., 1986, READINGS NATURAL LAN, P101.
   Pollard C., 1994, HEAD DRIVEN PHRASE S.
   Pool J., 2006, P 5 INT WORKSH CONTR.
   Power R., 2009, CEUR WORKSHOP P, V448.
   Schwarz RB, 2003, PROCESSING AND PROPERTIES OF STRUCTURAL NANOMATERIALS, P141.
   Schwitter R., 2008, CEUR WORKSHOP P, V496.
   Shiffman RN, 2010, LECT NOTES ARTIF INT, V5972, P265, DOI 10.1007/978-3-642-14418-9\_16.
   Spreeuwenberg S, 2010, LECT NOTES ARTIF INT, V5972, P155, DOI 10.1007/978-3-642-14418-9\_10.
   Steedman M, 2011, NON-TRANSFORMATIONAL SYNTAX: FORMAL AND EXPLICIT MODELS OF GRAMMAR, P181.
   Sukkarieh J. Z., 1999, P 3 INT WORKSH COMP, P367.
   Tennant H. R., 1983, 21st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, P151.
   Verbeke C. A., 1973, TRAIN DEV J, V27, P36.
   Wursch M., 2010, P 32 ACM IEEE INT C, P165, DOI DOI 10.1145/1806799.1806827.
   Wyner A, 2010, LECT NOTES ARTIF INT, V5972, P281, DOI 10.1007/978-3-642-14418-9\_17.}},
Number-of-Cited-References = {{51}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{J. Log. Lang. Inf.}},
Doc-Delivery-Number = {{V42VE}},
Unique-ID = {{ISI:000209640500003}},
DA = {{2020-12-06}},
}

@article{ ISI:000311240200005,
Author = {Ullberg, Johan and Johnson, Pontus and Buschle, Markus},
Title = {{A language for interoperability modeling and prediction}},
Journal = {{COMPUTERS IN INDUSTRY}},
Year = {{2012}},
Volume = {{63}},
Number = {{8, SI}},
Pages = {{766-774}},
Month = {{OCT}},
Abstract = {{Interoperability, defined as the satisfaction of a communication need
   between two or more actors, is a sought after quality for enterprises in
   today's competitive environment. For a decision maker, understanding the
   effects of a changing market place and understanding how to adapt to the
   new environment is essential. Sustainable interoperability is an
   approach where such dynamic environments are considered, including how
   to adapt to the new environments. This paper presents a modeling
   language for describing architectures from an interoperability
   perspective and a formalism for inferring the degree of interoperability
   from the architecture models, thus supporting sustainable
   interoperability.
   The interoperability language is expressed as a Unified Modeling
   Language, UML, class diagram specifying classes, attributes, and
   relationships relevant for interoperability modeling. The class diagram
   is also augmented with a set of statements in the Object Constraint
   Language, OCL, supporting automated interoperability prediction. (C)
   2012 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ullberg, J (Corresponding Author), KTH Royal Inst Technol, Sch Elect Engn, Dept Ind Informat \& Control Syst, Stockholm, Sweden.
   Ullberg, Johan; Johnson, Pontus; Buschle, Markus, KTH Royal Inst Technol, Sch Elect Engn, Dept Ind Informat \& Control Syst, Stockholm, Sweden.}},
DOI = {{10.1016/j.compind.2012.08.009}},
ISSN = {{0166-3615}},
EISSN = {{1872-6194}},
Keywords = {{Interoperability; Interoperability prediction; Information systems
   architecture; Interoperability modeling; Architecture analysis}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications}},
Author-Email = {{johanu@ics.kth.se
   pj101@ics.kth.se
   markusb@ics.kth.se}},
ResearcherID-Numbers = {{Johnson, Pontus/C-5796-2014}},
ORCID-Numbers = {{Johnson, Pontus/0000-0002-3293-1681}},
Cited-References = {{Agostinho C, 2009, LECT NOTES COMPUT SC, V5872, P194, DOI 10.1007/978-3-642-05290-3\_30.
   {[}Anonymous], 2009, OMG UN MOD LANG OMG.
   Berre AJ, 2007, ENTERPRISE INTEROPERABILITY II: NEW CHALLENGES AND APPROACHES, P569, DOI 10.1007/978-1-84628-858-6\_62.
   BRITTON C, 2001, IT ARCHITECTURES MID.
   Chen D., 2006, 2 INT WORKSH ENT INT.
   Chen D, 2008, COMPUT IND, V59, P647, DOI 10.1016/j.compind.2007.12.016.
   Erl T., 2005, SERVICE ORIENTED ARC.
   Ford T. C., 2007, 5 ANN C SYST ENG RES.
   Hohpe G, 2004, ENTERPRISE INTEGRATI.
   Interoperable Delivery of European eGovernment Services to public Administrations Businesses and Citizens IDABC, 2004, EUR INT FRAM PAN EUR.
   Johnson P., IEEE T DEPENDA UNPUB.
   Jurafsky D, 2000, SPEECH LANGUAGE PROC.
   Kasunic M., 2004, CMUSEI2004TN003.
   Linthicum D., 2000, ENTERPRISE APPL INTE.
   LITTLE JDC, 1970, MANAGE SCI B-APPL, V16, pB466, DOI 10.1287/mnsc.1040.0267.
   Matthes F. C, 2008, TECHNICAL REPORT.
   MOCKAPETRIS PV, 1987, DOMAIN NAMES CONCEPT.
   MORRIS R, 2004, CMUSEI2004TR004.
   OMG, 2014, OBJ CONSTR LANG SPEC.
   Ruokolainen T, 2007, ENTERPRISE INTEROPERABILITY II: NEW CHALLENGES AND APPROACHES, P159, DOI 10.1007/978-1-84628-858-6\_17.
   Saeed JI, 2003, SEMANTICS.
   Sommestad T, 2010, COMPUT SECUR, V29, P659, DOI 10.1016/j.cose.2010.02.002.
   The Institute of Electrical and Electronics Engineers: Standard Glossary of Software Engineering Terminology, 1990, 61012 I EL EL ENG.
   Tolk James A., 2003, 2003 FALL SIM INT WO.
   Ullberg J., TECHNICAL REPORT.
   Ullberg J, 2010, ENTERPRISE INTEROPERABILITY IV: MAKING THE INTERNET OF THE FUTURE FOR THE FUTURE OF ENTERPRISE, P81, DOI 10.1007/978-1-84996-257-5\_8.
   Ullberg J, 2009, LECT NOTES BUS INF P, V38, P13.
   ZIMMERMANN H, 1980, IEEE T COMMUN, V28, P425, DOI 10.1109/TCOM.1980.1094702.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Comput. Ind.}},
Doc-Delivery-Number = {{039JA}},
Unique-ID = {{ISI:000311240200005}},
DA = {{2020-12-06}},
}

@article{ ISI:000306984600007,
Author = {Mani, Nivedita and Huettig, Falk},
Title = {{Prediction During Language Processing is a Piece of Cake - But Only for
   Skilled Producers}},
Journal = {{JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE}},
Year = {{2012}},
Volume = {{38}},
Number = {{4}},
Pages = {{843-847}},
Month = {{AUG}},
Abstract = {{Are there individual differences in children's prediction of upcoming
   linguistic input and what do these differences reflect? Using a variant
   of the preferential looking paradigm (Golinkoff, Hirsh-Pasek, Cauley, \&
   Gordon, 1987), we found that, upon hearing a sentence like, ``The boy
   eats a big cake,{''} 2-year-olds fixate edible objects in a visual scene
   (a cake) soon after they hear the semantically constraining verb eats
   and prior to hearing the word cake. Importantly, children's prediction
   skills were significantly correlated with their productive vocabulary
   size-skilled producers (i.e., children with large production
   vocabularies) showed evidence of predicting upcoming linguistic input,
   while low producers did not. Furthermore, we found that children's
   prediction ability is tied specifically to their production skills and
   not to their comprehension skills. Prediction is really a piece of cake,
   but only for skilled producers.}},
Publisher = {{AMER PSYCHOLOGICAL ASSOC}},
Address = {{750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Mani, N (Corresponding Author), Univ Gottingen, Language Acquisit Jr Res Grp, Gosslerstr 14, D-37073 Gottingen, Germany.
   Mani, Nivedita, Univ Gottingen, Language Acquisit Jr Res Grp, D-37073 Gottingen, Germany.
   Huettig, Falk, Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   Huettig, Falk, Radboud Univ Nijmegen, Donders Inst Brain Cognit \& Behav, NL-6525 ED Nijmegen, Netherlands.}},
DOI = {{10.1037/a0029284}},
ISSN = {{0096-1523}},
Keywords = {{prediction; production vocabulary; language-mediated visual search;
   toddlers}},
Keywords-Plus = {{PROACTIVE BRAIN; EYE-MOVEMENTS; COMPREHENSION; EXPECTATIONS}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology; Psychology, Experimental}},
Author-Email = {{nmani@gwdg.de}},
ResearcherID-Numbers = {{Huettig, Falk/D-1991-2010
   Mani, Nivedita/F-8795-2010}},
ORCID-Numbers = {{Mani, Nivedita/0000-0002-9843-4629}},
Cited-References = {{Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005.
   Bar M, 2009, PHILOS T R SOC B, V364, P1235, DOI 10.1098/rstb.2008.0310.
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005.
   CANFIELD RL, 1991, DEV PSYCHOL, V27, P198, DOI 10.1037/0012-1649.27.2.198.
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234.
   GERNSBACHER MA, 1991, J EXP PSYCHOL LEARN, V17, P245, DOI 10.1037/0278-7393.17.2.245.
   GOLINKOFF RM, 1987, J CHILD LANG, V14, P23, DOI 10.1017/S030500090001271X.
   HAITH MM, 1988, CHILD DEV, V59, P467, DOI 10.2307/1130325.
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8.
   Mani N, 2010, PSYCHOL SCI, V21, P908, DOI 10.1177/0956797610373371.
   Misyak JB, 2010, TOP COGN SCI, V2, P138, DOI 10.1111/j.1756-8765.2009.01072.x.
   Nation K, 1999, COGNITION, V70, pB1, DOI 10.1016/S0010-0277(99)00004-9.
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001.
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002.
   Szagun G., 2009, FRAGEBOGEN FRUHKINDL.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{106}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{13}},
Journal-ISO = {{J. Exp. Psychol.-Hum. Percept. Perform.}},
Doc-Delivery-Number = {{981QN}},
Unique-ID = {{ISI:000306984600007}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000302530900001,
Author = {Giacobello, Daniele and Christensen, Mads Graesboll and Murthi, Manohar
   N. and Jensen, Soren Holdt and Moonen, Marc},
Title = {{Sparse Linear Prediction and Its Applications to Speech Processing}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2012}},
Volume = {{20}},
Number = {{5}},
Pages = {{1644-1657}},
Month = {{JUL}},
Abstract = {{The aim of this paper is to provide an overview of Sparse Linear
   Prediction, a set of speech processing tools created by introducing
   sparsity constraints into the linear prediction framework. These tools
   have shown to be effective in several issues related to modeling and
   coding of speech signals. For speech analysis, we provide predictors
   that are accurate in modeling the speech production process and overcome
   problems related to traditional linear prediction. In particular, the
   predictors obtained offer a more effective decoupling of the vocal tract
   transfer function and its underlying excitation, making it a very
   efficient method for the analysis of voiced speech. For speech coding,
   we provide predictors that shape the residual according to the
   characteristics of the sparse encoding techniques resulting in more
   straightforward coding strategies. Furthermore, encouraged by the
   promising application of compressed sensing in signal compression, we
   investigate its formulation and application to sparse linear predictive
   coding. The proposed estimators are all solutions to convex optimization
   problems, which can be solved efficiently and reliably using, e. g.,
   interior-point methods. Extensive experimental results are provided to
   support the effectiveness of the proposed methods, showing the
   improvements over traditional linear prediction in both speech analysis
   and coding.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Giacobello, D (Corresponding Author), Broadcom Corp, Off CTO, Irvine, CA 92617 USA.
   Giacobello, Daniele, Broadcom Corp, Off CTO, Irvine, CA 92617 USA.
   Christensen, Mads Graesboll, Aalborg Univ, Dept Architecture Design \& Media Technol, DK-9220 Aalborg, Denmark.
   Murthi, Manohar N., Univ Miami, Dept Elect \& Comp Engn, Coral Gables, FL 33146 USA.
   Jensen, Soren Holdt, Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.
   Moonen, Marc, Katholieke Univ Leuven, Dept Elect Engn, B-3001 Louvain, Belgium.}},
DOI = {{10.1109/TASL.2012.2186807}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{1-norm minimization; compressed sensing; linear prediction; sparse
   representation; speech analysis; speech coding}},
Keywords-Plus = {{VECTOR QUANTIZATION; PROPERTY; CURVE; L(1)}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{giacobello@broadcom.com
   mgc@imi.aau.dk
   mmurthi@miami.edu
   shj@es.aau.dk
   marc.moonen@esat.kuleuven.be}},
ResearcherID-Numbers = {{Giacobello, Daniele/J-7962-2013
   Giacobello, Daniele/AAI-3724-2020
   Jensen, Soren/C-6026-2009
   Christensen, Mads G/I-4132-2018}},
ORCID-Numbers = {{Giacobello, Daniele/0000-0001-8708-8604
   Giacobello, Daniele/0000-0001-8708-8604
   Jensen, Soren/0000-0002-1050-470X
   Christensen, Mads G/0000-0003-3586-7969}},
Funding-Acknowledgement = {{Marie Curie EST-SIGNAL FellowshipEuropean Union (EU)
   {[}MEST-CT-2005-021175]; National Science FoundationNational Science
   Foundation (NSF) {[}CCF-0347229, CNS-0519933]}},
Funding-Text = {{The work of D. Giacobello was supported by the Marie Curie EST-SIGNAL
   Fellowship under Contract MEST-CT-2005-021175 and was carried out at the
   Department of Electronic Systems, Aalborg University. The work of M. N.
   Murthi was supported by the National Science Foundation via awards
   CCF-0347229 and CNS-0519933. The associate editor coordinating the
   review of this manuscript and approving it for publication was Prof. Hui
   Jiang.}},
Cited-References = {{{[}Anonymous], 2003, BS15341 ITUR.
   {[}Anonymous], PAR COD CHAR MUST BE.
   {[}Anonymous], 2004, 26190 3GPP TS.
   Atal B. S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P614.
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x.
   BLOOMFIELD P, 1980, SIAM J SCI STAT COMP, V1, P290, DOI 10.1137/0901019.
   Boyd S., 2004, CONVEX OPTIMIZATION.
   Cadzow JA, 2002, DIGIT SIGNAL PROCESS, V12, P524, DOI 10.1006/dspr.2001.0409.
   Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731.
   Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x.
   Christensen M. G., 2009, AS C SIGN SYST COMP.
   Chu W. C., 2003, SPEECH CODING ALGORI.
   DENOEL E, 1985, IEEE T ACOUST SPEECH, V33, P1397, DOI 10.1109/TASSP.1985.1164759.
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582.
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100.
   Ekman LA, 2008, IEEE T AUDIO SPEECH, V16, P65, DOI 10.1109/TASL.2007.909448.
   ELJAROUDI A, 1991, IEEE T SIGNAL PROCES, V39, P411, DOI 10.1109/78.80824.
   Fuchs JJ, 2004, IEEE T INFORM THEORY, V50, P1341, DOI 10.1109/TIT.2004.828141.
   GERSHO A, 1993, VECTOR QUANTIZATION.
   Giacobello Daniele, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2524.
   Giacobello D, 2010, EUR SIGNAL PR CONF, P234.
   Giacobello D, 2010, INT CONF ACOUST SPEE, P4650, DOI 10.1109/ICASSP.2010.5495198.
   Giacobello D, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1353.
   Giacobello D, 2010, IEEE SIGNAL PROC LET, V17, P103, DOI 10.1109/LSP.2009.2034560.
   Giacobello D, 2009, INT CONF ACOUST SPEE, P4109, DOI 10.1109/ICASSP.2009.4960532.
   Hansen J. H. L., 1987, DISCRETE TIME PROCES, DOI Englewood Cliffs, NJ, USA.
   HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086.
   Hermansky H., 1984, P IEEE INT C AC SPEE, V9, P53.
   ITAKURA F, 1968, 6TH P INT C AC TOK, pC17.
   Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400.
   KABAL P, 1989, IEEE T ACOUST SPEECH, V37, P642, DOI 10.1109/29.17556.
   Kleijn WB, 2007, 2007 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P241.
   KNOCKAERT L, 1992, IEEE T INFORM THEORY, V38, P1483, DOI 10.1109/18.149499.
   KROON P, 1986, IEEE T ACOUST SPEECH, V34, P1054, DOI 10.1109/TASSP.1986.1164946.
   Kroon  P., 1995, SPEECH CODING SYNTHE, P79.
   Lansford J., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P335, DOI 10.1109/ICASSP.1988.196584.
   LEE CH, 1988, IEEE T ACOUST SPEECH, V36, P642, DOI 10.1109/29.1574.
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Mecklenbrauker WFG, 1998, IEEE SIGNAL PROC LET, V5, P87, DOI 10.1109/97.664174.
   Murthi MN, 1998, INT CONF ACOUST SPEE, P369, DOI 10.1109/ICASSP.1998.674444.
   Murthi MN, 2000, IEEE T SPEECH AUDI P, V8, P221, DOI 10.1109/89.841206.
   Nadarajah S, 2005, J APPL STAT, V32, P685, DOI 10.1080/02664760500079464.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   Reed M., 1975, METHODS MODERN MATH, V2.
   Scharf L., 1991, STAT SIGNAL PROCESSI.
   SCHROEDER J, 1989, SIGNAL PROCESS, V17, P19, DOI 10.1016/0165-1684(89)90069-8.
   Sreenivas TV, 2009, INT CONF ACOUST SPEE, P4125, DOI 10.1109/ICASSP.2009.4960536.
   STOICA P, 1990, SIGNAL PROCESS, V20, P257, DOI 10.1016/0165-1684(90)90015-Q.
   Stoica P., 2005, SPECTRAL ANAL SIGNAL.
   Subramaniam AD, 2003, IEEE T SPEECH AUDI P, V11, P130, DOI 10.1109/TSA.2003.809192.
   Wipf D, 2010, IEEE J-STSP, V4, P317, DOI 10.1109/JSTSP.2010.2042413.
   Wright S.J., 1997, PRIMAL DUAL INTERIOR.}},
Number-of-Cited-References = {{53}},
Times-Cited = {{81}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{23}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{922EZ}},
Unique-ID = {{ISI:000302530900001}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000302768000008,
Author = {Pesco, Diane and O'Neill, Daniela K.},
Title = {{Predicting Later Language Outcomes From the Language Use Inventory}},
Journal = {{JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH}},
Year = {{2012}},
Volume = {{55}},
Number = {{2}},
Pages = {{421-434}},
Month = {{APR 1}},
Abstract = {{Purpose: To examine the predictive validity of the Language Use
   Inventory (LUI), a parent report of language use by children 18-47
   months old (O'Neill, 2009).
   Method: 348 children whose parents had completed the LUI were reassessed
   at 5-6 years old with standardized, norm-referenced language measures
   and parent report of developmental history. The relationship between
   scores on the LUI and later measures was examined through correlation,
   binary classification, and receiver operating characteristic curve
   analysis.
   Results: For children aged 24-47 months at the time of LUI completion,
   LUI scores correlated significantly with language measure scores.
   Sensitivity, specificity, positive predictive value (PPV), and negative
   predictive value (NPV) were also calculated for 4 cutoff scores on the
   LUI, including -1.64 SD, a score that maximized sensitivity to 81\% and
   specificity to 93\%. For children aged 18-23 months at the time of LUI
   completion, specificity and NPV were high, but sensitivity and PPV were
   lower than desirable.
   Conclusions: The results provide initial support for the LUI's
   predictive validity, particularly for children 24-47 months, and suggest
   the LUI can serve as an indicator of later language outcomes in referred
   populations. The results compare favorably to findings for other early
   child-language measures.}},
Publisher = {{AMER SPEECH-LANGUAGE-HEARING ASSOC}},
Address = {{2200 RESEARCH BLVD, \#271, ROCKVILLE, MD 20850-3289 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Pesco, D (Corresponding Author), Concordia Univ, Montreal, PQ, Canada.
   Pesco, Diane, Concordia Univ, Montreal, PQ, Canada.
   O'Neill, Daniela K., Univ Waterloo, Waterloo, ON N2L 3G1, Canada.}},
DOI = {{10.1044/1092-4388(2011/10-0273)}},
ISSN = {{1092-4388}},
EISSN = {{1558-9102}},
Keywords = {{predictive validity; pragmatics; parent report; language assessment;
   language delay}},
Keywords-Plus = {{AUTISM SPECTRUM DISORDERS; PRAGMATIC LANGUAGE; COMMUNICATIVE
   DEVELOPMENT; YOUNG-CHILDREN; SCREENING TOOL; IMPAIRMENT; VALIDITY; AGE;
   KINDERGARTEN; CONCURRENT}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Rehabilitation}},
Author-Email = {{dpesco@education.concordia.ca}},
Funding-Acknowledgement = {{Canadian Institutes of Health Research (CIHR)Canadian Institutes of
   Health Research (CIHR)}},
Funding-Text = {{This work was made possible by a 2006-2009 grant from the Canadian
   Institutes of Health Research (CIHR). The authors gratefully acknowledge
   Mare Appleby and Jillian Spratt for their research assistance, Mary
   Thompson at the University of Waterloo for statistical consulting, and
   the many families and children who participated in the study.}},
Cited-References = {{Adams C, 2002, J CHILD PSYCHOL PSYC, V43, P973, DOI 10.1111/1469-7610.00226.
   Berglund E, 2000, SCAND J PSYCHOL, V41, P133, DOI 10.1111/1467-9450.00181.
   Betz S. K., 2010, S RES CHILD LANG DIS.
   Bishop D. V. M., 2006, CHILDRENS COMMUNICAT.
   Bishop DVM, 2009, INT J LANG COMM DIS, V44, P600, DOI 10.1080/13682820802259662.
   Bricker D., 1999, AGES STAGES QUESTION.
   Charman T, 2005, J CHILD PSYCHOL PSYC, V46, P500, DOI 10.1111/j.1469-7610.2004.00377.x.
   Condouris K, 2003, AM J SPEECH-LANG PAT, V12, P349, DOI 10.1044/1058-0360(2003/080).
   Conti-Ramsden G, 1999, J SPEECH LANG HEAR R, V42, P1195, DOI 10.1044/jslhr.4205.1195.
   Dale PS, 2003, J SPEECH LANG HEAR R, V46, P544, DOI 10.1044/1092-4388(2003/044).
   Dionne G, 2003, CHILD DEV, V74, P394, DOI 10.1111/1467-8624.7402005.
   Duby JC, 2006, PEDIATRICS, V118, P405, DOI 10.1542/peds.2006-1231.
   Edwards S, 1999, INT J LANG COMM DIS, V34, P151, DOI 10.1080/136828299247487.
   Feldman HM, 2005, CHILD DEV, V76, P856, DOI 10.1111/j.1467-8624.2005.00882.x.
   Fenson L, 2000, CHILD DEV, V71, P323, DOI 10.1111/1467-8624.00147.
   Fenson L., 2007, MACARTHUR BATES COMM.
   Fletcher RH, 2005, CLIN EPIDEMIOLOGY ES.
   Geurts H, 2010, INT J LANG COMM DIS, V45, P436, DOI 10.3109/13682820903165685.
   GLASCOE FP, 1995, PEDIATRICS, V95, P829.
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747.
   Jordan NC, 2010, SCHOOL PSYCHOL REV, V39, P181.
   Klee T, 2000, J SPEECH LANG HEAR R, V43, P821, DOI 10.1044/jslhr.4304.821.
   Law J, 2000, DEV MED CHILD NEUROL, V42, P190, DOI 10.1017/S0012162200000335.
   Law J, 2008, CHILD ADOL MENT H-UK, V13, P198, DOI 10.1111/j.1475-3588.2008.00503.x.
   Marks K, 2008, PEDIATRICS, V122, P866, DOI 10.1542/peds.2007-3142.
   MEEHL PE, 1955, PSYCHOL BULL, V52, P194, DOI 10.1037/h0048070.
   Norbury CF, 2004, INT J LANG COMM DIS, V39, P345, DOI 10.1080/13682820410001654883.
   O'Neill D, 2009, LANGUAGE USE INVENTO.
   O'Neill DK, 2007, J SPEECH LANG HEAR R, V50, P214, DOI 10.1044/1092-4388(2007/017).
   Osman DM, 2011, INT J PEDIATR OTORHI, V75, P171, DOI 10.1016/j.ijporl.2010.10.028.
   Perez-Pereira M, 2007, INFANC APRENDIZ, V30, P565, DOI 10.1174/021037007782334292.
   Perez-Pereira M, 2011, J CHILD LANG, V38, P121, DOI 10.1017/S0305000909990262.
   Phelps-Terasaki D., 1992, TEST PRAGMATIC LANGU.
   Philofsky A, 2007, AM J SPEECH-LANG PAT, V16, P368, DOI 10.1044/1058-0360(2007/040).
   Rapin I, 2003, BRAIN DEV-JPN, V25, P166, DOI 10.1016/S0387-7604(02)00191-2.
   Redmond SM, 2011, J SPEECH LANG HEAR R, V54, P99, DOI 10.1044/1092-4388(2010/10-0010).
   RESCORLA L, 1989, J SPEECH HEAR DISORD, V54, P587, DOI 10.1044/jshd.5404.587.
   Rescorla L, 2002, J SPEECH LANG HEAR R, V45, P360, DOI 10.1044/1092-4388(2002/028).
   Rice ML, 2008, J SPEECH LANG HEAR R, V51, P394, DOI 10.1044/1092-4388(2008/029).
   Rice ML, 2005, APPL PSYCHOLINGUIST, V26, P7, DOI 10.1017/S0142716405050034.
   Rollins PR, 1998, J CHILD LANG, V25, P653.
   Russell RL, 2008, CLIN CHILD FAM PSYCH, V11, P59, DOI 10.1007/s10567-008-0032-1.
   Rydz D, 2006, PEDIATRICS, V118, pE1178, DOI 10.1542/peds.2006-0466.
   Sachse S, 2008, J DEV BEHAV PEDIATR, V29, P34, DOI 10.1097/DBP.0b013e318146902a.
   Sanderson R., 2009, MATERNAL CHILD INDIC.
   Seymour H. N., 2005, DIAGNOSTIC EVALUATIO.
   Spaulding TJ, 2006, LANG SPEECH HEAR SER, V37, P61, DOI 10.1044/0161-1461(2006/007).
   Statistics Canada, 2007, 2006 COMM PROF.
   Streiner DL, 2003, J PERS ASSESS, V81, P209, DOI 10.1207/S15327752JPA8103\_03.
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245.
   Van Agt HME, 2007, DEV MED CHILD NEUROL, V49, P117, DOI 10.1111/j.1469-8749.2007.00117.x.
   Vance R, 1994, LANG SPEECH HEAR SER, V25, P15, DOI DOI 10.1044/0161-1461.2501.15.
   Volden J, 2010, AM J SPEECH-LANG PAT, V19, P204, DOI 10.1044/1058-0360(2010/09-0011).
   WASHINGTON K, 2010, CASLPA COMMUNIQUE, V24, P4.
   Washington K. N., 2010, COMMUNIQUE, V24, P8.
   Westerlund M, 2006, J SPEECH LANG HEAR R, V49, P237, DOI 10.1044/1092-4388(2006/020).
   Wiig E., 2004, CLIN EVALUATION LANG.
   World Health Organization, 2007, INT CLASS FUNCT DIS.}},
Number-of-Cited-References = {{58}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{20}},
Journal-ISO = {{J. Speech Lang. Hear. Res.}},
Doc-Delivery-Number = {{925NM}},
Unique-ID = {{ISI:000302768000008}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000304170300030,
Author = {Despotovic, Vladimir and Goertz, Norbert and Peric, Zoran},
Title = {{Nonlinear Long-Term Prediction of Speech Based on Truncated Volterra
   Series}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2012}},
Volume = {{20}},
Number = {{3}},
Pages = {{1069-1073}},
Month = {{MAR}},
Abstract = {{Previous studies of nonlinear prediction of speech have been mostly
   focused on short-term prediction. This paper presents long-term
   nonlinear prediction based on second-order Volterra filters. It will be
   shown that the presented predictor can outperform conventional linear
   prediction techniques in terms of prediction gain and ``whiter{''}
   residuals.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Letter}},
Language = {{English}},
Affiliation = {{Despotovic, V (Corresponding Author), Univ Belgrade, Tech Fac Bor, Bor 19210, Serbia.
   Despotovic, Vladimir, Univ Belgrade, Tech Fac Bor, Bor 19210, Serbia.
   Goertz, Norbert, Vienna Univ Technol, Inst Telecommun, A-1040 Vienna, Austria.
   Peric, Zoran, Univ Nis, Fac Elect Engn, Nish 18000, Serbia.}},
DOI = {{10.1109/TASL.2011.2169788}},
ISSN = {{1558-7916}},
Keywords = {{Linear predictive coding; long-term prediction; nonlinear filters;
   volterra series}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{vdespotovic@tf.bor.ac.rs
   norbert.goertz@nt.tuwien.ac.at
   peric@elfak.ni.ac.rs}},
ORCID-Numbers = {{Peric, Zoran/0000-0002-8267-9541}},
Cited-References = {{Alipoor G, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P185.
   Birgmeier M., 1997, P INT C AC SPEECH SI, V2, P1283.
   Chan SCK, 2000, IEEE T CIRCUITS-I, V47, P545, DOI 10.1109/81.841856.
   Chetouani M, 2005, LECT NOTES COMPUT SC, V3697, P779.
   Chu W. C., 2003, SPEECH CODING ALGORI.
   Collis WB, 1997, PROCEEDINGS OF THE IEEE SIGNAL PROCESSING WORKSHOP ON HIGHER-ORDER STATISTICS, P39, DOI 10.1109/HOST.1997.613483.
   Deller JR, 1993, DISCRETE TIME PROCES.
   Dubnov S, 2004, IEEE SIGNAL PROC LET, V11, P698, DOI 10.1109/LSP.2004.831663.
   Faundez-Zanuy M., 2002, Control and Intelligent Systems, V30, P1.
   Garofolo John S., 1993, TIMIT ACOUSTIC PHONE.
   Gazor S, 2003, IEEE SIGNAL PROC LET, V10, P204, DOI 10.1109/LSP.2003.813679.
   Goertz N., 2007, JOINT SOURCE CHANNEL.
   Jayant N.S., 1984, DIGITAL CODING WAVEF.
   KIM K, 1994, IEEE J OCEANIC ENG, V19, P183.
   Mumolo E., 1994, SIGNAL PROCESSING 7, V1, P387.
   Ogunfunmi T, 2007, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-0-387-68630-1.
   Schnell K., 2007, P ISCA ITRW NONL SPE, P116.
   Teager H. M., 1989, NATO ADV STUDY I S D, V55, P241.
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{944AL}},
Unique-ID = {{ISI:000304170300030}},
DA = {{2020-12-06}},
}

@article{ ISI:000302517600007,
Author = {Van Petten, Cyma and Luka, Barbara J.},
Title = {{Prediction during language comprehension: Benefits, costs, and ERP
   components}},
Journal = {{INTERNATIONAL JOURNAL OF PSYCHOPHYSIOLOGY}},
Year = {{2012}},
Volume = {{83}},
Number = {{2, SI}},
Pages = {{176-190}},
Month = {{FEB}},
Abstract = {{Because context has a robust influence on the processing of subsequent
   words, the idea that readers and listeners predict upcoming words has
   attracted research attention, but prediction has fallen in and out of
   favor as a likely factor in normal comprehension. We note that the
   common sense of this word includes both benefits for confirmed
   predictions and costs for disconfirmed predictions. The N400 component
   of the event-related potential (ERP) reliably indexes the benefits of
   semantic context Evidence that the N400 is sensitive to the other half
   of prediction - a cost for failure - is largely absent from the
   literature. This raises the possibility that ``prediction{''} is not a
   good description of what comprehenders do. However, it need not be the
   case that the benefits and costs of prediction are evident in a single
   ERP component Research outside of language processing indicates that
   late positive components of the ERP are very sensitive to disconfirmed
   predictions. We review late positive components elicited by words that
   are potentially more or less predictable from preceding sentence
   context. This survey suggests that late positive responses to unexpected
   words are fairly common, but that these consist of two distinct
   components with different scalp topographies, one associated with
   semantically incongruent words and one associated with congruent words.
   We conclude with a discussion of the possible cognitive correlates of
   these distinct late positivities and their relationships with more
   thoroughly characterized ERP components, namely the P300, P600 response
   to syntactic errors, and the ``old/new effect{''} in studies of
   recognition memory. (C) 2011 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Van Petten, C (Corresponding Author), SUNY Binghamton, Dept Psychol, 4400 Vestal Pkwy E, Binghamton, NY 13902 USA.
   Van Petten, Cyma, SUNY Binghamton, Dept Psychol, Binghamton, NY 13902 USA.
   Luka, Barbara J., Bard Coll, Psychol Program, Annandale On Hudson, NY 12504 USA.}},
DOI = {{10.1016/j.ijpsycho.2011.09.015}},
ISSN = {{0167-8760}},
EISSN = {{1872-7697}},
Keywords = {{Prediction; Sentence; Event-related potential; N400; P600; P300}},
Keywords-Plus = {{EVENT-RELATED POTENTIALS; SPOKEN-WORD RECOGNITION; SENTENCE-LEVEL
   CONTEXT; BRAIN POTENTIALS; ELECTROPHYSIOLOGICAL EVIDENCE; SEMANTIC
   INTEGRATION; SPATIOTEMPORAL ANALYSIS; LEXICAL INTEGRATION; MENTAL
   CHRONOMETRY; STIMULUS SEQUENCE}},
Research-Areas = {{Psychology; Neurosciences \& Neurology; Physiology}},
Web-of-Science-Categories  = {{Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental}},
Author-Email = {{cvanpett@binghamton.edu}},
Cited-References = {{ALTMANN G, 1988, COGNITION, V30, P191, DOI 10.1016/0010-0277(88)90020-0.
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1.
   ANDERSON MC, 1994, J EXP PSYCHOL LEARN, V20, P1063, DOI 10.1037/0278-7393.20.5.1063.
   ANDREWS S, 1993, BIOL PSYCHIAT, V34, P443, DOI 10.1016/0006-3223(93)90235-6.
   Arbel Y, 2011, PSYCHOPHYSIOLOGY, V48, P861, DOI 10.1111/j.1469-8986.2010.01151.x.
   ARDAL S, 1990, BRAIN LANG, V39, P187, DOI 10.1016/0093-934X(90)90011-5.
   Barber H, 2005, J COGNITIVE NEUROSCI, V17, P137, DOI 10.1162/0898929052880101.
   Bendixen A., INT J PSYCH IN PRESS.
   BESSON M, 1992, J COGNITIVE NEUROSCI, V4, P132, DOI 10.1162/jocn.1992.4.2.132.
   Besson M, 1997, BIOL PSYCHOL, V46, P3, DOI 10.1016/S0301-0511(96)05215-5.
   BESSON M, 1987, PSYCHOPHYSIOLOGY, V24, P14, DOI 10.1111/j.1469-8986.1987.tb01853.x.
   Bornkessel I, 2006, PSYCHOL REV, V113, P787, DOI 10.1037/0033-295X.113.4.787.
   Borovsky A, 2010, COGNITION, V116, P289, DOI 10.1016/j.cognition.2010.05.004.
   BRETON F, 1988, BIOL PSYCHOL, V27, P23, DOI 10.1016/0301-0511(88)90003-8.
   Brown-Schmidt S, 2004, J PSYCHOLINGUIST RES, V33, P103, DOI 10.1023/B:JOPR.0000017223.98667.10.
   Butterfield B, 2003, COGNITIVE BRAIN RES, V17, P793, DOI 10.1016/S0926-6410(03)00203-9.
   COHEN G, 1983, BRIT J PSYCHOL, V74, P239, DOI 10.1111/j.2044-8295.1983.tb01860.x.
   CONNOLLY JF, 1995, ELECTROEN CLIN NEURO, V94, P276, DOI 10.1016/0013-4694(95)98479-R.
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256.
   Coulson S, 1998, LANG COGNITIVE PROC, V13, P21, DOI 10.1080/016909698386582.
   Coulson S, 2005, J EXP PSYCHOL LEARN, V31, P129, DOI 10.1037/0278-7393.31.1.129.
   Coulson S, 2007, BRAIN RES, V1146, P128, DOI 10.1016/j.brainres.2007.03.008.
   COURCHESNE E, 1975, ELECTROEN CLIN NEURO, V39, P131, DOI 10.1016/0013-4694(75)90003-6.
   Daltrozzo J, 2007, ARCH SEX BEHAV, V36, P555, DOI 10.1007/s10508-006-9161-0.
   Dambacher M, 2006, BRAIN RES, V1084, P89, DOI 10.1016/j.brainres.2006.02.010.
   Debener S, 2005, COGNITIVE BRAIN RES, V22, P309, DOI 10.1016/j.cogbrainres.2004.09.006.
   Deldin P, 2006, BIOL PSYCHOL, V71, P74, DOI 10.1016/j.biopsycho.2005.02.005.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Delong KA, 2011, PSYCHOPHYSIOLOGY, V48, P1203, DOI 10.1111/j.1469-8986.2011.01199.x.
   Diaz MT, 2007, BRAIN RES, V1146, P85, DOI 10.1016/j.brainres.2006.07.034.
   Dien J, 2004, PSYCHOPHYSIOLOGY, V41, P665, DOI 10.1111/j.1469-8986.2004.00193.x.
   DONCHIN E, 1981, PSYCHOPHYSIOLOGY, V18, P493, DOI 10.1111/j.1469-8986.1981.tb01815.x.
   DONCHIN E, 1988, BEHAV BRAIN SCI, V11, P357, DOI 10.1017/S0140525X00058027.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Federmeier KD, 1999, COGNITIVE BRAIN RES, V8, P373, DOI 10.1016/S0926-6410(99)00036-1.
   Federmeier KD, 2005, MEM COGNITION, V33, P871, DOI 10.3758/BF03193082.
   Federmeier KD, 2005, PSYCHOPHYSIOLOGY, V42, P133, DOI 10.1111/j.1469-8986.2005.00274.x.
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133.
   FISCHLER IS, 1985, MEM COGNITION, V13, P128, DOI 10.3758/BF03197005.
   Folstein JR, 2008, PSYCHOPHYSIOLOGY, V45, P152, DOI 10.1111/j.1469-8986.2007.00602.x.
   Folstein JR, 2011, PSYCHOPHYSIOLOGY, V48, P825, DOI 10.1111/j.1469-8986.2010.01146.x.
   FORSTER KI, 1981, Q J EXP PSYCHOL-A, V33, P465, DOI 10.1080/14640748108400804.
   Friederici AD, 1996, J EXP PSYCHOL LEARN, V22, P1219, DOI 10.1037/0278-7393.22.5.1219.
   Friederici AD, 1999, MEM COGNITION, V27, P438, DOI 10.3758/BF03211539.
   FRIEDERICI AD, 1993, COGNITIVE BRAIN RES, V1, P183, DOI 10.1016/0926-6410(93)90026-2.
   Friederici AD, 2001, COGNITIVE BRAIN RES, V11, P305, DOI 10.1016/S0926-6410(00)00065-3.
   Friedman D, 2001, NEUROSCI BIOBEHAV R, V25, P355, DOI 10.1016/S0149-7634(01)00019-7.
   Ganis G, 1996, J COGNITIVE NEUROSCI, V8, P89, DOI 10.1162/jocn.1996.8.2.89.
   Goldstein A, 2002, PSYCHOPHYSIOLOGY, V39, P781, DOI 10.1017/S004857720201048X.
   Grose-Fifer J, 2011, PSYCHOPHYSIOLOGY, V48, P1184, DOI 10.1111/j.1469-8986.2011.01197.x.
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386.
   GUNTER TC, 1992, PSYCHOPHYSIOLOGY, V29, P38, DOI 10.1111/j.1469-8986.1992.tb02009.x.
   Gunter TC, 1997, PSYCHOPHYSIOLOGY, V34, P660, DOI 10.1111/j.1469-8986.1997.tb02142.x.
   Hagoort P, 2000, NEUROPSYCHOLOGIA, V38, P1518, DOI 10.1016/S0028-3932(00)00052-X.
   HAGOORT P, 1993, LANG COGNITIVE PROC, V8, P439, DOI 10.1080/01690969308407585.
   Hagoort P, 2007, PHILOS T R SOC B, V362, P801, DOI 10.1098/rstb.2007.2089.
   Hahne A, 1999, J COGNITIVE NEUROSCI, V11, P194, DOI 10.1162/089892999563328.
   Hoeks JCJ, 2004, COGNITIVE BRAIN RES, V19, P59, DOI 10.1016/j.cogbrainres.2003.10.022.
   HOLCOMB PJ, 1991, PSYCHOBIOLOGY, V19, P286.
   HORST RL, 1980, MEM COGNITION, V8, P476, DOI 10.3758/BF03211144.
   Jackendoff R., 2002, FDN LANGUAGE.
   Johnson BW, 2000, CLIN NEUROPHYSIOL, V111, P532, DOI 10.1016/S1388-2457(99)00270-9.
   Johnson Jr R, 1988, ADV PSYCHOPHYSIOLOGY, V3, P69.
   JOHNSON R, 1980, PSYCHOPHYSIOLOGY, V17, P167, DOI 10.1111/j.1469-8986.1980.tb00131.x.
   Juottonen K, 1996, COGNITIVE BRAIN RES, V4, P99.
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084.
   Kazmerski VA, 1997, COGNITIVE BRAIN RES, V5, P255, DOI 10.1016/S0926-6410(97)00004-9.
   Kim A, 2005, J MEM LANG, V52, P205, DOI 10.1016/j.jml.2004.10.002.
   KINTSCH W, 1988, PSYCHOL REV, V95, P163, DOI 10.1037/0033-295X.95.2.163.
   Kolk HHJ, 2003, BRAIN LANG, V85, P1, DOI 10.1016/S0093-934X(02)00548-5.
   Kuo TY, 2008, NEUROPSYCHOLOGIA, V46, P2243, DOI 10.1016/j.neuropsychologia.2008.02.018.
   Kuo TY, 2006, J COGNITIVE NEUROSCI, V18, P1133, DOI 10.1162/jocn.2006.18.7.1133.
   Kuperberg GR, 2007, BRAIN RES, V1146, P23, DOI 10.1016/j.brainres.2006.12.063.
   Kuperberg GR, 2003, COGNITIVE BRAIN RES, V17, P117, DOI 10.1016/S0926-6410(03)00086-7.
   KUTAS M, 1988, BRAIN, V111, P553, DOI 10.1093/brain/111.3.553.
   KUTAS M, 1983, MEM COGNITION, V11, P539, DOI 10.3758/BF03196991.
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657.
   KUTAS M, 1977, SCIENCE, V197, P792, DOI 10.1126/science.887923.
   KUTAS M, 1980, BIOL PSYCHOL, V11, P99, DOI 10.1016/0301-0511(80)90046-0.
   KUTAS M, 1993, LANG COGNITIVE PROC, V8, P533, DOI 10.1080/01690969308407587.
   Kutas M, 1987, Electroencephalogr Clin Neurophysiol Suppl, V40, P406.
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0.
   Kutas M., 2006, HDB PSYCHOLINGUISTIC, V2, P659, DOI DOI 10.1016/B978-012369374-7/50018-3.
   Kutas M., 1984, PREPARATORY STATES P, P217.
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123.
   Laszlo S, 2008, PSYCHOPHYSIOLOGY, V45, P458, DOI 10.1111/j.1469-8986.2007.00636.x.
   Leon I, 2010, EMOTION, V10, P863, DOI 10.1037/a0019983.
   Matsuki K, 2011, J EXP PSYCHOL LEARN, V37, P913, DOI 10.1037/a0022964.
   MCCALLUM WC, 1984, ELECTROEN CLIN NEURO, V59, P477, DOI 10.1016/0168-5597(84)90006-6.
   McKinnon R, 1996, LANG COGNITIVE PROC, V11, P495, DOI 10.1080/016909696387132.
   MILLER GA, 1963, J VERB LEARN VERB BE, V2, P217, DOI 10.1016/S0022-5371(63)80087-0.
   MITCHELL PF, 1993, PSYCHOPHYSIOLOGY, V30, P496, DOI 10.1111/j.1469-8986.1993.tb02073.x.
   Moreno EM, 2005, COGNITIVE BRAIN RES, V22, P205, DOI 10.1016/j.cogbrainres.2004.08.010.
   Moreno EM, 2002, BRAIN LANG, V80, P188, DOI 10.1006/brln.2001.2588.
   MOSS HE, 1993, J EXP PSYCHOL LEARN, V19, P1254, DOI 10.1037/0278-7393.19.6.1254.
   MUNTE TF, 1993, J COGNITIVE NEUROSCI, V5, P335, DOI 10.1162/jocn.1993.5.3.335.
   MUNTE TF, 1994, COGNITIVE ELECTROPHY, P211.
   Neath I., 2003, HUMAN MEMORY, P68.
   Nebes R D, 1986, Psychol Aging, V1, P261, DOI 10.1037/0882-7974.1.3.261.
   Newman RL, 2004, COGNITIVE BRAIN RES, V21, P94, DOI 10.1016/j.cogbrainres.2004.05.006.
   NIGAM A, 1992, J COGNITIVE NEUROSCI, V4, P15, DOI 10.1162/jocn.1992.4.1.15.
   Nixon SJ, 2002, PROG NEURO-PSYCHOPH, V26, P919, DOI 10.1016/S0278-5846(02)00206-3.
   NOBRE AC, 1994, J COGNITIVE NEUROSCI, V6, P233, DOI 10.1162/jocn.1994.6.3.233.
   O'Rourke PL, 2011, BRAIN RES, V1392, P62, DOI 10.1016/j.brainres.2011.03.071.
   Osterhout L, 1999, LANG COGNITIVE PROC, V14, P1, DOI 10.1080/016909699386356.
   OSTERHOUT L, 1992, J MEM LANG, V31, P785, DOI 10.1016/0749-596X(92)90039-Z.
   OSTERHOUT L, 1994, J EXP PSYCHOL LEARN, V20, P786, DOI 10.1037/0278-7393.20.4.786.
   Osterhout L, 1995, J MEM LANG, V34, P739, DOI 10.1006/jmla.1995.1033.
   Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463.
   PALLER KA, 1995, PSYCHOL SCI, V6, P107, DOI 10.1111/j.1467-9280.1995.tb00315.x.
   Phillips C, 2005, COGNITIVE BRAIN RES, V22, P407, DOI 10.1016/j.cogbrainres.2004.09.012.
   Pijnacker J, 2010, NEUROPSYCHOLOGIA, V48, P2940, DOI 10.1016/j.neuropsychologia.2010.06.003.
   Polich J, 2003, BRAIN TOPOGR, V15, P141, DOI 10.1023/A:1022637732495.
   POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160.
   Revonsuo A, 1998, J COGNITIVE NEUROSCI, V10, P408, DOI 10.1162/089892998562726.
   Robichon F, 2002, BIOL PSYCHOL, V59, P29, DOI 10.1016/S0301-0511(01)00118-1.
   Rubin SR, 1999, COGN NEUROPSYCHOL, V16, P459, DOI 10.1080/026432999380889.
   RUCHKIN DS, 1975, PSYCHOPHYSIOLOGY, V12, P591, DOI 10.1111/j.1469-8986.1975.tb00052.x.
   RUCHKIN DS, 1973, B PSYCHONOMIC SOC, V2, P144.
   Ruchsow M, 2003, SCHIZOPHR RES, V64, P147, DOI 10.1016/S0920-9964(02)00482-6.
   Ruchsow M, 2008, J PSYCHOPHYSIOL, V22, P121, DOI 10.1027/0269-8803.22.3.121.
   Sanford AJ, 2011, J COGNITIVE NEUROSCI, V23, P514, DOI 10.1162/jocn.2009.21370.
   SCHWANENFLUGEL PJ, 1988, J EXP PSYCHOL LEARN, V14, P344, DOI 10.1037/0278-7393.14.2.344.
   SCHWANENFLUGEL PJ, 1985, J MEM LANG, V24, P232, DOI 10.1016/0749-596X(85)90026-9.
   Sedivy JC, 1999, COGNITION, V71, P109, DOI 10.1016/S0010-0277(99)00025-6.
   SEIDENBERG MS, 1982, COGNITIVE PSYCHOL, V14, P489, DOI 10.1016/0010-0285(82)90017-2.
   Senkfor AJ, 1998, J EXP PSYCHOL LEARN, V24, P1005, DOI 10.1037/0278-7393.24.4.1005.
   Spencer KM, 2001, PSYCHOPHYSIOLOGY, V38, P343, DOI 10.1111/1469-8986.3820343.
   Spencer KM, 1999, PSYCHOPHYSIOLOGY, V36, P409, DOI 10.1017/S0048577299981180.
   SQUIRES K, 1977, PERCEPT PSYCHOPHYS, V22, P31, DOI 10.3758/BF03206077.
   SQUIRES KC, 1976, SCIENCE, V193, P1142, DOI 10.1126/science.959831.
   SQUIRES NK, 1975, ELECTROEN CLIN NEURO, V38, P387, DOI 10.1016/0013-4694(75)90263-1.
   STANOVICH KE, 1981, J EXP PSYCHOL HUMAN, V7, P658.
   STANOVICH KE, 1983, J EXP PSYCHOL GEN, V112, P1, DOI 10.1037/0096-3445.112.1.1.
   SUTTON S, 1967, SCIENCE, V155, P1436, DOI 10.1126/science.155.3768.1436.
   Swaab T, 1997, J COGNITIVE NEUROSCI, V9, P39, DOI 10.1162/jocn.1997.9.1.39.
   Tabossi P., 1991, UNDERSTANDING WORD S, V77, P1.
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863.
   Thornhill D.E., LEXICAL VERSUS UNPUB.
   Traxler MJ, 2000, J EXP PSYCHOL LEARN, V26, P1266, DOI 10.1037//0278-7393.26.5.1266.
   TULVING E, 1963, J EXP PSYCHOL, V66, P319, DOI 10.1037/h0048802.
   TYLER LK, 1983, PERCEPT PSYCHOPHYS, V34, P409, DOI 10.3758/BF03203056.
   van Berkum JJA, 1999, J COGNITIVE NEUROSCI, V11, P657, DOI 10.1162/089892999563724.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   van den Brink D, 2006, J EXP PSYCHOL LEARN, V32, P364, DOI 10.1037/0278-7393.32.3.364.
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872.
   van Herten M, 2005, COGNITIVE BRAIN RES, V22, P241, DOI 10.1016/j.cogbrainres.2004.09.002.
   van Herten M, 2006, J COGNITIVE NEUROSCI, V18, P1181, DOI 10.1162/jocn.2006.18.7.1181.
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394.
   Van Petten C, 2006, BRAIN LANG, V97, P279, DOI 10.1016/j.bandl.2005.11.003.
   VANPETTEN C, 1993, LANG COGNITIVE PROC, V8, P485, DOI 10.1080/01690969308407586.
   VanPetten C, 1996, PSYCHOPHYSIOLOGY, V33, P491.
   VANPETTEN C, 1995, PSYCHOPHYSIOLOGY, V32, P511.
   VANPETTEN C, 1990, MEM COGNITION, V18, P380, DOI 10.3758/BF03197127.
   VANPETTEN C, 1991, MEM COGNITION, V19, P95, DOI 10.3758/BF03198500.
   VANPETTEN C, 1991, UNDERSTANDING WORD S, P129, DOI DOI 10.1016/S0166-4115(08)61532-0.
   Vissers CTWM, 2006, BRAIN RES, V1106, P150, DOI 10.1016/j.brainres.2006.05.012.
   WEST RF, 1982, J EXP PSYCHOL LEARN, V8, P385, DOI 10.1037/0278-7393.8.5.385.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   Wlotko EW, 2007, NEUROPSYCHOLOGIA, V45, P3001, DOI 10.1016/j.neuropsychologia.2007.05.013.
   WOODWARD SH, 1993, ELECTROEN CLIN NEURO, V87, P306, DOI 10.1016/0013-4694(93)90184-W.}},
Number-of-Cited-References = {{163}},
Times-Cited = {{328}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{92}},
Journal-ISO = {{Int. J. Psychophysiol.}},
Doc-Delivery-Number = {{921ZW}},
Unique-ID = {{ISI:000302517600007}},
DA = {{2020-12-06}},
}

@article{ ISI:000305902900007,
Author = {Chen, Fei},
Title = {{Predicting the Intelligibility of Cochlear-implant Vocoded Speech from
   Objective Quality Measure}},
Journal = {{JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING}},
Year = {{2012}},
Volume = {{32}},
Number = {{3}},
Pages = {{189-193}},
Abstract = {{A reliable measure for predicting the intelligibility of
   cochlear-implant vocoded speech is desirable as it can be used to guide
   the development of new speech coding algorithms for cochlear implants.
   The present study assesses the perfomiance of several speech quality
   measures in predicting the intelligibility of cochlear-implant vocoded
   speech (vocoded English and vocoded Mandarin Chinese). The quality
   measures are analyzed and correlated with the intelligibility scores of
   vocoded speech obtained from normal-hearing listeners in three
   experiments. The perceptual evaluation of speech quality measure (r =
   0.91) and the weighted spectral slope measure (r = -0.87) are well
   correlated with the intelligibility score. The language effect impacts
   the performance of objective quality measures in predicting the
   intelligibility of vocoded speech.}},
Publisher = {{SPRINGER HEIDELBERG}},
Address = {{TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chen, F (Corresponding Author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.
   Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.}},
DOI = {{10.5405/jmbe.885}},
ISSN = {{1609-0985}},
EISSN = {{2199-4757}},
Keywords = {{Vocoded speech; Speech quality measure; Intelligibility prediction}},
Keywords-Plus = {{RECOGNITION}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Biomedical}},
Author-Email = {{fxc091000@utdallas.edu}},
ResearcherID-Numbers = {{Chen, Fei/G-4674-2018
   Chen, Fei/AAK-6755-2020}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Cited-References = {{{[}Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225.
   BLADON RAW, 1981, J ACOUST SOC AM, V69, P1414, DOI 10.1121/1.385824.
   Chen F, 2011, EAR HEARING, V32, P331, DOI 10.1097/AUD.0b013e3181ff3515.
   Chen F, 2011, J ACOUST SOC AM, V129, P3281, DOI 10.1121/1.3570957.
   Chen F, 2010, EAR HEARING, V31, P259, DOI 10.1097/AUD.0b013e3181c7db17.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Gantz BJ, 2003, LARYNGOSCOPE, V113, P1726, DOI 10.1097/00005537-200310000-00012.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   Hansen J. H. L., 1998, P INT C SPOK LANG PR, V7, P2819.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   ITU, 2000, PERC EV SPEECH QUAL, P862.
   Klatt D. H., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1278.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Loizou PC, 1999, IEEE ENG MED BIOL, V18, P32, DOI 10.1109/51.740962.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Qin MK, 2006, J ACOUST SOC AM, V119, P2417, DOI 10.1121/1.2178719.
   Quackenbush S., 1988, OBJECTIVE MEASURES S.
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023.
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303.
   {*}TIGERSPEECH TECHN, INN SPEECH SOFTW.
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405.
   Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{J. Med. Biol. Eng.}},
Doc-Delivery-Number = {{967JI}},
Unique-ID = {{ISI:000305902900007}},
DA = {{2020-12-06}},
}

@article{ ISI:000296698900005,
Author = {Lee, Saebyeok and Lim, Heuiseok},
Title = {{Brain-Operated Typewriter using the Language Prediction Model}},
Journal = {{KSII TRANSACTIONS ON INTERNET AND INFORMATION SYSTEMS}},
Year = {{2011}},
Volume = {{5}},
Number = {{10}},
Pages = {{1770-1782}},
Month = {{OCT 31}},
Abstract = {{A brain-computer interface (BCI) is a communication system that
   translates brain activity into commands for computers or other devices.
   In other words, BCIs create a new communication channel between the
   brain and an output device by bypassing conventional motor output
   pathways consisting of nerves and muscles. This is particularly useful
   for facilitating communication for people suffering from paralysis. Due
   to the low bit rate, it takes much more time to translate brain activity
   into commands. Especially it takes much time to input characters by
   using BCI-based typewriters. In this paper, we propose a brain-operated
   typewriter which is accelerated by a language prediction model. The
   proposed system uses three kinds of strategies to improve the entry
   speed: word completion, next-syllable prediction, and next word
   prediction. We found that the entry speed of BCI-based typewriter
   improved about twice as much through our demonstration which utilized
   the language prediction model.}},
Publisher = {{KSII-KOR SOC INTERNET INFORMATION}},
Address = {{KOR SCI \& TECHNOL CTR, 409 ON 4TH FLR, MAIN BLDG, 635-4 YEOKSAM 1-DONG,
   GANGNAM-GU, SEOUL 00000, SOUTH KOREA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lim, H (Corresponding Author), Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
   Lee, Saebyeok; Lim, Heuiseok, Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.}},
DOI = {{10.3837/tiis.2011.10.005}},
ISSN = {{1976-7277}},
Keywords = {{Language prediction model; brain-computer interface; Korean typewriter}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{saebyeok@blp.korea.ac.kr
   limhseok@korea.ac.kr}},
Funding-Acknowledgement = {{National Research Foundation of Korea (NRF)National Research Foundation
   of Korea; Korea governmentKorean Government {[}2011-0018014]}},
Funding-Text = {{The part of this paper was presented in the ICONI (International
   Conference on Internet) 2010, December 16-20, 2010, Philippines. This
   version includes a concrete analysis and supporting implementation
   results. This work was supported by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (No. 2011-0018014).}},
Cited-References = {{Andrea K., 2008, BRAIN COMPUTER INTER.
   Black Michael J., 2008, BRAIN COMPUTER INTER.
   Cecotti H., 2010, P 5 FRENCH C COMP NE.
   Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125.
   Dornhege G., 2004, NEURAL INFORM PROCES.
   {*}EM SYST, EM BRAIN COMP INT TE.
   Farwell L. A., 1988, ELECTROENCEPHALOGRAP, V70.
   Hayashi H., 1989, J NEUROLOGICAL SCI, V93.
   Lebedev M. A., 2006, TRENDS NEUROSCIENCES, V29.
   Liang N., 2008, P 4 INT BRAIN COMP I.
   Manning C.D., 1999, FDN STAT NATURAL LAN.
   McFarland DJ, 2003, BIOL PSYCHOL, V63, P237, DOI 10.1016/S0301-0511(03)00073-5.
   NeuroSky Inc, NEUROSKY WHAT WE DO.
   OBERMAIER B, 2001, IEEE T NEURAL SYSTEM, V9.
   Ramoser H., 1998, IEEE T REHABILITATIO, V8.
   Szafir Daniel J., 2010, THESIS BOSTON COLL.
   Taylor Dawn M., 2008, BRAIN COMPUTER INTER.
   Wikipedia, LANG MOD WIK FREE EN.
   Williamson J., 2009, INT J HUMAN COMPUTER, V67.
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3.
   Wolpaw JR, 2004, PNAS, V101.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{KSII Trans. Internet Inf. Syst.}},
Doc-Delivery-Number = {{843UM}},
Unique-ID = {{ISI:000296698900005}},
DA = {{2020-12-06}},
}

@article{ ISI:000295107800019,
Author = {Chen, Fei},
Title = {{The relative importance of temporal envelope information for
   intelligibility prediction: A study on cochlear-implant vocoded speech}},
Journal = {{MEDICAL ENGINEERING \& PHYSICS}},
Year = {{2011}},
Volume = {{33}},
Number = {{8}},
Pages = {{1033-1038}},
Month = {{OCT}},
Abstract = {{Vocoder simulation has been long applied as an effective tool to assess
   factors influencing the intelligibility of cochlear implants listeners.
   Considering that the temporal envelope information contained in
   contiguous bands of vocoded speech is correlated and redundant, this
   study examined the hypothesis that the intelligibility measure
   evaluating the distortions from a small number of selected envelope cues
   is sufficient to well predict the intelligibility scores. The speech
   intelligibility data from 80 conditions was collected from vocoder
   simulation experiments involving 22 normal-hearing listeners. The
   relative importance of temporal envelope information in cochlear-implant
   vocoded speech was modeled by correlating its speech-transmission
   indices (STIs) with the intelligibility scores. The relative importance
   pattern was subsequently utilized to determine a binary weight vector
   for STIs of all envelopes to compute the index predicting the speech
   intelligibility. A high correlation (r=0.95) was obtained when selecting
   a small number (e.g., 4 out of 20) of temporal envelope cues from
   disjoint bands to predict the intelligibility of cochlear-implant
   vocoded speech. (C) 2011 IPEM. Published by Elsevier Ltd. All rights
   reserved.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chen, F (Corresponding Author), Univ Texas Dallas, Dept Elect Engn, 800 W Campbell Rd, Richardson, TX 75083 USA.
   Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.}},
DOI = {{10.1016/j.medengphy.2011.04.004}},
ISSN = {{1350-4533}},
EISSN = {{1873-4030}},
Keywords = {{Cochlear implants; Vocoded speech; Speech intelligibility prediction}},
Keywords-Plus = {{RECOGNITION; CHANNELS; NUMBER; NOISE; COMPRESSION; HEARING; CUES}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Biomedical}},
Author-Email = {{fchen@utdallas.edu}},
ResearcherID-Numbers = {{Chen, Fei/G-4674-2018
   Chen, Fei/AAK-6755-2020}},
ORCID-Numbers = {{Chen, Fei/0000-0002-6988-492X
   Chen, Fei/0000-0002-6988-492X}},
Cited-References = {{American national standard institute, 1997, METH CALC SPEECH INT.
   {[}Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225.
   Apoux F, 2004, J ACOUST SOC AM, V116, P1671, DOI 10.1121/1.1781329.
   Chen F, 2011, EAR HEARING, V32, P331, DOI 10.1097/AUD.0b013e3181ff3515.
   Chen F, 2010, EAR HEARING, V31, P259, DOI 10.1097/AUD.0b013e3181c7db17.
   Crouzet O, 2001, WORKSH CONS REL AC C.
   Doherty KA, 1996, J ACOUST SOC AM, V100, P3769, DOI 10.1121/1.417336.
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603.
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550.
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052.
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354.
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224.
   Husch H, 2001, J ACOUST SOC AM, V109, P2896, DOI 10.1121/1.1371971.
   Kasturi K, 2002, J ACOUST SOC AM, V112, P1102, DOI 10.1121/1.1498855.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Qin MK, 2006, J ACOUST SOC AM, V119, P2417, DOI 10.1121/1.2178719.
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023.
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199.
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303.
   Steeneken HJM, 1999, SPEECH COMMUN, V28, P109, DOI 10.1016/S0167-6393(99)00007-2.
   Steeneken HJM, 2002, SPEECH COMMUN, V38, P413, DOI 10.1016/S0167-6393(02)00010-9.
   Stone MA, 2003, J ACOUST SOC AM, V114, P1023, DOI 10.1121/1.1592160.
   Stone MA, 2004, J ACOUST SOC AM, V116, P2311, DOI 10.1121/1.1784447.
   Stone MA, 2008, J ACOUST SOC AM, V124, P2272, DOI 10.1121/1.2968678.
   Stone MA, 2007, J ACOUST SOC AM, V121, P1654, DOI 10.1121/1.2434754.
   Whitmal NA, 2007, J ACOUST SOC AM, V122, P2376, DOI 10.1121/1.2773993.
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Med. Eng. Phys.}},
Doc-Delivery-Number = {{823FL}},
Unique-ID = {{ISI:000295107800019}},
DA = {{2020-12-06}},
}

@article{ ISI:000293734500024,
Author = {Taal, Cees H. and Hendriks, Richard C. and Heusdens, Richard and Jensen,
   Jesper},
Title = {{An Algorithm for Intelligibility Prediction of Time-Frequency Weighted
   Noisy Speech}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2011}},
Volume = {{19}},
Number = {{7}},
Pages = {{2125-2136}},
Month = {{SEP}},
Abstract = {{In the development process of noise-reduction algorithms, an objective
   machine-driven intelligibility measure which shows high correlation with
   speech intelligibility is of great interest. Besides reducing time and
   costs compared to real listening experiments, an objective
   intelligibility measure could also help provide answers on how to
   improve the intelligibility of noisy unprocessed speech. In this paper,
   a short-time objective intelligibility measure (STOI) is presented,
   which shows high correlation with the intelligibility of noisy and
   time-frequency weighted noisy speech (e.g., resulting from noise
   reduction) of three different listening experiments. In general, STOI
   showed better correlation with speech intelligibility compared to five
   other reference objective intelligibility models. In contrast to other
   conventional intelligibility models which tend to rely on global
   statistics across entire sentences, STOI is based on shorter time
   segments (386 ms). Experiments indeed show that it is beneficial to take
   segment lengths of this order into account. In addition, a free Matlab
   implementation is provided.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Taal, CH (Corresponding Author), Delft Univ Technol, Signal Informat \& Proc Lab, NL-2628 CD Delft, Netherlands.
   Taal, Cees H.; Hendriks, Richard C.; Heusdens, Richard; Jensen, Jesper, Delft Univ Technol, Signal Informat \& Proc Lab, NL-2628 CD Delft, Netherlands.}},
DOI = {{10.1109/TASL.2011.2114881}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{Noise reduction; objective measure; speech enhancement; speech
   intelligibility prediction}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{c.h.taal@tudelft.nl}},
Funding-Acknowledgement = {{Oticon foundation; Dutch Technology Foundation STWTechnologiestichting
   STW}},
Funding-Text = {{Manuscript received August 24, 2010; revised November 30, 2010; accepted
   February 04, 2011. Date of publication February 14, 2011; date of
   current version July 22, 2011. This work was supported by the Oticon
   foundation and the Dutch Technology Foundation STW. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Malcolm Slaney.}},
Cited-References = {{ANSI, 1997, S351997 ANSI.
   Arai T, 1999, J ACOUST SOC AM, V105, P2783, DOI 10.1121/1.426895.
   Boldt Jesper B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1849.
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929.
   Christiansen C, 2010, SPEECH COMMUN, V52, P678, DOI 10.1016/j.specom.2010.03.004.
   Dau T, 1996, J ACOUST SOC AM, V99, P3623, DOI 10.1121/1.414960.
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959.
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836.
   Dubbelboer F, 2008, J ACOUST SOC AM, V124, P3937, DOI 10.1121/1.3001713.
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453.
   Erkelens JS, 2007, IEEE T AUDIO SPEECH, V15, P1741, DOI 10.1109/TASL.2007.899233.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   Goldsworthy RL, 2004, J ACOUST SOC AM, V116, P3679, DOI 10.1121/1.1804628.
   Hendriks RC, 2010, INT CONF ACOUST SPEE, P4266, DOI 10.1109/ICASSP.2010.5495680.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Hu Y, 2007, J ACOUST SOC AM, V122, P1777, DOI 10.1121/1.2766778.
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575.
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673.
   Koch R., 1992, THESIS U GOTTINGEN G.
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1689, DOI 10.1121/1.1909094.
   Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617.
   Loizou P. C., 2007, SPEECH ENHANCEMENT T.
   LUDVIGSEN C, 1993, SCAND AUDIOL, V22, P50.
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493.
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915.
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713.
   Schlesinger A, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1309.
   Sheskin D., 2004, HDB PARAMETRIC NONPA.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   Taal C. H., 2009, P INTERSPEECH, P1947.
   VANDENBRINK G, 1964, J ACOUST SOC AM, V36, P1206, DOI 10.1121/1.1919184.
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080.
   Zhang Z, 2008, PROCEEDINGS OF THE 11TH JOINT CONFERENCE ON INFORMATION SCIENCES.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{654}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{46}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{805NL}},
Unique-ID = {{ISI:000293734500024}},
DA = {{2020-12-06}},
}

@article{ ISI:000284571300001,
Author = {Federmeier, Kara D. and Kutas, Marta and Schul, Rina},
Title = {{Age-related and individual differences in the use of prediction during
   language comprehension}},
Journal = {{BRAIN AND LANGUAGE}},
Year = {{2010}},
Volume = {{115}},
Number = {{3}},
Pages = {{149-161}},
Month = {{DEC}},
Abstract = {{During sentence comprehension older adults are less likely than younger
   adults to predict features of likely upcoming words A pair of
   experiments assessed whether such differences would extend to tasks with
   reduced working memory demands and time pressures In Experiment 1
   event-related brain potentials were measured as younger and older adults
   read short phrases cuing antonyms or category exem plars followed three
   seconds later by targets that were either congruent or incongruent and
   for congruent category exemplars of higher or lower typicality When
   processing the less expected low typicality targets younger - but not
   older - adults elicited a prefrontal positivity (500-900 ms) that has
   been linked to processing consequences of having predictions
   disconfirmed Thus age-related changes in prediction during comprehension
   generalize across task circumstances Analyses of individual differences
   revealed that older adults with higher category fluency were more likely
   to show the young like pattern Experiment 2 showed that these
   age-related differences were not due to simple slowing of language
   production mechanisms as older adults generated overt responses to the
   cues as quickly as - and more accurately than - younger adults However
   older adults who were relatively faster to produce category exemplars in
   Experiment 2 were more likely to have shown predictive processing
   patterns in Experiment 1 Taken together the results link prediction
   during language comprehension to language production mechanisms and
   suggest that although older adults can produce speeded language output
   on demand they are less likely to automatically recruit these mechanisms
   during comprehension unless top-down circuitry is particularly strong
   (C) 2010 Elsevier Inc All rights reserved}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Federmeier, KD (Corresponding Author), UIUC, Dept Psychol, 603 E Daniel St, Champaign, IL 61820 USA.
   Federmeier, Kara D., Univ Illinois, Dept Psychol, Program Neurosci, Champaign, IL 61820 USA.
   Federmeier, Kara D., Univ Illinois, Beckman Inst Adv Sci \& Technol, Champaign, IL 61820 USA.
   Kutas, Marta, Univ Calif San Diego, Dept Cognit Sci \& Neurosci, Ctr Res Language, San Diego, CA 92103 USA.
   Kutas, Marta, Univ Calif San Diego, Kavli Inst Brain \& Mind, San Diego, CA 92103 USA.
   Schul, Rina, Univ Calif San Diego, Dept Psychiat, San Diego, CA 92103 USA.
   Schul, Rina, Univ Calif San Diego, Counseling \& Psychol Serv, San Diego, CA 92103 USA.}},
DOI = {{10.1016/j.bandl.2010.07.006}},
ISSN = {{0093-934X}},
EISSN = {{1090-2155}},
Keywords = {{Aging; Language comprehension; Language production; Prediction; Category
   exemplar generation; Event related brain potentials; N400; Frontal
   positivity; Verbal fluency}},
Keywords-Plus = {{VISUAL WORD IDENTIFICATION; ADULT LIFE-SPAN; OLDER-ADULTS;
   WORKING-MEMORY; COGNITIVE FUNCTIONS; CATEGORY NORMS; CONTEXT; YOUNG;
   TASK; RECRUITMENT}},
Research-Areas = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences \&
   Neurology; Psychology}},
Web-of-Science-Categories  = {{Audiology \& Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental}},
ORCID-Numbers = {{Federmeier, Kara/0000-0002-7815-1808}},
Funding-Acknowledgement = {{NIAUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)
   {[}AG026308, AG08313]; NICHDUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health \& Human Development (NICHD)
   {[}HD22614]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH
   \& HUMAN DEVELOPMENTUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health \& Human Development (NICHD)
   {[}R01HD022614, R01HD022614, R01HD022614, R01HD022614, R01HD022614,
   R01HD022614, R01HD022614, R01HD022614] Funding Source: NIH RePORTER;
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH \&HUMAN
   DEVELOPMENTUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health \& Human Development (NICHD) {[}R01HD022614,
   R01HD022614, R01HD022614, R01HD022614, R01HD022614, R01HD022614,
   R01HD022614, R01HD022614, R01HD022614, R01HD022614, R01HD022614,
   R01HD022614, R01HD022614, R01HD022614, R01HD022614, R01HD022614,
   R01HD022614, R01HD022614, R01HD022614, R01HD022614, R01HD022614,
   R01HD022614, R01HD022614, R01HD022614] Funding Source: NIH RePORTER;
   NATIONAL INSTITUTE ON AGINGUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Aging (NIA) {[}R01AG008313, R01AG008313, R01AG026308, R01AG008313,
   R01AG026308, R01AG026308, R01AG008313, R01AG008313, R01AG026308,
   R01AG026308, R01AG026308, R01AG008313, R01AG008313, R01AG008313,
   R01AG026308, R01AG026308, R01AG008313, R01AG026308, R01AG026308,
   R01AG008313, R01AG008313, R01AG008313, R01AG026308, R01AG026308,
   R01AG008313, R01AG008313, R01AG008313] Funding Source: NIH RePORTER}},
Funding-Text = {{This work was supported by NIA Grant AG026308 to K D F and NIA Grant
   AG08313 and NICHD Grant HD22614 to M K We thank Charlene Lee for help
   with data processing}},
Cited-References = {{Ackerman PL, 1999, PSYCHOL AGING, V14, P314, DOI 10.1037/0882-7974.14.2.314.
   Baltes PB, 1997, PSYCHOL AGING, V12, P12, DOI 10.1037/0882-7974.12.1.12.
   BATTIG WF, 1969, J EXP PSYCHOL, V80, P1, DOI 10.1037/h0027577.
   Benton A, 1978, MULTILINGUAL APHASIA.
   BOWLES NL, 1983, EXP AGING RES, V9, P175, DOI 10.1080/03610738308258448.
   Burke D M, 1986, Psychol Aging, V1, P283, DOI 10.1037/0882-7974.1.4.283.
   Burke D. M., 2008, HDB AGING COGNITION, P373.
   BURKE DM, 1987, J EXP PSYCHOL HUMAN, V13, P79, DOI 10.1037/0096-1523.13.1.79.
   CRAIK FIM, 1987, J EXP PSYCHOL LEARN, V13, P474, DOI 10.1037/0278-7393.13.3.474.
   Dagerman KS, 2006, COGNITIVE SCI, V30, P311, DOI 10.1207/s15516709cog0000\_46.
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6.
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504.
   Double KL, 1996, NEUROBIOL AGING, V17, P513.
   Dunn LM, 1997, PEABODY PICTURE VOCA.
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660.
   Federmeier KD, 1999, COGNITIVE BRAIN RES, V8, P373, DOI 10.1016/S0926-6410(99)00036-1.
   Federmeier KD, 2005, PSYCHOPHYSIOLOGY, V42, P133, DOI 10.1111/j.1469-8986.2005.00274.x.
   Federmeier KD, 2003, PSYCHOL AGING, V18, P858, DOI 10.1037/0882-7974.18.4.858.
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133.
   FOZARD JL, 1994, J GERONTOL, V49, pP179, DOI 10.1093/geronj/49.4.P179.
   Francis W., 1982, FREQUENCY ANAL ENGLI.
   FULLER MKP, 1995, J ACOUST SOC AM, V97, P593.
   Gourovitch ML, 2000, NEUROPSYCHOLOGY, V14, P353, DOI 10.1037//0894-4105.14.3.353.
   Grossman M, 2002, BRAIN LANG, V80, P296, DOI 10.1006/brln.2001.2581.
   GUNTER TC, 1992, PSYCHOPHYSIOLOGY, V29, P38, DOI 10.1111/j.1469-8986.1992.tb02009.x.
   GUNTER TC, 1995, PSYCHOPHYSIOLOGY, V32, P215, DOI 10.1111/j.1469-8986.1995.tb02951.x.
   Heinze HJ, 1998, BIOL PSYCHOL, V47, P121, DOI 10.1016/S0301-0511(97)00024-0.
   HORN JL, 1967, ACTA PSYCHOL, V26, P107, DOI 10.1016/0001-6918(67)90011-X.
   HOWARD DV, 1981, J GERONTOL, V36, P707, DOI 10.1093/geronj/36.6.707.
   HOWARD DV, 1980, J GERONTOL, V35, P225, DOI 10.1093/geronj/35.2.225.
   Hunt K. P., 1971, PSYCHONOMIC MONOGR S, V4, P97.
   IRAGUI VJ, 1993, PSYCHOPHYSIOLOGY, V30, P10, DOI 10.1111/j.1469-8986.1993.tb03200.x.
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6.
   KUTAS M, 1982, NEUROPSYCHOLOGIA, V20, P579, DOI 10.1016/0028-3932(82)90031-8.
   Kutas M, 1998, EVOKED POTENTIAL, V108, P456, DOI 10.1016/S0168-5597(98)00023-9.
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004.
   LIGHT LL, 1985, J GERONTOL, V40, P737, DOI 10.1093/geronj/40.6.737.
   LIGHT LL, 1991, ANNU REV PSYCHOL, V42, P333, DOI 10.1146/annurev.ps.42.020191.002001.
   Logan JM, 2002, NEURON, V33, P827, DOI 10.1016/S0896-6273(02)00612-8.
   LOVELACE EA, 1982, J GERONTOL, V37, P432, DOI 10.1093/geronj/37.4.432.
   Madden DJ, 1996, NEUROIMAGE, V3, P127, DOI 10.1006/nimg.1996.0015.
   Madden DJ, 2002, BRAIN COGNITION, V49, P297, DOI 10.1006/brcg.2001.1502.
   Mattis S, 1976, GERIATRIC PSYCHIAT, P77.
   MCEVOY CL, 1982, AM J PSYCHOL, V95, P581, DOI 10.2307/1422189.
   MORROW EAL, 1999, J GERONTOL B-PSYCHOL, V54, P125.
   Nelson D. L., 1998, U S FLORIDA WORD ASS.
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4.
   Park DC, 2002, PSYCHOL AGING, V17, P299, DOI 10.1037//0882-7974.17.2.299.
   Persson J, 2004, NEUROIMAGE, V23, P1382, DOI 10.1016/j.neuroimage.2004.08.004.
   PETRIDES M, 1982, NEUROPSYCHOLOGIA, V20, P249, DOI 10.1016/0028-3932(82)90100-2.
   Pfefferbaum A, 2005, NEUROIMAGE, V26, P891, DOI 10.1016/j.neuroimage.2005.02.034.
   Raz N, 2005, CEREB CORTEX, V15, P1676, DOI 10.1093/cercor/bhi044.
   Resnick SM, 2003, J NEUROSCI, V23, P3295.
   Roe K, 2000, MEM COGNITION, V28, P756, DOI 10.3758/BF03198410.
   Ronnlund M, 2005, PSYCHOL AGING, V20, P3, DOI 10.1037/0882-7974.20.1.3.
   Salthouse TA., 1991, THEORETICAL PERSPECT.
   Shapiro S. I., 1970, PSYCHON MONOGR, V3, P107.
   Spencer WD, 1995, PSYCHOL AGING, V10, P527, DOI 10.1037/0882-7974.10.4.527.
   Tombaugh TN, 1999, ARCH CLIN NEUROPSYCH, V14, P167, DOI 10.1016/S0887-6177(97)00095-4.
   Uttl B, 2002, J CLIN EXP NEUROPSYC, V24, P1123, DOI 10.1076/jcen.24.8.1123.8375.
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443.
   Verhaeghen P, 2003, PSYCHOL AGING, V18, P443, DOI 10.1037/0882-7974.18.3.443.
   Verhaeghen P, 2003, PSYCHOL AGING, V18, P332, DOI 10.1037/0882-7974.18.2.332.
   Verhaeghen P., 2008, HDB COGNITIVE AGING, P134, DOI DOI 10.4135/9781412976589.N8.
   Wechsler D, 1981, WECHSLER ADULT INTEL.
   West RL, 1996, PSYCHOL BULL, V120, P272, DOI 10.1037/0033-2909.120.2.272.
   Whiting WL, 2007, PSYCHOL AGING, V22, P223, DOI 10.1037/0882-7974.22.2.223.
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487.
   WINGFIELD A, 1988, EXP AGING RES, V14, P103, DOI 10.1080/03610738808259731.
   Zelinski EM, 2003, PSYCHOL AGING, V18, P727, DOI 10.1037/0882-7974.18.4.727.}},
Number-of-Cited-References = {{72}},
Times-Cited = {{122}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{31}},
Journal-ISO = {{Brain Lang.}},
Doc-Delivery-Number = {{684TD}},
Unique-ID = {{ISI:000284571300001}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000288376900005,
Author = {Nakatani, Tomohiro and Yoshioka, Takuya and Kinoshita, Keisuke and
   Miyoshi, Masato and Juang, Biing-Hwang},
Title = {{Speech Dereverberation Based on Variance-Normalized Delayed Linear
   Prediction}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2010}},
Volume = {{18}},
Number = {{7}},
Pages = {{1717-1731}},
Month = {{SEP}},
Abstract = {{This paper proposes a statistical model-based speech dereverberation
   approach that can cancel the late reverberation of a reverberant speech
   signal captured by distant microphones without prior knowledge of the
   room impulse responses. With this approach, the generative model of the
   captured signal is composed of a source process, which is assumed to be
   a Gaussian process with a time-varying variance, and an observation
   process modeled by a delayed linear prediction (DLP). The optimization
   objective for the dereverberation problem is derived to be the sum of
   the squared prediction errors normalized by the source variances; hence,
   this approach is referred to as variance-normalized delayed linear
   prediction (NDLP). Inheriting the characteristic of DLP, NDLP can
   robustly estimate an inverse system for late reverberation in the
   presence of noise without greatly distorting a direct speech signal. In
   addition, owing to the use of variance normalization, NDLP allows us to
   improve the dereverberation result especially with relatively short (of
   the order of a few seconds) observations. Furthermore, NDLP can be
   implemented in a computationally efficient manner in the time-frequency
   domain. Experimental results demonstrate the effectiveness and
   efficiency of the proposed approach in comparison with two existing
   approaches.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Nakatani, T (Corresponding Author), NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan.
   Nakatani, Tomohiro; Yoshioka, Takuya; Kinoshita, Keisuke, NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan.
   Miyoshi, Masato, Kanazawa Univ, Grad Sch Nat Sci \& Technol, Kanazawa, Ishikawa 9201192, Japan.
   Juang, Biing-Hwang, Georgia Inst Technol, Sch Elect \& Comp Engn, Atlanta, GA 30332 USA.}},
DOI = {{10.1109/TASL.2010.2052251}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{Dereverberation; inverse filtering; multichannel linear prediction;
   speech enhancement; statistical model-based signal processing}},
Keywords-Plus = {{MULTICHANNEL BLIND DECONVOLUTION; SUPPRESSION}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{nak@cslab.kecl.ntt.co.jp
   takuya@cslab.kecl.ntt.co.jp
   ki-noshita@cslab.kecl.ntt.co.jp
   mmiyoshi@t.kanazawa-u.ac.jp
   juang@ece.gatech.edu}},
ORCID-Numbers = {{Nakatani, Tomohiro/0000-0002-7487-7150}},
Cited-References = {{AbedMeraim K, 1997, IEEE T SIGNAL PROCES, V45, P694, DOI 10.1109/78.558487.
   Douglas SC, 2003, SPEECH COMMUN, V39, P65, DOI 10.1016/S0167-6393(02)00059-6.
   Elko GW, 2000, SPRING INT SER ENG C, V551, P181.
   FLANAGAN JL, 1985, J ACOUST SOC AM, V78, P1508, DOI 10.1121/1.392786.
   FURUI S, 2001, DIGITAL SPEECH PROCE.
   Furuya K, 2007, IEEE T AUDIO SPEECH, V15, P1579, DOI 10.1109/TASL.2007.898456.
   Gannot S, 2003, EURASIP J APPL SIG P, V2003, P1074, DOI 10.1155/S1110865703305049.
   Gesbert D, 1997, INT CONF ACOUST SPEE, P3621, DOI 10.1109/ICASSP.1997.604650.
   Gillespie BW, 2001, INT CONF ACOUST SPEE, P3701, DOI 10.1109/ICASSP.2001.940646.
   GURELLI MI, 1995, IEEE T SIGNAL PROCES, V43, P134, DOI 10.1109/78.365293.
   Habets EAP, 2005, INT CONF ACOUST SPEE, P173.
   Hikichi T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/34013.
   HUANG YT, 2006, INT CONF ACOUST SPEE, P25.
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Miyoshi M., 2003, P ICA 03, P585.
   NAKATANI T, 2008, P IWAENC 08.
   Nakatani T, 2008, IEEE T AUDIO SPEECH, V16, P1512, DOI 10.1109/TASL.2008.2004306.
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552.
   NAYLOR P, 2005, P IWAENC 05.
   SLOCK DTM, 1994, INT CONF ACOUST SPEE, P585.
   TRIKI M, 2005, P ICASSP 05, V5, P97.
   Unoki M., 2003, P IEEE INT C AC SPEE, P840.
   Weiss S, 2000, ELECTRON LETT, V36, P1502, DOI 10.1049/el:20001068.
   Yoshioka Takuya, 2009, 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P145, DOI 10.1109/ASPAA.2009.5346489.
   YOSHIOKA T, 2008, P EUSIPCO 08.
   Yoshioka T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/65698.
   Yoshioka T, 2009, INT CONF ACOUST SPEE, P3733, DOI 10.1109/ICASSP.2009.4960438.
   Yoshioka T, 2009, IEEE T AUDIO SPEECH, V17, P231, DOI 10.1109/TASL.2008.2008042.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{116}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{734XU}},
Unique-ID = {{ISI:000288376900005}},
DA = {{2020-12-06}},
}

@article{ ISI:000280919700009,
Author = {Cidota, Marina-Anca},
Title = {{Choosing the parameters of the NARMA model implemented with the
   recurrent perceptron for speech prediction}},
Journal = {{NEURAL COMPUTING \& APPLICATIONS}},
Year = {{2010}},
Volume = {{19}},
Number = {{6}},
Pages = {{903-910}},
Month = {{SEP}},
Abstract = {{Speech signals have statistically nonstationary properties and cannot be
   processed properly by means of classical linear parametric models (AR,
   MA, ARMA). The neural network approach to time series prediction is
   suitable for learning and recognizing the nonlinear nature of the speech
   signal. We present a neural implementation of the NARMA model (nonlinear
   ARMA) and test it on a class of speech signals, spoken by both men and
   women in different dialects of the English language. The Akaike's
   information criterion is proposed for the selection of the parameters of
   the NARMA model.}},
Publisher = {{SPRINGER LONDON LTD}},
Address = {{236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cidota, MA (Corresponding Author), Univ Bucharest, Bucharest, Romania.
   Univ Bucharest, Bucharest, Romania.}},
DOI = {{10.1007/s00521-010-0375-7}},
ISSN = {{0941-0643}},
EISSN = {{1433-3058}},
Keywords = {{Prediction; NARMA model; Recurrent perceptron; AIC criterion}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{cidota@fmi.unibuc.ro}},
Cited-References = {{Akaike H., 1973, 2 INT S INF THEOR, P267, DOI DOI 10.1007/978-1-4612-1694-0\_15.
   Brockwell P., 1987, TIME SERIES THEORY M.
   Catlin D. E., 1989, ESTIMATION CONTROL D.
   Hamilton J.D., 1994, TIME SERIES ANAL.
   Mandic DP, 2001, ADAPT LEARN SYST SIG.
   Singhal S., 1989, ADV NEURAL INFORMATI, P133.
   Welch G., 2001, INTRO KALMAN FILTER.
   Young S, 2001, HTK BOOK.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Neural Comput. Appl.}},
Doc-Delivery-Number = {{638TQ}},
Unique-ID = {{ISI:000280919700009}},
DA = {{2020-12-06}},
}

@article{ ISI:000282562000009,
Author = {Wang, Gang and Li, Chunguang and Dong, Le},
Title = {{Noise Estimation Using Mean Square Cross Prediction Error for Speech
   Enhancement}},
Journal = {{IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS}},
Year = {{2010}},
Volume = {{57}},
Number = {{7}},
Pages = {{1489-1499}},
Month = {{JUL}},
Abstract = {{This paper shows the feasibility of noise extraction from noisy speech
   and presents a two-stage approach for speech enhancement. The
   preproposed mean square cross prediction error (MSCPE) based blind
   source extraction algorithm is utilized to extract the additive noise
   from the noisy speech signal in the first stage. After that a modified
   spectral subtraction and a modified Wiener filter approach are proposed
   to extract the speech signal for speech enhancement in the second stage,
   where all the frequency spectra of the extracted noise are utilized.
   Theoretical justification shows that the MSCPE-based algorithm can
   extract desired signal from mixed sources. Experimental results show
   that the averaged correlation coefficient between the extracted noise
   and the original additive noise are beyond 85\% for Gaussian noise and
   beyond 75\% for real-world noise at SNR = 0 dB, and the proposed speech
   enhancement approaches perform better than conventional methods, such as
   spectral subtraction and Wiener filter.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wang, G (Corresponding Author), Univ Elect Sci \& Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
   Wang, Gang, Univ Elect Sci \& Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
   Li, Chunguang, Zhejiang Univ, Dept Informat Sci \& Elect Engn, Hangzhou 310027, Peoples R China.
   Dong, Le, Univ Elect Sci \& Technol China, Sch Comp Sci \& Engn, Inst Intelligent Syst \& Informat Technol, Chengdu 610054, Peoples R China.}},
DOI = {{10.1109/TCSI.2010.2054930}},
ISSN = {{1549-8328}},
EISSN = {{1558-0806}},
Keywords = {{Autoregressive (AR) parameter; blind source extraction (BSE); mean
   square cross prediction error (MSCPE); spectral subtraction (SS); speech
   enhancement; Wiener filter (WF)}},
Keywords-Plus = {{EXTRACTION}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{wanggang\_hld@hotmail.com
   cgli@zju.edu.cn
   ledongisi@gmail.com}},
ResearcherID-Numbers = {{Li, Chunguang/F-1458-2016}},
ORCID-Numbers = {{Li, Chunguang/0000-0003-3147-1553}},
Funding-Acknowledgement = {{National Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) {[}30900318, 60871094]}},
Funding-Text = {{Manuscript received July 31, 2009; revised March 26, 2010 and May 23,
   2010; accepted May 25, 2010. Date of current version July 16, 2010. This
   work was supported by National Science Foundation of China under Grants
   30900318 and 60871094. This paper was recommended by Associate Editor A.
   Uncini.}},
Cited-References = {{Barros AK, 2001, NEURAL COMPUT, V13, P1995, DOI 10.1162/089976601750399272.
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   BREITHAUPT C, 2003, P INT C AC SPEECH SI, V1, P896.
   Cichocki A, 1997, ELECTRON LETT, V33, P64, DOI 10.1049/el:19970060.
   CICHOCKI A, 2003, ADAPTIVE BLIND SIGNA.
   Ephraim Y., 2005, ELECT HDB.
   Gazor S, 2005, IEEE T SPEECH AUDI P, V13, P896, DOI 10.1109/TSA.2005.851943.
   He C, 1999, INT CONF ACOUST SPEE, P793, DOI 10.1109/ICASSP.1999.759790.
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054.
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006.
   Hyvarinen A, 1999, NEURAL COMPUT, V11, P1739, DOI 10.1162/089976699300016214.
   HYVARINEN A, 2003, INDEPEDENT COMPONENT.
   Kamath S, 2002, INT CONF ACOUST SPEE, P4164.
   Lee JH, 2000, ELECTRON LETT, V36, P1506, DOI 10.1049/el:20001028.
   LETTER T, 2005, EURASIP J APPL SIG P, V7, P1110.
   Lev-Ari H, 2003, IEEE SIGNAL PROC LET, V10, P104, DOI 10.1109/LSP.2003.808544.
   LIM JS, 1979, P IEEE, V67, P1586, DOI 10.1109/PROC.1979.11540.
   Liu H, 2007, IET SOFTW, V1, P29, DOI 10.1049/iet-sen:20060023.
   Liu W, 2006, IEEE T CIRCUITS-II, V53, P931, DOI 10.1109/TCSII.2006.881815.
   Martin R, 2005, IEEE T SPEECH AUDI P, V13, P845, DOI 10.1109/TSA.2005.851927.
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915.
   Rezayee A, 2001, IEEE T SPEECH AUDI P, V9, P87, DOI 10.1109/89.902276.
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233.
   Soon IY, 2000, IEE P-VIS IMAGE SIGN, V147, P247, DOI 10.1049/ip-vis:20000323.
   Wang G, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/728409.
   Zou X, 2008, IEEE T SIGNAL PROCES, V56, P1812, DOI 10.1109/TSP.2007.910555.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{15}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{IEEE Trans. Circuits Syst. I-Regul. Pap.}},
Doc-Delivery-Number = {{659JE}},
Unique-ID = {{ISI:000282562000009}},
DA = {{2020-12-06}},
}

@article{ ISI:000271445100001,
Author = {Garay-Vitoria, Nestor and Abascal, Julio},
Title = {{Modelling text prediction systems in low- and high-inflected languages}},
Journal = {{COMPUTER SPEECH AND LANGUAGE}},
Year = {{2010}},
Volume = {{24}},
Number = {{2}},
Pages = {{117-135}},
Month = {{APR}},
Abstract = {{Text prediction was initially proposed to help people with a low text
   composition speed to enhance their message composition. After the
   important advancements obtained in the last years, text prediction
   methods may nowadays benefit anyone trying to input text messages or
   commands, if they are adequately integrated within the user interface of
   the application. Diverse text prediction methods are based in different
   statistic and linguistic properties of natural languages. Hence, they
   are very dependent oil the language concerned. In order to discuss
   general issues of text prediction it is necessary to propose abstract
   descriptions of the methods used. In this paper a number of models
   applied to text prediction are presented. Some of them are oriented to
   low-inflected languages while others are for high-inflected languages.
   All these models have been implemented and their results are compared.
   Presented models may be useful for future discussion. Finally, some
   comments related to the comparison of previously published results are
   also done. (C) 2009 Elsevier Ltd. All rights reserved.}},
Publisher = {{ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD}},
Address = {{24-28 OVAL RD, LONDON NW1 7DX, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Garay-Vitoria, N (Corresponding Author), Univ Basque Country, Lab Human Comp Interact Special Needs, Manuel Lardizabal 1, E-20018 Donostia San Sebastian, Spain.
   Garay-Vitoria, Nestor; Abascal, Julio, Univ Basque Country, Lab Human Comp Interact Special Needs, E-20018 Donostia San Sebastian, Spain.}},
DOI = {{10.1016/j.csl.2009.03.008}},
ISSN = {{0885-2308}},
Keywords = {{Text prediction; Anticipative interfaces; Prediction models;
   Communication speed enhancement; Prediction measures}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{nestor.garay@ehu.es
   julio.abascal@ehu.es}},
ResearcherID-Numbers = {{Garay-Vitoria, Nestor/G-4984-2010
   Garay-Vitoria, Nestor/V-4808-2019
   Abascal, Julio/B-1194-2014}},
ORCID-Numbers = {{Garay-Vitoria, Nestor/0000-0002-1561-4799
   Garay-Vitoria, Nestor/0000-0002-1561-4799
   Abascal, Julio/0000-0002-6551-1616}},
Cited-References = {{Abascal J, 2004, LECT NOTES COMPUT SC, V3118, P788.
   AGIRRE E, 1992, P 3 C APPL NAT LANG, P119.
   ALLEN J, 1995, NATURAL LANGUAGE UND.
   ALM N, 1992, COMMUN ACM, V35, P46.
   Arnott J., 1992, AUGMENT ALTERN COMM, V8, P215.
   Beck C, 2004, LECT NOTES COMPUT SC, V3118, P813.
   BERTENSTAM J, 1995, ASSIST TECHN RES SER, V1, P312.
   Carlberger A., 1997, P ACL WORKSH NAT LAN, P23.
   CARLBERGER J, 1997, THESIS KTH STOCKHOLM.
   COPESTAKE A, 1997, P ACL WORKSH NAT LAN, P37.
   COPESTAKE A, 1998, IS 98 RES S P.
   DIGIOVANNI JM, 1996, WORD PREDICTION SOFT.
   GAMYVITORIA N, 2004, P 7 INT C WORK COMP, P77.
   GARAY N, 2002, LECT NOTES ARTIF INT, V2448, P397.
   GARAY N, 1994, INFORMATION SYSTEMS, P223.
   Garay-Vitoria N, 2004, LECT NOTES COMPUT SC, V3196, P400.
   Garay-Vitoria N., 2001, SISTEMAS PREDICCION.
   Garay-Vitoria N, 1995, P 15 INT S HUM FACT, P131.
   GARAYVITORIA N, 2006, INT J UNIVERSAL ACCE, V4, P88.
   GARAYVITORIA N, 1997, P NAT LANG PROC COMM, P29.
   GARAYVITORIA N, 1997, P INT US INT 97 C, P241.
   GARAYVITORIA N, 1994, LNCS, V860, P363.
   HIGGINBOTHAM DJ, 1992, AUGMENTATIVE ALTERNA, V8, P258, DOI DOI 10.1080/07434619212331276303.
   HUNNICUTT S, 1989, P EUR C SPEECH COMM, V1, P191.
   Hunnicutt S., 2003, 5 INT S LANG LOG COM.
   HUNNICUTT S, 1987, 231987 STLQPRS, P15.
   Koester H. H., 1994, IEEE Transactions on Rehabilitation Engineering, V2, P177, DOI 10.1109/86.331567.
   MAGNUSON T, 1995, ASSIST TECHN RES SER, V1, P320.
   NEWELL AF, 1992, AUGMENTATIVE ALTERNA, V8, P89.
   Swiffin A. L., 1987, RESNA `87: Meeting the Challenge. Proceedings of the 10th Annual Conference on Rehabilitation Technology, P124.
   Swiffin AL, 1987, AUGMENTATIVE ALTERNA, V3, P181.
   VANDYKE JA, 1991, THESIS U DELAWARE.
   VAYRYNEN P, 2005, THESIS U OULU FINLAN.
   VENKATAGIRI, 1993, AUGMENTATIVE ALTERNA, V9, P161.
   Wood Matthew E. J., 1996, THESIS U BRISTOL.
   WOOD MEJ, 1993, P EUR SPEECH COMM AS, P115.
   Zordell J., 1990, CLOSING GAP, V9, P10.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Comput. Speech Lang.}},
Doc-Delivery-Number = {{515CV}},
Unique-ID = {{ISI:000271445100001}},
DA = {{2020-12-06}},
}

@article{ ISI:000272764100002,
Author = {Hanson, Elizabeth K. and Beukelman, David R. and Heidemann, Jana Kahl
   and Shutts-Johnson, Erin},
Title = {{The impact of alphabet supplementation and word prediction on sentence
   intelligiblity of electronically distorted speech}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2010}},
Volume = {{52}},
Number = {{2}},
Pages = {{99-105}},
Month = {{FEB}},
Abstract = {{Alphabet supplementation is a low-tech augmentative and alternative
   communication (AAC) strategy that involves pointing to the first letter
   of each word spoken. Sentence intelligibility scores increased an
   average of 25\% (Hanson et al., 2004) when speakers with moderate and
   severe dysarthria (a neurologic speech impairment) used alphabet
   supplementation strategies. This project investigated the impact of both
   alphabet supplementation and ail electronic word prediction strategy,
   commonly used in augmentative and alternative communication technology,
   oil the sentence intelligibility of normal natural speech that was
   electronically distorted to reduce intelligibility to the profound range
   of <30\%. Results demonstrated large sentence intelligibility increases
   (average 80\% increase) when distorted speech was supplemented with
   alphabet supplementation and word prediction. (C) 2009 Elsevier B.V. All
   rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hanson, EK (Corresponding Author), Univ S Dakota, Dept Commun Disorders, 414 E Clark St, Vermillion, SD 57069 USA.
   Hanson, Elizabeth K., Univ S Dakota, Dept Commun Disorders, Vermillion, SD 57069 USA.
   Beukelman, David R., Univ Nebraska, Barkley Mem Ctr 202, Lincoln, NE 68583 USA.}},
DOI = {{10.1016/j.specom.2009.08.004}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Alphabet supplementation; Word prediction; Language modeling; Speech
   intelligibility; Speech-generating device; SGD; Prototype; Dysarthria;
   AAC; Augmentative and alternative communication}},
Keywords-Plus = {{SEVERELY DYSARTHRIC SPEECH; STIMULUS COHESION; COMPRESSED SPEECH;
   LINGUISTIC CUES; ADAPTATION}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{ekhanson@usd.edu
   dbeukelma-n1@unl.edu}},
Funding-Acknowledgement = {{National Institute of Disability and Rehabilitation Research {[}H113
   980026]; US Department of EducationUS Department of Education}},
Funding-Text = {{This publication was produced in part under Grant \#H113\#980026 from
   the National Institute of Disability and Rehabilitation Research, US
   Department of Education. The opinions expressed in this publication are
   those of the grantee and do not necessarily reflect those of NID-RR or
   the Department of Education.}},
Cited-References = {{BELIVEAU C, 1995, AUGMENTATIVE ALTERNA, V11, P176.
   BERGER K, 1968, J COMMUN DISORD, V1, P201, DOI 10.1016/0021-9924(68)90032-4.
   BEUKELMAN DR, 1977, J SPEECH HEAR DISORD, V42, P265, DOI 10.1044/jshd.4202.265.
   Beukelman DR, 2002, J MED SPEECH-LANG PA, V10, P237.
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131.
   CROW E, 1989, RECENT ADV CLIN DYSA.
   DARLEY FL, 1969, J SPEECH HEAR RES, V12, P462, DOI 10.1044/jshr.1203.462.
   DePaul R, 2000, AM J SPEECH-LANG PAT, V9, P230, DOI 10.1044/1058-0360.0903.230.
   Dowden P. A, 1997, AUGMENTATIVE ALTERNA, V13, P48, DOI DOI 10.1080/07434619712331277838.
   Dupoux E, 1997, J EXP PSYCHOL HUMAN, V23, P914, DOI 10.1037/0096-1523.23.3.914.
   Hanson EK, 2004, J MED SPEECH-LANG PA, V12, pIX.
   HANSON EK, 2008, C MOT SPEECH MONT CA.
   Hustad KC, 2008, J SPEECH LANG HEAR R, V51, P1438, DOI 10.1044/1092-4388(2008/07-0185).
   Hustad KC, 2003, J SPEECH LANG HEAR R, V46, P462, DOI 10.1044/1092-4388(2003/038).
   Hustad KC, 2002, J SPEECH LANG HEAR R, V45, P545, DOI 10.1044/1092-4388(2002/043).
   Hustad KC, 2001, J SPEECH LANG HEAR R, V44, P497, DOI 10.1044/1092-4388(2001/039).
   HUSTAD KC, 2001, AUGMENTATIVE ALTERNA, V17, P213, DOI DOI 10.1080/AAC.17.4.213.220.
   KING D, 2004, SPEAKING DYNAMICALLY.
   LINDBLOM B, 1990, AAC (Augmentative and Alternative Communication), V6, P220, DOI 10.1080/07434619012331275504.
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469.
   Peelle JE, 2005, J EXP PSYCHOL HUMAN, V31, P1315, DOI 10.1037/0096-1523.31.6.1315.
   PISONI DB, 1985, SPEECH COMMUN, V4, P75, DOI 10.1016/0167-6393(85)90037-8.
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{532QI}},
Unique-ID = {{ISI:000272764100002}},
DA = {{2020-12-06}},
}

@article{ ISI:000283866800012,
Author = {Misyak, Jennifer B. and Christiansen, Morten H. and Tomblin, J. Bruce},
Title = {{Sequential Expectations: The Role of Prediction-Based Learning in
   Language}},
Journal = {{TOPICS IN COGNITIVE SCIENCE}},
Year = {{2010}},
Volume = {{2}},
Number = {{1}},
Pages = {{138-153}},
Month = {{JAN}},
Abstract = {{Prediction-based processes appear to play an important role in language.
   Few studies, however, have sought to test the relationship within
   individuals between prediction learning and natural language processing.
   This paper builds upon existing statistical learning work using a novel
   paradigm for studying the on-line learning of predictive dependencies.
   Within this paradigm, a new ``prediction task'' is introduced that
   provides a sensitive index of individual differences for developing
   probabilistic sequential expectations. Across three interrelated
   experiments, the prediction task and results thereof are used to bridge
   knowledge of the empirical relation between statistical learning and
   language within the context of nonadjacency processing. We first chart
   the trajectory for learning nonadjacencies, documenting individual
   differences in prediction learning. Subsequent simple recurrent network
   simulations then closely capture human performance patterns in the new
   paradigm. Finally, individual differences in prediction performances are
   shown to strongly correlate with participants' sentence processing of
   complex, long-distance dependencies in natural language.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Misyak, JB (Corresponding Author), Cornell Univ, Dept Psychol, B72 Uris Hall, Ithaca, NY 14853 USA.
   Misyak, Jennifer B.; Christiansen, Morten H., Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA.
   Tomblin, J. Bruce, Univ Iowa, Dept Commun Sci \& Disorders, Iowa City, IA 52242 USA.}},
DOI = {{10.1111/j.1756-8765.2009.01072.x}},
ISSN = {{1756-8757}},
EISSN = {{1756-8765}},
Keywords = {{Prediction; Sentence processing; Language comprehension; Statistical
   learning; Nonadjacent dependencies; Serial reaction time task; Simple
   recurrent network}},
Keywords-Plus = {{INDIVIDUAL-DIFFERENCES; WORKING-MEMORY; ADJACENT; CAPACITY}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{jbm36@cornell.edu}},
Cited-References = {{Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x.
   Christiansen MH, 1999, COGNITIVE SCI, V23, P157, DOI 10.1016/S0364-0213(99)00003-8.
   Christiansen MH, 2009, LANG LEARN, V59, P126, DOI 10.1111/j.1467-9922.2009.00538.x.
   CLEEREMANS A, 1991, J EXP PSYCHOL GEN, V120, P235, DOI 10.1037/0096-3445.120.3.235.
   Conway Ch. M, COGNITION IN PRESS.
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844.
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x.
   FERREIRA F, 1986, J MEM LANG, V25, P348, DOI 10.1016/0749-596X(86)90006-9.
   Gennari SP, 2008, J MEM LANG, V58, P161, DOI 10.1016/j.jml.2007.07.004.
   Gomez RL, 2000, TRENDS COGN SCI, V4, P178, DOI 10.1016/S1364-6613(00)01467-4.
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476.
   Howard JH, 2008, J EXP PSYCHOL LEARN, V34, P1139, DOI 10.1037/a0012797.
   Hunt RH, 2001, J EXP PSYCHOL GEN, V130, P658, DOI 10.1037//0096-3445.130.4.658.
   JUST MA, 1992, PSYCHOL REV, V99, P122, DOI 10.1037/0033-295X.99.1.122.
   JUST MA, 1982, J EXP PSYCHOL GEN, V111, P228, DOI 10.1037/0096-3445.111.2.228.
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x.
   KING J, 1991, J MEM LANG, V30, P580, DOI 10.1016/0749-596X(91)90027-H.
   MacDonald MC, 2002, PSYCHOL REV, V109, P35, DOI 10.1037//0033-295X.109.1.35.
   Misyak J. B., 2007, P 29 ANN COGN SCI SO, P1307.
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2.
   NISSEN MJ, 1987, COGNITIVE PSYCHOL, V19, P1, DOI 10.1016/0010-0285(87)90002-8.
   Onnis L, 2003, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, PTS 1 AND 2, P886.
   Pacton S, 2008, J EXP PSYCHOL LEARN, V34, P80, DOI 10.1037/0278-7393.34.1.80.
   Reali F, 2007, J MEM LANG, V57, P1, DOI 10.1016/j.jml.2006.08.014.
   REBER AS, 1967, J VERB LEARN VERB BE, V6, P855, DOI 10.1016/S0022-5371(67)80149-X.
   Remillard G, 2008, Q J EXP PSYCHOL, V61, P400, DOI 10.1080/17470210701210999.
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243.
   Saffran JR, 2001, J MEM LANG, V44, P493, DOI 10.1006/jmla.2000.2759.
   Thomas KM, 2001, J EXP CHILD PSYCHOL, V79, P364, DOI 10.1006/jecp.2000.2613.
   Van Berkum JJA, 2008, CURR DIR PSYCHOL SCI, V17, P376, DOI 10.1111/j.1467-8721.2008.00609.x.
   Waters GS, 1996, Q J EXP PSYCHOL-A, V49, P51, DOI 10.1080/027249896392801.
   Wells JB, 2009, COGNITIVE PSYCHOL, V58, P250, DOI 10.1016/j.cogpsych.2008.08.002.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{82}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{13}},
Journal-ISO = {{Top. Cogn. Sci.}},
Doc-Delivery-Number = {{675VE}},
Unique-ID = {{ISI:000283866800012}},
DA = {{2020-12-06}},
}

@article{ ISI:000271681800005,
Author = {Binkley, David and Feild, Henry and Lawrie, Dawn and Pighin, Maurizio},
Title = {{Increasing diversity: Natural language measures for software fault
   prediction}},
Journal = {{JOURNAL OF SYSTEMS AND SOFTWARE}},
Year = {{2009}},
Volume = {{82}},
Number = {{11, SI}},
Pages = {{1793-1803}},
Month = {{NOV}},
Abstract = {{While challenging, the ability to predict faulty modules of a program is
   valuable to a software project because it can reduce the cost of
   software development, as well as software maintenance and evolution.
   Three language-processing based measures are introduced and applied to
   the problem of fault prediction. The first measure is based on the usage
   of natural language in a program's identifiers. The second measure
   concerns the conciseness and consistency of identifiers. The third
   measure, referred to as the QALP score, makes use of techniques from
   information retrieval to judge software quality. The QALP score has been
   shown to correlate with human judgments of software quality.
   Two case studies consider the language processing measures applicability
   to fault prediction using two programs (one open source, one
   proprietary). Linear mixed-effects regression models are used to
   identify relationships between defects and the measures. Results, while
   complex, show that language processing measures improve fault
   prediction, especially when used in combination. Overall, the models
   explain one-third and two-thirds of the faults in the two case studies.
   Consistent with other uses of language processing, the value of the
   three measures increases with the size of the program module considered.
   (C) 2009 Elsevier Inc. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE INC}},
Address = {{STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lawrie, D (Corresponding Author), Loyola Coll, Baltimore, MD 21210 USA.
   Binkley, David; Lawrie, Dawn, Loyola Coll, Baltimore, MD 21210 USA.
   Feild, Henry, Univ Massachusetts, Amherst, MA 01003 USA.
   Pighin, Maurizio, Univ Udine, Dept Math \& Comp Sci, I-33100 Udine, Italy.}},
DOI = {{10.1016/j.jss.2009.06.036}},
ISSN = {{0164-1212}},
EISSN = {{1873-1228}},
Keywords = {{Information retrieval; Code comprehension; Fault prediction; Linear
   regression models; Empirical software engineering}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Computer Science, Theory \&
   Methods}},
Author-Email = {{binkley@cs.loyola.edu
   hfeild@cs.umass.edu
   lawrie@cs.loyola.edu
   maurizio.pighin@uniud.it}},
ORCID-Numbers = {{Lawrie, Dawn/0000-0001-7347-7086
   PIGHIN, Maurizio/0000-0002-3836-7380}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}CCR0305330]}},
Funding-Text = {{This work is supported by National Science Foundation Grant CCR0305330.
   The authors wish to thank Tibor Gyimothy's research group for providing
   the Mozilla fault data and the anonymous referees for providing such
   extremely helpful comments.}},
Cited-References = {{Bell Robert M., 2006, P 2006 INT S SOFTW T.
   BENTLEY J, 1986, COMMUN ACM, V29.
   BINKLEY D, 2007, P 2 TEST AC IND C TA.
   Boehm B., 2001, IEEE COMPUTER, V34.
   CHIDAMBER SR, 1994, IEEE T SOFTWARE ENG, V20, P476, DOI 10.1109/32.295895.
   Collard ML, 2003, PROG COMPREHEN, P134.
   CORDES D, 1991, COMPUTER, V24, P52, DOI 10.1109/2.86838.
   DEISSENBOCK F, 2005, P 13 INT WORKSH PROG.
   Feild Henry, 2006, P IASTED INT C SOFTW.
   Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815.
   FERENC R, 2002, IEEE INT C SOFTW MAI.
   Gyimothy T, 2005, IEEE T SOFTWARE ENG, V31, P897, DOI 10.1109/TSE.2005.112.
   KOKOL P, 2001, P 2 AS PAC C QUAL SO.
   KORU G, 2007, IEEE T SOFTWARE ENG, V33.
   LAVRENKO V, 2001, P 24 ANN INT ACM SIG.
   LAWRIE D, 2006, P 2006 IEEE WORKSH S.
   LAWRIE D, 2006, 14 INT C PROGR COMPR.
   Manning C, 2008, INTRO INFORM RETRIEV.
   Marcus A, 2008, IEEE T SOFTWARE ENG, V34, P287, DOI 10.1109/TSE.2007.70768.
   Menzies Tim, 2007, IEEE T SOFTWARE ENG, V33.
   Mitchell TM, 1997, MACHINE LEARNING.
   MOONEN L, 2001, WORK C REV ENG.
   MORRELL C, 1997, AM STAT, V51.
   MUNSON JC, 1992, IEEE T SOFTWARE ENG, V18, P423, DOI 10.1109/32.135775.
   Ott RL, 2001, INTRO STAT METHODS D.
   PORTER AA, 1990, IEEE SOFTWARE, V7, P46, DOI 10.1109/52.50773.
   Salton G., 1983, INTRO MODERN INFORM.
   TIAN J, 1998, SYSTEMS SOFTWARE, V44.
   Verbeke G., 2001, LINEAR MIXED MODELS.
   WHEELER DA, 2005, SLOC COUNT USERS GUI.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{J. Syst. Softw.}},
Doc-Delivery-Number = {{518HN}},
Unique-ID = {{ISI:000271681800005}},
DA = {{2020-12-06}},
}

@article{ ISI:000270630800004,
Author = {Kayasith, Prakasith and Theeramunkong, Thanaruk},
Title = {{Speech confusion index (Phi): A confusion-based speech quality indicator
   and recognition rate prediction for dysarthria}},
Journal = {{COMPUTERS \& MATHEMATICS WITH APPLICATIONS}},
Year = {{2009}},
Volume = {{58}},
Number = {{8}},
Pages = {{1534-1549}},
Month = {{OCT}},
Abstract = {{This paper presents an automated method to help us assess the speech
   quality of a dysarthric speaker, in place of laborious and subjective
   manual methods. The assessment result can be used as a good indicator
   for predicting the accuracy of speech recognition. The so-called speech
   confusion index (Phi) is proposed to measure the speech disorder
   severity of a speaker in terms of how easily his/her speech signal may
   be misrecognized to other unintended words. Based on signal processing
   without any high-level information, the dynamic-time-warping technique
   incorporated with adaptive slope constraint and accumulative mismatch
   score is used to measure a distance between any two speech signals of a
   same word or two different words. Compared to the articulatory and
   intelligibility tests, the proposed indicator was shown to have more
   predictability on the recognition rates obtained from the Hidden Markov
   Model (HMM) and Artificial Neural Networks (ANN). Based on three
   evaluation criteria, namely root-mean-square difference. correlation
   coefficient and rank-order inconsistency, the experimental results on a
   phoneme-balance set showed that P achieved better prediction than both
   articulatory and intelligibility tests. Another experiment on a reduced
   training set is made to investigate the robustness of the proposed
   indicator. Finally, a detailed analysis of speech confusion is done at
   the phoneme level. (C) 2009 Elsevier Ltd. All rights reserved.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Theeramunkong, T (Corresponding Author), Thammasat Univ, Sirindhorn Int Inst Technol, 160 Moo 5,Tivanond Rd, Muang 12000, Pathumthani, Thailand.
   Kayasith, Prakasith; Theeramunkong, Thanaruk, Thammasat Univ, Sirindhorn Int Inst Technol, Muang 12000, Pathumthani, Thailand.
   Kayasith, Prakasith, NSTDA, Natl Elect \& Comp Technol Ctr, Klongluang 12120, Pathumthani, Thailand.}},
DOI = {{10.1016/j.camwa.2009.06.051}},
ISSN = {{0898-1221}},
EISSN = {{1873-7668}},
Keywords = {{Dysarthric speech recognition; Speech assessment; Speech quality index;
   Recognition rate prediction; Speech confusion index}},
Keywords-Plus = {{WORD RECOGNITION; CONSISTENCY; PEOPLE}},
Research-Areas = {{Mathematics}},
Web-of-Science-Categories  = {{Mathematics, Applied}},
Author-Email = {{thanaruk@siit.tu.ac.th}},
Funding-Acknowledgement = {{Royal Golden Jubilee Ph.D. ProgramThailand Research Fund (TRF); Thailand
   Research Fund (TRF)Thailand Research Fund (TRF) {[}PHD/0267/2545]}},
Funding-Text = {{This research is supported by the Royal Golden Jubilee Ph.D. Program,
   Thailand Research Fund (TRF), under the contract number PHD/0267/2545.}},
Cited-References = {{Bernthal J. E., 1993, ARTICULATION PHONOLO.
   BODT M, 2002, J COMMUN DISORD, V35, P283.
   CHAN Y, 1993, COMP ARTICULATION CA.
   Collins M., 1984, J COMMUN DISORD, V5, P159.
   CORMAN T, 1990, INTRO ALGORITHM.
   Darley F., 1975, MOTOR SPEECH DISORDE.
   David H. A., 1988, METHOD PAIRED COMP.
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   DELLER JR, 1991, COMPUT METH PROG BIO, V35, P125, DOI 10.1016/0169-2607(91)90071-Z.
   ENDERBY P, 1980, BRIT J DISORD COMMUN, V15, P165.
   Enderby P.M., 1983, FRENCHAY DYSARTHRIA.
   Ferrier L. J., 1992, J COMPUTER USERS SPE, V8, P33.
   Forrest K., 1997, CLIN MANAGEMENT SENS, P63.
   Green P., 2003, P 8 EUR C SPEECH COM, P1189.
   HARDY J, 1983, CEREBRAL PALSY.
   Hawley M., 2002, BRIT J OCCUPATIONAL, V65, P15, DOI DOI 10.1177/030802260206500104.
   Hawley MS, 2007, MED ENG PHYS, V29, P586, DOI 10.1016/j.medengphy.2006.06.009.
   Hawley MS, 2006, LECT NOTES COMPUT SC, V4061, P882.
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641.
   KAYASITH P, 2005, US THAIL S BIOM ENG.
   Kayasith P, 2006, LECT NOTES ARTIF INT, V4139, P604.
   Kayasith P, 2006, LECT NOTES ARTIF INT, V4099, P885.
   Kent R. D., 1994, AM J SPEECH-LANG PAT, V3, P81, DOI DOI 10.1044/1058-0360.0302.81.
   KENT RD, 1996, AM J SPEECH-LANG PAT, V7, P7.
   KOTLER A, 1997, J AUGMENTATIVE ALTER, V12, P71.
   LUKSANEEYANAWIN S, 1993, P S NAT LANG PROC TH, P276.
   MANOCHIOPINIG S, 2007, I CREATE 07, P153.
   Manochiopinig S, 2008, DISABIL REHABIL-ASSI, V3, P332, DOI 10.1080/17483100802281368.
   Markov K, 2006, SPEECH COMMUN, V48, P161, DOI 10.1016/j.specom.2005.07.003.
   Mermelstein P., 1976, PATTERN RECOGN, P374.
   Power MH, 1996, J ACOUST SOC AM, V100, P3882, DOI 10.1121/1.417243.
   ROSEN K, 2000, J AUGMENTATIVE ALTER, V16, P46.
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055.
   SHRIBERG L, 1982, J SPEECH HEAR DISORD, V47, P70.
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P708, DOI 10.1044/jslhr.4004.708.
   THUBTHONG N, 2006, 12 INT SOC AUGMENTAT.
   THUBTHONG N, 2004, 11 INT SOC AUGM ALT.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Comput. Math. Appl.}},
Doc-Delivery-Number = {{504QA}},
Unique-ID = {{ISI:000270630800004}},
DA = {{2020-12-06}},
}

@article{ ISI:000270237400013,
Author = {Lung, For-Wey and Shu, Bih-Ching and Chiang, Tung-Liang and Chen, Po-Fei
   and Lin, Li-Ling},
Title = {{Predictive validity of Bayley scale in language development of children
   at 6-36 months}},
Journal = {{PEDIATRICS INTERNATIONAL}},
Year = {{2009}},
Volume = {{51}},
Number = {{5}},
Pages = {{666-669}},
Month = {{OCT}},
Abstract = {{Background:
   The aim of the present study was to investigate the prediction of
   development among 6-, 18-, and 36-month-old infants on the Bayley Scale
   of Infant Development (BSID).
   Methods:
   One hundred infants were assessed using the BSID at 6 months; of these,
   70 completed the 18 and 36 month assessment at follow up.
   Results:
   Multivariate regression and structural equation modeling were used to
   determine predictive validity in the mental and psychomotor
   developmental scales. Structural equation analysis also confirmed the
   conceptual scheme of the stability of development from 6 to 36 months
   for boys. Boys had a steadier overall developmental trajectory compared
   to girls.
   Conclusions:
   The validity of BSID was consistent with previous studies. The language
   spurt in girls, however, from 6 to 18 months affected the stability of
   the BSID. Thus, the gender difference in language development should be
   considered in clinical assessment.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Shu, BC (Corresponding Author), Natl Cheng Kung Univ, Inst Allied Hlth Sci, 1 Da Hsueh Rd, Tainan 701, Taiwan.
   Lung, For-Wey, Kaohsiung Armed Forces Gen Hosp, Dept Psychiat, Kaohsiung, Taiwan.
   Lung, For-Wey, Kaohsiung Med Univ, Grad Inst Behav Sci, Kaohsiung, Taiwan.
   Lung, For-Wey, Natl Def Med Ctr, Dept Psychiat, Taipei, Taiwan.
   Lung, For-Wey, Calo Psychiat Ctr, Taipei, Pingtung County, Taiwan.
   Shu, Bih-Ching, Natl Cheng Kung Univ, Inst Allied Hlth Sci, Taipei, Taiwan.
   Shu, Bih-Ching, Natl Cheng Kung Univ, Dept Nursing, Taipei, Taiwan.
   Chiang, Tung-Liang, Natl Taiwan Univ, Coll Publ Hlth, Inst Hlth Policy \& Management, Taipei 10764, Taiwan.
   Chen, Po-Fei, Kaohsiung Med Univ, Dept Psychol, Kaohsiung, Taiwan.
   Lin, Li-Ling, Chang Jung Christian Univ, Dept Nursing, Tainan, Taiwan.}},
DOI = {{10.1111/j.1442-200X.2009.02844.x}},
ISSN = {{1328-8067}},
EISSN = {{1442-200X}},
Keywords = {{Bayley Scale of Infant Development; panel study; predictive validity}},
Keywords-Plus = {{HIGH-RISK INFANTS; GENDER-DIFFERENCES; 1ST YEAR; AGE; VALIDATION;
   STABILITY; ABILITY; AUTISM; BIRTH; LIFE}},
Research-Areas = {{Pediatrics}},
Web-of-Science-Categories  = {{Pediatrics}},
Author-Email = {{forweylung@gmail.com}},
ORCID-Numbers = {{CHIANG, TUNG-LIANG/0000-0002-7876-3943}},
Funding-Acknowledgement = {{Bureau of Health Promotion {[}DOH93-HP-1702]}},
Funding-Text = {{This study was supported by a grant from the Bureau of Health Promotion
   (DOH93-HP-1702). The views expressed herein are the authors' own. The
   present study relied on the work of many colleagues. We also thank the
   families who cooperated so generously at all stages of the study.}},
Cited-References = {{Aina OF, 2001, J TROP PEDIATRICS, V47, P323, DOI 10.1093/tropej/47.6.323.
   Andersson HW, 1998, SCAND J PSYCHOL, V39, P267, DOI 10.1111/1467-9450.00086.
   Bayley N., 1993, BAYLEY SCALES INFANT.
   Bayley N, 1969, BAYLEY SCALES INFANT.
   Bornstein MH, 1998, CHILD DEV, V69, P654, DOI 10.2307/1132196.
   Chapman RS, 2000, J CHILD PSYCHOL PSYC, V41, P33, DOI 10.1111/1469-7610.00548.
   CHRISTIANSEN K, 1987, NEUROPSYCHOBIOLOGY, V18, P27, DOI 10.1159/000118389.
   Else-Quest NM, 2006, PSYCHOL BULL, V132, P33, DOI 10.1037/0033-2909.132.1.33.
   Hack M, 2005, PEDIATRICS, V116, P333, DOI 10.1542/peds.2005-0173.
   HARDYBROWN K, 1981, DEV PSYCHOL, V17, P704, DOI 10.1037/0012-1649.17.6.704.
   Harris SR, 2005, DEV MED CHILD NEUROL, V47, P820, DOI 10.1017/S0012162205001738.
   Hazlett HC, 2005, ARCH GEN PSYCHIAT, V62, P1366, DOI 10.1001/archpsyc.62.12.1366.
   HINES M, 1992, BEHAV NEUROSCI, V106, P3, DOI 10.1037/0735-7044.106.1.3.
   Huang Huei-Lin, 2000, Kaohsiung Journal of Medical Sciences, V16, P197.
   Huang Huei-Lin, 2002, Kaohsiung Journal of Medical Sciences, V18, P517.
   HYDE JS, 1988, PSYCHOL BULL, V104, P53, DOI 10.1037/0033-2909.104.1.53.
   Johnson S, 2004, DEV MED CHILD NEUROL, V46, P389, DOI 10.1017/S0012162204000635.
   Niccols A, 2002, BRIT J DEV DISABIL, V48, P3, DOI 10.1179/096979502799104328.
   Reilly S, 2007, PEDIATRICS, V120, pE1441, DOI 10.1542/peds.2007-0045.
   REZNICK J, 1997, MONOGR SOC RES CHILD, V62, P155.
   Van Hulle CA, 2004, J SPEECH LANG HEAR R, V47, P904, DOI 10.1044/1092-4388(2004/067).
   Wu YT, 2008, J PEDIATR PSYCHOL, V33, P102, DOI 10.1093/jpepsy/jsm067.
   Zwaigenbaum L, 2005, INT J DEV NEUROSCI, V23, P143, DOI 10.1016/j.ijdevneu.2004.05.001.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{19}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{Pediatr. Int.}},
Doc-Delivery-Number = {{499PS}},
Unique-ID = {{ISI:000270237400013}},
DA = {{2020-12-06}},
}

@article{ ISI:000269092500015,
Author = {Wang, Hongcui and Waple, Christopher J. and Kawahara, Tatsuya},
Title = {{Computer Assisted Language Learning system based on dynamic question
   generation and error prediction for automatic speech recognition}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2009}},
Volume = {{51}},
Number = {{10, SI}},
Pages = {{995-1005}},
Month = {{OCT}},
Abstract = {{We have developed a new Computer Assisted Language Learning (CALL)
   system to aid students learning Japanese as a second language. The
   system offers students the chance to practice elementary Japanese by
   creating their own sentences based on visual prompts, before receiving
   feedback on their mistakes. It is designed to detect lexical and
   grammatical errors in the input sentence as well as pronunciation errors
   in the speech input. Questions are dynamically generated along with
   sentence patterns of the lesson point, to realize variety and
   flexibility of the lesson. Students can give their answers with either
   text input or speech input. To enhance speech recognition performance, a
   decision tree-based method is incorporated to predict possible errors
   made by non-native speakers for each generated sentence on the fly.
   Trials of the system were conducted by foreign university students, and
   positive feedback was reported. (C) 2009 Elsevier B.V. All rights
   reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wang, HC (Corresponding Author), Kyoto Univ, Sch Informat, Sakyo Ku, Kyoto 6068501, Japan.
   Wang, Hongcui; Waple, Christopher J.; Kawahara, Tatsuya, Kyoto Univ, Sch Informat, Sakyo Ku, Kyoto 6068501, Japan.}},
DOI = {{10.1016/j.specom.2009.03.006}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Computer Assisted Language Learning (CALL); Second language learning;
   Automatic speech recognition; Error prediction}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{wang@ar.media.kyoto-u.ac.jp}},
ResearcherID-Numbers = {{Kawahara, Tatsuya/AAE-4682-2020}},
ORCID-Numbers = {{Kawahara, Tatsuya/0000-0002-2686-2296}},
Funding-Acknowledgement = {{Grants-in-Aid for Scientific ResearchMinistry of Education, Culture,
   Sports, Science and Technology, Japan (MEXT)Japan Society for the
   Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)
   {[}21013028] Funding Source: KAKEN}},
Cited-References = {{ABDOU SM, 2006, P ICSLP.
   Bernstein J., 1999, CALICO Journal, V16, P361.
   ESKENAZI M, 1998, STILL.
   FRANCO H, 2000, P INSTIL INT SPEECH.
   Kawai G, 2000, SPEECH COMMUN, V30, P131, DOI 10.1016/S0167-6393(99)00041-2.
   LEVIE WH, 1982, ECTJ-EDUC COMMUN TEC, V30, P195.
   Nagata N, 2002, COMPUTER ASSISTED SY.
   NELSON DL, 1976, HUMAN LEARNING MEMOR, V2, P523.
   NEUMEYER L, 1998, STILL.
   SMITH MC, 1980, J EXP PSYCHOL GEN, V109, P373, DOI 10.1037/0096-3445.109.4.373.
   Tsubota Y., 2002, P ICSLP, P1205.
   TSUBOTA Y, 2004, P ICSLP, P1689.
   WANG H, 2008, P ICASSP.
   Witt S. M., 1999, THESIS.
   ZINOVJEVA N, 2005, SPEECH TECHNOLOGY.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{485AK}},
Unique-ID = {{ISI:000269092500015}},
DA = {{2020-12-06}},
}

@article{ ISI:000268506800014,
Author = {Ito, Hironori and Ozawa, Kazunori},
Title = {{Low Complexity Speech Mixing with Speech Codecs Based on Predictive
   Coding for Multimedia Conferences}},
Journal = {{IEICE TRANSACTIONS ON COMMUNICATIONS}},
Year = {{2009}},
Volume = {{E92B}},
Number = {{7}},
Pages = {{2477-2483}},
Month = {{JUL}},
Abstract = {{This paper proposes a method of low complexity speech mixing with speech
   codecs based on predictive coding for multimedia conferences. The
   proposed method applies a filter state management (FSM) technique to a
   partial mixing method in order to avoid inconsistency of the filter
   states of encoders. The inconsistency is created by switching of the
   encoders when the speakers to be mixed are switched. The results of
   subjective evaluations of speech quality show that the proposed method
   avoids the inconsistency, and achieves significantly higher speech
   quality than the conventional partial mixing method without the FSM and
   almost the same speech quality as the full mixing method. The complexity
   evaluation results show that the proposed method achieves much lower
   complexity than the full mixing method.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ito, H (Corresponding Author), NEC Corp Ltd, Mobile IP Network Div, Kawasaki, Kanagawa 2118666, Japan.
   Ito, Hironori; Ozawa, Kazunori, NEC Corp Ltd, Mobile IP Network Div, Kawasaki, Kanagawa 2118666, Japan.}},
DOI = {{10.1587/transcom.E92.B.2477}},
ISSN = {{0916-8516}},
EISSN = {{1745-1345}},
Keywords = {{speech mixing; predictive coding and CELP}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{h-ito@df.jp.com}},
Cited-References = {{{*}3GPP TS, 2004, 23228 3GPP TS.
   {*}3GPP TS, 2005, 26090 3GPP TS.
   Hiwasaki Y, 2006, IEICE T INF SYST, VE89D, P2542, DOI 10.1093/ietisy/e89-d.9.2542.
   {*}ITU T, 1988, G711 ITUT.
   {*}ITU T, 2006, P800 ITUT.
   ITU-T, 2001, P862 ITUT.
   SCHROEDER MR, 1985, P IEEE ICASSP TAMP F, V10, P937.
   SERIZAWA M, 2002, P IEEE INT C AC SPEE, V1, P169.
   {*}TIA EIA IS, 1997, TIAEIAIS127.
   {*}TX INSTR, 2006, TMS320C64X C64X DSP.
   Yu KY, 1998, THIRD IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, PROCEEDINGS, P549, DOI 10.1109/ISCC.1998.702591.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Commun.}},
Doc-Delivery-Number = {{477GM}},
Unique-ID = {{ISI:000268506800014}},
DA = {{2020-12-06}},
}

@article{ ISI:000266857700003,
Author = {Gallant, Dorinda J.},
Title = {{Predictive validity evidence for an assessment program based on the Work
   Sampling System in mathematics and language and literacy}},
Journal = {{EARLY CHILDHOOD RESEARCH QUARTERLY}},
Year = {{2009}},
Volume = {{24}},
Number = {{2}},
Pages = {{133-141}},
Month = {{JUN}},
Abstract = {{This study examined the predictive nature of teacher ratings of student
   performance on the mathematical thinking and language and literacy
   domains of a state mandated curriculum-embedded performance assessment
   for children in first grade to student achievement on a
   criterion-referenced test in third grade in mathematics and English
   language arts, using a multilevel modeling approach. The sample included
   1,281 elementary school children nested within 132 classrooms in an
   urban school district in South Carolina. Results showed positive
   associations between first grade teacher ratings and students' third
   grade achievement. However, first grade teacher ratings were not found
   to uniquely contribute to the proportion of explained variance in third
   grade performance on a high-stakes statewide assessment, over and above
   student demographic variables. (C) 2009 Elsevier Inc. All rights
   reserved.}},
Publisher = {{ELSEVIER SCIENCE INC}},
Address = {{STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gallant, DJ (Corresponding Author), Ohio State Univ, Sch Educ Policy \& Leadership, Coll Educ \& Human Ecol, 29 W Woodruff Ave,310B Ramseyer Hall, Columbus, OH 43210 USA.
   Ohio State Univ, Sch Educ Policy \& Leadership, Coll Educ \& Human Ecol, Columbus, OH 43210 USA.}},
DOI = {{10.1016/j.ecresq.2009.03.003}},
ISSN = {{0885-2006}},
EISSN = {{1873-7706}},
Keywords = {{Predictive validity; Teacher ratings; Work Sampling System}},
Keywords-Plus = {{PERFORMANCE ASSESSMENT; ACADEMIC-ACHIEVEMENT; YOUNG-CHILDREN; JUDGMENTS;
   RATINGS}},
Research-Areas = {{Education \& Educational Research; Psychology}},
Web-of-Science-Categories  = {{Education \& Educational Research; Psychology, Developmental}},
Author-Email = {{gallant.32@osu.edu}},
Cited-References = {{{[}Anonymous], 1988, YOUNG CHILDREN, V43, P42.
   {[}Anonymous], 1991, YOUNG CHILDREN, V46, P21.
   Cohen J., 1988, STAT POWER ANAL BEHA.
   DICHTELMILLER ML, 1998, USING WORK SAMPLING.
   Gronlund N.E., 1998, ASSESSMENT STUDENT A.
   Hecht SA, 2001, SCHOOL PSYCHOL REV, V30, P50.
   HOGE RD, 1989, REV EDUC RES, V59, P297, DOI 10.2307/1170184.
   HUYNH H, 2000, TECHNICAL DOCUMENTAT.
   HUYNH H, 2002, TECHNICAL DOCUMENTAT.
   Kim J, 2003, EARLY CHILD RES Q, V18, P547, DOI 10.1016/j.ecresq.2003.09.011.
   MEISELS SJ, 1993, YOUNG CHILDREN, V48, P34.
   MEISELS SJ, 1995, EARLY CHILD RES Q, V10, P277, DOI 10.1016/0885-2006(95)90008-X.
   Meisels SJ, 2001, AM EDUC RES J, V38, P73, DOI 10.3102/00028312038001073.
   MEISELS SJ, 2003, ED POLICY ANAL ARCH, V11.
   National Association for the Education of Young Children, 2003, EARL CHILDH CURR ASS.
   QUAY LC, 1998, EARLY EDUC DEV, V9, P207, DOI DOI 10.1207/S15566935EED09003\_1.
   RAUDENBUSH SW, 2004, HLM 6 0 HIERARCHICAL.
   Raudenbush SW, 2002, HIERARCHICAL LINEAR.
   SCHWEINHART LJ, 1993, YOUNG CHILDREN, V48, P29.
   {*}SPSS INC, 2004, STAT PACK SOC SCI 13.
   STEVENSON HW, 1976, J EDUC PSYCHOL, V68, P507.
   Teale W. H., 1988, ELEMENTARY SCH J, V89, P172.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Early Childhood Res. Q.}},
Doc-Delivery-Number = {{456OY}},
Unique-ID = {{ISI:000266857700003}},
DA = {{2020-12-06}},
}

@article{ ISI:000264416700001,
Author = {Kinoshita, Keisuke and Delcroix, Marc and Nakatani, Tomohiro and
   Miyoshi, Masato},
Title = {{Suppression of Late Reverberation Effect on Speech Signal Using
   Long-Term Multiple-step Linear Prediction}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2009}},
Volume = {{17}},
Number = {{4}},
Pages = {{1-12}},
Month = {{MAY}},
Abstract = {{A speech signal captured by a distant microphone is generally smeared by
   reverberation, which severely degrades automatic speech recognition
   (ASR) performance. One way to solve this problem is to dereverberate the
   observed signal prior to ASR. In this paper, a room impulse response is
   assumed to consist of three parts: a direct-path response, early
   reflections and late reverberations. Since late reverberations are known
   to be a major cause of ASR performance degradation, this paper focuses
   on dealing with the effect of late reverberations. The proposed method
   first estimates the late reverberations using long-term multi-step
   linear prediction, and then reduces the late reverberation effect by
   employing spectral subtraction. The algorithm provided good
   dereverberation with training data corresponding to the duration of one
   speech utterance, in our case, less than 6 s. This paper describes the
   proposed framework for both single-channel and multichannel scenarios.
   Experimental results showed substantial improvements in ASR performance
   with real recordings under severe reverberant conditions.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kinoshita, K (Corresponding Author), NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan.
   Kinoshita, Keisuke; Delcroix, Marc; Nakatani, Tomohiro; Miyoshi, Masato, NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan.}},
DOI = {{10.1109/TASL.2008.2009015}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{Automatic speech recognition (ASR); dereverberation; multi-step linear
   prediction (MSLP); reverberation}},
Keywords-Plus = {{ALGORITHM}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{kinoshita@cslab.kecl.ntt.co.jp
   marc@cslab.kecl.ntt.co.jp
   nak@cslab.kecl.ntt.co.jp
   miyo@cslab.kecl.ntt.co.jp}},
Cited-References = {{ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599.
   ALVAREZ A, 2003, P INT WORKSH AC ECH, V1, P123.
   AYADI J, 1999, P 2 IEEE WORKSH SIGN, P251.
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   BONDON P, 1998, P IEEE INT C AC SPEE, V3, P1361.
   Delcroix M, 2005, ACOUST SCI TECHNOL, V26, P432, DOI 10.1250/ast.26.432.
   Gales MJF, 1996, IEEE T SPEECH AUDI P, V4, P352, DOI 10.1109/89.536929.
   Gannot S, 2003, EURASIP J APPL SIG P, V2003, P1074, DOI 10.1155/S1110865703305049.
   Gaubitch N., 2003, P INT WORKSH AC ECH, P99.
   Gesbert D, 1997, INT CONF ACOUST SPEE, P3621, DOI 10.1109/ICASSP.1997.604650.
   GIANNAKIS GB, 2006, SIGNAL PROCESSING AD.
   Gillespie BW, 2002, INT CONF ACOUST SPEE, P557.
   GILLESPIE BW, 2001, P IEEE INT C AC SPEE, V1, P3701.
   GURELLI MI, 1995, IEEE T SIGNAL PROCES, V43, P134, DOI 10.1109/78.365293.
   Harville D. A., 1997, MATRIX ALGEBRA STAT.
   Kailath T, 2000, PR H INF SY, pXIX.
   Kingsbury BED, 1997, INT CONF ACOUST SPEE, P1259, DOI 10.1109/ICASSP.1997.596174.
   KINOSHITA K, 2007, P INT, P854.
   Kinoshita K, 2006, INT CONF ACOUST SPEE, P817.
   KITAWAKI N, 1984, IEEE COMMUN MAG, V22, P26, DOI 10.1109/MCOM.1984.1091825.
   KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830.
   KRESSNER D, 2000, FACTORIZATIONS LINEA.
   Kuttruff H., 2000, ROOM ACOUSTICS.
   Lebart K, 2001, ACUSTICA, V87, P359.
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010.
   MARTIN F, 1993, P EUR, P1031.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   ODELL JJ, 1995, THESIS CAMBRIDGE U C.
   QUATIERI TF, 1997, DISCRETE TIME SPEECH.
   Radlovic BD, 2000, IEEE T SPEECH AUDI P, V8, P311, DOI 10.1109/89.841213.
   TASHEV I, 2005, P HANDS FREE COMM MI, P8.
   Tong L, 1999, IEEE T SIGNAL PROCES, V47, P2345, DOI 10.1109/78.782179.
   VARGA A, 1999, APPL COMPUTATIONAL C, V1, P499.
   WU M, 2003, P IEEE INT C AC SPEE, V1, P844.
   Yegnanarayana B, 2000, IEEE T SPEECH AUDI P, V8, P267, DOI 10.1109/89.841209.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{121}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{422GX}},
Unique-ID = {{ISI:000264416700001}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000264576200021,
Author = {Chen, Zhumin and Ma, Jun and Lei, Jingsheng and Yuan, Bo and Lian, Li
   and Song, Ling},
Title = {{A cross-language focused crawling algorithm based on multiple relevance
   prediction strategies}},
Journal = {{COMPUTERS \& MATHEMATICS WITH APPLICATIONS}},
Year = {{2009}},
Volume = {{57}},
Number = {{6}},
Pages = {{1057-1072}},
Month = {{MAR}},
Note = {{4th International Conference on Fuzzy Systems and Knowledge
   Discovery/3rd International Conference on Natural Computation, Haikou,
   PEOPLES R CHINA, AUG 24-27, 2007}},
Abstract = {{Focused crawling is increasingly seen as a solution to address the
   scalability limitations of existing general-purpose search engines, by
   traversing the Web to only gather pages that are relevant to a specific
   topic. How to predict the relevance of the unvisited pages pointed to by
   candidate URLs in the crawling frontier to a given topic is a key issue
   in the design of focused crawlers. In this paper, we propose a novel
   approach based on multiple relevance prediction strategies to address
   this problem. For cross-language crawling, we first introduce a
   hierarchical taxonomy to describe topics in both English and Chinese. We
   then present a formal description of the relevance predicting process
   and discuss four strategies that make use of page contents, anchor
   texts, URL addresses and link types of Web pages, respectively, to
   evaluate the relevance more accurately, in which we propose a particular
   strategy using Chinese URL addresses to estimate the relevance of
   cross-language Web pages. Finally, we get a new focused crawling
   algorithm (FCMRPS, Focused Crawling based on Multiple Relevance
   Prediction Strategies) based on the combination of these strategies and
   Shark-Search, which is a classic focused crawling algorithm. Experiments
   show that the FCMRPS is more effective than the traditional algorithms,
   namely Breadth-First, Best-First and Shark-Search, in terms of precision
   and sum of information. (C) 2008 Elsevier Ltd. All rights reserved.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Chen, ZM (Corresponding Author), Shandong Univ, Sch Comp Sci \& Technol, Jinan 250061, Peoples R China.
   Chen, Zhumin; Ma, Jun; Lian, Li; Song, Ling, Shandong Univ, Sch Comp Sci \& Technol, Jinan 250061, Peoples R China.
   Lei, Jingsheng, Hainan Univ, Coll Informat Sci \& Technol, Haikou 570228, Peoples R China.
   Yuan, Bo, Univ So Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90088 USA.
   Song, Ling, Shandong Jianzhu Univ, Sch Comp Sci \& Technol, Jinan 250101, Peoples R China.}},
DOI = {{10.1016/j.camwa.2008.09.021}},
ISSN = {{0898-1221}},
EISSN = {{1873-7668}},
Keywords = {{Focused crawling; Multiple relevance prediction strategies; Topic
   taxonomy; Cross-language; Shark-search algorithm}},
Research-Areas = {{Mathematics}},
Web-of-Science-Categories  = {{Mathematics, Applied}},
Author-Email = {{chenzhumin@mail.sdu.edu.cn
   majun@sdu.edu.cn
   jshlei@hainu.edu.cn
   boyuan@usc.edu
   lianli@sdu.edu.cn
   song\_ling@sdjzu.edu.cn}},
Cited-References = {{Aggarwal C.C., 2001, P 10 INT WORLD WID W, P96, DOI DOI 10.1145/371920.371955.
   Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3.
   Chakrabarti S, 2002, P 11 INT C WORLD WID, P148, DOI DOI 10.1145/511446.511466.
   Chakraverty S, 2002, ASP-DAC/VLSI DESIGN 2002: 7TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE AND 15TH INTERNATIONAL CONFERENCE ON VLSI DESIGN, PROCEEDINGS, P251, DOI 10.1109/ASPDAC.2002.994931.
   Chau M, 2003, COMPUTER, V36, P56, DOI 10.1109/MC.2003.1198237.
   CHEN ZM, 2007, J COMPUTATIONAL INFO, V3, P1753.
   CHEN ZM, 2008, LNCS, V4993, P623.
   CHIRITA PA, 2005, P 28 ANN INT ACM SIG, P178.
   Cho J, 1998, COMPUT NETWORKS ISDN, V30, P161, DOI 10.1016/S0169-7552(98)00108-1.
   Davison B. D., 2000, P 23 ANN INT ACM SIG, P272, DOI DOI 10.1145/345508.345597.
   DEBRA P, 1994, P 4 RIAO C NEW YORK, P481.
   DILIGENTI M, 2000, P 26 INT C VER LARG, P527.
   Ehrig M., 2003, P 2003 ACM S APPL CO, P1174, DOI DOI 10.1145/952532.952761.
   Gao W., 2006, P 15 INT C WORLD WID, P287.
   Haveliwala T, 2002, P 11 INT C WORLD WID, P517, DOI DOI 10.1145/511446.511513.
   Hersovici M, 1998, COMPUT NETWORKS ISDN, V30, P317, DOI 10.1016/S0169-7552(98)00038-5.
   Jamali M, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P753, DOI 10.1109/WI.2006.19.
   JOHNSON J, 2003, P 12 INT C MACH LEAR.
   Luo FF, 2005, Proceedings of the 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE'05), P523.
   Menczer F., 2004, ACM T INTERNET TECHN, V4, P378, DOI DOI 10.1145/1031114.1031117.
   Menczer F, 2001, P 24 ANN INT ACM SIG, P241, DOI DOI 10.1145/383952.383995.
   Najork Marc, 2001, P 10 INT C WORLD WID, P114, DOI {[}10.1145/371920.371965, DOI 10.1145/371920.371965].
   Pinkerton B, 1994, P 2 INT WORLD WID WE.
   Ricardo B.-Y., 1999, MODERN INFORM RETRIE.
   Srinivasan P, 2005, INFORM RETRIEVAL, V8, P417, DOI 10.1007/s10791-005-6993-5.
   Tanudjaja F., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P1232, DOI 10.1109/HICSS.2002.993981.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Comput. Math. Appl.}},
Doc-Delivery-Number = {{424OO}},
Unique-ID = {{ISI:000264576200021}},
DA = {{2020-12-06}},
}

@article{ ISI:000265630300009,
Author = {Kayasith, Prakasith and Theeramunkong, Thanaruk},
Title = {{Speech Clarity Index (Psi): A Distance-Based Speech Quality Indicator
   and Recognition Rate Prediction for Dysarthric Speakers with Cerebral
   Palsy}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{2009}},
Volume = {{E92D}},
Number = {{3}},
Pages = {{460-468}},
Month = {{MAR}},
Abstract = {{It is a tedious and subjective task to measure severity of a dysarthria
   by manually evaluating his/her speech using available standard
   assessment methods based on human perception. This paper presents an
   automated approach to assess speech quality of a dysarthric speaker with
   cerebral palsy. With the consideration of two complementary factors,
   speech consistency and speech distinction, a speech quality indicator
   called speech clarity index (Psi) is proposed as a measure of the
   speaker's ability to produce consistent speech signal for a certain word
   and distinguished speech signal for different words. As an application,
   it can be used to assess speech quality and forecast speech recognition
   rate of speech made by an individual dysarthric speaker before actual
   exhaustive implementation of an automatic speech recognition system for
   the speaker. The effectiveness of Psi as a speech recognition rate
   predictor is evaluated by rank-order inconsistency, correlation
   coefficient, and root-mean-square of difference. The evaluations had
   been done by comparing its predicted recognition rates with one
   predicted by the standard methods called the articulatory and
   intelligibility tests based on the two recognition systems (HMM and
   ANN). The results show that Psi is a promising indicator for predicting
   recognition rate of dysarthric speech. All experiments had been done on
   speech corpus composed of speech data from eight normal speakers and
   eight dysarthric speakers.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kayasith, P (Corresponding Author), Thammasat Univ, Informat \& Comp Technol Sch, Sirindhorn Int Inst Technol, Bangkok, Thailand.
   Kayasith, Prakasith; Theeramunkong, Thanaruk, Thammasat Univ, Informat \& Comp Technol Sch, Sirindhorn Int Inst Technol, Bangkok, Thailand.}},
DOI = {{10.1587/transinf.E92.D.460}},
ISSN = {{0916-8532}},
Keywords = {{speech disorder; dysarthric speech recognition; speech assessment;
   speech quality index; recognition rate prediction}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Author-Email = {{thanaruk@siit.tu.ac.th}},
Funding-Acknowledgement = {{Thailand Research Fund (TRF)Thailand Research Fund (TRF)
   {[}PHD/0267/2545]}},
Funding-Text = {{This research is supported by the Royal Golden Jubilee Ph.D. Program,
   Thailand Research Fund (TRF) under the contract number PHD/0267/2545.}},
Cited-References = {{Bernthal J. E., 1993, ARTICULATION PHONOLO.
   BODT M, 2002, J COMMUN DISORD, V35, P283.
   CARMICHAEL J, 2004, 8 INT C SPOK LANG PR, P742.
   DAVID HA, 1988, METHOD PAIRED COMPAR.
   DELLER JR, 1991, COMPUT METH PROG BIO, V35, P125, DOI 10.1016/0169-2607(91)90071-Z.
   Gu LY, 2005, EURASIP J APPL SIG P, V2005, P1400, DOI 10.1155/ASP.2005.1400.
   {*}HTK, HTK HOM.
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641.
   Kent R. D., 1994, AM J SPEECH-LANG PAT, V3, P81, DOI DOI 10.1044/1058-0360.0302.81.
   KENT RD, 1996, AM J SPEECH-LANG PAT, V7, P7.
   KOTLER A, 1997, J AUGMENTATIVE ALTER, V12, P71.
   Mermelstein P., 1976, PATTERN RECOGN, P374.
   {*}NICO, NICO HOM.
   Power MH, 1996, J ACOUST SOC AM, V100, P3882, DOI 10.1121/1.417243.
   ROSEN K, 2000, J AUGMENTATIVE ALTER, V16, P46.
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055.
   SHRIBERG LD, 1982, J SPEECH HEAR DISORD, V47, P256, DOI 10.1044/jshd.4703.256.
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P708, DOI 10.1044/jslhr.4004.708.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{439MD}},
Unique-ID = {{ISI:000265630300009}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000265700800030,
Author = {Na, Deok-Su and Bae, Myung-Jin},
Title = {{A Variable Break Prediction Method Using CART in a Japanese
   Text-to-Speech System}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{2009}},
Volume = {{E92D}},
Number = {{2}},
Pages = {{349-352}},
Month = {{FEB}},
Abstract = {{Break prediction is an important step in text-to-speech systems as break
   indices (BIs) have a great influence on how to correctly represent
   prosodic phrase boundaries. However, an accurate prediction is difficult
   since BIs are often chosen according to the meaning of a sentence or the
   reading style of the speaker. In Japanese, the prediction of an
   accentual phrase boundary (APB) and major phrase boundary (MPB) is
   particularly difficult. Thus, this paper presents a method to complement
   the prediction errors of an APB and MPB. First, we define a subtle BI in
   which it is difficult to decide between an APB and MPB clearly as a
   variable break (VB), and an explicit BI as a fixed break (FB). The VB is
   chosen using the classification and regression tree, and multiple
   prosodic targets in relation to the pith and duration are then
   generated. Finally, unit-selection is conducted using multiple prosodic
   targets. The experimental results show that the proposed method improves
   the naturalness of synthesized speech.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Na, DS (Corresponding Author), Voiceware Co Ltd, Sungsu Dong 2 Ga 280-13, Seoul 133120, South Korea.
   Na, Deok-Su, Voiceware Co Ltd, Seoul 133120, South Korea.
   Bae, Myung-Jin, Soongsil Univ, Dept Informat \& Telecommun Engn, Seoul, South Korea.}},
DOI = {{10.1587/transinf.E92.D.349}},
ISSN = {{1745-1361}},
Keywords = {{text-to-speech system; break prediction; variable break}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Author-Email = {{dsna@voiceware.co.kr}},
ORCID-Numbers = {{Bae, Myung-Jin/0000-0002-8558-6412}},
Cited-References = {{{[}Anonymous], 2003, IT4001 JEITA, P42.
   Conkie A., 2000, P ICSLP, V3, P314.
   Na DS, 2007, J ACOUST SOC KOREA, V26, P159.
   SUN X, 2001, P EUROSPEECH2001, V1, P537.
   VENDITTI Jennifer, 1997, OSU WORKING PAPERS L, V50, P127.}},
Number-of-Cited-References = {{5}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{440LC}},
Unique-ID = {{ISI:000265700800030}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000261731200008,
Author = {Betts, Joseph and Reschly, Amy and Pickart, Mary and Heistad, Dave and
   Sheran, Christina and Marston, Doug},
Title = {{An Examination of Predictive Bias for Second Grade Reading Outcomes From
   Measures of Early Literacy Skills in Kindergarten With Respect to
   English-Language Learners and Ethnic Subgroups}},
Journal = {{SCHOOL PSYCHOLOGY QUARTERLY}},
Year = {{2008}},
Volume = {{23}},
Number = {{4}},
Pages = {{553-570}},
Month = {{DEC}},
Abstract = {{The assessment of early literacy skills during the kindergarten year can
   provide useful information about student performance in prereading
   skills, which are predictors of later reading achievement. This study
   examined the use of fluency-based prompts of student phonemic awareness,
   alphabetic principle, and oral reading at the end of kindergarten for
   predicting later reading achievement at the end of second grade.
   Predictive validity and bias studies were undertaken with respect to
   English-language learners (ELLs) and four selected ethnic subgroups:
   European American (EA), African American (AA), Asian American (ASA), and
   Hispanic American (HA). Results indicated that the predictive validity
   of the early literacy measures was strong, and no evidence of predictive
   bias for ELL and non-ELL groups was found. However, evidence of a small
   amount of predictive bias was found between the EA and HA students with
   respect to intercept differences.}},
Publisher = {{AMER PSYCHOLOGICAL ASSOC}},
Address = {{750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Betts, J (Corresponding Author), 29 High Point Woods Dr,102, Madison, WI 53719 USA.
   Reschly, Amy, Univ Georgia, Dept Educ Psychol \& Instruct Technol, Athens, GA 30602 USA.
   Sheran, Christina, Univ St Thomas, Dept Special Educ, Houston, TX USA.}},
DOI = {{10.1037/1045-3830.23.4.553}},
ISSN = {{1045-3830}},
EISSN = {{1939-1560}},
Keywords = {{differential prediction; curriculum-based measurement; early literacy
   assessment; English language learners}},
Keywords-Plus = {{CURRICULUM-BASED MEASUREMENT; DIAGNOSTIC-ACCURACY; EARLY INTERVENTION;
   VALIDITY; RELIABILITY; INVOLVEMENT; STUDENTS; SUCCESS; SCHOOL; TESTS}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Educational}},
Author-Email = {{bett0088@umn.edu}},
Cited-References = {{Abbott SP, 1997, LEARN DISABILITY Q, V20, P249, DOI 10.2307/1511311.
   Abedi J, 2006, TEACH COLL REC, V108, P2282, DOI 10.1111/j.1467-9620.2006.00782.x.
   Adams M. J., 1990, BEGINNING READ THINK.
   Aguinis H., 2004, REGRESSION ANAL CATE.
   Al Otaiba S., 2007, HDB RESPONSE INTERVE, P212, DOI {[}10.1007/978-0-387-49053-3\_15, DOI 10.1007/978-0-387-49053-3\_15].
   {*}AM ED RES ASS NAT, 1985, STAND ED PSYCH TEST.
   {*}AM ED RES ASS NAT, 1999, STAND ED PSYCH TEST.
   Baker SK, 1995, SCHOOL PSYCHOL REV, V24, P561.
   BETTS J, 2006, PREDICTIVE VAL UNPUB.
   CHRISTENSON SL, 1998, FAMILY SCH COMMUNITY.
   CLEARY TA, 1968, J EDUC MEAS, V5, P115, DOI 10.1111/j.1745-3984.1968.tb00613.x.
   CLEARY TA, 1975, AM PSYCHOL, V30, P15, DOI 10.1037/0003-066X.30.1.15.
   Clements MA, 2004, EARLY CHILD RES Q, V19, P273, DOI 10.1016/j.ecresq.2004.04.005.
   Cohen J., 1988, STAT POWER ANAL BEHA.
   Cole N. S., 1993, ED MEASUREMENT, P201.
   {*}COMM READ NAT AC, 1985, BEC NAT READ.
   Cronbach LJ, 1972, DEPENDABILITY BEHAV.
   Cunningham P. M., 2002, WHAT RES HAS SAY REA, P87.
   Daly EJ, 1997, SCHOOL PSYCHOL QUART, V12, P268, DOI 10.1037/h0088962.
   DENO SL, 1985, EXCEPT CHILDREN, V52, P219.
   Denton CA, 2003, REM SPEC EDUC, V24, P258, DOI 10.1177/07419325030240050101.
   Donovan M. S., 2002, MINORITY STUDENTS SP.
   EHRI L, 2002, WHAT RES HAS SAY REA, P111.
   Fan XT, 2001, EDUC PSYCHOL REV, V13, P1, DOI 10.1023/A:1009048817385.
   Fantuzzo J, 2004, SCHOOL PSYCHOL REV, V33, P467.
   Feldt L. S., 1993, ED MEASUREMENT, P105.
   Foorman B. R., 2004, CONTEMP EDUC PSYCHOL, V31, P1.
   GILMER JS, 1983, PSYCHOMETRIKA, V48, P99, DOI 10.1007/BF02314679.
   Good R. H., 2001, SCI STUD READ, V5, P257, DOI {[}DOI 10.1207/S1532799XSSR0503\_, DOI 10.1207/S1532799XSSR0503\_4].
   Gottfried AE, 1998, CHILD DEV, V69, P1448, DOI 10.2307/1132277.
   GRESHAM FM, 2007, HDB RESPONSE INTERVE, P10, DOI DOI 10.1007/978-0-387-49053-3\_2.
   GULLIKSEN H, 1950, PSYCHOMETRIKA, V15, P91.
   Gutman L. M., 2000, URBAN REV, V32, P1, DOI DOI 10.1023/A:1005112300726.
   Haager D, 2001, LEARN DISABILITY Q, V24, P235, DOI 10.2307/1511113.
   Haager D, 2007, LEARN DISABILITY Q, V30, P213, DOI 10.2307/30035565.
   Hart B., 1995, MEANINGFUL DIFFERENC.
   Hintze JM, 2005, SCHOOL PSYCHOL REV, V34, P372.
   Hintze JM, 2003, SCHOOL PSYCHOL REV, V32, P541.
   Hintze JM, 2002, SCHOOL PSYCHOL REV, V31, P540.
   Jensen A. R., 1980, BIAS MENTAL TESTING.
   Jimerson S.R., 2007, HDB RESPONSE INTERVE.
   JUEL C, 1988, J EDUC PSYCHOL, V80, P437, DOI 10.1037/0022-0663.80.4.437.
   Kaminski RA, 1996, SCHOOL PSYCHOL REV, V25, P215.
   Kindler A., 2002, SURVEY STATES LTD EN.
   Klein JR, 2005, SCHOOL PSYCHOL QUART, V20, P23, DOI 10.1521/scpq.20.1.23.64196.
   Kranzler JH, 1999, SCHOOL PSYCHOL QUART, V14, P327, DOI 10.1037/h0089012.
   KRATOCHWILL TR, 2007, HDB RESPONSE INTERVE, P25.
   Lennon JE, 1999, SCHOOL PSYCHOL REV, V28, P353.
   Little R., 2002, STAT ANAL MISSING DA.
   LITTLE RJA, 1988, J AM STAT ASSOC, V83, P1198, DOI 10.2307/2290157.
   Marcon RA, 1999, SCHOOL PSYCHOL REV, V28, P395.
   Marston D., 2007, EXCEPTIONALITY, V15, P97, DOI {[}10.1080/09362830701294177, DOI 10.1080/09362830701294177].
   MARSTON D, 2003, LEARNING DISABILITIE, V18, P187, DOI DOI 10.1111/1540-5826.00074.
   MARSTON DB, 1989, CURRICULUM BASED MEA.
   McCardle P., 2005, LEARNING DISABILITIE, V20, P1, DOI {[}DOI 10.1111/J.1540-5826.2005.00114.X, 10.1111/j.1540-5826.2005.00114.x].
   McConnell S. R., 2002, BEST PRACTICES SCH P, P1231.
   McConnell S. R., 2002, ASSESSMENT EFFECTIVE, V27, P3, DOI DOI 10.1177/073724770202700402.
   MESSICK S, 1980, AM PSYCHOL, V35, P1012, DOI 10.1037/0003-066X.35.11.1012.
   {*}NAT CTR ED STAT, 2006, 2006071 NCES.
   National Institute of Child Health and Human Development, 2000, NIH PUBL.
   Northwest Evaluation Association, 2004, REL VAL EST NWEA ACH.
   Perie M., 2005, 2006451 NCES US DEP.
   Pickart M., 2006, MINNEAPOLIS KINDERGA.
   POTTHOFF R, 1966, I STAT MIMEO SERIES.
   PRAKASH N, 2003, 2003004 NCES US DEP.
   RAMIREZ RD, 2006, SCH PSYCHOL REV, V35, P356.
   RESCHLY DJ, 1988, SCHOOL PSYCHOL REV, V17, P39.
   REYNOLDS CR, 1982, HDB METHODS DETECTIN, P199.
   REYNOLDS CR, 1999, HDB SCH PSYCHOL.
   RUMBERGER RW, 2000, ED OUTCOMES OPPORTUN.
   SANDBERG K, 2007, CURRICULUM BAS UNPUB.
   SAUNDERS DR, 1956, EDUC PSYCHOL MEAS, V16, P209, DOI 10.1177/001316445601600205.
   Shapiro ES, 2006, J PSYCHOEDUC ASSESS, V24, P19, DOI 10.1177/0734282905285237.
   Shinn M. R., 1989, CURRICULUM BASED MEA.
   Silberglitt B, 2005, J PSYCHOEDUC ASSESS, V23, P304, DOI 10.1177/073428290502300402.
   SIMMONS DC, 1998, WHAT READING RES TEL.
   Snedecor G. W., 1989, STAT METHODS.
   Snow C E, 1998, PREVENTING READING D.
   Stage SA, 2001, SCHOOL PSYCHOL REV, V30, P407.
   Strickland DS, 2002, WHAT RES HAS SAY REA, P69.
   SWANSON C, 2001, GRADUATES WHO DOESNT.
   Taylor BM, 2000, ELEM SCHOOL J, V101, P121, DOI 10.1086/499662.
   VanDerHeyden AM, 2003, SCHOOL PSYCHOL REV, V32, P204.
   VAUAHN S, 2003, EXCEPT CHILDREN, V69, P391.
   Vellutino FR, 1996, J EDUC PSYCHOL, V88, P601, DOI 10.1037/0022-0663.88.4.601.
   VELLUTINO FR, 2007, HDB RESPONSE INTERVE, P185, DOI DOI 10.1007/978-0-387-49053-3\_14.
   Wiley HI, 2005, REM SPEC EDUC, V26, P207.
   ZIMMERMAN DW, 1993, EDUC PSYCHOL MEAS, V53, P33, DOI 10.1177/0013164493053001003.}},
Number-of-Cited-References = {{88}},
Times-Cited = {{18}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Sch. Psychol. Q.}},
Doc-Delivery-Number = {{384FR}},
Unique-ID = {{ISI:000261731200008}},
DA = {{2020-12-06}},
}

@article{ ISI:000257074700002,
Author = {Deng, Jianping and Bouchard, Martin and Yeap, Tet Hin},
Title = {{Feature enhancement for noisy speech recognition with a time-variant
   linear predictive HMM structure}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2008}},
Volume = {{16}},
Number = {{5}},
Pages = {{891-899}},
Month = {{JUL}},
Abstract = {{This paper presents a new approach for speech feature enhancement in the
   log-spectral domain for noisy speech recognition. A switching linear
   dynamic model (SLDM) is explored as a parametric model for the clean
   speech distribution. Each multivariate linear dynamic model (LDM) is
   associated with the hidden state of a hidden Markov model (HMM) as an
   attempt to describe the temporal correlations among adjacent frames of
   speech features. The state transition on the Markov chain is the process
   of activating a different LDM or activating some of them simultaneously
   by different probabilities generated by the HMM. Rather than holding a
   transition probability for the whole process, a connectionist model is
   employed to learn the time variant transition probabilities. With the
   resulting SLDM as the speech model and with a model for the noise,
   speech and noise are jointly tracked by means of switching Kalman
   filtering. Comprehensive experiments are carried out using the Aurora2
   database to evaluate the new algorithm. The results show that the new
   SLDM approach can further improve the speech feature enhancement
   performance in terms of noise-robust recognition accuracy, since the
   transition probabilities among the LDMs can be described more precisely
   at each time point.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Deng, JP (Corresponding Author), Univ Ottawa, Sch Informat Technol \& Engn, Ottawa, ON K1N 6N5, Canada.
   Deng, Jianping; Bouchard, Martin; Yeap, Tet Hin, Univ Ottawa, Sch Informat Technol \& Engn, Ottawa, ON K1N 6N5, Canada.}},
DOI = {{10.1109/TASL.2004.924593}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{speech feature enhancement; speech recognition; switching linear dynamic
   models (SLDMs); time-variant linear predictive hidden Markov model (HMM)}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{bouchard@site.uottawa.ca}},
ORCID-Numbers = {{Bouchard, Martin/0000-0002-1165-438X}},
Cited-References = {{Afify M, 2004, IEEE T SPEECH AUDI P, V12, P19, DOI 10.1109/TSA.2003.819954.
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x.
   DENG J, 2007, J MULTIMEDIA, V2, P47.
   DENG J, 2005, P INT 05 SEP, P949.
   DENG J, 2006, P IEEE INT C AC SPEE, V1, P497.
   Deng L, 2004, IEEE T SPEECH AUDI P, V12, P218, DOI 10.1109/TSA.2003.822627.
   Droppo J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P953.
   EPHRAIM Y, 1992, P C INF SCI SYST PRI, P595.
   Gales MJF, 1996, IEEE T SPEECH AUDI P, V4, P352, DOI 10.1109/89.536929.
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616.
   Hirsch H. G., 2000, P ISCA ITRW ASR2000, P181.
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797.
   KENNY P, 1990, IEEE T ACOUST SPEECH, V38, P220, DOI 10.1109/29.103057.
   Kim DS, 1999, IEEE T SPEECH AUDI P, V7, P55, DOI 10.1109/89.736331.
   Kim NS, 2005, IEEE SIGNAL PROC LET, V12, P473, DOI 10.1109/LSP.2005.847862.
   Kim NS, 1998, IEEE SIGNAL PROC LET, V5, P57, DOI 10.1109/97.661559.
   Kim NS, 1998, IEEE SIGNAL PROC LET, V5, P146, DOI 10.1109/97.681432.
   Kohlmorgen J, 2000, BIOL CYBERN, V83, P73, DOI 10.1007/s004220000144.
   KRISHNAN V, 2006, P IEEE INT C AC SPEE, V1, P781.
   Lee KY, 1996, IEEE SIGNAL PROC LET, V3, P196, DOI 10.1109/97.508163.
   Liehr S, 1999, THEOR BIOSCI, V118, P246.
   Ming J, 2002, IEEE T SPEECH AUDI P, V10, P403, DOI 10.1109/TSA.2002.803439.
   Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281.
   Moreno P. J., 1996, THESIS CARNEGIE MELL.
   Rabiner L., 1993, FUNDAMENTALS SPEECH.
   Raj B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P965.
   SHALOM YB, 1993, ESTIMATION TRACKING.
   UMBACH RH, 2005, P INT 05 SEP, P913.
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463.
   WANG X, 2004, NEURAL INF PROCESS L, V3, P39.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{318EP}},
Unique-ID = {{ISI:000257074700002}},
DA = {{2020-12-06}},
}

@article{ ISI:000263999300038,
Author = {Thomas, Samuel and Ganapathy, Sriram and Hermansky, Hynek},
Title = {{Recognition of Reverberant Speech Using Frequency Domain Linear
   Prediction}},
Journal = {{IEEE SIGNAL PROCESSING LETTERS}},
Year = {{2008}},
Volume = {{15}},
Pages = {{681-684}},
Abstract = {{Performance of a typical automatic speech recognition (ASR) system
   severely degrades when it encounters speech from reverberant
   environments. Part of the reason for this degradation is the feature
   extraction techniques that use analysis windows which are much shorter
   than typical room impulse responses. We present a feature extraction
   technique based on modeling temporal envelopes of the speech signal in
   narrow subbands using frequency domain linear prediction (FDLP). FDLP
   provides an all-pole approximation of the Hilbert envelope of the signal
   obtained by linear prediction on cosine transform of the signal. ASR
   experiments on speech data degraded with a number of room impulse
   responses (with varying degrees of distortion) show significant
   performance improvements for the proposed FDLP features when compared to
   other robust feature extraction techniques (average relative reduction
   of 24\% in word error rate). Similar improvements are also obtained for
   far-field data which contain natural reverberation in background noise.
   These results are achieved without any noticeable degradation in
   performance for clean speech.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Thomas, S (Corresponding Author), IDIAP Res Inst, Martigny, Switzerland.
   Thomas, Samuel; Ganapathy, Sriram; Hermansky, Hynek, Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
   Thomas, Samuel; Ganapathy, Sriram; Hermansky, Hynek, IDIAP Res Inst, Martigny, Switzerland.}},
DOI = {{10.1109/LSP.2008.2002708}},
ISSN = {{1070-9908}},
Keywords = {{Automatic speech recognition; frequency domain linear prediction;
   reverberant speech}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{tsamuel@idiap.ch
   ganapathy@idiap.ch
   hynek@idiap.ch}},
ResearcherID-Numbers = {{Thomas, Samuel/AAH-3526-2020}},
Funding-Acknowledgement = {{European Commission 6th Framework DIRAC Integrated ProjectEuropean Union
   (EU); Swiss National Center of Competence in Research (NCCR)Swiss
   National Science Foundation (SNSF)}},
Funding-Text = {{Manuscript received January 22, 2008; revised June 03, 2008. This work
   was supported by the European Commission 6th Framework DIRAC Integrated
   Project and the Swiss National Center of Competence in Research (NCCR)
   on Interactive Multi-Modal Information Management IM2, managed by the
   IDIAP Research Institute on behalf of the Swiss Federal Authorities. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Li Deng.}},
Cited-References = {{ATHINEOS M, 2004, P ICSLP, P1154.
   Avendano C, 1997, IEEE T SPEECH AUDI P, V5, P372, DOI 10.1109/89.593318.
   AVENDANO C, 1997, THESIS OREGON GRAD I.
   FLANAGAN JL, 1985, J ACOUST SOC AM, V78, P1508, DOI 10.1121/1.392786.
   Gelbart D., 2002, P ICSLP, P2185.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   HERRE J, 1996, P 101 AES CONV LOS A, P1.
   Hirsch H. G., 2000, P ISCA ITRW ASR2000, P18.
   {*}ICSI, ICSI M REC PROJ.
   {*}ICSI, ICSI ROOM RESP.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Mourjopoulos J., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P1144.
   PIERCE D, 2002, P ICSLP SESS NOIS RO.
   ROSENBERG AE, 1994, P ICSLP, P1835.
   WANG H, 1991, P ICASSP, P953.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{36}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{IEEE Signal Process. Lett.}},
Doc-Delivery-Number = {{416IL}},
Unique-ID = {{ISI:000263999300038}},
DA = {{2020-12-06}},
}

@article{ ISI:000251947000007,
Author = {Ekman, L. Anders and Kleijn, W. Bastiaan and Murthi, Manohar N.},
Title = {{Regularized linear prediction of speech}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2008}},
Volume = {{16}},
Number = {{1}},
Pages = {{65-73}},
Month = {{JAN}},
Abstract = {{All-pole spectral envelope estimates based on linear prediction (LP) for
   speech signals often exhibit unnaturally sharp peaks, especially for
   high-pitch speakers. In this paper, regularization is used to penalize
   rapid changes in the spectral envelope, which improves the spectral
   envelope estimate. Based on extensive experimental evidence, we conclude
   that regularized linear prediction outperforms bandwidth-expanded linear
   prediction. The regularization approach gives lower spectral distortion
   on average, and fewer outliers, while maintaining a very low
   computational complexity.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ekman, LA (Corresponding Author), Royal Inst Technol, Sch Elect Engn, SE-10044 Stockholm, Sweden.
   Ekman, L. Anders; Kleijn, W. Bastiaan, Royal Inst Technol, Sch Elect Engn, SE-10044 Stockholm, Sweden.
   Murthi, Manohar N., Univ Miami, Dept Elect \& Comp Engn, Coral Gables, FL 33124 USA.}},
DOI = {{10.1109/TASL.2007.909448}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{bandwidth expansion; envelope estimation; linear prediction (LP);
   regularization}},
Keywords-Plus = {{PARAMETERS}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{anders.ekman@ee.kth.se
   bastiaan.kleijn@ee.kth.se
   mmurthi@miami.edu}},
ORCID-Numbers = {{Kleijn, W./0000-0002-1973-3920
   Ekman, Anders/0000-0002-9479-9508}},
Cited-References = {{Abramowitz M., 1964, HDB MATH FUNCTIONS F.
   {*}AMR, 2004, 26090 3GPP TS.
   {*}AMRWB, 2005, 26190 3GPP TS.
   Boyd S., 2004, CONVEX OPTIMIZATION.
   Brookes M., 2006, VOICEBOX SPEECH PROC.
   Cappe O, 1996, IEEE SIGNAL PROC LET, V3, P100, DOI 10.1109/97.489060.
   {*}CSACELP, 1996, 729 ITUT.
   {*}DARPA TIMIT, 1990, ACOUST PHON CONT SPE.
   Doddington GR, 2000, SPEECH COMMUN, V31, P225, DOI 10.1016/S0167-6393(99)00080-1.
   Durbin J., 1960, REV INT STATIST I, V28, P233, DOI {[}10.2307/1401322, DOI 10.2307/1401322, 10.2307/1401322 0101.35604].
   Ekman LA, 2006, INT CONF ACOUST SPEE, P245.
   ELJAROUDI A, 1991, IEEE T SIGNAL PROCES, V39, P411, DOI 10.1109/78.80824.
   Hogg RV, 1978, INTRO MATH STAT.
   {*}ISO IEC, N2203CELP.
   Kabal P, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P824.
   LEVINSON N, 1946, J MATH PHYS CAMB, V25, P261, DOI 10.1002/sapm1946251261.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   MOULINES E, 1995, SPEECH COMMUN, V16, P175, DOI 10.1016/0167-6393(94)00054-E.
   Murthi MN, 2000, 2000 IEEE WORKSHOP ON SPEECH CODING, PROCEEDINGS, P96, DOI 10.1109/SCFT.2000.878410.
   Murthi MN, 2000, IEEE T SPEECH AUDI P, V8, P221, DOI 10.1109/89.841206.
   NASH JC, 1979, COMPACT NUMERICAL ME, P70.
   Nocedal J., 1999, NUMERICAL OPTIMIZATI.
   Oudot M, 1997, 1997 IEEE WORKSHOP ON SPEECH CODING FOR TELECOMMUNICATIONS, PROCEEDINGS, P11, DOI 10.1109/SCFT.1997.623871.
   Paliwal K.K., 1995, SPEECH CODING SYNTHE, P433.
   TOHKURA Y, 1978, IEEE T ACOUST SPEECH, V26, P587, DOI 10.1109/TASSP.1978.1163165.
   TOHKURA Y, 1979, IEEE T ACOUST SPEECH, V27, P273, DOI 10.1109/TASSP.1979.1163241.
   VISWANATHAN R, 1975, IEEE T ACOUST SPEECH, VAS23, P309, DOI 10.1109/TASSP.1975.1162675.
   Wei B, 2003, IEEE SIGNAL PROC LET, V10, P101, DOI 10.1109/LSP.2003.808550.
   Wei B, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P111, DOI 10.1109/ISIMP.2001.925344.
   WEI B, 2000, P DSP WORKSH.
   Zilca RD, 2006, IEEE T AUDIO SPEECH, V14, P467, DOI 10.1109/TSA.2005.857809.
   1992, 728 CCITT.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{26}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{245PH}},
Unique-ID = {{ISI:000251947000007}},
DA = {{2020-12-06}},
}

@article{ ISI:000247547000020,
Author = {Skowronski, Mark D. and Harris, John G.},
Title = {{Noise-robust automatic speech recognition using a predictive echo state
   network}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2007}},
Volume = {{15}},
Number = {{5}},
Pages = {{1724-1730}},
Month = {{JUL}},
Abstract = {{Artificial neural networks have been shown to perform well in automatic
   speech recognition (ASR) tasks, although their complexity and excessive
   computational costs have limited their use. Recently, a recurrent neural
   network with simplified training, the echo state network (ESN), was
   introduced by Jaeger and shown to outperform conventional methods in
   time series prediction experiments. We created the predictive ESN
   classifier by combining the ESN with a state machine framework. In
   small-vocabulary ASR experiments, we compared the noise-robust
   performance of the predictive ESN classifier with a hidden Markov model
   (HMM) as a function of model size and signal-to-noise ratio (SNR). The
   predictive ESN classifier outperformed an HMM by 8-dB SNR, and both
   models achieved maximum noise-robust accuracy for architectures with
   more states and fewer kernels per state. Using ten trials of random sets
   of training/validation/test speakers, accuracy for the predictive ESN
   classifier, averaged between 0 and 20 dB SNR, was 81 +/- 3\%, compared
   to 61 +/- 2\% for an HMM. The closed-form regression training for the
   ESN significantly reduced the computational cost of the network, and the
   reservoir of the ESN created a high-dimensional representation of the
   input with memory which led to increased noise-robust classification.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Skowronski, MD (Corresponding Author), Univ Western Ontario, Dept Biol, London, ON N6A 5B8, Canada.
   Univ Western Ontario, Dept Biol, London, ON N6A 5B8, Canada.
   Univ Florida, Computat NeuroEngn Lab, Gainesville, FL 32611 USA.}},
DOI = {{10.1109/TASL.2007.896669}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{digit recognition; noise-robust automatic speech recognition; predictive
   echo state network}},
Keywords-Plus = {{NEURAL-NETWORKS; SYSTEMS; MODEL}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{markskow@cnel.ufl.edu}},
Cited-References = {{ATAL BS, 1974, J ACOUST SOC AM, V55, P1304, DOI 10.1121/1.1914702.
   Atiya AF, 2000, IEEE T NEURAL NETWOR, V11, P697, DOI 10.1109/72.846741.
   Bishop CM, 1995, NEURAL NETWORKS PATT.
   COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137.
   Deller JR, 1993, DISCRETE TIME PROCES.
   Deng L, 2005, IEEE T SPEECH AUDI P, V13, P412, DOI 10.1109/TSA.2005.845814.
   Duda R. O., 2001, PATTERN CLASSIFICATI.
   ELMAN JL, 1988, J ACOUST SOC AM, V83, P1615, DOI 10.1121/1.395916.
   EPHRAIM Y, 1995, IEEE T SPEECH AUDI P, V3, P251, DOI 10.1109/89.397090.
   FRANZINI M, 1990, P INT C AC SPEECH SI, V1, P425.
   Furuya Y, 2002, SURG TODAY, V32, P29, DOI 10.1007/s595-002-8109-9.
   GISH H, 1990, P INT C AC SPEECH SI, V1, P1361.
   GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J.
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042.
   Haykin S, 2005, LECT NOTES ARTIF INT, V3445, P43.
   Haykin S., 2001, ADAPTIVE FILTER THEO.
   Haykin S., 1999, NEURAL NETWORKS COMP.
   Hirsch H. G., 2000, P ISCA ITRW ASR2000, P181.
   ISO K, 1991, INT CONF ACOUST SPEE, P57, DOI 10.1109/ICASSP.1991.150277.
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79.
   Jaeger H, 2005, IEEE IJCNN, P1460.
   Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277.
   JAEGER H, 2002, FRAUNHOFER I AUTON I.
   Jaeger H, 2003, ADV NEURAL INFORM PR, V15, P593.
   Jaeger H., 2001, 148 GERM NAT RES CTR, P13.
   JUANG BH, 1990, IEEE T ACOUST SPEECH, V38, P1639, DOI 10.1109/29.60082.
   LEVIN E, 1990, INT CONF ACOUST SPEE, P433, DOI 10.1109/ICASSP.1990.115740.
   MORGAN N, 1995, P IEEE, V83, P742, DOI 10.1109/5.381844.
   MURPHY K, 2006, HIDDEN MARKOV MODEL.
   Neukirchen C, 2001, IEEE T SPEECH AUDI P, V9, P367, DOI 10.1109/89.917682.
   Petek B, 2000, INT CONF ACOUST SPEE, P3442, DOI 10.1109/ICASSP.2000.860141.
   Prokhorov D, 2005, IEEE IJCNN, P1463.
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626.
   ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192.
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318, DOI {[}DOI 10.1016/B978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2].
   Skowronski MD, 2004, J ACOUST SOC AM, V116, P1774, DOI 10.1121/1.1777872.
   SKOWRONSKI MD, 2007, IN PRESS NEURAL NETW.
   SKOWRONSKI MD, 2007, P INT S CIRC SYST NE.
   Strope B, 1997, IEEE T SPEECH AUDI P, V5, P451, DOI 10.1109/89.622569.
   TEBELSKIS J, 1995, THESIS CARNEGIE MELL.
   TEBELSKIS J, 1990, P INT C AC SPEECH SI, V1, P437.
   Trentin E, 2003, IEEE T NEURAL NETWOR, V14, P1519, DOI 10.1109/TNN.2003.820838.
   YOUNG S, 1995, HTK BOOK VERSION 2 0.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{50}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{183BF}},
Unique-ID = {{ISI:000247547000020}},
DA = {{2020-12-06}},
}

@article{ ISI:000246962400010,
Author = {Laffont, Isabelle and Dumas, Claude and Pozzi, Delphine and Ruquet,
   Maria and Tissier, Anne Claire and Lofaso, Frederic and Dizien, Olivier},
Title = {{Home trials of a speech synthesizer in severe dysarthria: Patterns of
   use, satisfaction, and utility of word prediction}},
Journal = {{JOURNAL OF REHABILITATION MEDICINE}},
Year = {{2007}},
Volume = {{39}},
Number = {{5}},
Pages = {{399-404}},
Month = {{MAY}},
Abstract = {{Objective: The aim of this study was to evaluate a speech synthesizer
   with respect to patterns of use and satisfaction, during a 2-month trial
   at home, and the usefulness of the word prediction function.
   Design: Prospective study.
   Participants: Of the 24 patients with severe dysarthria recruited, 10
   completed the study. Five patients had cerebral palsy, 3 amyotrophic
   lateral sclerosis, one locked-in syndrome, and one anoxic brain damage.
   Mean age was 32 (standard deviation 21) years (range 9-66 years).
   Methods: Each participant received 10 hours of training with the device
   (Dialo((R))) and then used it at home for 2 months. The main outcome
   measures were: level of use recorded by the device, Quebec User
   Evaluation of Satisfaction with Assistive Technology (QUEST)
   satisfaction score (maximum = 5), and time needed to take dictations of
   standard-dictionary and personal-dictionary words with and without word
   prediction.
   Results: Level of use varied widely across participants. Overall
   satisfaction at the end of the home trial was high, with a mean QUEST
   score of 3.4 (SD 1) and was related to the level of use of the device.
   Level of satisfaction at the end of the training session could not
   predict the level or use at home. No significant differences were found
   in dictation-taking times with and without word prediction. However, 6
   of the 10 patients took dictation faster with than without word
   prediction.
   Conclusion: This study provides the first evidence supporting the
   benefits of a speech synthesizer used at home for several weeks. Word
   prediction is useful for some patients even if increase in dictation
   speed did not reach significance.}},
Publisher = {{TAYLOR \& FRANCIS AS}},
Address = {{PO BOX 12 POSTHUSET, NO-0051 OSLO, NORWAY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Laffont, I (Corresponding Author), Hop Ray Poincare, Ctr Innovat Technol, 104 Blvd Raymond Poincare, FR-92380 Garches, France.
   Hop Ray Poincare, Ctr Innovat Technol, FR-92380 Garches, France.
   Hop Ray Poincare, Unite Med Phys \& Readaptat, FR-92380 Garches, France.}},
DOI = {{10.2340/16501977-0056}},
ISSN = {{1650-1977}},
Keywords = {{dysarthria; augmentative and alternative communication; word prediction;
   speech synthesizer; cerebral palsy; training}},
Keywords-Plus = {{AUGMENTATIVE COMMUNICATION-SYSTEMS; CEREBRAL-PALSY; PEOPLE;
   INTELLIGIBILITY; SAMPLES; DEVICES; SELF}},
Research-Areas = {{Rehabilitation; Sport Sciences}},
Web-of-Science-Categories  = {{Rehabilitation; Sport Sciences}},
Author-Email = {{isabelle.laffont@rpc.aphp.fr}},
ResearcherID-Numbers = {{Lofaso, Frederic/R-6100-2018
   LAFFONT, Isabelle/X-4186-2019}},
Cited-References = {{Angelo J, 1998, ASSIST TECHNOL, V10, P77, DOI 10.1080/10400435.1998.10131965.
   ANGELO J, 1992, AM J OCCUP THER, V46, P217, DOI 10.5014/ajot.46.3.217.
   Ball LJ, 2004, J COMMUN DISORD, V37, P197, DOI 10.1016/j.jcomdis.2003.09.002.
   BLENKHORN P, 1992, J MED ENG TECHNOL, V16, P243, DOI 10.3109/03091909209030775.
   Culp D. M., 1986, AUGMENTATIVE ALTERNA, V2, P19.
   DATTILO J, 1991, J APPL BEHAV ANAL, V24, P369, DOI 10.1901/jaba.1991.24-369.
   Demers L, 1996, Assist Technol, V8, P3.
   Girous F., 1999, J REHABILITATION OUT, V3, P42.
   Glennen SL, 1985, AUGMENTATIVE ALTERNA, V1, P134.
   Handley-More D, 2003, AM J OCCUP THER, V57, P139, DOI 10.5014/ajot.57.2.139.
   HOOVER J, 1987, J SPEECH HEAR RES, V30, P425, DOI 10.1044/jshr.3003.425.
   KEATING DL, 1986, BRIT J DISORD COMMUN, V21, P167.
   LIGHT J, 1992, J SPEECH HEAR RES, V35, P853, DOI 10.1044/jshr.3504.853.
   LoPresti EF, 2003, J REHABIL RES DEV, V40, P199.
   MCCUAIG M, 1991, AM J OCCUP THER, V45, P224, DOI 10.5014/ajot.45.3.224.
   Montani C, 1997, ENCEPHALE, V23, P194.
   Murphy J, 2004, AMYOTROPH LATERAL SC, V5, P121, DOI 10.1080/14660820410020411.
   NEWMAN GC, 1989, AM J OCCUP THER, V43, P529, DOI 10.5014/ajot.43.8.529.
   SPIEGEL BB, 1993, AUGMENTATIVE ALTERNA, V9, P111.
   Tam Cynthia, 2002, Occup Ther Int, V9, P237, DOI 10.1002/oti.167.
   Yorkston K. M., 1996, AM J SPEECH-LANG PAT, V5, P55, DOI DOI 10.1044/1058-0360.0501.55.
   YORKSTON KM, 1990, J SPEECH HEAR DISORD, V55, P225, DOI 10.1044/jshd.5502.225.
   Yorkston KM, 1996, J SPEECH HEAR RES, V39, pS46, DOI 10.1044/jshr.3905.s46.
   YORKSTON KM, 1990, J SPEECH HEAR DISORD, V55, P217, DOI 10.1044/jshd.5502.217.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{J. Rehabil. Med.}},
Doc-Delivery-Number = {{174SF}},
Unique-ID = {{ISI:000246962400010}},
OA = {{DOAJ Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000244318600001,
Author = {Yahampath, Pradeepa and Rondeau, Paul},
Title = {{Multiple-description predictive-vector quantization with applications to
   low bit-rate speech coding over networks}},
Journal = {{IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING}},
Year = {{2007}},
Volume = {{15}},
Number = {{3}},
Pages = {{749-755}},
Month = {{MAR}},
Abstract = {{An algorithm for designing linear prediction-based two-channel
   multiple-description predictive-vector quantizers; (MD-PVQs) for
   packet-loss channels is presented. This algorithm iteratively improves
   the encoder partition, the set of multiple description codebooks, and
   the linear predictor for a given channel loss probability, based on a
   training set of source data. The effectiveness of the designs obtained
   with the given algorithm is demonstrated using a waveform coding example
   involving a Markov source as well as vector quantization of speech line'
   spectral pairs.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yahampath, P (Corresponding Author), Univ Manitoba, Dept Elect \& Comp Engn, Winnipeg, MB R3T 5V6, Canada.
   Univ Manitoba, Dept Elect \& Comp Engn, Winnipeg, MB R3T 5V6, Canada.}},
DOI = {{10.1109/TASL.2006.885937}},
ISSN = {{1558-7916}},
EISSN = {{1558-7924}},
Keywords = {{multiple-description coding; predictive coding; speech coding; vector
   quantization}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{pradeepa@ee.umanitoba.ca}},
Cited-References = {{ANDERSON JB, 1975, IEEE T INFORM THEORY, V21, P379, DOI 10.1109/TIT.1975.1055415.
   Andersson T, 2005, 2005 39TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, VOLS 1 AND 2, P13.
   CUPERMAN V, 1985, IEEE T COMMUN, V33, P685, DOI 10.1109/TCOM.1985.1096372.
   Gersho Allen, 1992, VECTOR QUANTIZATION.
   INGLE A, 1995, IEEE T SPEECH AUDI P, V3, P48, DOI 10.1109/89.365381.
   JAYANT NS, 1981, AT\&T TECH J, V60, P501, DOI 10.1002/j.1538-7305.1981.tb03069.x.
   Khalil H, 2001, IEEE DATA COMPR CONF, P33, DOI 10.1109/DCC.2001.917134.
   Lahouti F, 2004, IEEE T INFORM THEORY, V50, P2103, DOI 10.1109/TIT.2004.833337.
   Linden J, 2000, IEEE T SPEECH AUDI P, V8, P370, DOI 10.1109/89.848219.
   {*}NIST, 1990, DARPA TIMIT AC CONT.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   Schuller G, 2005, IEEE T SPEECH AUDI P, V13, P1014, DOI 10.1109/TSA.2005.853205.
   VAISHAMPAYAN VA, 1991, 25 ANN C INF SCI SYS, P564.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Trans. Audio Speech Lang. Process.}},
Doc-Delivery-Number = {{137US}},
Unique-ID = {{ISI:000244318600001}},
DA = {{2020-12-06}},
}

@article{ ISI:000244487600005,
Author = {Paek, Tim and Chickering, David Maxwell},
Title = {{Improving command and control speech recognition on mobile devices:
   using predictive user models for language modeling}},
Journal = {{USER MODELING AND USER-ADAPTED INTERACTION}},
Year = {{2007}},
Volume = {{17}},
Number = {{1-2}},
Pages = {{93-117}},
Month = {{MAR}},
Abstract = {{Command and control (C\&C) speech recognition allows users to interact
   with a system by speaking commands or asking questions restricted to a
   fixed grammar containing pre-defined phrases. Whereas C\&C interaction
   has been commonplace in telephony and accessibility systems for many
   years, only recently have mobile devices had the memory and processing
   capacity to support client-side speech recognition. Given the personal
   nature of mobile devices, statistical models that can predict commands
   based in part on past user behavior hold promise for improving C\&C
   recognition accuracy. For example, if a user calls a spouse at the end
   of every workday, the language model could be adapted to weight the
   spouse more than other contacts during that time. In this paper, we
   describe and assess statistical models learned from a large population
   of users for predicting the next user command of a commercial C\&C
   application. We explain how these models were used for language
   modeling, and evaluate their performance in terms of task completion.
   The best performing model achieved a 26\% relative reduction in error
   rate compared to the base system. Finally, we investigate the effects of
   personalization on performance at different learning rates via online
   updating of model parameters based on individual user data.
   Personalization significantly increased relative reduction in error rate
   by an additional 5\%.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Paek, T (Corresponding Author), Microsoft Corp, Res, Redmond, WA 98052 USA.
   Microsoft Corp, Res, Redmond, WA 98052 USA.}},
DOI = {{10.1007/s11257-006-9021-6}},
ISSN = {{0924-1868}},
EISSN = {{1573-1391}},
Keywords = {{command and control; language modeling; speech recognition; predictive
   user models}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Cybernetics}},
Author-Email = {{timpaek@microsoft.com
   dmax@microsoft.com}},
Cited-References = {{CHICKERING D, 2005, PERSONALIZING INFLUE.
   CHICKERING DM, 1997, P 13 C UNC ART INT U, P80.
   CHICKERING DM, 2002, MSRTR2002103 MICR.
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197.
   HORVITZ E, 2001, P 8 INT C US MOD SON, P3.
   HOVITZ E, 1995, 19 ANN S COMP APPL M.
   HUNT A, 2004, SPEECH RECOGNITION R.
   JAMESON A, 2001, P 17 INT JOINT C ART, P1185.
   JAMESON A, 2004, SPOKEN MULTIMODAL HU, P349.
   Jelinek F., 1997, STAT METHODS SPEECH.
   JOHANSSON P, 2002, 022 SAR SANT ANN IT.
   Manning C.D., 1999, FDN STAT NATURAL LAN.
   Oviatt S, 1998, SPEECH COMMUN, V24, P87, DOI 10.1016/S0167-6393(98)00005-3.
   PAEK T, 2000, P 16 C UNC ART INT U, P455.
   Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083.
   Rosenfeld R., 2001, Interactions, V8, P34, DOI 10.1145/384076.384085.
   STROTHER N, 2005, IN0502105WH INSTAT.
   Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175.
   Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900.
   Woods W. A., 1985, Computer speech processing, P305.
   YU D, 2003, P EUR GEN SWITZ, P1229.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{21}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{User Model. User-Adapt. Interact.}},
Doc-Delivery-Number = {{140ES}},
Unique-ID = {{ISI:000244487600005}},
DA = {{2020-12-06}},
}

@article{ ISI:000243787100009,
Author = {LeBlanc, Joanne and de Guise, Elaine and Feyz, Mitra and Lamoureux,
   Julie},
Title = {{Early prediction of language impairment following traumatic brain injury}},
Journal = {{BRAIN INJURY}},
Year = {{2006}},
Volume = {{20}},
Number = {{13-14}},
Pages = {{1391-1401}},
Month = {{DEC}},
Abstract = {{Primary objective: This study investigated which factors collected early
   in the acute care setting (age, education, cerebral imaging, Glasgow
   Coma Scale score) would predict initial impairments of language
   comprehension and expression in patients with traumatic brain injury
   (TBI) of all severity.
   Methods and procedures: Results of language tests carried out during the
   patients' stay in an acute tertiary trauma centre were obtained. These
   tests measured performance in the areas of confrontation naming,
   auditory comprehension, semantic and letter category naming and
   comprehension of verbal absurdities. Data for the predictive variables
   were gathered by retrospective chart review. Stepwise multiple linear
   regressions were carried out on the predictive variables.
   Main outcomes and results: Education and TBI severity as measured with
   the GCS score were the most significant factors predicting language
   deficits in the acute care setting.
   Conclusions: These findings will serve to guide health care
   professionals in predicting prognosis for cognitive-communication
   deficits post-TBI and in planning for appropriate resources in
   speech-language pathology to meet these patients' needs.}},
Publisher = {{TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{LeBlanc, J (Corresponding Author), McGill Univ, Montreal Gen Hosp, Hlth Ctr, Traumat Brain Injury Program, Local D13-124,1650 Av Cedar, Quebec City, PQ H3G 1A4, Canada.
   McGill Univ, Montreal Gen Hosp, Hlth Ctr, Traumat Brain Injury Program, Quebec City, PQ H3G 1A4, Canada.
   Univ Montreal, Social \& Prevent Med Dept, Montreal, PQ, Canada.}},
DOI = {{10.1080/02699050601081927}},
ISSN = {{0269-9052}},
EISSN = {{1362-301X}},
Keywords = {{language impairment; communication; traumatic brain injury; prediction}},
Keywords-Plus = {{CLOSED-HEAD INJURY; COGNITIVE RESERVE; ELDERLY-PATIENTS; WORKING-MEMORY;
   VERBAL FLUENCY; ACUTE-CARE; COMA; LEVEL; INTEGRATION; MORTALITY}},
Research-Areas = {{Neurosciences \& Neurology; Rehabilitation}},
Web-of-Science-Categories  = {{Neurosciences; Rehabilitation}},
Author-Email = {{joanne.leblanc@mcgill.ca}},
ORCID-Numbers = {{Lamoureux, Julie/0000-0002-4986-2504}},
Cited-References = {{ADAMOVICH BB, 1985, COGNITIVE REHABILITA, P98.
   {*}AM SPEECH LANG HE, 1988, ASHA, V30, P29.
   Andrews PJD, 2002, J NEUROSURG, V97, P326, DOI 10.3171/jns.2002.97.2.0326.
   Baker HJ, 1965, DETROIT TEST LEARNIN.
   Balestreri M, 2004, J NEUROL NEUROSUR PS, V75, P161.
   BAULES KA, 1991, ARIZONA BATTERY COMM.
   BAYLES KA, 1983, CLIN APHASIOLOGY C P, P304.
   Bombardier CH, 1998, BRAIN INJURY, V12, P725, DOI 10.1080/026990598122124.
   Bopp KL, 2005, J GERONTOL B-PSYCHOL, V60, pP223, DOI 10.1093/geronb/60.5.P223.
   Brickman AM, 2005, ARCH CLIN NEUROPSYCH, V20, P561, DOI 10.1016/j.acn.2004.12.006.
   Brooks N, 1987, Brain Inj, V1, P5, DOI 10.3109/02699058709034439.
   Carroll LJ, 2004, J REHABIL MED, V36, P84, DOI 10.1080/16501960410023859.
   Cattelani R, 2002, BRAIN INJURY, V16, P51, DOI 10.1080/02699050110088821.
   Cifu DX, 1997, ARCH PHYS MED REHAB, V78, P125, DOI 10.1016/S0003-9993(97)90252-5.
   Coelho CA, 2002, J SPEECH LANG HEAR R, V45, P1232, DOI 10.1044/1092-4388(2002/099).
   COOKE DL, 1995, J CLIN EXP NEUROPSYC, V17, P90, DOI 10.1080/13803399508406585.
   De Guise E, 2005, BRAIN INJURY, V19, P1087, DOI 10.1080/02699050500149882.
   DEGUISE E, UNPUB PEDICTION BEHA.
   Dikmen SS, 2003, ARCH PHYS MED REHAB, V84, P1449, DOI 10.1016/S0003-9993(03)00287-9.
   Duff MC, 2002, BRAIN INJURY, V16, P773, DOI 10.1080/02699050210128870.
   EISENBERG HM, 1990, J NEUROSURG, V73, P688, DOI 10.3171/jns.1990.73.5.0688.
   Frank EM, 1996, J MED SPEECH-LANG PA, V4, P81.
   Galski T, 1998, BRAIN INJURY, V12, P769, DOI 10.1080/026990598122160.
   Goodglass H, 1983, BOSTON DIAGNOSTIC AP.
   Goodglass H, 2001, BOSTON DIAGNOSTIC AP.
   GRUEN AK, 1990, J COMMUN DISORD, V23, P163, DOI 10.1016/0021-9924(90)90020-Y.
   Hagen C., 1981, TOP LANG DIS, V1, P73.
   Hammond FM, 2004, J HEAD TRAUMA REHAB, V19, P314, DOI 10.1097/00001199-200407000-00006.
   Harris OA, 2000, J TRAUMA, V49, P1076, DOI 10.1097/00005373-200012000-00017.
   HARTLEY L L, 1991, Brain Injury, V5, P267, DOI 10.3109/02699059109008097.
   Hartley Leila L., 1992, Seminars in Speech and Language, V13, P264, DOI 10.1055/s-2008-1064202.
   Henderson LW, 1998, APHASIOLOGY, V12, P901, DOI 10.1080/02687039808249458.
   Hinchliffe FJ, 1998, BRAIN INJURY, V12, P369, DOI 10.1080/026990598122502.
   Hinchliffe FJ, 1998, BRAIN INJURY, V12, P109, DOI 10.1080/026990598122746.
   HUX K, 1997, J MED SPEECH-LANG PA, V5, P181.
   Jiang JY, 2002, J NEUROTRAUM, V19, P869, DOI 10.1089/08977150260190456.
   KAKARIEKA A, 1994, ACTA NEUROCHIR, V129, P1, DOI 10.1007/BF01400864.
   Kaplan E., 1983, BOSTON NAMING TEST.
   KATZ DI, 1994, ARCH NEUROL-CHICAGO, V51, P661, DOI 10.1001/archneur.1994.00540190041013.
   Kelly MP, 1997, BRAIN INJURY, V11, P391, DOI 10.1080/026990597123386.
   KERR C, 1995, BRAIN INJURY, V9, P777, DOI 10.3109/02699059509008234.
   Kesler SR, 2003, APPL NEUROPSYCHOL, V10, P153, DOI 10.1207/S15324826AN1003\_04.
   Kilaru S, 1996, J TRAUMA, V41, P957, DOI 10.1097/00005373-199612000-00003.
   Lannoo E, 1998, INTENS CARE MED, V24, P236, DOI 10.1007/s001340050556.
   Lannoo E, 2000, J NEUROTRAUM, V17, P403, DOI 10.1089/neu.2000.17.403.
   Leblanc J, 2006, BRAIN INJURY, V20, P779, DOI 10.1080/02699050600831835.
   Lehtonen S, 2005, BRAIN INJURY, V19, P239, DOI 10.1080/0269905040004310.
   LEVIN HS, 1990, J NEUROSURG, V73, P699, DOI 10.3171/jns.1990.73.5.0699.
   LEVIN HS, 1976, J NEUROL NEUROSUR PS, V39, P1062, DOI 10.1136/jnnp.39.11.1062.
   LIVINGSTON M, 1988, J HEAD TRAUMA REHAB, V3, P6, DOI DOI 10.1097/00001199-198812000-00004.
   MCDONALD S, 1999, BRAIN DAM B, P19.
   McDowell S, 1997, NEUROPSYCHOLOGIA, V35, P1341, DOI 10.1016/S0028-3932(97)00082-1.
   Raskin SA, 1996, NEUROPSYCHOLOGY, V10, P416, DOI 10.1037/0894-4105.10.3.416.
   RIMEL RW, 1982, NEUROSURGERY, V11, P344, DOI 10.1227/00006123-198209000-00002.
   SARNO MT, 1986, ARCH PHYS MED REHAB, V67, P400.
   SARNO MT, 1980, J NERV MENT DIS, V168, P685, DOI 10.1097/00005053-198011000-00008.
   Servadei F, 2000, NEUROSURGERY, V46, P70.
   SHATZ RS, 1998, MED SPEECH LANGUAGE, P243.
   Snow P, 1997, BRAIN INJURY, V11, P409.
   SOLOMON DA, 1992, NEUROPSYCHOL REV, V3, P249, DOI 10.1007/BF01109050.
   Spreen O, 1969, NEUROSENSORY CTR COM.
   Stern Y, 2002, J INT NEUROPSYCH SOC, V8, P448, DOI 10.1017/S1355617702813248.
   Stout CE, 2000, J MED SPEECH-LANG PA, V8, P15.
   Sullivan A, 2001, SOCIOLOGY, V35, P893, DOI 10.1177/0038038501035004006.
   Susman M, 2002, J TRAUMA, V53, P219, DOI 10.1097/00005373-200208000-00004.
   Turkstra L, 2005, J MED SPEECH-LANG PA, V13, pIX.
   VOLLMER DG, 1991, J NEUROSURG, V75, pS37, DOI 10.3171/sup.1991.75.1s.0s37.
   Wallesch CW, 2001, J NEUROTRAUM, V18, P11, DOI 10.1089/089771501750055730.
   Wecker NS, 2005, NEUROPSYCHOLOGY, V19, P345, DOI 10.1037/0894-4105.19.3.345.
   Wehman Paul, 1993, Brain Injury, V7, P31, DOI 10.3109/02699059309008154.
   Ylvisaker M, 2000, LANGUAGE INTERVENTIO, P745.
   Ylvisaker Mark, 1992, Seminars in Speech and Language, V13, P239, DOI 10.1055/s-2008-1064200.
   Youse KM, 2005, BRAIN INJURY, V19, P1001, DOI 10.1080/02699050500109951.}},
Number-of-Cited-References = {{73}},
Times-Cited = {{15}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{Brain Inj.}},
Doc-Delivery-Number = {{130GF}},
Unique-ID = {{ISI:000243787100009}},
DA = {{2020-12-06}},
}

@article{ ISI:000242809400016,
Author = {Oh, Seung-Shin and Kim, Sang-Hun},
Title = {{Modality-based sentence-final intonation prediction for Korean
   conversational-style text-to-speech systems}},
Journal = {{ETRI JOURNAL}},
Year = {{2006}},
Volume = {{28}},
Number = {{6}},
Pages = {{807-810}},
Month = {{DEC}},
Abstract = {{This letter presents a prediction model for sentence-final intonations
   for Korean conversational-style text-to-speech systems in which we
   introduce the linguistic feature of `modaliiy' as a new parameter Based
   on their function and meaning, we classify tonal forms in speech data
   into tone types meaningful for speech synthesis and use the result of
   this classification to build our prediction model using a tree
   structured classification algorithm. In order to show that modality is
   more effective for the prediction model than features such as sentence
   type or speech act, an experiment is performed on a test set of 970
   utterances with a training set of 3,883 utterances. The results show
   that modality makes a higher contribution to the determination of
   sentence-final intonation than sentence type or speech act, and that
   prediction accuracy improves up to 25\% when the feature of modality is
   introduced.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Oh, SS (Corresponding Author), ETRI, Embedded Software Res Div, Taejon, South Korea.
   ETRI, Embedded Software Res Div, Taejon, South Korea.}},
DOI = {{10.4218/etrij.06.0206.0118}},
ISSN = {{1225-6463}},
EISSN = {{2233-7326}},
Keywords = {{sentence-final intonation; prediction model; modality; text-to-speech
   system; conversational-style}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{oss63354@etri.re.kr
   ksh@etri.re.kr}},
Cited-References = {{Boersma P., PRAAT DOING PHONETIC.
   HUANG X, 2001, SPOKEN LANGUAGE PROC, P757.
   JUN SA, 1994, P ICSLP 94 YOK JAP, P323.
   JUN SA, 2000, K TOBI LABELLING CON.
   Lee C, 2006, ETRI J, V28, P337, DOI 10.4218/etrij.06.0105.0020.
   LEE HY, 1999, MALSORI, V38, P25.
   PALMER FR, 1986, MOOD MODALITY, P14.}},
Number-of-Cited-References = {{7}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{ETRI J.}},
Doc-Delivery-Number = {{116NK}},
Unique-ID = {{ISI:000242809400016}},
OA = {{Bronze}},
DA = {{2020-12-06}},
}

@article{ ISI:000241305800052,
Author = {Delcroix, Marc and Hikichi, Takafumi and Miyoshvi, Masato},
Title = {{On a blind speech dereverberation algorithm using multi-channel linear
   prediction}},
Journal = {{IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND
   COMPUTER SCIENCES}},
Year = {{2006}},
Volume = {{E89A}},
Number = {{10}},
Pages = {{2837-2846}},
Month = {{OCT}},
Abstract = {{It is well known that speech captured in a room by distant microphones
   suffers from distortions caused by reverberation. These distortions may
   seriously damage both speech characteristics and intelligibility, and
   consequently be harmful to many speech applications. To solve this
   problem, we proposed a dereverberation algorithm based on multi-channel
   linear prediction. The method is as follows. First we calculate
   prediction filters that cancel out the room reverberation but also
   degrade speech characteristics by causing excessive whitening of the
   speech. Then, we evaluate the prediction-filter degradation to
   compensate for the excessive whitening. As the reverberation lengthens,
   the compensation performance becomes worse due to computational accuracy
   problems. In this paper, we propose a new computation that may improve
   compensation accuracy when dealing with long reverberation.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Delcroix, M (Corresponding Author), NTT Corp, Commun Sci Labs, Kyoto 6190237, Japan.
   NTT Corp, Commun Sci Labs, Kyoto 6190237, Japan.
   Hokkaido Univ, Grad Sch Informat Sci \& Technol, Sapporo, Hokkaido 0600814, Japan.}},
DOI = {{10.1093/ietfec/e89-a.10.2837}},
ISSN = {{0916-8508}},
EISSN = {{1745-1337}},
Keywords = {{blind dereverberation; linear prediction; multi-channel}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Engineering, Electrical \& Electronic}},
Author-Email = {{marc.delcroix@cslab.kecl.ntt.co.jp}},
Cited-References = {{Aichner R, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P445, DOI 10.1109/NNSP.2002.1030056.
   Delcroix M., 2004, P ICSLP 04, V2, P877.
   DELCROIX M, 2006, P ICASSP 06, V1, P825.
   Delcroix M, 2005, ACOUST SCI TECHNOL, V26, P432, DOI 10.1250/ast.26.432.
   GANNOT S, 2001, P IWAENC, P47.
   Gillespie BW, 2002, INT CONF ACOUST SPEE, P557.
   Harville D. A., 1997, MATRIX ALGEBRA STAT.
   Haykin S., 1996, ADAPTIVE FILTER THEO.
   HIKICHI T, 2006, IN PRESS P EUSIPCO 0.
   HIKICHI T, 2005, P IEEE INT C AC SPEE, V1, P1069.
   Kailath T, 2000, PR H INF SY, pXIX.
   Li K, 2005, IEEE T SPEECH AUDI P, V13, P965, DOI 10.1109/TSA.2005.851955.
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509.
   Miyoshi M., 2003, P ICA 03, P585.
   MOULAERT F, 1995, PROGR PLANNING, V43, P2.
   Qiu WZ, 1997, AUTOMATICA, V33, P741, DOI 10.1016/S0005-1098(96)00244-0.
   SUN X, 2001, P 3 INT C ICA BSS SA, P59.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{IEICE Trans. Fundam. Electron. Commun. Comput. Sci.}},
Doc-Delivery-Number = {{095KE}},
Unique-ID = {{ISI:000241305800052}},
DA = {{2020-12-06}},
}

@article{ ISI:000238236700020,
Author = {Rufiner, Hugo L. and Goddard, John and Rocha, Luis F. and Torres, Maria
   E.},
Title = {{Statistical method for sparse coding of speech including a linear
   predictive model}},
Journal = {{PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS}},
Year = {{2006}},
Volume = {{367}},
Pages = {{231-251}},
Month = {{JUL 15}},
Abstract = {{Recently, different methods for obtaining sparse representations of a
   signal using dictionaries of waveforms have been studied. They are often
   motivated by the way the brain seems to process certain sensory signals.
   Algorithms have been developed using a specific criterion to choose the
   waveforms occurring in the representation. The waveforms are choosen
   from a fixed dictionary and some algorithms also construct them as a
   part of the method. In the case of speech signals, most approaches do
   not take into consideration the important temporal correlations that are
   exhibited. It is known that these correlations are well approximated by
   linear models. Incorporating this a priori knowledge of the signal can
   facilitate the search for a suitable representation solution and also
   can help with its interpretation. Lewicki proposed a method to solve the
   noisy and overcomplete independent component analysis problem. In the
   present paper we propose a modification of this statistical technique
   for obtaining a sparse representation using a generative parametric
   model. The representations obtained with the method proposed here and
   other techniques are applied to artificial data and real speech signals,
   and compared using different coding costs and sparsity measures. The
   results show that the proposed method achieves more efficient
   representations of these signals compared to the others. A qualitative
   analysis of these results is also presented, which suggests that the
   restriction imposed by the parametric model is helpful in discovering
   meaningful characteristics of the signals. (c) 2005 Elsevier B.V. All
   rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Rufiner, HL (Corresponding Author), Univ Nac Entre Rios, Fac Ingn, Ruta Prov 11,Km 10, RA-3100 Oro Verde, Entre Rios, Argentina.
   Univ Nac Entre Rios, Fac Ingn, RA-3100 Oro Verde, Entre Rios, Argentina.
   Univ Autonoma Metropolitana Iztapalapa, Dept Ing Elect, Mexico City, DF, Mexico.
   Univ Buenos Aires, Fac Ingn, RA-1053 Buenos Aires, DF, Argentina.}},
DOI = {{10.1016/j.physa.2005.11.029}},
ISSN = {{0378-4371}},
EISSN = {{1873-2119}},
Keywords = {{speech analysis and representation; sparse coding; linear predictive
   coding; basis pursuit; matching pursuit; independent component analysis}},
Keywords-Plus = {{INDEPENDENT COMPONENT ANALYSIS; RECOGNITION; ALGORITHMS}},
Research-Areas = {{Physics}},
Web-of-Science-Categories  = {{Physics, Multidisciplinary}},
Author-Email = {{lrufiner@bioingenieria.edu.ar}},
ResearcherID-Numbers = {{Rufiner, Hugo Leonardo/R-7337-2019
   Rufiner, Hugo Leonardo/B-8484-2012
   Torres, Maria/A-5982-2010}},
ORCID-Numbers = {{Rufiner, Hugo Leonardo/0000-0002-1083-5891
   Rufiner, Hugo Leonardo/0000-0002-1083-5891
   Torres, Maria/0000-0002-1512-9507}},
Cited-References = {{ABDALLAH SA, 2002, THESIS KINGS COLL LO.
   ARONSON L, 2000, RIOPLATENSE FONAUDIO, V46, P12.
   CASACUBERTA F, 1991, WORKSH INT COOP STAN, P26.
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010.
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732.
   DAUBECHIES I, 1988, IEEE T INFORM THEORY, V34, P605, DOI 10.1109/18.9761.
   DONOHO DL, 1998, SPARSE COMPONENTS IM.
   Goodwin MM, 1999, IEEE T SIGNAL PROCES, V47, P1890, DOI 10.1109/78.771038.
   GUSPI F, 2000, INGENIERO RED, V1.
   HARPUR GF, 1997, THESIS U CAMBRIDGE Q.
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616.
   Hillenbrand JM, 2001, J ACOUST SOC AM, V109, P748, DOI 10.1121/1.1337959.
   Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5.
   Hyvarinen A., 1999, NEURAL COMPUTING SUR, V2, P94.
   JUNG TP, 2000, P 2 INT WORKSH IND C, P633.
   Katayama K, 2002, PHYSICA A, V310, P532, DOI 10.1016/S0378-4371(02)00785-9.
   Kwon OW, 2004, SIGNAL PROCESS, V84, P1005, DOI 10.1016/j.sigpro.2004.03.004.
   Lee JH, 2000, INT CONF ACOUST SPEE, P1631, DOI 10.1109/ICASSP.2000.862023.
   Lewicki MS, 1998, ADV NEUR IN, V10, P556.
   Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587.
   Lewicki MS, 2002, NAT NEUROSCI, V5, P356, DOI 10.1038/nn831.
   Lippmann RP, 1997, SPEECH COMMUN, V22, P1, DOI 10.1016/S0167-6393(97)00021-6.
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979.
   Makeig S, 1996, ADV NEUR IN, V8, P145.
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082.
   Olshausen BA, 2000, AM SCI, V88, P238, DOI 10.1511/2000.3.238.
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0.
   OLSHAUSEN BA, 1995, P WORKSH INF THEORY, V7, P33.
   Parks TW, 1987, DIGITAL FILTER DESIG, P226.
   Plumbley MD, 2002, CYBERNET SYST, V33, P603, DOI 10.1080/01969720290040777.
   Rabiner L., 1993, FUNDAMENTALS SPEECH.
   Rufiner H., 2002, P INT C SPOK LANG PR, P989.
   RUFINER HL, 2001, 5 WORLD MULT C SYST, P517.
   RUFINER HL, 2002, P 2 JOINT M IEEE ENG, V1, P288.
   Saito N, 2000, PROC SPIE, V4119, P474, DOI 10.1117/12.408635.
   SAITO N, 2003, STUDIES COMPUTATIONA, V10, P225.
   TORRES ME, 1999, THESIS U NACL ROSARI.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Physica A}},
Doc-Delivery-Number = {{052MB}},
Unique-ID = {{ISI:000238236700020}},
DA = {{2020-12-06}},
}

@article{ ISI:000239178600006,
Author = {Faundez-Zanuy, Marcos},
Title = {{Speech coding through adaptive combined nonlinear prediction}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2006}},
Volume = {{48}},
Number = {{7}},
Pages = {{838-847}},
Month = {{JUL}},
Note = {{Research Workshop on Non-Linear Speech Processing (NOLISP), Le Croisic,
   FRANCE, MAY 20-23, 2003}},
Organization = {{IRISA; IRCCyN; ISCA}},
Abstract = {{In this paper we propose a nonlinear predictive speech encoder based on
   an adaptive combiner with a neural net that weighs the prediction of
   several nonlinear predictors. Thus, we exploit the advantages of data
   fusion on a nonlinear prediction scheme, where it appears in a more
   natural way than for linear predictors. Experimental results reveal that
   this scheme outperforms the fixed combination (with mean, median, etc.
   operators) up to 1.5 dB in SEGSNR. (C) 2005 Elsevier B.V. All rights
   reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Faundez-Zanuy, M (Corresponding Author), Escola Univ Politecn Mataro, Avda Puig \& Cadafalch 101-111, Barcelona 08303, Spain.
   Escola Univ Politecn Mataro, Barcelona 08303, Spain.}},
DOI = {{10.1016/j.specom.2005.09.007}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{speech coding; nonlinear prediction; neural networks; data fusion}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{faundez@eupmt.es}},
ResearcherID-Numbers = {{Faundez-Zanuy, Marcos/F-6503-2012}},
ORCID-Numbers = {{Faundez-Zanuy, Marcos/0000-0003-0605-1282}},
Cited-References = {{Banbrook M, 1999, IEEE T SPEECH AUDI P, V7, P1, DOI 10.1109/89.736326.
   BIRGMEIER M, 1996, P EUSIPCO, V1, P459.
   CAMPBELL KP, 1999, BIOMETRICS PERSONAL, pCH8.
   Faundez-Zanuy M, 2005, IEEE AERO EL SYS MAG, V20, P34, DOI 10.1109/MAES.2005.1396793.
   Faundez-Zanuy M., 2002, Control and Intelligent Systems, V30, P1.
   FAUNDEZZANUY M, 2000, EUSIPCO 2000 TAMP, V2, P813.
   FORESEE FD, 1997, P 1997 INT JOINT C N, P1930, DOI DOI 10.1109/ICNN.1997.614194.
   GERSHO A, 1990, IEEE T COMMUN, V38, P1285, DOI 10.1109/26.61363.
   HAYKIN S, 1999, COMMITTEE MACHINES N.
   HIGGINS AL, 1993, P ICASSP, V2, P375.
   JAIN AK, 1996, IEEE COMPUTER    MAR, P31.
   JAYANT NS, 1984, DIGITAL COMPRESSION.
   KUBIN G, 1996, ICASSP.
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415.
   Mann I, 2001, SIGNAL PROCESS, V81, P1743, DOI 10.1016/S0165-1684(01)00087-1.
   MUMOLO E, 1993, WORKSH NONL DIG SIGN.
   NARAYANAN SS, 1995, J ACOUST SOC AM, V97, P2511, DOI 10.1121/1.411971.
   Perrone M., 1993, NEURAL NETWORKS SPEE.
   REYNOLDS DA, 1995, IEEE T SPEECH AUDIO, V3.
   SOONG FK, 1988, IEEE T ACOUST SPEECH, V36, P871, DOI 10.1109/29.1598.
   THYSSEN J, 1994, P IEEE INT C AC SPEE, V1, P185.
   Webb A.R., 2002, STAT PATTERN RECOGNI.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{065SC}},
Unique-ID = {{ISI:000239178600006}},
DA = {{2020-12-06}},
}

@article{ ISI:000234686500002,
Author = {van Wijngaarden, SJ and Verhave, JA},
Title = {{Prediction of speech intelligibility for public address systems in
   traffic tunnels}},
Journal = {{APPLIED ACOUSTICS}},
Year = {{2006}},
Volume = {{67}},
Number = {{4}},
Pages = {{306-323}},
Month = {{APR}},
Abstract = {{Traffic tunnels are generally hostile acoustic environments, both in
   terms of reverberation and ambient noise levels. Public address (PA)
   systems used to convey spoken warnings must meet stringent design
   requirements in order to produce sufficiently intelligible speech. To be
   able to predict PA system performance at tunnel design time, two
   different speech transmission index (STI) calculation procedures were
   implemented. The first procedure predicts the STI based on ray-tracing
   simulations. Comparison with measured STI data showed that this
   simulation approach yields accurate intelligibility estimates. However,
   the procedure is time-consuming and too complex to be used by
   non-specialists. For this reason, a second (simpler and more efficient)
   procedure was developed, based on fixed non-linear regression,
   statistically deriving prediction functions from measured data and
   ray-tracing results. This procedure was compared to the approach based
   on ray tracing, and found to yield STI predictions closely matching
   those of the ray-tracing model. (c) 2005 Elsevier Ltd. All rights
   reserved.}},
Publisher = {{ELSEVIER SCI LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{van Wijngaarden, SJ (Corresponding Author), TNO, POB 23, NL-3769 ZG Soesterberg, Netherlands.
   TNO, NL-3769 ZG Soesterberg, Netherlands.}},
DOI = {{10.1016/j.apacoust.2005.07.001}},
ISSN = {{0003-682X}},
Keywords = {{tunnels; intelligibility; prediction; STI}},
Keywords-Plus = {{MODULATION TRANSFER-FUNCTION; UNIVERSITY CLASSROOMS; ROOM ACOUSTICS;
   NOISE-LEVELS; QUALITY}},
Research-Areas = {{Acoustics}},
Web-of-Science-Categories  = {{Acoustics}},
Author-Email = {{sander.vanwijngaarden@tno.nl}},
Cited-References = {{{[}Anonymous], 2003, 9921 ISO.
   CHRISTENSEN CL, 1998, ODEON ROOM ACOUSTICS.
   Heerema N, 1999, APPL ACOUST, V57, P51, DOI 10.1016/S0003-682X(98)00037-1.
   Hodgson M, 2002, J ACOUST SOC AM, V112, P568, DOI 10.1121/1.1490363.
   Hodgson M, 1999, J ACOUST SOC AM, V105, P226, DOI 10.1121/1.424600.
   HOUTGAST T, 1973, ACUSTICA, V28, P66.
   HOUTGAST T, 1980, ACUSTICA, V46, P60.
   {*}INT EL COMM, 2003, 6026816 IEC.
   JACOB K, 2002, PAST PRESENT FUTURE.
   LUZZATO E, 1986, P INTERNOISE, P905.
   SCHROEDER MR, 1981, ACUSTICA, V49, P179.
   {*}STATS INC, 2000, STAT WIND COMP PROGR.
   Steeneken HJM, 1999, SPEECH COMMUN, V28, P109, DOI 10.1016/S0167-6393(99)00007-2.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEENEKEN HJM, 1992, THESIS U AMSTERDAM.
   VANRIETSCHOTE HF, 1981, ACUSTICA, V49, P245.
   VANWIJNGAARDEN SJ, 2001, INFLUENCE FANM TRAFF.
   VANWIJNGAARDEN SJ, 2002, PAST PRESENT FUTURE.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Appl. Acoust.}},
Doc-Delivery-Number = {{003MO}},
Unique-ID = {{ISI:000234686500002}},
DA = {{2020-12-06}},
}

@article{ ISI:000235508800051,
Author = {Kondo, K and Nakagawa, K},
Title = {{A speech packet loss concealment method using linear prediction}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{2006}},
Volume = {{E89D}},
Number = {{2}},
Pages = {{806-813}},
Month = {{FEB}},
Note = {{8th International Conference for Spoken Language Processing, Cheju Isl,
   SOUTH KOREA, OCT 05-09, 2004}},
Abstract = {{We proposed and evaluated a speech packet loss concealment method which
   predicts lost segments from speech included in packets either before, or
   both before and after the lost packet. The lost segments are predicted
   recursively by using linear prediction both in the forward direction
   from the packet preceding the loss, and in the backward direction from
   the packet succeeding the lost segment. Predicted samples in each
   direction are smoothed by averaging using linear weights to obtain the
   final interpolated signal. The adjacent segments are also smoothed
   extensively to significantly reduce the speech quality discontinuity
   between the interpolated signal and the received speech signal.
   Subjective quality comparisons between the proposed method and the the
   packet loss concealment algorithm described in the ITU standard G.711
   Appendix I showed similar scores up to about 10\% packet loss. However,
   the proposed method showed higher scores above this loss rate, with Mean
   Opinion Score rating exceeding 2.4, even at an extremely high packet
   loss rate of 30\%. Packet loss concealment of speech degraded with G.729
   coding, and babble noise mixed speech showed similar trends, with the
   proposed method showing higher qualities at high loss rates. We plan to
   further improve the performance by using adaptive LPC prediction order
   depending on the estimated pitch, and adaptive LPC bandwidth expansion
   depending on the consecutive number of repetitive prediction, among many
   other improvements. We also plan to investigate complexity reduction
   using gradient LPC coefficient updates, and processing delay reduction
   using adaptive forward/bidirectional prediction modes depending on the
   measured packet loss ratio.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kondo, K (Corresponding Author), Yamagata Univ, Fac Engn, Yonezawa, Yamagata 9928510, Japan.
   Yamagata Univ, Fac Engn, Yonezawa, Yamagata 9928510, Japan.}},
DOI = {{10.1093/ietisy/e89-d.2.806}},
ISSN = {{1745-1361}},
Keywords = {{speech packets; packet loss concealment; linear prediction; segment
   smoothing; subjective speech quality evaluations}},
Keywords-Plus = {{SUBSTITUTION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Author-Email = {{kkondo@yz.yamagata-u.ac.jp}},
ResearcherID-Numbers = {{Kondo, Kazuhiro/D-3063-2016}},
ORCID-Numbers = {{Kondo, Kazuhiro/0000-0003-2160-8683}},
Cited-References = {{{*}ANSI, 2000, T1521A2000 ITUT.
   GOODMAN DJ, 1986, IEEE T ACOUST SPEECH, V34, P1440, DOI 10.1109/TASSP.1986.1164984.
   Gunduzhan E, 2001, IEEE T SPEECH AUDI P, V9, P778, DOI 10.1109/89.966081.
   HARDMAN V, 1995, P INET 95, P171.
   Haykin S., 1996, ADAPTIVE FILTER THEO.
   Itahashi S., 1999, Journal of the Acoustical Society of Japan (E), V20, P163.
   {*}ITUT, G711 ITUT.
   {*}ITUT, 1996, G729 CSACELP.
   {*}JAP INF PROC DEV, 1991, ASJ CONT SPEECH CORP.
   kondo K., 2004, P INT C SPOK LANG PR.
   LEE M, 2004, P INT C SPOK LANG PR.
   Montgomery W. A., 1983, IEEE Journal on Selected Areas in Communications, VSAC-1, P1022, DOI 10.1109/JSAC.1983.1146024.
   Perkins C, 1998, IEEE NETWORK, V12, P40, DOI 10.1109/65.730750.
   SANNECK H, 1996, P IEEE GLOBECOM, P48.
   TOHKURA Y, 1978, IEEE T ACOUST SPEECH, V26, P587, DOI 10.1109/TASSP.1978.1163165.
   Wah BW, 2000, INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P17, DOI 10.1109/MMSE.2000.897185.
   WASEM OJ, 1988, IEEE T ACOUST SPEECH, V36, P342, DOI 10.1109/29.1530.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{014VP}},
Unique-ID = {{ISI:000235508800051}},
DA = {{2020-12-06}},
}

@article{ ISI:000233943400015,
Author = {Polur, PD and Miller, GE},
Title = {{Experiments with fast Fourier transform, linear predictive and cepstral
   coefficients in dysarthric speech recognition algorithms using hidden
   Markov model}},
Journal = {{IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING}},
Year = {{2005}},
Volume = {{13}},
Number = {{4}},
Pages = {{558-561}},
Month = {{DEC}},
Abstract = {{In this study, a hidden Markov Model was constructed and conditions were
   investigated that would provide improved performance for a dysarthric
   speech (isolated word) recognition system. The speaker dependant system
   was intended to act as an assistive/control tool. A small size
   vocabulary spoken by three cerebral palsy subjects was chosen. Fast
   Fourier transform, linear predictive, and Mel frequency cepstral
   coefficients extracted from data provided training input to several
   whole-word hidden Markov model configurations. The effect of model
   structure, number of states, and frame rates were also investigated. It
   was noted that a 10-state ergodic model using 15 msec frames was better
   than other configurations. Furthermore, it was found that a Mel cepstrum
   based model outperformed a fast Fourier transform and linear prediction
   based model. The system offers effective and robust application as a
   rehabilitation and/or control tool to assist dysarthric motor impaired
   individuals.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Polur, PD (Corresponding Author), Virginia Commonwealth Univ, Dept Biomed Engn, Richmond, VA 23298 USA.
   Virginia Commonwealth Univ, Dept Biomed Engn, Richmond, VA 23298 USA.}},
DOI = {{10.1109/TNSRE.2005.856074}},
ISSN = {{1534-4320}},
EISSN = {{1558-0210}},
Keywords = {{cerebral palsy; dysarthric speech; fast Fourier coefficients; hidden
   Markov model; linear prediction coefficients; Mel frequency cepstral
   coefficients; speech recognition}},
Research-Areas = {{Engineering; Rehabilitation}},
Web-of-Science-Categories  = {{Engineering, Biomedical; Rehabilitation}},
Author-Email = {{pbpolur@vcu.edu
   gemiller@vcu.edu}},
Cited-References = {{Bickley C., 2000, Proceedings of the RESNA 2000 Annual Conference. Technology for the New Millennium, P76.
   CHEN F, 1997, IEEE EMBS C CHIC IL, V4, P1436.
   DELLER JR, 1991, COMPUT METH PROG BIO, V35, P125, DOI 10.1016/0169-2607(91)90071-Z.
   Gold CJ, 2001, CEREBRAL PALSY J COO.
   Green P. D., 2003, EUROSPEECH, P1189.
   HATZIS A, 2003, P 8 EUR C SPEECH COM, P2213.
   JAYARAM G, 1995, J REHABIL RES DEV, V32, P162.
   Jelinek F., 1998, STAT METHODS SPEECH.
   Mak BKW, 2004, IEEE T SPEECH AUDI P, V12, P27, DOI 10.1109/TSA.2003.819951.
   MenendezPidal X, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1962, DOI 10.1109/ICSLP.1996.608020.
   Noyes Jan M., 1992, AAC (Augmentative and Alternative Communication), V8, P297, DOI 10.1080/07434619212331276333.
   PAO TL, P ROCL 16.
   PARKER M, 2003, STARDUST PROJECT SPE.
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626.
   TOMPKINS WJ, 1981, DESIGN MICROCOMPUTER.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{26}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{IEEE Trans. Neural Syst. Rehabil. Eng.}},
Doc-Delivery-Number = {{993GU}},
Unique-ID = {{ISI:000233943400015}},
DA = {{2020-12-06}},
}

@article{ ISI:000230037700004,
Author = {Fosler-Lussier, E and Amdal, I and Kuo, HKJ},
Title = {{A framework for predicting speech recognition errors}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2005}},
Volume = {{46}},
Number = {{2}},
Pages = {{153-170}},
Month = {{JUN}},
Note = {{Workshop on Pronunciation Modeling and Lexicon Adaptation, Estes Pk, CO,
   2002}},
Abstract = {{Pronunciation modeling in automatic speech recognition systems has had
   mixed results in the past; one likely reason for poor performance is the
   increased confusability in the lexicon from adding new pronunciation
   variants. In this work, we propose a new framework for determining
   lexically confusable words based on inverted finite state transducers
   (FSTs); we also present experiments designed to test some of the
   implementation details of this framework. The method is evaluated by
   examining how well the algorithm predicts the errors in an ASR system.
   The model is able to generalize confusions learned from a training set
   to predict errors made by the speech recognizer on an unseen test set.
   (c) 2005 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Fosler-Lussier, E (Corresponding Author), Ohio State Univ, Dept Comp Sci \& Engn, Columbus, OH 43210 USA.
   Ohio State Univ, Dept Comp Sci \& Engn, Columbus, OH 43210 USA.
   Norwegian Univ Sci \& Technol, N-7034 Trondheim, Norway.
   IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.}},
DOI = {{10.1016/j.specom.2005.03.003}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{automatic speech recognition; error prediction; pronunciation modeling;
   lexicon optimization; lexical adaptation}},
Keywords-Plus = {{WORD}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{fosler@cse.ohio-state.edu}},
ORCID-Numbers = {{Fosler-Lussier, Eric/0000-0001-8004-5169}},
Cited-References = {{Bilmes J, 2002, INT CONF ACOUST SPEE, P3916.
   CHASE L, 1997, THESIS CARNEGIE MELO.
   CHEN Z, 2000, P INT C SPOK LANG PR, P493.
   Chomsky N., 1968, SOUND PATTERN ENGLIS.
   Cucchiarini C, 1996, CLIN LINGUIST PHONET, V10, P131, DOI 10.3109/02699209608985167.
   DENG Y, 2003, P EUR GEN SWITZ SEPT, P929.
   FOSLERLUSSIER E, 2002, ISCA TUT RES WORKSH.
   FOSLERLUSSIER E, 1999, DARPA BROADC NEWS WO.
   FOSLERLUSSIER JE, 1999, THESIS U CALIFORNIA.
   Goel V, 2004, IEEE T SPEECH AUDI P, V12, P234, DOI 10.1109/TSA.2004.825678.
   Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487.
   GREENBERG S, 1996, P 4 INT C SPOK LANG, pS24.
   Greenberg S., 2000, P NIST SPEECH TRANSC.
   HETHERINGTON L, 1995, P EUR C SPEECH COMM, P1645.
   HIRSCHBERG J, 1999, P AUT SPEECH REC UND.
   Holter T, 1999, SPEECH COMMUN, V29, P177, DOI 10.1016/S0167-6393(99)00036-9.
   Jakobson R., 1952, 13 MIT AC LAB.
   Kessens JM, 1999, SPEECH COMMUN, V29, P193, DOI 10.1016/S0167-6393(99)00048-5.
   Kuo KHJ, 2002, INT CONF ACOUST SPEE, P325.
   Livescu K, 2000, INT CONF ACOUST SPEE, P1683, DOI 10.1109/ICASSP.2000.862074.
   Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152.
   MCALLASTER D, 1998, P INT C SPOK LANG PR, P1847.
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526.
   Mohri M, 1998, INT CONF ACOUST SPEE, P665, DOI 10.1109/ICASSP.1998.675352.
   MOU X, 2000, P EUR ALB DENM, P451.
   {*}NAT I STAND TECHN, 2001, SCLITE SCOR SOFTW.
   PITRELLI J, 1995, PHONEBOOK NYNEX ISOL.
   POTAMIANOS A, 2000, P INT C SPOK LANG PR, P603.
   Press W. H., 1999, NUMERICAL RECIPES C.
   Printz H, 2002, COMPUT SPEECH LANG, V16, P131, DOI 10.1006/csla.2001.0188.
   RILEY M, 1998, ESCA TUT RES WORKSH, P109.
   RILEY MD, 1991, INT CONF ACOUST SPEE, P737, DOI 10.1109/ICASSP.1991.150446.
   Schaaf T, 1997, INT CONF ACOUST SPEE, P875, DOI 10.1109/ICASSP.1997.596075.
   SCHRAMM H, 2002, ISCA TUT RES WORKSH.
   Sloboda T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2328, DOI 10.1109/ICSLP.1996.607274.
   SPROAT R, 1998, MULTILINGUAL TEXT SP.
   Voiers W. D., 1983, Speech Technology, V1, P30.
   WESTER M, 2000, P INT C SPOK LANG PR, P270.
   WILLIAMS DAG, 1999, THESIS U SHEFFIELD S.
   ZHOU Q, 1997, P EUR RHOD GREEC, P621.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{938XW}},
Unique-ID = {{ISI:000230037700004}},
DA = {{2020-12-06}},
}

@article{ ISI:000228403900007,
Author = {Chien, JT and Furui, S},
Title = {{Predictive hidden Markov model selection for speech recognition}},
Journal = {{IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING}},
Year = {{2005}},
Volume = {{13}},
Number = {{3}},
Pages = {{377-387}},
Month = {{MAY}},
Abstract = {{This paper surveys a series of model selection approaches and presents a
   novel predictive information criterion (PIC) for hidden Markov model
   (HMM) selection. The approximate Bayesian using Viterbi approach is
   applied for PIC selection of the best HMMs providing the largest
   prediction information for generalization of future data. When the
   perturbation of HMM parameters is expressed by a product of conjugate
   prior densities, the segmental prediction information is derived at the
   frame level without Laplacian integral approximation. In particular, a
   multivariate t distribution is attained to characterize the prediction
   information corresponding to HMM mean vector and precision matrix. When
   performing model selection in tree structure HMMs, we develop a top-down
   prior/posterior propagation algorithm for estimation of structural
   hyperparameters. The prediction information is determined so as to
   choose the best HMM tree model. Different from maximum likelihood (ML)
   and minimum description length (MDL) selection criteria, the parameters
   of PIC chosen HMMs are computed via maximum a posteriori estimation. In
   the evaluation of continuous speech recognition using decision tree
   HMMs, the PIC criterion outperforms ML and MDL criteria in building a
   compact tree structure with moderate tree size and higher recognition
   rate.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chien, JT (Corresponding Author), Natl Cheng Kung Univ, Dept Comp Sci \& Informat Engn, Tainan 70101, Taiwan.
   Natl Cheng Kung Univ, Dept Comp Sci \& Informat Engn, Tainan 70101, Taiwan.
   Tokyo Inst Technol, Dept Comp Sci, Tokyo 1528552, Japan.}},
DOI = {{10.1109/TSA.2005.845810}},
ISSN = {{1063-6676}},
Keywords = {{approximate Bayesian; decision tree state tying; model selection;
   multivariate t distribution; predictive information criterion;
   prior/posterior propagation; speech recognition}},
Keywords-Plus = {{TRANSFORMATION; ADAPTATION}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{jtchien@mail.ncku.edu.tw
   furui@cs.titech.ac.jp}},
ORCID-Numbers = {{Chien, Jen-Tzung/0000-0003-3466-8941}},
Cited-References = {{AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705.
   Attias H, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P21.
   BAHL LR, 1991, INT CONF ACOUST SPEE, P185, DOI 10.1109/ICASSP.1991.150308.
   Chen SS, 1998, INT CONF ACOUST SPEE, P645, DOI 10.1109/ICASSP.1998.675347.
   Chien JT, 2000, SPEECH COMMUN, V30, P235, DOI 10.1016/S0167-6393(99)00052-7.
   Chien JT, 2001, IEEE T SPEECH AUDI P, V9, P399, DOI 10.1109/89.917685.
   CHIEN JT, 2002, P IEEE INT C AC SPEE, V1, P873.
   CHOU W, 1999, P ICASSP 99, V1, P345.
   DeGroot Morris H., 1970, OPTIMAL STAT DECISIO.
   DJURIC PM, 1994, IEEE T SIGNAL PROCES, V42, P1685, DOI 10.1109/78.298276.
   DJURIC PM, 1990, P IEEE INT C AC SPEE, V5, P2415.
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138.
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278.
   GEISSER S, 1979, J AM STAT ASSOC, V74, P153, DOI 10.2307/2286745.
   Haykin S., 1999, NEURAL NETWORKS COMP.
   Huo Q, 1997, IEEE T SPEECH AUDI P, V5, P161, DOI 10.1109/89.554778.
   Huo Q, 1997, INT CONF ACOUST SPEE, P1547, DOI 10.1109/ICASSP.1997.596246.
   Hwang MY, 1993, IEEE T SPEECH AUDI P, V1, P414, DOI 10.1109/89.242487.
   Hwang MY, 1996, IEEE T SPEECH AUDI P, V4, P412, DOI 10.1109/89.544526.
   Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5.
   Jiang H, 1999, IEEE T SPEECH AUDI P, V7, P426, DOI 10.1109/89.771309.
   Mackay D. J. C., 1992, NEURAL COMPUT, V4, P405.
   MERHAV N, 1989, IEEE T INFORM THEORY, V35, P1109, DOI 10.1109/18.42231.
   Padmanabhan M, 1998, IEEE T SPEECH AUDI P, V6, P71, DOI 10.1109/89.650313.
   Rabiner L., 1993, FUNDAMENTALS SPEECH.
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5.
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136.
   Shinoda K, 2001, IEEE T SPEECH AUDI P, V9, P276, DOI 10.1109/89.906001.
   Shinoda K, 1997, P EUR, P99.
   Siohan O, 2002, COMPUT SPEECH LANG, V16, P5, DOI 10.1006/csla.2001.0181.
   Ueberla JP, 1997, INT CONF ACOUST SPEE, P807, DOI 10.1109/ICASSP.1997.596052.
   Vila JP, 2000, IEEE T NEURAL NETWOR, V11, P265, DOI 10.1109/72.838999.
   YOUNG SJ, 1994, P ARPA WORKSH HUM LA, P286.
   ZHANG Z, 2001, P IEEE WORKSH AUT SP.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{25}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{IEEE Trans. Speech Audio Process.}},
Doc-Delivery-Number = {{916RQ}},
Unique-ID = {{ISI:000228403900007}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000227673000005,
Author = {Chang, CM and Kuo, HS and Chang, SH and Chang, HJ and Liou, DM and
   Laszlo, T and Chen, THH},
Title = {{Computer-aided disease prediction system: development of application
   software with SAS component language}},
Journal = {{JOURNAL OF EVALUATION IN CLINICAL PRACTICE}},
Year = {{2005}},
Volume = {{11}},
Number = {{2}},
Pages = {{139-159}},
Month = {{APR}},
Abstract = {{Aims The intricacy of predictive models associated with prognosis and
   risk classification of disease often discourages medical personnel who
   are interested in this field. The aim of this study was therefore to
   develop a computer-aided disease prediction model underpinning a
   step-by-step statistics-guided approach including five components: (1)
   data management; (2) exploratory analysis; (3) type of predictive model;
   (4) model verification; (5) interactive mode of disease prediction using
   SAS 8.02 Windows 2000 as a platform. Methods The application of this
   system was illustrated by using data from the Swedish Two-County Trial
   on breast cancer screening. The effects of tumour size, node status, and
   histological grade on breast cancer death using logistic regression
   model or survival models were predicted. A total of 20 questions were
   designed to exemplify the usefulness of each component. We also
   evaluated the system using a controlled randomized trial. Times to
   finish the above 20 questions were used as endpoint to evaluate the
   performance of the current system. User satisfaction with the current
   system such as easy to use, the efficiency of risk prediction, and the
   reduction of barrier to predictive model was also evaluated. Results The
   intervention group not only performed more efficiently than the control
   group but also satisfied with this application software. Conclusions The
   MD-DP-SOS system characterized by menu-driven style, comprehensiveness,
   accuracy and adequacy assessment, and interactive mode of disease
   prediction is helpful for medical personnel who are involved in disease
   prediction.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chen, THH (Corresponding Author), Natl Taiwan Univ, Coll Publ Hlth, Inst Prevent Med, Room 207,2F,No 19 Xuzhou Rd, Taipei 100, Taiwan.
   Natl Taiwan Univ, Coll Publ Hlth, Inst Prevent Med, Taipei 100, Taiwan.
   Natl Yang Ming Univ, Sch Med, Inst Publ Hlth, Taipei 112, Taiwan.
   Natl Taiwan Univ, Coll Publ Hlth, Grad Inst Epidemiol, Biostat Unit, Taipei 10764, Taiwan.
   Dept Hlth, Bur Natl Hlth Insurance, Taipei, Taiwan.
   Natl Yang Ming Univ, Sch Med, Inst Hlth Informat \& Decis Making, Taipei 112, Taiwan.
   Falun Cent Hosp, Dept Mammog, Falun, Sweden.}},
DOI = {{10.1111/j.1365-2753.2005.00514.x}},
ISSN = {{1356-1294}},
EISSN = {{1365-2753}},
Keywords = {{computer-aided system; Cox regression model; disease prediction model;
   logistic regression; randomized control trial; SAS software; survival
   model}},
Keywords-Plus = {{CHRONIC HEALTH EVALUATION; APACHE-II SEVERITY; CLASSIFICATION-SYSTEM;
   ACUTE PHYSIOLOGY; SCORING SYSTEM; ILLNESS SCORE; BREAST-CANCER;
   VALIDATION; MORTALITY; RISK}},
Research-Areas = {{Health Care Sciences \& Services; Medical Informatics; General \&
   Internal Medicine}},
Web-of-Science-Categories  = {{Health Care Sciences \& Services; Medical Informatics; Medicine, General
   \& Internal}},
Author-Email = {{stony@episerv.cph.ntu.edu.tw}},
ORCID-Numbers = {{Chen, Hsiu-Hsi/0000-0002-5799-6705
   Chang, Shu-Hui/0000-0002-6164-0875}},
Cited-References = {{BRIGGS M, 1984, BRIT MED J, V288, P983.
   CALVERT W, 1996, CONCEPTS CASE STUDIE.
   CUCKLE HS, 1987, BRIT J OBSTET GYNAEC, V94, P387, DOI 10.1111/j.1471-0528.1987.tb03115.x.
   D'Agostino R B, 1982, Stat Med, V1, P41, DOI 10.1002/sim.4780010107.
   EDWARDS FH, 1988, ANN THORAC SURG, V45, P437, DOI 10.1016/S0003-4975(98)90020-0.
   HEADLEY J, 1992, CANCER-AM CANCER SOC, V70, P497, DOI 10.1002/1097-0142(19920715)70:2<497::AID-CNCR2820700220>3.0.CO;2-H.
   JOHNSON MH, 1986, CRIT CARE MED, V14, P693, DOI 10.1097/00003246-198608000-00006.
   KNAUS WA, 1981, CRIT CARE MED, V9, P591, DOI 10.1097/00003246-198108000-00008.
   KNAUS WA, 1985, CRIT CARE MED, V13, P818, DOI 10.1097/00003246-198510000-00009.
   LUDWIGS U, 1995, CRIT CARE MED, V23, P854, DOI 10.1097/00003246-199505000-00013.
   {*}SAS AF, 2000, SAS AF SOFTW PROC GU.
   {*}SAS GRAPH, 2000, SAS GRAPH SOFTW REF, V1.
   {*}SAS GRAPH, 2000, SAS GRAPH SOFTW REF, V2.
   {*}SAS STAT, 1990, SAS STAT US GUID VER, V1.
   {*}SAS STAT, 1990, SAS STAT US GUID VER, V2.
   TABAR L, 1985, LANCET, V1, P829, DOI 10.1016/S0140-6736(85)92204-4.
   WONG DT, 1991, CAN J ANAESTH, V38, P374, DOI 10.1007/BF03007629.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{J. Eval. Clin. Pract.}},
Doc-Delivery-Number = {{906VS}},
Unique-ID = {{ISI:000227673000005}},
DA = {{2020-12-06}},
}

@article{ ISI:000235836400007,
Author = {Remus, JJ and Collins, LM},
Title = {{The effects of noise on speech recognition in cochlear implant subjects:
   Predictions and analysis using acoustic models}},
Journal = {{EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING}},
Year = {{2005}},
Volume = {{2005}},
Number = {{18}},
Pages = {{2979-2990}},
Abstract = {{Cochlear implants can provide partial restoration of hearing, even with
   limited spectral resolution and loss of fine temporal structure, to
   severely deafened individuals. Studies have indicated that background
   noise has significant deleterious effects on the speech recognition
   performance of cochlear implant patients. This study investigates the
   effects of noise on speech recognition using acoustic models of two
   cochlear implant speech processors and several predictive
   signal-processing-based analyses. The results of a listening test for
   vowel and consonant recognition in noise are presented and analyzed
   using the rate of phonemic feature transmission for each acoustic model.
   Three methods for predicting patterns of consonant and vowel confusion
   that are based on signal processing techniques calculating a
   quantitative difference between speech tokens are developed and tested
   using the listening test results. Results of the listening test and
   confusion predictions are discussed in terms of comparisons between
   acoustic models and confusion prediction performance.}},
Publisher = {{HINDAWI LTD}},
Address = {{ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Remus, JJ (Corresponding Author), Duke Univ, Pratt Sch Engn, Dept Elect \& Comp Engn, POB 90291, Durham, NC 27708 USA.
   Duke Univ, Pratt Sch Engn, Dept Elect \& Comp Engn, Durham, NC 27708 USA.}},
DOI = {{10.1155/ASP.2005.2979}},
ISSN = {{1110-8657}},
EISSN = {{1687-0433}},
Keywords = {{speech perception; confusion prediction; acoustic model; cochlear
   implant}},
Keywords-Plus = {{NORMAL-HEARING; SIGNAL PROCESSORS; LISTENERS; CHANNELS; INTELLIGIBILITY;
   STIMULATION; RESOLUTION; SENTENCES; NUMBER; VOWEL}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{jeremiah.remus@duke.edu
   lcollins@ee.duke.edu}},
Cited-References = {{Baskent D, 2003, J ACOUST SOC AM, V113, P2064, DOI 10.1121/1.1558357.
   BLAMEY PJ, 1984, J ACOUST SOC AM, V76, P97, DOI 10.1121/1.391012.
   {*}COCHL CORP U IOW, 1995, COCHL CORP U IOW REV.
   Deller JR, 1993, DISCRETE TIME PROCES.
   Devore J.L., 1995, PROBABILITY STAT ENG.
   Dorman MF, 1998, EAR HEARING, V19, P481, DOI 10.1097/00003446-199812000-00009.
   Dorman MF, 1998, J ACOUST SOC AM, V104, P3583, DOI 10.1121/1.423940.
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603.
   Fetterman BL, 2002, OTOLARYNG HEAD NECK, V126, P257, DOI 10.1067/mhn.2002.123044.
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538.
   Fu QJ, 1998, J ACOUST SOC AM, V104, P3586, DOI 10.1121/1.423941.
   Fu QJ, 2000, J ACOUST SOC AM, V107, P589, DOI 10.1121/1.428325.
   Fu QJ, 2001, J ACOUST SOC AM, V109, P379, DOI 10.1121/1.1327578.
   Husch H, 2001, J ACOUST SOC AM, V109, P2896, DOI 10.1121/1.1371971.
   LEIJON A, 2001, ACTA ACUST UNITED AC, V88, P423.
   Loizou PC, 2000, J ACOUST SOC AM, V108, P2377, DOI 10.1121/1.1317557.
   Loizou PC, 2000, ANN OTO RHINOL LARYN, V109, P67, DOI 10.1177/0003489400109S1228.
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526.
   Musch H, 2001, J ACOUST SOC AM, V109, P2910, DOI 10.1121/1.1371972.
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626.
   Svirsky MA, 2000, J ACOUST SOC AM, V107, P1521, DOI 10.1121/1.428459.
   THORNTON AR, 1978, J SPEECH HEAR RES, V21, P507, DOI 10.1044/jshr.2103.507.
   Throckmorton CS, 2002, J ACOUST SOC AM, V112, P285, DOI 10.1121/1.1482073.
   TONG YC, 1990, ACTA OTO-LARYNGOL, P135.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{EURASIP J Appl. Signal Process.}},
Doc-Delivery-Number = {{019LE}},
Unique-ID = {{ISI:000235836400007}},
OA = {{Other Gold}},
DA = {{2020-12-06}},
}

@article{ ISI:000220774000001,
Author = {Alku, P and Backstrom, T},
Title = {{Linear predictive method for improved spectral modeling of lower
   frequencies of speech with small prediction orders}},
Journal = {{IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING}},
Year = {{2004}},
Volume = {{12}},
Number = {{2}},
Pages = {{93-99}},
Month = {{MAR}},
Abstract = {{An all-pole modeling technique, Linear Prediction with Low-frequency
   Emphasis (LPLE) which emphasizes the lower frequency range of the input
   signal, is presented. The method is based on first interpreting.
   conventional linear predictive (LP) analyses of successive prediction
   orders with parallel structures using the concept of symmetric linear
   prediction. In these implementations, symmetric linear prediction is
   preceded by simple pre-filters, which are, of either low or high
   frequency characteristics. Combining those symmetric linear predictors
   that are not preceded by high-frequency pre-filters yields the proposed
   LPLE predictor. It is proved that the all-pole filters computed by LPLE
   are always stable. The results achieved with vowels show that the
   proposed method is well-suited for those applications, where low-order
   all-pole models with improved modeling of the lowest formants, are
   needed.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Alku, P (Corresponding Author), Helsinki Univ Technol, Lab Acoust \& Audio Signal Proc, FIN-02015 Espoo, Finland.
   Helsinki Univ Technol, Lab Acoust \& Audio Signal Proc, FIN-02015 Espoo, Finland.}},
DOI = {{10.1109/TSA.2003.822625}},
ISSN = {{1063-6676}},
Keywords = {{all-pole modeling; linear prediction; LSP decomposition}},
Keywords-Plus = {{PAIR FREQUENCIES; RECOGNITION}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{Paavo.Alku@hut.fi
   Tom.Backstrom@hut.fi}},
ResearcherID-Numbers = {{Alku, Paavo/E-2400-2012
   Backstrom, Tom/E-2121-2011
   }},
ORCID-Numbers = {{Backstrom, Tom/0000-0002-5590-2349
   Alku, Paavo/0000-0002-8173-9418}},
Cited-References = {{Choi SH, 2000, SPEECH COMMUN, V30, P223, DOI 10.1016/S0167-6393(99)00047-3.
   Chu P. L., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1318.
   CHU PL, 1982, IEEE T ACOUST SPEECH, V30, P545, DOI 10.1109/TASSP.1982.1163930.
   {*}CSACELP, 1996, REC G729 COD SPEECH.
   {*}ETSI, 1992, 0610 ETSI GSM.
   {*}GSM, 1997, DIG CELL TEL SYST.
   Harma A, 2001, IEEE T SPEECH AUDI P, V9, P769, DOI 10.1109/89.966080.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   Kim HK, 1999, IEEE T SPEECH AUDI P, V7, P87, DOI 10.1109/89.736334.
   LIU CS, 1990, P IEEE INT C AC SPEE, P277.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Markel J., 1980, LINEAR PREDICTION SP.
   Mian GA, 1994, IEEE T SPEECH AUDI P, V2, P536, DOI 10.1109/89.326634.
   Moore B., 1995, HEARING.
   Oppenheim A. V., 1989, DISCRETE TIME SIGNAL.
   Paliwal K.K., 1995, SPEECH CODING SYNTHE, P433.
   PALIWAL KK, 1989, SPEECH COMMUN, V8, P27, DOI 10.1016/0167-6393(89)90065-4.
   PALIWAL KK, 1995, P IEEE SPEECH COD WO.
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875.
   SCHUSSLER HW, 1976, IEEE T ACOUST SPEECH, V24, P87, DOI 10.1109/TASSP.1976.1162762.
   SOONG FK, 1984, P IEEE ICASSP 84, V1.
   STOICA P, 1988, IEEE T ACOUST SPEECH, V36, P940, DOI 10.1109/29.1612.
   STOICA P, 1986, IEEE T ACOUST SPEECH, V34, P1419.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Trans. Speech Audio Process.}},
Doc-Delivery-Number = {{811LS}},
Unique-ID = {{ISI:000220774000001}},
DA = {{2020-12-06}},
}

@article{ ISI:000187085900002,
Author = {Moir, TJ and Barrett, JF},
Title = {{A kepstrum approach to filtering, smoothing and prediction with
   application to speech enhancement}},
Journal = {{PROCEEDINGS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING
   SCIENCES}},
Year = {{2003}},
Volume = {{459}},
Number = {{2040}},
Pages = {{2957-2976}},
Month = {{DEC 8}},
Abstract = {{A kepstrum (or complex-cepstrum) approach to minimum-phase Wiener
   filtering of stationary scalar processes is proposed and solved for the
   case of signal plus coloured noise, where the noise possibly includes a
   white-noise component. A general solution is found in an innovations
   form. The spectral factorization of the noise model and of the
   signal-plus-noise model required for the solution are determined from
   data using the kepstrum technique with the fast Fourier transform. This
   approach avoids dependence on any form of multidimensional state-space
   or polynomial-based model and so avoids use of recursive parameter
   estimation or of Diophantine equations.}},
Publisher = {{ROYAL SOC}},
Address = {{6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Moir, TJ (Corresponding Author), Massey Univ, Inst Informat \& Math Sci, Private Bag 102-904, Auckland, New Zealand.
   Massey Univ, Inst Informat \& Math Sci, Auckland, New Zealand.}},
DOI = {{10.1098/rspa.2003.1137}},
ISSN = {{1364-5021}},
EISSN = {{1471-2946}},
Keywords = {{kepstrum; complex cepstrum; smoothing; prediction; coloured noise}},
Keywords-Plus = {{POLYNOMIAL APPROACH; UNIFIED APPROACH}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{t.j.moir@massey.ac.nz}},
Cited-References = {{AGAIBY H, 1997, P 5 EUR C SPEECH COM, V3, P1119.
   ALLEN JB, 1977, J ACOUST SOC AM, V62, P912, DOI 10.1121/1.381621.
   BARRETT JF, 1986, INT J CONTROL, V43, P29, DOI 10.1080/00207178608933447.
   BARRETT JF, 1987, KYBERNETIKA, V23, P177.
   BARRETT JF, 1983, P IASTED S MECO 83 A.
   DABIS HS, 1993, INT J CONTROL, V57, P577, DOI 10.1080/00207179308934408.
   GRIMBLE MJ, 1985, INT J CONTROL, V41, P1545, DOI 10.1080/0020718508961214.
   GRIMBLE MJ, 1988, INT J CONTROL, V48, P2161, DOI 10.1080/00207178808906317.
   HAGANDER P, 1977, IEEE T INFORM THEORY, V23, P377, DOI 10.1109/TIT.1977.1055719.
   Haykin S. S., 1986, ADAPTIVE FILTER THEO.
   Kalman R.E., 1960, J BASIC ENG, V82, P35, DOI {[}10.1115/1.3662552, DOI 10.1115/1.3662552].
   Kolmogoroff A, 1939, CR HEBD ACAD SCI, V208, P2043.
   Kolmogorov AN, 1941, B MOSCOW STATE U, V2, P1.
   LJUNG L, 1982, THEORY PRACTICE RECU.
   MARTINEZ R, 2001, P 2001 IEEE INT S CI, V2, P793.
   OPPENHEI.AV, 1968, PR INST ELECTR ELECT, V56, P1264, DOI 10.1109/PROC.1968.6570.
   Oppenheim A. V., 1975, DIGITAL SIGNAL PROCE.
   Popescu DC, 1998, INT CONF ACOUST SPEE, P997, DOI 10.1109/ICASSP.1998.675435.
   ROBERTS AP, 1988, INT J CONTROL, V47, P681, DOI 10.1080/00207178808906046.
   SILVIA MT, 1978, GEOEXPLORATION, V16, P55, DOI 10.1016/0016-7142(78)90007-8.
   Stahl V, 2000, INT CONF ACOUST SPEE, P1875, DOI 10.1109/ICASSP.2000.862122.
   WAHBA G, 1980, J AM STAT ASSOC, V75, P122, DOI 10.2307/2287399.
   Widrow B, 1985, ADAPTIVE SIGNAL PROC.
   Wiener N., 1949, EXTRAPOLATION INTERP.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Proc. R. Soc. A-Math. Phys. Eng. Sci.}},
Doc-Delivery-Number = {{751UT}},
Unique-ID = {{ISI:000187085900002}},
OA = {{Green Accepted}},
DA = {{2020-12-06}},
}

@article{ ISI:000184971900007,
Author = {Ozaydin, S and Baykal, B},
Title = {{Matrix quantization and mixed excitation based linear predictive speech
   coding at very low bit rates}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2003}},
Volume = {{41}},
Number = {{2-3}},
Pages = {{381-392}},
Month = {{OCT}},
Abstract = {{A matrix quantization scheme and a very low bit rate vocoder is
   developed to obtain good quality speech for low capacity communication
   links. The new matrix quantization method operates at bit rates between
   400 and 800 bps and using a 25 ms linear predictive coding (LPC)
   analysis frame, spectral distortion about I dB is achieved at 800 bps.
   Techniques for improving the performance at very low bit rate vocoding
   include quantization of residual line spectral frequency (LSF) vectors,
   multistage matrix quantization, joint quantization of pitch and
   voiced/unvoiced/mixed decisions and a technique to obtain
   voiced/unvoiced/mixed decisions. In the new matrix quantization based
   mixed excitation (MQME) vocoder, the residual LSF vectors for two
   consecutive frames are obtained using autoregressive moving average
   (ARMA) prediction, then grouped into a superframe and jointly quantized.
   For other speech parameters, quantization is made in each frame. The
   residual LSF vector quantization yields bit rate reduction in the
   vocoder. For the MQME vocoder, listening tests have proven that an
   efficient and high quality coding has been achieved at a bit rate of
   1200 bps. Test results are compared with the mixed excitation based 2400
   bps MELP vocoder which is chosen as the new federal standard, and it is
   observed that the degradation in speech quality is tolerable and the
   performance is near the 2400 bps MELP vocoder particularly in quiet
   environments. (C) 2003 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Baykal, B (Corresponding Author), Middle E Tech Univ, Dept Elect \& Elect Engn, TR-06531 Ankara, Turkey.
   Middle E Tech Univ, Dept Elect \& Elect Engn, TR-06531 Ankara, Turkey.
   Undersecretariat Def Ind, TR-06100 Ankara, Turkey.}},
DOI = {{10.1016/S0167-6393(03)00009-8}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{very low bit rate; LSF matrix quantization; LSF vector quantization;
   mixed excitation; MELP; ARMA prediction}},
Keywords-Plus = {{PARAMETERS; DESIGN}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{buyurman@metu.edu.tr}},
ResearcherID-Numbers = {{Baykal, Buyurman/ABA-2490-2020
   Ozaydin, Selma/P-7627-2018}},
ORCID-Numbers = {{Baykal, Buyurman/0000-0003-0966-4607
   Ozaydin, Selma/0000-0002-4613-9441}},
Cited-References = {{BHATTACHARYA B, 1992, P ICASSP, P105.
   BRUHN S, 1995, P IEEE INT C AC SPEE, V1, P724.
   Campbell J. P.  Jr., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P473.
   DEMARCA JRB, 1994, IEEE T VEH TECHNOL, V43, P413, DOI 10.1109/25.312805.
   Ghaemmaghami S, 1999, ELECTRON LETT, V35, P456, DOI 10.1049/el:19990316.
   Kondoz A. M., 1994, DIGITAL SPEECH CODIN.
   LeBlanc WP, 1993, IEEE T SPEECH AUDI P, V1, P373, DOI 10.1109/89.242483.
   LEBLANC WP, 1993, WIRELESS NETWORK APP, V39, P302.
   MCCREE AV, 1995, IEEE T SPEECH AUDI P, V3, P242, DOI 10.1109/89.397089.
   MEDAN Y, 1991, IEEE T SIGNAL PROCES, V39, P40, DOI 10.1109/78.80763.
   NANDKUMAR S, 1998, P IEEE INT C AC SPEE, V1, P41.
   OHMURO H, 1994, ELECTRON COMM JPN 3, V77, P12, DOI 10.1002/ecjc.4430771002.
   Ozaydin S, 2001, INT CONF ACOUST SPEE, P677, DOI 10.1109/ICASSP.2001.941005.
   Ozaydin S, 2001, 2001 IEEE THIRD WORKSHOP ON SIGNAL PROCESSING ADVANCES IN WIRELESS COMMUNICATIONS, PROCEEDINGS, P372, DOI 10.1109/SPAWC.2001.923928.
   SHIRAKI Y, 1988, IEEE T ACOUST SPEECH, V36, P1437, DOI 10.1109/29.90372.
   SKOGLUND J, 1996, P IEEE INT C AC SPEE, P1351.
   Tokuda K, 1998, INT CONF ACOUST SPEE, P609, DOI 10.1109/ICASSP.1998.675338.
   TREMAIN TE, 1982, SPEECH TECHNOLOG APR, P40.
   TSAO C, 1985, IEEE T ACOUST SPEECH, V33, P537.
   Wang T, 2000, INT CONF ACOUST SPEE, P1375, DOI 10.1109/ICASSP.2000.861835.
   Xydeas CS, 1999, IEEE T SPEECH AUDI P, V7, P113, DOI 10.1109/89.748117.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{715KW}},
Unique-ID = {{ISI:000184971900007}},
DA = {{2020-12-06}},
}

@article{ ISI:000184890200004,
Author = {Chong-White, NR and Cox, RV},
Title = {{An intelligibility enhancement for the mixed excitation linear
   prediction speech coder}},
Journal = {{IEEE SIGNAL PROCESSING LETTERS}},
Year = {{2003}},
Volume = {{10}},
Number = {{9}},
Pages = {{263-266}},
Month = {{SEP}},
Abstract = {{A technique to increase the robustness of perceptually important
   acoustic cues in speech, based on modification of the phoneme timing
   structure, was recently proposed. Here, the technique is applied as a
   preprocessor to improve the intelligibility of the mixed excitation
   linear prediction (MELP) coder. The enhancement strategy, however,
   requires adaptations to minimize the introduction of unnatural speech
   characteristics that are introduced and intensified by parametric coding
   schemes. The enhanced 2.4-kb/s fixed-point MELP coder achieves a level
   of speech intelligibility comparable to the 8-kb/s G.729 Annex A coder.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chong-White, NR (Corresponding Author), Dilithium Networks, Sydney, NSW, Australia.
   AT\&T Labs Res, Florham Pk, NJ 07932 USA.}},
DOI = {{10.1109/LSP.2003.815617}},
ISSN = {{1070-9908}},
EISSN = {{1558-2361}},
Keywords = {{mixed excitation linear prediction (MELP); speech intelligibility;
   time-scale modification}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{nicola.chong-white@dilithiumnetworks.com
   rvc@research.att.com}},
Cited-References = {{CHONGWHITE NR, 2001, UNPUB SPEECH COM JUL.
   Kohler MA, 1997, INT CONF ACOUST SPEE, P1587, DOI 10.1109/ICASSP.1997.596256.
   MARTIN R, 1999, P 1999 IEEE WORKSH S, P165.
   McCree A, 1998, INT CONF ACOUST SPEE, P593, DOI 10.1109/ICASSP.1998.675334.
   Supplee LM, 1997, INT CONF ACOUST SPEE, P1591, DOI 10.1109/ICASSP.1997.596257.
   Unno T, 1999, INT CONF ACOUST SPEE, P245, DOI 10.1109/ICASSP.1999.758108.
   Verhelst W, 2000, SPEECH COMMUN, V30, P207, DOI 10.1016/S0167-6393(99)00051-5.
   VOIERS WD, 1977, SPEECH INTELLIGIBILI.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{IEEE Signal Process. Lett.}},
Doc-Delivery-Number = {{714AM}},
Unique-ID = {{ISI:000184890200004}},
DA = {{2020-12-06}},
}

@article{ ISI:000181049900008,
Author = {Chien, JT},
Title = {{Linear regression based Bayesian predictive classification for speech
   recognition}},
Journal = {{IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING}},
Year = {{2003}},
Volume = {{11}},
Number = {{1}},
Pages = {{70-79}},
Month = {{JAN}},
Abstract = {{The uncertainty in parameter estimation due to the adverse environments
   deteriorates the classification performance for speech recognition. It
   becomes crucial to incorporate the parameter uncertainty into decision
   so that the classification robustness can be assured. In this paper, we
   propose a novel linear regression based Bayesian predictive
   classification (LRBPC) for robust speech recognition. This framework is
   constructed under the paradigm of linear regression adaptation of speech
   hidden Markov models (HMMs). Because the regression mapping between HMMs
   and adaptation data is ill posed, we properly characterize the
   uncertainty A regression parameters using a joint Gaussian distribution.
   A closed-form predictive distribution can be derived to set up the LRBPC
   decision for speech recognition. Such decision is robust compared to the
   plug-in maximum a posteriori (MAP) decision adopted in the maximum
   likelihood linear regression (MLLR) and MAP linear regression (MAPLR).
   Since the specified distribution belongs to the conjugate prior family,
   the evolutionary hyperparameters are established. With the statistically
   rich hyperparameters, the LRBPC achieves decision robustness. In the
   experiments, we find that LRBPC decision in cases of general linear
   regression as well as single variable linear regression attains
   significantly better recognition performance than MLLR and MAPLR
   adaptation.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chien, JT (Corresponding Author), Natl Cheng Kung Univ, Dept Comp Sci \& Informat Engn, Tainan 70101, Taiwan.
   Natl Cheng Kung Univ, Dept Comp Sci \& Informat Engn, Tainan 70101, Taiwan.}},
DOI = {{10.1109/TSA.2002.805640}},
ISSN = {{1063-6676}},
Keywords = {{Bayesian predictive classification; conjugate prior distribution; joint
   Gaussian distribution; linear regression model; speech recognition}},
Keywords-Plus = {{MAXIMUM-LIKELIHOOD; SPEAKER ADAPTATION; TRANSFORMATION}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{jtchien@mail.ncku.edu.tw}},
ORCID-Numbers = {{Chien, Jen-Tzung/0000-0003-3466-8941}},
Cited-References = {{Berger J. O., 1985, STAT DECISION THEORY, DOI 10.1007/978-1-4757-4286-2.1282.
   CHE C, 1999, P EUR C SPEECH COMM, V2, P803.
   Chesta C., 1999, P EUR C SPEECH COMM, V1, P211.
   Chien JT, 1997, SPEECH COMMUN, V22, P369, DOI 10.1016/S0167-6393(97)00033-2.
   Chien JT, 2001, IEEE T SPEECH AUDI P, V9, P399, DOI 10.1109/89.917685.
   Chien JT, 1999, IEEE T SPEECH AUDI P, V7, P656, DOI 10.1109/89.799691.
   CHOU W, 1999, P EUR C SPEECH COMM, V1, P1.
   DeGroot Morris H., 1970, OPTIMAL STAT DECISIO.
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x.
   DIGALAKIS VV, 1995, IEEE T SPEECH AUDI P, V3, P357, DOI 10.1109/89.466659.
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530.
   Huo Q, 1997, INT CONF ACOUST SPEE, P1547, DOI 10.1109/ICASSP.1997.596246.
   Jiang H, 1999, IEEE T SPEECH AUDI P, V7, P426, DOI 10.1109/89.771309.
   Jiang H, 2000, IEEE T SPEECH AUDI P, V8, P688, DOI 10.1109/89.876302.
   Jiang H, 1997, INT CONF ACOUST SPEE, P1551, DOI 10.1109/ICASSP.1997.596247.
   Jiang H, 1999, SPEECH COMMUN, V28, P313, DOI 10.1016/S0167-6393(99)00018-7.
   Lee C. H., 1990, Computer Speech and Language, V4, P127, DOI 10.1016/0885-2308(90)90002-N.
   Lee CH, 2000, P IEEE, V88, P1241, DOI 10.1109/5.880082.
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010.
   MENDEL JM, 1995, LESSONS ESTIMATION T, P166.
   Merhav N, 1993, IEEE T SPEECH AUDI P, V1, P90, DOI 10.1109/89.221371.
   NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P326, DOI 10.1109/TASSP.1985.1164513.
   Shahshahani BM, 1997, IEEE T SPEECH AUDI P, V5, P183, DOI 10.1109/89.554780.
   SURENDRAN AC, 1998, P INT C SPOK LANG PR, V2, P463.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{IEEE Trans. Speech Audio Process.}},
Doc-Delivery-Number = {{646TG}},
Unique-ID = {{ISI:000181049900008}},
DA = {{2020-12-06}},
}

@article{ ISI:000179096200010,
Author = {Steeneken, HJM and Houtgast, T},
Title = {{Phoneme-group specific octave-band weights in predicting speech
   intelligibility}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2002}},
Volume = {{38}},
Number = {{3-4}},
Pages = {{399-411}},
Month = {{NOV}},
Abstract = {{In an earlier study we derived robust frequency-weighting functions for
   prediction of the intelligibility of short nonsense words. These
   frequency-weighting functions are applied for prediction of
   intelligibility such as with the speech transmission index (STI). Six
   independent experiments revealed essentially similar frequency-weighting
   functions for the prediction of the nonsense word scores with respect to
   signal-to-noise ratio and gender {[}Speech Communication 28 (1999) 109].
   Although the frequency weightings do not vary significantly for
   signal-to-noise ratio or gender, other studies have shown that using
   different types of speech material (i.e., nonsense words, phonetically
   balanced words and connected discourse) resulted in quite different
   frequency-weighting functions. This may be related to the distribution
   of specific phonemes in the test material. In order to obtain a more
   generic description of the frequency weighting, four relevant groups of
   phonemes were identified. In situations with reduced intelligibility, a
   small confusion rate of the phonemes between the groups and a high
   confusion rate of the phonemes within each group was observed. For each
   group a specific frequency-weighting function and a good prediction of
   the phoneme group scores could be obtained. It was shown that from these
   (weighted) phoneme group scores, word scores could be predicted with a
   prediction accuracy of ca. 4\% (this corresponds to a signal-to-noise
   ratio of about I dB). Hence, this method provides a more generic way to
   predict intelligibility scores for different types of speech material.
   (C) 2002 Elsevier Science B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Steeneken, HJM (Corresponding Author), TNO, Human Factors, POB 23, NL-3769 ZG Soesterberg, Netherlands.
   TNO, Human Factors, NL-3769 ZG Soesterberg, Netherlands.}},
DOI = {{10.1016/S0167-6393(02)00011-0}},
Article-Number = {{PII S0167-6393(02)00011-0}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{speech intelligibility; octave-band contributions; frequency-importance
   function; phoneme groups; diagnostic prediction; objective measurement;
   speech transmission index}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{steeneken@tm.tno.nl}},
Cited-References = {{{[}Anonymous], 1997, S35 ANSI.
   BRONKHORST AW, 1993, J ACOUST SOC AM, V93, P499, DOI 10.1121/1.406844.
   DUGGIRALA V, 1988, J ACOUST SOC AM, V83, P2372, DOI 10.1121/1.396316.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224.
   {*}IEC INT STAND, 1998, SOUND SYST EQ 16.
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526.
   PAVLOVIC CV, 1987, J ACOUST SOC AM, V82, P413, DOI 10.1121/1.395442.
   PAVLOVIC CV, 1984, J ACOUST SOC AM, V75, P1606, DOI 10.1121/1.390870.
   Steeneken HJM, 1999, SPEECH COMMUN, V28, P109, DOI 10.1016/S0167-6393(99)00007-2.
   Steeneken HJM, 2002, SPEECH COMMUN, V38, P413, DOI 10.1016/S0167-6393(02)00010-9.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEENEKEN JHM, 1989, P IEEE ICASSP GLASG, P540.
   STEENEKEN JHM, 1992, THESIS U AMSTERDAM.
   STUDEBAKER GA, 1987, J ACOUST SOC AM, V81, P1130, DOI 10.1121/1.394633.
   WELLS JC, 1987, J INT PHON ASSOC, V17, P94.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{21}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{612VM}},
Unique-ID = {{ISI:000179096200010}},
DA = {{2020-12-06}},
}

@article{ ISI:000178164900004,
Author = {Moller, S and Raake, A},
Title = {{Telephone speech quality prediction: Towards network planning and
   monitoring models for modern network scenarios}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2002}},
Volume = {{38}},
Number = {{1-2}},
Pages = {{47-75}},
Month = {{SEP}},
Abstract = {{This paper addresses the problem of predicting the quality of telephone
   speech. Starting from a definition of quality, which takes communicative
   as well as service-related factors into account, a new classification
   scheme for prediction models is proposed. It considers input and output
   parameters, the network components and application area the model is
   used for, as well as the psychoacoustic and judgment-related bases.
   According to this scheme, quality prediction models can be classified
   into signal-based comparative measures, network planning models and
   monitoring models. Whereas signal-based approaches have been described
   extensively in literature, this paper discusses the latter two
   approaches in detail. The underlying psychoacoustic properties of two
   network planning models, the E-model and the SUBMOD model, are analyzed,
   and combined approaches for monitoring models are developed. Quality
   predictions obtained from the models are compared to the results of
   auditory test data, and weaknesses as well as network elements that
   remain uncovered are identified. Possible future extensions to the
   models are pointed out, including wide-band scenarios and speech sound
   quality, non-stationary impairments as well as speech technology
   devices. (C) 2002 Elsevier Science B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Moller, S (Corresponding Author), Ruhr Univ Bochum, Inst Kommunikationsakust, D-44780 Bochum, Germany.
   Ruhr Univ Bochum, Inst Kommunikationsakust, D-44780 Bochum, Germany.}},
DOI = {{10.1016/S0167-6393(01)00043-7}},
Article-Number = {{PII S0167-6393(01)00043-7}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{speech quality; telephone speech; quality prediction model; network
   planning; monitoring}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{moeller@ika.ruhr-uni-bochum.de}},
Cited-References = {{ALLNATT J, 1975, INT J MAN MACH STUD, V7, P801, DOI 10.1016/S0020-7373(75)80037-X.
   Bappert V., 1994, Acta Acustica, V2, P49.
   BEERENDS JG, 1995, 98 CONV AUD ENG SOC.
   BERGER J, 1998, ARBEITEN DIGITALE SI, V13.
   BODDEN M, 1996, UNPUB ENTWICKLUNG DU.
   Collard J., 1929, Electrical Communication, V7, P168.
   {*}ETSI ETR, 1996, 250 ESTI ETR.
   EULER S, 1994, P INT C AC SPEECH SI, V1, P621.
   Fletcher H, 1937, J ACOUST SOC AM, V9, P1, DOI 10.1121/1.1915904.
   GLEISS N, 1992, USABILITY CONCEPTS E, P24.
   HANSEN M, 1998, THESIS CARLVONOSSIET.
   HAUENSTEIN M, 1997, ARBETEN DIGITALE SIG.
   Hollier MP, 1996, BT TECHNOL J, V14, P206.
   JEKOSCH U, 2000, THESIS U GH ESSEN.
   Johannesson NO, 1997, IEEE COMMUN MAG, V35, P70, DOI 10.1109/35.568213.
   JOHANNESSON NO, 1996, UP IPSW M 23 27 SEPT.
   KARIS D, 1991, P HUM FACT SOC 35 AN, V1, P217.
   KITAWAKI N, 1991, IEEE J SEL AREA COMM, V9, P586, DOI 10.1109/49.81952.
   MCADAMS S, 1993, THINKING SOUND COGNI.
   MCDERMOTT BJ, 1969, J ACOUST SOC AM, V45, P774, DOI 10.1121/1.1911465.
   MOLLER S, 1999, J ACTA ACUSTICA S1, V85, pS49.
   MOLLER S, 2000, P INT C SPOK LANG PR, V1, P750.
   Moller S., 2000, ASSESSMENT PREDICTIO.
   NAKATANI LH, 1973, J ACOUST SOC AM, V53, P1083, DOI 10.1121/1.1913428.
   RAAKE A, 1999, UNPUB ANAL VERIFICAT.
   RAAKE A, 2000, P ICSLP 2000 CHN BEI, V4, P744.
   RICHARDS DL, 1974, P I ELECTR ENG, V121, P313, DOI 10.1049/piee.1974.0063.
   RICHARDS DL, 1973, COMMUNICATION.
   RIX AW, 2000, 109 CONV AUD ENG SOC.
   VEAUX C, 1999, P 6 EUR C SPEECH COM, V6, P2579.
   Voiers W. D., 1977, P INT C AC SPEECH SI, P204.
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{596KW}},
Unique-ID = {{ISI:000178164900004}},
DA = {{2020-12-06}},
}

@article{ ISI:000176314600010,
Author = {Chien, JT},
Title = {{A Bayesian prediction approach to robust speech recognition and online
   environmental learning}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{2002}},
Volume = {{37}},
Number = {{3-4}},
Pages = {{321-334}},
Month = {{JUL}},
Abstract = {{A robust speech recognizer is developed to tackle the inevitable
   mismatch between training and testing environments. Because the
   realistic environments are uncertain and nonstationary, it is necessary
   to characterize the uncertainty of speech hidden Markov models (HMMs)
   for recognition and trace the uncertainty incrementally to catch the
   newest environmental statistics. In this paper, we develop a new
   Bayesian predictive classification (BPC) for robust decision and online
   environmental learning. The BPC decision is adequately established by
   modeling the uncertainties of both the HMM mean rector and precision
   matrix using a conjugate prior density. The frame-based predictive
   distributions using multivariate t distributions and approximate
   Gaussian distributions are herein exploited. After the recognition, the
   prior density is pooled with the likelihood of the Current test sentence
   to generate the reproducible prior density. The hyperparameters of the
   prior density are accordingly adjusted to meet the newest environments
   and apply for the recognition of upcoming data. As a result, an
   efficient online unsupervised learning strategy is developed for
   HMM-based speech recognition without needing adaptation data. In the
   experiments, the proposed approach is significantly better than
   conventional plug-in maximum a posteriori (MAP) decision on the
   recognition of connected Chinese digits in hands-free car environments.
   This approach is economical in computation. (C) 2002 Elsevier Science
   B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chien, JT (Corresponding Author), Natl Cheng Kung Univ, Dept Comp Sci \& Informat Engn, Tainan 70101, Taiwan.
   Natl Cheng Kung Univ, Dept Comp Sci \& Informat Engn, Tainan 70101, Taiwan.}},
DOI = {{10.1016/S0167-6393(01)00032-2}},
Article-Number = {{PII S0167-6393(01)00032-2}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Bayesian predictive classification (BPC); online unsupervised learning;
   speaker adaptation; speech recognition; hidden Markov model}},
Keywords-Plus = {{HIDDEN MARKOV-MODELS; CLASSIFICATION APPROACH; SPEAKER ADAPTATION;
   INCREMENTAL ESTIMATION; MAXIMUM-LIKELIHOOD; ALGORITHMS}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{jtchien@mail.ncku.edu.tw}},
ORCID-Numbers = {{Chien, Jen-Tzung/0000-0003-3466-8941}},
Cited-References = {{Berger J. O., 1985, STAT DECISION THEORY, DOI 10.1007/978-1-4757-4286-2.1282.
   Chien JT, 2000, SPEECH COMMUN, V30, P235, DOI 10.1016/S0167-6393(99)00052-7.
   Chien JT, 1999, IEEE T SPEECH AUDI P, V7, P656, DOI 10.1109/89.799691.
   DeGroot Morris H., 1970, OPTIMAL STAT DECISIO.
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x.
   Digalakis VV, 1999, IEEE T SPEECH AUDI P, V7, P253, DOI 10.1109/89.759031.
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530.
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278.
   Geisser S., 1993, PREDICTIVE INFERENCE.
   Gotoh Y, 1998, IEEE T SPEECH AUDI P, V6, P539, DOI 10.1109/89.725320.
   Huo Q, 1997, IEEE T SPEECH AUDI P, V5, P161, DOI 10.1109/89.554778.
   Huo Q, 2000, IEEE T SPEECH AUDI P, V8, P200, DOI 10.1109/89.824706.
   HUO Q, 1998, P INT S CHIN SPOK LA, P31.
   HUO Q, 1997, IEEE P INT C AC SPEE, V2, P1547.
   HUO Q, 1997, P EUR C SPEECH COMM, V4, P1847.
   Jiang H, 1999, SPEECH COMMUN, V28, P313, DOI 10.1016/S0167-6393(99)00018-7.
   JIANG H, 1997, IEEE P INT C AC SPEE, V2, P1551.
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694.
   LEE CH, 1999, P WORKSH ROB METH SP, P45.
   Lee JJ, 1998, SYMBIOSIS, V25, P1.
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010.
   Matsui T, 1998, COMPUT SPEECH LANG, V12, P41, DOI 10.1006/csla.1997.0036.
   MERHAV N, 1991, IEEE T SIGNAL PROCES, V39, P2157, DOI 10.1109/78.91172.
   Merhav N, 1993, IEEE T SPEECH AUDI P, V1, P90, DOI 10.1109/89.221371.
   NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P326, DOI 10.1109/TASSP.1985.1164513.
   Ripley B.D., 1996, PATTERN RECOGNITION.
   Shahshahani BM, 1997, IEEE T SPEECH AUDI P, V5, P183, DOI 10.1109/89.554780.
   SURENDRAN AC, 1999, P WORKSH ROB METH SP, P155.
   SURENDRAN AC, 1998, P INT C SPOK LANG PR, V2, P463.
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{564KY}},
Unique-ID = {{ISI:000176314600010}},
DA = {{2020-12-06}},
}

@article{ ISI:000176653900001,
Author = {Priami, C},
Title = {{Language-based performance prediction for distributed and mobile systems}},
Journal = {{INFORMATION AND COMPUTATION}},
Year = {{2002}},
Volume = {{175}},
Number = {{2}},
Pages = {{119-145}},
Month = {{JUN 15}},
Abstract = {{We present a framework for performance prediction of distributed and
   mobile systems. We rely on process calculi and their structural
   operational semantics. The dynamic behaviour is described through
   transition systems whose transitions are labelled by encodings of their
   proofs that we then map into stochastic processes, we enhance related
   works by allowing general continuous distributions resorting to a notion
   of enabling between transitions. We also discuss how the number of
   resources available affects the overall model. Finally, we introduce a
   notion of bisimulation that takes stochastic information into account
   and prove it to be a congruence. When only exponential distributions are
   of interest our equivalence induces a lumpable partition on the
   underlying Markov process. (C) 2002 Elsevier Science (USA).}},
Publisher = {{ACADEMIC PRESS INC ELSEVIER SCIENCE}},
Address = {{525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Priami, C (Corresponding Author), Univ Trent, Dipartimento Informat \& TLC, Via Sommarive 14, I-38050 Povo, Italy.
   Univ Trent, Dipartimento Informat \& TLC, I-38050 Povo, Italy.}},
DOI = {{10.1006/inco.2000.3058}},
ISSN = {{0890-5401}},
EISSN = {{1090-2651}},
Keywords = {{operational semantics; proved transition system; stochastic process
   algebra; general distributions; performance prediction}},
Keywords-Plus = {{PROCESS ALGEBRAS; CALCULUS; INTEGRATION; CONCURRENT; CAUSALITY;
   SEMANTICS; LOTOS}},
Research-Areas = {{Computer Science; Mathematics}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Mathematics, Applied}},
Author-Email = {{priami@dit.unitn.it}},
Cited-References = {{BALDI M, 1998, P ICSE 98 ASS COMP M.
   Bernardo M, 1998, INFORM COMPUT, V144, P83, DOI 10.1006/inco.1998.2706.
   BOREALE M, 1998, THEORET COMPUT SCI, V198.
   Boudol G., 1988, Fundamenta Informaticae, V11, P433.
   Bravetti M, 1998, LECT NOTES COMPUT SC, V1466, P405.
   BRAVETTI M, 1999, P PAPM 99.
   Brinksma E, 1995, COMPUT J, V38, P552, DOI 10.1093/comjnl/38.7.552.
   BRODO L, 2000, P PAPM 00.
   BUCHHOLZ P, 1994, 500 U DORTM INF 4.
   Cardelli L, 1998, LECT NOTES COMPUT SC, V1378, P140, DOI 10.1007/bfb0053547.
   CARZANIGA A, 1997, P ICSE 97, P23.
   CLEAVELAND R, 1996, P ACM WORKSH STRAT D.
   DARGENIO PR, 1999, THESIS U TWENTE.
   DARGENIO PR, 1998, IFIP SERIES, P126.
   DEGANO P, 1985, LECT NOTES COMPUT SC, V199, P520.
   Degano P, 1999, ACTA INFORM, V36, P335, DOI 10.1007/s002360050164.
   Degano P, 1999, THEOR COMPUT SCI, V216, P237, DOI 10.1016/S0304-3975(99)80003-6.
   Degano P, 1996, ACM COMPUT SURV, V28, P352, DOI 10.1145/234528.234748.
   DEGANO P, 1992, LECT NOTES COMPUT SC, V623, P629.
   FOURNET C, 1996, LECT NOTES COMPUTER, V1119, P406.
   GIACALONE A, 1989, INT J PARALLEL PROG, V18, P121, DOI 10.1007/BF01491213.
   GOTZ N, 1992, 492 U ERL NURNB IMMD.
   GOTZ N, 1993, FOKUS SERIES.
   HANSSON H, 1990, P IEEE RTSS 90 ORL F.
   HARRISON PG, 1995, QUANTITATIVE METHODS, P18.
   Hermanns H, 1998, COMPUT NETWORKS ISDN, V30, P901, DOI 10.1016/S0169-7552(97)00133-5.
   HERZOG U, 1996, P 4 INT WORKSH PROC, P1.
   Hillston J., 1996, COMPOSITIONAL APPROA.
   KATOEN JP, 1996, 9609 CTIT U TWENT.
   Kemeny J. G., 1960, FINITE MARKOV CHAINS.
   LARSEN KG, 1992, LECT NOTES COMPUTER, V630.
   Maggiolo-Schettini A., 1999, Fundamenta Informaticae, V40, P221.
   MARSAN MA, 1994, IEEE ACM T NETWORK, V2, P151, DOI 10.1109/90.298433.
   MARSAN MA, 1989, IEEE T SOFTWARE ENG, V15, P832, DOI 10.1109/32.29483.
   MILNER R, 1992, INFORM COMPUT, V100, P1, DOI 10.1016/0890-5401(92)90008-4.
   MILNER R, 1993, THEOR COMPUT SCI, V114, P149, DOI 10.1016/0304-3975(93)90156-N.
   Milner R, 1989, COMMUNICATION CONCUR.
   NICOLLIN X, 1992, LECT NOTES COMPUT SC, V600, P526.
   Nielson F, 1996, THEOR COMPUT SCI, V155, P179, DOI 10.1016/0304-3975(95)00017-8.
   Nottegar C, 1999, LECT NOTES COMPUT SC, V1577, P204.
   Nottegar C, 2001, IEEE T SOFTWARE ENG, V27, P867, DOI 10.1109/32.962559.
   PIERCE BC, 1999, PROOF LANGUAGE INTER.
   Plotkin G.D., 1981, FN19 DAIMI AARH U.
   Priami C, 2001, INFORM PROCESS LETT, V80, P25, DOI 10.1016/S0020-0190(01)00214-9.
   Priami C, 1995, COMPUT J, V38, P578, DOI 10.1093/comjnl/38.7.578.
   Priami C, 1996, P 4 WORKSH PROC ALG, P41.
   PRIAMI C, 1998, P IT C THEOR COMP SC, P192.
   PRIAMI C, 1996, P 29 HAW INT C SYST, V1, P508.
   REGEV A, UNPUB STOCHASTIC PRO.
   RIELY J, 1998, P POPL 98, P378.
   SANGIORGI D, 1992, THESIS U EDINBURGH.
   THOMSEN B, 1993, ACTA INFORM, V30, P1, DOI 10.1007/BF01200262.
   VANGLABBEEK RJ, 1995, INFORM COMPUT, V121, P59, DOI 10.1006/inco.1995.1123.}},
Number-of-Cited-References = {{53}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Inf. Comput.}},
Doc-Delivery-Number = {{570HY}},
Unique-ID = {{ISI:000176653900001}},
DA = {{2020-12-06}},
}

@article{ ISI:000173567900005,
Author = {Bao, CC},
Title = {{High quality harmonic excited linear predictive speech coding at 2.4kb/s}},
Journal = {{CHINESE JOURNAL OF ELECTRONICS}},
Year = {{2002}},
Volume = {{11}},
Number = {{1}},
Pages = {{19-23}},
Month = {{JAN}},
Abstract = {{This paper presents a new speech coding algorithm at 2.4kb/s based on
   Harmonic excited linear predictive (HELP) model. The algorithm uses the
   robust pitch detection and simple voicing decision method. The linear
   predictive residual signal is simply classified into voiced and
   unvoiced, and synthesized with the uniform harmonic model. In addition,
   a transparent Predictive splitting vector quantization (PSVQ) scheme for
   Line spectral frequency (LSF) is proposed at 20bit/frame. Informal
   listening test showed that this coder can produce natural and smooth
   speech, and the synthesized speech quality is closed to that of G.723.1
   at 5.3kb/s.}},
Publisher = {{TECHNOLOGY EXCHANGE LIMITED HONG KONG}},
Address = {{BLDG\#13, PUHUINANLI, SOUTH YUYUANTAN RD, HAIDIAN DIST, BEIJING, 00000,
   PEOPLES R CHINA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bao, CC (Corresponding Author), Beijing Polytech Univ, Elect Informat \& Control Engn Coll, Beijing 100022, Peoples R China.
   Beijing Polytech Univ, Elect Informat \& Control Engn Coll, Beijing 100022, Peoples R China.}},
ISSN = {{1022-4653}},
EISSN = {{2075-5597}},
Keywords = {{speech coding; harmonic excited linear prediction (HELP); vector
   quantization}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{chchbao@bipu.edu.cn}},
Cited-References = {{ATAL BS, 1984, P INT C COMM AMST, P1610.
   BAO CC, 1996, J CHINA U POSTS TELE, V3, P21.
   CHEN JH, 1995, IEEE T SPEECH AUDI P, V3, P59, DOI 10.1109/89.365380.
   GRIFFIN DW, 1988, IEEE T ACOUST SPEECH, V36, P1223, DOI 10.1109/29.1651.
   KLEIJN WB, 1995, SPEECH CODING SYNTHE, P175.
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577.
   McAulay R., 1995, SPEECH CODING SYNTHE, P121.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   PAUL DB, 1981, IEEE T ACOUST SPEECH, V29, P786, DOI 10.1109/TASSP.1981.1163643.
   ZHUO L, CCSP 99, P154.}},
Number-of-Cited-References = {{10}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Chin. J. Electron.}},
Doc-Delivery-Number = {{516QH}},
Unique-ID = {{ISI:000173567900005}},
DA = {{2020-12-06}},
}

@article{ ISI:000173484800004,
Author = {Botting, N and Faragher, B and Simkin, Z and Knox, E and Conti-Ramsden,
   G},
Title = {{Predicting pathways of specific language impairment: What differentiates
   good and poor outcome?}},
Journal = {{JOURNAL OF CHILD PSYCHOLOGY AND PSYCHIATRY AND ALLIED DISCIPLINES}},
Year = {{2001}},
Volume = {{42}},
Number = {{8}},
Pages = {{1013-1020}},
Month = {{NOV}},
Abstract = {{A group of 117 children who met criteria for Specific Language
   Impairment (SLI) at 7 years of age were reassessed at 11 years of age.
   The data gathered from both stages were used to identify predictors of
   good and poor outcome from earlier test assessments. Results of logistic
   regressions indicated that measures of narrative retelling skills and
   expressive syntax were the strongest predictors of overall prognosis.
   This finding persisted when a nonverbal measure was included as a
   predictor alongside language measures in the regression model. There was
   found to be a lack of independent predictive contribution of early
   measures of articulation to later overall prognosis. Demographic factors
   (maternal education and family income) were not differently distributed
   across outcome groups. The theoretical and practical implications of the
   findings are discussed.}},
Publisher = {{BLACKWELL PUBL LTD}},
Address = {{108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Conti-Ramsden, G (Corresponding Author), Univ Manchester, Sch Educ, Oxford Rd, Manchester M13 9PL, Lancs, England.
   Univ Manchester, Sch Educ, Manchester M13 9PL, Lancs, England.}},
DOI = {{10.1111/1469-7610.00799}},
ISSN = {{0021-9630}},
Keywords = {{outcome; prediction; specific language improvement}},
Keywords-Plus = {{FOLLOW-UP; CHILDREN; PRESCHOOLERS; DISORDERS; STABILITY; SLI}},
Research-Areas = {{Psychology; Psychiatry}},
Web-of-Science-Categories  = {{Psychology, Developmental; Psychiatry; Psychology}},
ORCID-Numbers = {{Botting, Nicola/0000-0003-1082-9501}},
Cited-References = {{ARAM DM, 1984, J SPEECH HEAR RES, V27, P232, DOI 10.1044/jshr.2702.244.
   BEITCHMAN JH, 1994, J AM ACAD CHILD PSY, V33, P1322, DOI 10.1097/00004583-199411000-00015.
   BISHOP DV, 1989, TEST RECEPTION GRAMM.
   Bishop DVM, 1998, J CHILD PSYCHOL PSYC, V39, P879, DOI 10.1111/1469-7610.00388.
   BISHOP DVM, 1987, J SPEECH HEAR DISORD, V52, P156, DOI 10.1044/jshd.5202.156.
   Bishop DVM, 1996, J CHILD PSYCHOL PSYC, V37, P391, DOI 10.1111/j.1469-7610.1996.tb01420.x.
   Bronfrenbrenner U., 1979, ECOLOGY HUMAN DEV.
   Conti-Ramsden G, 2001, INT J LANG COMM DIS, V36, P207, DOI 10.1080/13682820010019883.
   ContiRamsden G, 1997, J SPEECH LANG HEAR R, V40, P765, DOI 10.1044/jslhr.4004.765.
   Davison FM, 1997, EUR J DISORDER COMM, V32, P19.
   DUNN L, 1998, BRIT PICT VOCABULARY.
   Elliot C. D., 1983, BRIT ABILITY SCALES.
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J.
   Goldman R., 1986, GOLDMAN FRISTOE TEST.
   Hammer CS, 2001, INT J LANG COMM DIS, V36, P185, DOI 10.1080/13682820010019919.
   Hohnen B, 1999, DEV PSYCHOL, V35, P590, DOI 10.1037/0012-1649.35.2.590.
   Johnson CJ, 1999, J SPEECH LANG HEAR R, V42, P744, DOI 10.1044/jslhr.4203.744.
   KIRK SA, 1968, ILLINOIS TEST PSYCHO.
   Leonard LB, 1997, J SPEECH LANG HEAR R, V40, P741, DOI 10.1044/jslhr.4004.741.
   LEONARD LB, 1998, CHILDREN SPECIFIC LA.
   Marchman VA, 1999, J SPEECH LANG HEAR R, V42, P206, DOI 10.1044/jslhr.4201.206.
   {*}OFF NAT STAT, 1998, FAM SPEND 1996 1997.
   PAUL R, 1983, J AM ACAD CHILD PSY, V22, P525, DOI 10.1097/00004583-198311000-00002.
   Raven J. C., 1986, COLOURED PROGR MATRI.
   RENFREW C, 1991, RENFREW LANGUAGE SCA.
   RICE ML, 1995, J SPEECH HEAR RES, V38, P850, DOI 10.1044/jshr.3804.850.
   SCHERY TK, 1985, J SPEECH HEAR DISORD, V50, P78.
   Semel E. M., 1987, CLIN EVALUATION LANG.
   SIMKIN Z, IN PRESS INT J LANGU.
   Stothard SE, 1998, J SPEECH LANG HEAR R, V41, P407, DOI 10.1044/jslhr.4102.407.
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245.
   Wiig E. H., 1992, CLIN EVALUATION LANG.
   Williams K, 1997, EXPRESSIVE VOCABULAR.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{48}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{J. Child Psychol. Psychiatry Allied Discip.}},
Doc-Delivery-Number = {{515FM}},
Unique-ID = {{ISI:000173484800004}},
DA = {{2020-12-06}},
}

@article{ ISI:000169493900007,
Author = {Lin, WR and Koh, SN and Lin, X},
Title = {{An 8.0-/8.4-kbps wideband speech coder based on mixed excitation linear
   prediction}},
Journal = {{SIGNAL PROCESSING}},
Year = {{2001}},
Volume = {{81}},
Number = {{7}},
Pages = {{1437-1448}},
Month = {{JUL}},
Abstract = {{A new method based on the Mixed Excitation Linear Prediction (MELP)
   model for coding wideband speech signals at medium bit rates is
   proposed. Modifications are made to the voiced/unvoiced strength
   analysis, pitch estimation and linear predictive (LP) analysis/synthesis
   of the Federal MELP Standard. An 8.0-/8.4-kbps wideband MELP coder is
   developed based on the modifications. Both the objective and subjective
   tests show that the subjective quality of the synthesized clean speech
   coded by the proposed 8.4-kbps wideband MELP coder is comparable to that
   of the ITU G.722 (P. Mermelstein, G. 722: a new CCITT coding standard
   for digital transmission of wideband audio signals, IEEE Comm. Mag. 26
   (1) (1988) 8-15.) coder coding at. 48 kbps. For the operating bit rate
   of 8 kbps, the performance of the coder is slightly better than that of
   MPEG4 CELP (Code-Excited Linear Prediction) (J.D. Johnson, S.R.
   Quackenbush, J. Herrz, B. Grill, Review of MPEG-4 general audio coding,
   in: Multimedia Systems, Standards and Networks, A. Purl, T. Chen (Eds.),
   Marcel Dekker, New York, 2000 (Chapter 5)) coder operating at 14.4kbps.
   (C) 2001 Elsevier Science B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Koh, SN (Corresponding Author), Nanyang Technol Univ, Sch Elect \& Elect Engn, South Spine,Block S1 Nanyang Ave, Singapore 639798, Singapore.
   Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.}},
DOI = {{10.1016/S0165-1684(01)00029-9}},
ISSN = {{0165-1684}},
Keywords = {{wideband speech coding; mixed excitation linear prediction; vector
   quantisation of LSP}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Cited-References = {{Abu-Shikhan N., 1999, P ISSPA, V1, P135.
   BESSETTE B, 1999, P IEEE WORKSH SPEECH, P7.
   Chen CQ, 1997, SIGNAL PROCESS, V56, P157, DOI 10.1016/S0165-1684(96)00164-8.
   CHEN J, 1996, P ICASSP 1996 MAY, V1, P275.
   GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849.
   LAFLAMME C, 1991, P IEEE ICASSP, V1, P13.
   LEFEBVRE R, 1994, P IEEE ICASSP AD AUS, V1, P193.
   MCCREE A, 1996, P IEEE INT C AC SPEE, V1, P200.
   MCCREE AV, 1995, IEEE T SPEECH AUDI P, V3, P242, DOI 10.1109/89.397089.
   MCELROY C, 1993, P IEEE ICASSP, V2, P620.
   {*}NAT COMM SYST OFF, 1991, 1016 NAT COMM SYST O.
   {*}NAT COMM SYST OFF, 1984, 1015 NAT COMM SYST O.
   ORDENTLICH E, 1991, P IEEE ICASSP, V1, P9.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   QUACKENBUSH S, 1991, P IEEE ICASSP, V1, P1.
   RAMPRASHAD SA, 1999, P IEEE WORKSH SPEECH, P10.
   SANCHEZ VE, 1993, P IEEE ICASSP, V2, P415.
   STACHURSKI J, 1999, P IEEE ICASSP AZ MAY.
   SUPPLEE LM, 1997, P IEEE INT C AC SPEE, V2, P1591.
   TAORI R, 2000, P IEEE ICASSP IST JU.
   UBALE A, 1998, P IEEE ICASSP, V1, P165.
   WANG SH, 1992, IEEE J SEL AREA COMM, V10, P819, DOI 10.1109/49.138987.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Signal Process.}},
Doc-Delivery-Number = {{446BW}},
Unique-ID = {{ISI:000169493900007}},
DA = {{2020-12-06}},
}

@article{ ISI:000088984700005,
Author = {Hu, HT and Kuo, FJ and Wang, HJ},
Title = {{A pseudo glottal excitation model for the linear prediction vocoder with
   speech signals coded at 1.6 kbps}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{2000}},
Volume = {{E83D}},
Number = {{8}},
Pages = {{1654-1661}},
Month = {{AUG}},
Abstract = {{This paper presents a pseudo glottal excitation model for the type of
   linear prediction vocoders with speech being coded at 1.6 kbps. While
   unvoiced speech and silence intervals are processed with a stochastic
   codebook of 512 entries, a glottal codebook with 32 entries for voiced
   excitation is used to describe the glottal phase characteristics. Steps
   of formulating the pseudo glottal excitation for one pitch period
   consist of 1) applying a polynomial model to simulate the low-frequency
   constituent of the residual, 2) inserting a magnitude-adjustable pulse
   sequence to characterize the main excitation, and 3) introducing
   turbulent noise in series with the resulting excitation. Procedures are
   described for codebook construction in addition to analysis and
   synthesis of the pseudo glottal excitation. Results in a mean opinion
   score (MOS) test show that the quality produced by the proposed coder is
   almost as good as that by 4.8 kbps CELP coder for male utterances, but
   the quality for female utterances is yet somewhat inferior.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hu, HT (Corresponding Author), Natl I Lan Inst Technol, Dept Elect Engn, 1 Shern Nong Rd, Ilan 260, Taiwan.
   Natl I Lan Inst Technol, Dept Elect Engn, Ilan 260, Taiwan.}},
ISSN = {{1745-1361}},
Keywords = {{speech coding; vocoder; pseudo glottal excitation; linear prediction}},
Keywords-Plus = {{VECTOR QUANTIZATION; QUALITY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Cited-References = {{Atal B. S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P614.
   ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679.
   Campbell J. P.  Jr., 1991, Digital Signal Processing, V1, P145, DOI 10.1016/1051-2004(91)90106-U.
   CHILDERS DG, 1991, J ACOUST SOC AM, V90, P2394, DOI 10.1121/1.402044.
   CHILDERS DG, 1994, J ACOUST SOC AM, V96, P2026, DOI 10.1121/1.411319.
   Hagen R, 1996, IEEE T SPEECH AUDI P, V4, P266, DOI 10.1109/89.506930.
   HEDELIN P, 1988, P IEEE ICASSP 88, P339.
   HOLMES JN, 1973, IEEE T ACOUST SPEECH, VAU21, P298, DOI 10.1109/TAU.1973.1162466.
   Hu HT, 1995, ELECTRON LETT, V31, P2145, DOI 10.1049/el:19951498.
   HU HT, 1996, COMPUTER PROCESSING, V10, P79.
   KAHN M, 1983, P ICASSP, V2, P539.
   KANG GS, 1985, IEEE T ACOUST SPEECH, V33, P377, DOI 10.1109/TASSP.1985.1164556.
   KONDOZ AM, 1994, DIGITAL SPEECH.
   KROON P, 1986, IEEE T ACOUST SPEECH, V34, P1054, DOI 10.1109/TASSP.1986.1164946.
   LALWANI AL, 1991, P ICASSP, V2, P777.
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577.
   MA CK, 1991, ELECTRON LETT, V27, P1772, DOI 10.1049/el:19911102.
   MCCREE AV, 1995, IEEE T SPEECH AUDI P, V3, P242, DOI 10.1109/89.397089.
   MCCREE AV, 1991, P IEEE INT C AC SPEE, P593.
   PINTO NB, 1989, IEEE T ACOUST SPEECH, V37, P1870, DOI 10.1109/29.45534.
   ROSE RC, 1990, IEEE T ACOUST SPEECH, V38, P1489, DOI 10.1109/29.60069.
   ROSENBERG AE, 1971, J ACOUST SOC AM, V49, P583, DOI 10.1121/1.1912389.
   Schroeder M. R., 1985, P IEEE INT C AC SPEE, V10, P937, DOI DOI 10.1109/ICASSP.1985.1168147.
   SINGHAL S, 1989, IEEE T ACOUST SPEECH, V37, P317, DOI 10.1109/29.21700.
   SUPPLEE LM, 1997, P IEEE INT C AC SPEE, P1591.
   TREMAIN TE, 1982, SPEECH TECHNOLOG APR, P40.
   WONG DY, 1980, P ICASSP, V3, P725.
   ZHANG S, 1995, P INT C AC SPEECH SI, P37.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{348KU}},
Unique-ID = {{ISI:000088984700005}},
DA = {{2020-12-06}},
}

@article{ ISI:000085821300012,
Author = {Huo, Q and Lee, CH},
Title = {{A Bayesian predictive classification approach to robust speech
   recognition}},
Journal = {{IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING}},
Year = {{2000}},
Volume = {{8}},
Number = {{2}},
Pages = {{200-204}},
Month = {{MAR}},
Abstract = {{We introduce a new decision strategy called Bayesian predictive
   classification (BPC) for robust speech recognition where unknown
   mismatch between training and testing conditions exists. We then propose
   and focus on one of the approximate BPC approaches called quasi-Bayes
   predictive classification (QBPC), In a series of comparative experiments
   where the mismatch is caused by additive white Gaussian noise, we show
   that the proposed QBPC approach achieves a considerable improvement over
   the conventional plug-in MAP decision rule.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Huo, Q (Corresponding Author), Univ Hong Kong, Dept Comp Sci \& Informat Syst, Hong Kong, Hong Kong, Peoples R China.
   ATR Interpreting Telecommun Res Labs, Kyoto, Japan.}},
DOI = {{10.1109/89.824706}},
ISSN = {{1063-6676}},
Keywords = {{Bayesian predictive classification (BPC); plug-in maximum a posteriori
   (MAP) decision; quasi-Bayes approximation; robust automatic speech
   recognition}},
Keywords-Plus = {{HIDDEN MARKOV MODEL}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{qhuo@cs.hku.hk}},
Cited-References = {{Aitchison J, 1975, STAT PREDICTION ANAL.
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370.
   Geisser S., 1993, PREDICTIVE INFERENCE.
   Huo Q, 1997, IEEE T SPEECH AUDI P, V5, P161, DOI 10.1109/89.554778.
   Huo Q, 1997, INT CONF ACOUST SPEE, P1547, DOI 10.1109/ICASSP.1997.596246.
   HUO Q, 1995, IEEE T SPEECH AUDI P, V3, P334, DOI 10.1109/89.466661.
   Huo Q, 1998, INT CONF ACOUST SPEE, P741, DOI 10.1109/ICASSP.1998.675371.
   Huo Q, 1998, IEEE T SPEECH AUDI P, V6, P386, DOI 10.1109/89.701369.
   HUO Q, 1998, P INT S CHIN SPOK LA, P31.
   HUO Q, 1997, P EUR C SPEECH COMM, P1847.
   Jiang H, 1999, IEEE T SPEECH AUDI P, V7, P426, DOI 10.1109/89.771309.
   KHARIN Y., 1996, ROBUSTNESS STAT PATT.
   MERHAV N, 1991, IEEE T SIGNAL PROCES, V39, P2157, DOI 10.1109/78.91172.
   Merhav N, 1993, IEEE T SPEECH AUDI P, V1, P90, DOI 10.1109/89.221371.
   NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P326, DOI 10.1109/TASSP.1985.1164513.
   Ripley B.D., 1996, PATTERN RECOGNITION.
   TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{30}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{IEEE Trans. Speech Audio Process.}},
Doc-Delivery-Number = {{292XT}},
Unique-ID = {{ISI:000085821300012}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000085821300014,
Author = {da Silva, LM and Alcaim, A},
Title = {{Differential coding of speech LSF parameters using hybrid vector
   quantization and bidirectional prediction}},
Journal = {{IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING}},
Year = {{2000}},
Volume = {{8}},
Number = {{2}},
Pages = {{208-211}},
Month = {{MAR}},
Abstract = {{This correspondence presents a new strategy to encode the LP short-time
   spectral envelope (stse) of speech. A better reconstruction of the stse
   is achieved by modifying the usual trade-off between the transmission
   rate of LP parameters and the performance of the quantization algorithm.
   A differential coding based on bidirectional prediction and hybrid
   vector quantization is used to compensate the increase in transmission
   rate. Simulation results show the effectiveness of this coding strategy.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017-2394 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{da Silva, LM (Corresponding Author), Univ Brasilia, Dept Elect Engn, BR-22453900 Rio De Janeiro, Brazil.
   Univ Brasilia, Dept Elect Engn, BR-22453900 Rio De Janeiro, Brazil.}},
DOI = {{10.1109/89.824708}},
ISSN = {{1063-6676}},
Keywords = {{low bit rate speech coding; linear predictive coding (LPC) quantization;
   spectral quantization}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Cited-References = {{ERZIN E, 1993, P IEEE INT C AC SPEE, P25.
   HAGEN R, 1992, P I ELECT ENG I, V139, P118.
   LAROIA R, 1991, P IEEE INT C AC SPEE, P641.
   LeBlanc WP, 1993, IEEE T SPEECH AUDI P, V1, P373, DOI 10.1109/89.242483.
   MARCA JRB, 1994, IEEE T VEH TECHNOL, V43, P413.
   Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363.
   Salami R, 1998, IEEE T SPEECH AUDI P, V6, P116, DOI 10.1109/89.661471.
   SILVA LM, 1996, P SBT IEEE INT TEL S, P35.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Trans. Speech Audio Process.}},
Doc-Delivery-Number = {{292XT}},
Unique-ID = {{ISI:000085821300014}},
DA = {{2020-12-06}},
}

@article{ ISI:000082181300005,
Author = {Kim, HK and Lee, HS},
Title = {{Use of spectral autocorrelation in spectral envelope linear prediction
   for speech recognition}},
Journal = {{IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING}},
Year = {{1999}},
Volume = {{7}},
Number = {{5}},
Pages = {{533-541}},
Month = {{SEP}},
Abstract = {{This paper proposes a linear predictive (LP) analysis method where
   sample autocorrelations are estimated from the spectral envelope of
   speech signal on the basis of the spectral autocorrelation, The spectral
   autocorrelation is defined as discrete quantities of speech spectrum
   with spectral resolution identical to the discrete Fourier transform
   (DFT) used to obtain the speech spectrum, From analytical and empirical
   derivation of its properties, we can estimate the fundamental frequency
   and the maximally correlated frequency for voiced and unvoiced speech,
   respectively, and then obtain the spectral envelope by sampling at a
   rate of the estimated frequency. A frequency normalization can be
   applied to the estimated spectral envelope because the number of samples
   of the spectral envelope usually differs from frame to frame. The
   spectral envelope is warped into the mel-frequency scale and the inverse
   DFT is applied to extract the estimate of sample autocorrelations. From
   the result of LP analysis on the sample autocorrelations, we finally
   obtain the spectral envelope cepstral coefficients (SECC), Hidden Markov
   model (HMM) recognition experiments show that SECC significantly
   improves the performance of a recognizer at low signal-to-noise ratios
   (SNR's) over several other representations.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017-2394 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kim, HK (Corresponding Author), AT\&T Bell Labs, Res, Florham Park, NJ 07932 USA.
   Korea Adv Inst Sci \& Technol, Dept Elect Engn, Seoul 130012, South Korea.}},
ISSN = {{1063-6676}},
Keywords = {{feature extraction; linear prediction; spectral autocorrelation;
   spectral envelope; speech recognition}},
Keywords-Plus = {{WORD RECOGNITION; ALGORITHM; NOISE}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
ResearcherID-Numbers = {{Lee, Hwang-Soo/C-1867-2011}},
Cited-References = {{DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   ERELL A, 1991, P ICASSP TOR ONT CAN, P909.
   HANSON BA, 1987, IEEE T ACOUST SPEECH, V35, P968, DOI 10.1109/TASSP.1987.1165241.
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423.
   Hermansky H., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P777.
   JUANG BH, 1987, IEEE T ACOUST SPEECH, V35, P947.
   JUNQUA JC, 1989, P ICASSP GLASG UK MA, P25.
   LAHAT M, 1987, IEEE T ACOUST SPEECH, V35, P741, DOI 10.1109/TASSP.1987.1165224.
   MANSOUR D, 1989, IEEE T ACOUST SPEECH, V37, P795, DOI 10.1109/ASSP.1989.28053.
   Markel JD, 1976, LINEAR PREDICTION SP.
   Oppenheim A. V., 1975, DIGITAL SIGNAL PROCE.
   OPPENHEIM AV, 1968, IEEE T ACOUST SPEECH, VAU16, P221, DOI 10.1109/TAU.1968.1161965.
   Paliwal K. K., 1982, Speech Communication, V1, P151, DOI 10.1016/0167-6393(82)90034-6.
   PAUL DB, 1981, IEEE T ACOUST SPEECH, V29, P786, DOI 10.1109/TASSP.1981.1163643.
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055.
   Schroeder M. R., 1985, P IEEE INT C AC SPEE, V10, P937, DOI DOI 10.1109/ICASSP.1985.1168147.
   STRUBE HW, 1980, J ACOUST SOC AM, V68, P1071, DOI 10.1121/1.384992.
   TOHKURA Y, 1978, IEEE T ACOUST SPEECH, V26, P587, DOI 10.1109/TASSP.1978.1163165.
   WILPON JG, 1985, IEEE T ACOUST SPEECH, V33, P587, DOI 10.1109/TASSP.1985.1164581.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Trans. Speech Audio Process.}},
Doc-Delivery-Number = {{229EV}},
Unique-ID = {{ISI:000082181300005}},
DA = {{2020-12-06}},
}

@article{ ISI:000081824700004,
Author = {Jiang, H and Hirose, K and Huo, Q},
Title = {{Improving Viterbi Bayesian predictive classification via sequential
   Bayesian learning in robust speech recognition}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{1999}},
Volume = {{28}},
Number = {{4}},
Pages = {{313-326}},
Month = {{AUG}},
Abstract = {{In this paper, we extend our proposed Viterbi Bayesian predictive
   classification (VBPC) algorithm to a new class of prior probability
   density function(pdf), namely a family of natural conjugate prior pdf's
   of the complete-data density in continuous density hidden Markov model
   (CDHMM) and their mixtures. In this way, we can on-line adapt the prior
   pdf via a sequential Bayesian learning algorithm when some new data are
   available, so that the performance of VBPC can be continuously improved.
   Moreover, we also study a sequential Bayesian learning strategy for
   CDHMM based on a finite mixture approximation of its prior/posterior
   density which attempts to derive a more accurate prior pdf to describe
   the unknown mismatches. The experimental results on a
   speaker-independent recognition task of isolated Japanese digits confirm
   the viability and the usefulness of the proposed method. (C) 1999
   Elsevier Science B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hirose, K (Corresponding Author), Univ Tokyo, Dept Informat \& Commun Engn, Bunkyo Ku, Hongo 7-3-1, Tokyo 1138656, Japan.
   Univ Tokyo, Dept Informat \& Commun Engn, Bunkyo Ku, Tokyo 1138656, Japan.
   Univ Waterloo, Dept Elect \& Comp Engn, Waterloo, ON N2L 3G1, Canada.
   Univ Hong Kong, Dept Informat Syst \& Comp Sci, Hong Kong, Peoples R China.}},
DOI = {{10.1016/S0167-6393(99)00018-7}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{Bayesian predictive classification (BPC); Viterbi BPC (VBPC); sequential
   Bayesian learning; robust speech recognition; natural conjugate prior}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{hjiang@crg3.uwaterloo.ca
   hirose@gavo.t.u-tokyo.ac.jp
   qhuo@csis.hku.hk}},
Cited-References = {{Bernardo J. M., 1988, BAYESIAN STATISTICS, V3, P67.
   Furui S., 1997, P ESCA NATO TUT RES, P11.
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278.
   Huo Q, 1997, IEEE T SPEECH AUDI P, V5, P161, DOI 10.1109/89.554778.
   HUO Q, 1997, P INT C AC SPEECH SI.
   HUO Q, 1997, UNPUB IEEE T SPEECH.
   HUO Q, 1997, P EUR C SPEECH COMM, P1847.
   JIANG H, 1999, IN PRESS IEEE T SPEE, V7.
   JIANG H, 1997, P INT C AC SPEECH SI.
   Lee CH, 1998, SPEECH COMMUN, V25, P29, DOI 10.1016/S0167-6393(98)00028-4.
   Matsui T, 1998, COMPUT SPEECH LANG, V12, P41, DOI 10.1006/csla.1997.0036.
   Merhav N, 1993, IEEE T SPEECH AUDI P, V1, P90, DOI 10.1109/89.221371.
   MOKBEL C, 1997, P ESCA WORKSH ROB SP, P211.
   SMITH AFM, 1985, BAYESIAN STAT, V2.
   Titterington DM, 1985, STAT ANAL FINITE MIX.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{223DJ}},
Unique-ID = {{ISI:000081824700004}},
DA = {{2020-12-06}},
}

@article{ ISI:000080961100007,
Author = {Jiang, H and Hirose, K and Huo, Q},
Title = {{Robust speech recognition based on a Bayesian prediction approach}},
Journal = {{IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING}},
Year = {{1999}},
Volume = {{7}},
Number = {{4}},
Pages = {{426-440}},
Month = {{JUL}},
Abstract = {{In this paper, we study a category of robust speech recognition problem
   in which mismatches exist between training and testing conditions, and
   no accurate knowledge of the mismatch mechanism is available. The only
   available information is the test data along with a set of pretrained
   Gaussian mixture continuous density hidden Markov models (CDHMM's). We
   investigate the problem from the viewpoint of Bayesian prediction. A
   simple prior distribution, namely constrained uniform distribution, is
   adopted to characterize the uncertainty of the mean vectors of the
   CDHMM's, Two methods, namely a model compensation technique based on
   Bayesian predictive density and a robust decision strategy called
   Viterbi Bayesian predictive classification are studied. The proposed
   methods are compared with the conventional Viterbi decoding algorithm in
   speaker-independent recognition experiments on isolated digits and TI
   connected digit strings (TIDIGITS), where the mismatches between
   training and testing conditions are caused by: 1) additive Gaussian
   white noise, 2) each of 25 types of actual additive ambient noises, and
   3) gender difference. The experimental results show that the adopted
   prior distribution and the proposed techniques help to improve the
   performance robustness under the examined mismatch conditions.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017-2394 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jiang, H (Corresponding Author), Univ Waterloo, Dept Elect \& Comp Engn, Waterloo, ON N2L 3G1, Canada.
   Univ Tokyo, Dept Informat \& Commun Engn, Tokyo 1138656, Japan.}},
DOI = {{10.1109/89.771309}},
ISSN = {{1063-6676}},
Keywords = {{Bayesian predictive classification; minimax decision; plug-in maximum a
   posteriori decision; predictive density; Viterbi Bayesian predictive
   classification}},
Keywords-Plus = {{MAXIMUM-LIKELIHOOD APPROACH; HIDDEN MARKOV-MODELS; ADAPTATION;
   PARAMETERS}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Cited-References = {{ACERO A, 1993, ACOUSTICAL ENV ROBUS.
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370.
   Furui S., 1997, P ESCA NATO TUT RES, P11.
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278.
   Geisser S., 1993, PREDICTIVE INFERENCE.
   GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J.
   Huber P J, 1981, ROBUST STAT.
   Huo Q, 1997, IEEE T SPEECH AUDI P, V5, P161, DOI 10.1109/89.554778.
   HUO Q, 1995, IEEE T SPEECH AUDI P, V3, P334, DOI 10.1109/89.466661.
   Huo Q, 1996, IEEE T SPEECH AUDI P, V4, P141, DOI 10.1109/89.486065.
   Huo Q, 1998, IEEE T SPEECH AUDI P, V6, P386, DOI 10.1109/89.701369.
   HUO Q, UNPUB BAYESIAN PREDI.
   HUO Q, 1997, P ICASSP97 MUN APR, V2, P1547.
   ITAHASHI S, 1991, T IEICE E, V74, P1906.
   JIANG H, 1996, P AC SOC JPN FALL M, P149.
   JIANG H, 1997, SP9693 IEICE, P45.
   JIANG H, 1997, P ICASSP97 MUN APR, V2, P1551.
   JIANG H, 1997, P 1997 CHIN JAP S AD, P41.
   JIANG H, 1997, P AC SOC JPN SPRING, P35.
   Juang B. H., 1991, Computer Speech and Language, V5, P275, DOI 10.1016/0885-2308(91)90011-E.
   LEE CH, 1997, P ESCA NATO WORKSH R, P45.
   LEE CH, 1996, AUTOMATIC SPEECH SPE.
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010.
   LEONARD RG, P ICASSP84.
   MERHAV N, 1991, IEEE T SIGNAL PROCES, V39, P2157, DOI 10.1109/78.91172.
   Merhav N, 1993, IEEE T SPEECH AUDI P, V1, P90, DOI 10.1109/89.221371.
   NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P326, DOI 10.1109/TASSP.1985.1164513.
   ROSE RC, 1995, P IEEE ASR WORKSH SN, P98.
   Sankar A, 1996, IEEE T SPEECH AUDI P, V4, P190, DOI 10.1109/89.496215.
   SHAHSHAHANI BM, P ICASSP96 ATL, P697.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{35}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{IEEE Trans. Speech Audio Process.}},
Doc-Delivery-Number = {{207XM}},
Unique-ID = {{ISI:000080961100007}},
DA = {{2020-12-06}},
}

@article{ ISI:000081775400010,
Author = {Akutsu, T},
Title = {{Approximation and exact algorithms for RNA secondary structure
   prediction and recognition of stochastic context-free languages}},
Journal = {{JOURNAL OF COMBINATORIAL OPTIMIZATION}},
Year = {{1999}},
Volume = {{3}},
Number = {{2-3}},
Pages = {{321-336}},
Month = {{JUL}},
Abstract = {{For a basic version (i.e., maximizing the number of base-pairs) of the
   RNA secondary structure prediction problem and the construction of a
   parse tree for a stochastic context-free language, O(n(3)) time
   algorithms were known. For both problems, this paper shows slightly
   improved O(n(3)(loglog n)(1/2)/(log n)(1/2)) time exact algorithms,
   which are obtained by combining Valiant's algorithm for context-free
   recognition with fast funny matrix multiplication. Moreover, this paper
   shows an O(n(2.776) + (1/epsilon)(O(1))) time approximation algorithm
   for the former problem and an O(n(2.976) log n + (1/epsilon)(O(1))) time
   approximation algorithm for the latter problem, each of which has a
   guaranteed approximation ratio 1 - epsilon for any positive constant
   epsilon, where the absolute value of the logarithm of the probability is
   considered as an objective value in the latter problem. The former
   algorithm is obtained from a non-trivial modification of the well-known
   O(n(3)) time dynamic programming algorithm, and the latter algorithm is
   obtained by combining Valiant's algorithm with approximate funny matrix
   multiplication. Several related results are shown too.}},
Publisher = {{KLUWER ACADEMIC PUBL}},
Address = {{SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Akutsu, T (Corresponding Author), Univ Tokyo, Inst Med Sci, Ctr Human Genome, Minato Ku, 4-6-1 Shirokanedai, Tokyo 1088639, Japan.
   Univ Tokyo, Inst Med Sci, Ctr Human Genome, Minato Ku, Tokyo 1088639, Japan.}},
DOI = {{10.1023/A:1009898029639}},
ISSN = {{1382-6905}},
Keywords = {{computational biology; RNA secondary structure prediction; stochastic
   context-free grammar; approximation algorithms}},
Keywords-Plus = {{SEQUENCES}},
Research-Areas = {{Computer Science; Mathematics}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Mathematics, Applied}},
Cited-References = {{ABRAHAMS JP, 1990, NUCLEIC ACIDS RES, V18, P3035, DOI 10.1093/nar/18.10.3035.
   AKUTSU T, 1997, GENOME INFORMATICS 1, P173.
   ALON N, 1991, PROCEEDINGS - 32ND ANNUAL SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, P569.
   COPPERSMITH D, 1990, J SYMB COMPUT, V9, P251, DOI 10.1016/S0747-7171(08)80013-2.
   EPPSTEIN D, 1992, J ACM, V39, P546, DOI 10.1145/146637.146656.
   EPPSTEIN D, 1988, P 29 IEEE S FDN COMP, P488.
   Fredman M. L., 1976, SIAM Journal on Computing, V5, P83, DOI 10.1137/0205006.
   GALIL Z, 1992, THEOR COMPUT SCI, V92, P49, DOI 10.1016/0304-3975(92)90135-3.
   KANEHISA MI, 1982, NUCLEIC ACIDS RES, V10, P265, DOI 10.1093/nar/10.1.265.
   LARMORE LL, 1991, J ALGORITHM, V12, P490, DOI 10.1016/0196-6774(91)90016-R.
   SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112.
   SETUBAL J, 1997, INTRO COMPUTATIONAL.
   TAKAOKA T, 1992, INFORM PROCESS LETT, V43, P195, DOI 10.1016/0020-0190(92)90200-F.
   Tamaki Hisao, 1998, P 9 ANN ACM SIAM S D, V1998, P446.
   TURNER DH, 1988, ANNU REV BIOPHYS BIO, V17, P167.
   UEMURA Y, 1995, P GEN INF WORKSH, V6, P67.
   VALIANT LG, 1975, J COMPUT SYST SCI, V10, P308, DOI 10.1016/S0022-0000(75)80046-8.
   Waterman Michael S., 1995, INTRO COMPUTATIONAL, P14.
   WATERMAN MS, 1978, MATH BIOSCI, V42, P257, DOI 10.1016/0025-5564(78)90099-8.
   WATERMAN MS, 1986, ADV APPL MATH, V7, P455, DOI 10.1016/0196-8858(86)90025-4.
   ZUKER M, 1981, NUCLEIC ACIDS RES, V9, P133, DOI 10.1093/nar/9.1.133.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{22}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{J. Comb. Optim.}},
Doc-Delivery-Number = {{222GH}},
Unique-ID = {{ISI:000081775400010}},
DA = {{2020-12-06}},
}

@article{ ISI:000081151900006,
Author = {Grossman, R and Bailey, S and Ramu, A and Malhi, B and Hallstrom, P and
   Pulleyn, I and Qin, X},
Title = {{The management and mining of multiple predictive models using the
   predictive modeling markup language}},
Journal = {{INFORMATION AND SOFTWARE TECHNOLOGY}},
Year = {{1999}},
Volume = {{41}},
Number = {{9}},
Pages = {{589-595}},
Month = {{JUN 25}},
Abstract = {{We introduce a markup language based upon XML for working with the
   predictive models produced by data mining systems. The language is
   called the predictive model markup language (PMML) and can be used to
   define predictive models and ensembles of predictive models. It provides
   a flexible mechanism for defining schema for predictive models and
   supports model selection and model averaging, involving multiple
   predictive models. It has proved useful for applications requiring
   ensemble learning, partitioned learning and distributed learning. In
   addition, it facilitates moving predictive models across applications
   and systems. (C) 1999 Elsevier Science B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Grossman, R (Corresponding Author), Univ Illinois, Natl Ctr Data Min, 851 S Morgan, Chicago, IL 60607 USA.
   Univ Illinois, Natl Ctr Data Min, Chicago, IL 60607 USA.
   Magnify Inc, Chicago, IL 60606 USA.}},
DOI = {{10.1016/S0950-5849(99)00022-1}},
ISSN = {{0950-5849}},
Keywords = {{data mining; predictive modeling; data interchange formats; XML; SGML;
   ensemble learning; partitioned learning; distributed learning}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
ResearcherID-Numbers = {{Grossman, Robert/B-1865-2009}},
ORCID-Numbers = {{Grossman, Robert/0000-0003-3741-5739}},
Cited-References = {{BODEK H, 1997, MATH MODELING SCI CO, V8.
   BRIEMAN L, 1996, MACH LEARN, V24, P123.
   BUNEMAN P, 1995, INTEROPERATING NONDA.
   CHAN PK, 1995, P 12 INT C MACH LEAR, P90.
   {*}DAT MIN GROUP, 1998, PRED MOD MARK LANG V.
   DIETTERICH T, IN PRESS MACH LEARNI.
   Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1, DOI DOI 10.1609/AIMAG.V17I3.1230.
   Gropp W., 1994, USING MPI PORTABLE P.
   GROSSMAN R, 1998, ENTERPRISE SYSTE AUG, P52.
   GROSSMAN R, 981 MAGN TECHN.
   GROSSMAN RL, 1998, KDD99 WORKSH DISTR D.
   GROSSMAN RL, 1996, P 2 INT C KNOWL DISC, P323.
   LAYMAN A, 1998, SPECIFICATION XML DA.
   RAFTERY AE, UNPUB BAYESIAN MODEL.
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{25}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Inf. Softw. Technol.}},
Doc-Delivery-Number = {{211GE}},
Unique-ID = {{ISI:000081151900006}},
DA = {{2020-12-06}},
}

@article{ ISI:000080834900002,
Author = {Steeneken, HJM and Houtgast, T},
Title = {{Mutual dependence of the octave-band weights in predicting speech
   intelligibility}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{1999}},
Volume = {{28}},
Number = {{2}},
Pages = {{109-123}},
Month = {{JUN}},
Abstract = {{Current objective measures for predicting the intelligibility of speech
   by an index assume that this can be obtained by simple addition of the
   contributions of individual frequency bands. The Articulation Index (AI,
   and the related Speech Intelligibility Index) and the Speech
   Transmission Index (STI) are based on this assumption. There is evidence
   that the underlying assumption of additive (mutually independent)
   contributions from a number of frequency bands is not optimal and may
   lead to erroneous prediction of the intelligibility for conditions with
   a limited or with a discontiguous frequency transfer. Depending on the
   frequency band considered, errors between 0.1 and 0.25 STI may occur. An
   experiment was designed to estimate the contribution of individual
   frequency bands, and their mutual dependence. For this purpose the
   speech spectrum was subdivided into seven octave bands with center
   frequencies ranging from 125 Hz to 8 kHz. For 26 different combinations
   of three or more octave bands, the Consonant-Vowel-Consonant-word score
   (CVC, nonsense words) was determined at three signal-to-noise ratios. It
   was found that successful prediction of the scores required a revised
   model which accounts for mutual dependency between adjacent octave
   bands. In this model a so-called redundancy correction is introduced.
   Consequences for the existing objective measures are discussed. The
   presented results are included in the revised IEC standard (IEC
   60268-part 16, 1988). (C) 1999 Elsevier Science B.V. All rights
   reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Steeneken, HJM (Corresponding Author), TNO, Human Factors Res Inst, POB 23, NL-3769 ZG Soesterberg, Netherlands.
   TNO, Human Factors Res Inst, NL-3769 ZG Soesterberg, Netherlands.}},
DOI = {{10.1016/S0167-6393(99)00007-2}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{speech intelligibility; prediction; objective measurement; octave-band
   contribution}},
Keywords-Plus = {{ROOM ACOUSTICS}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Cited-References = {{{[}Anonymous], 1998, 6026816 IEC.
   ANSI, 1969, S351969 ANSI.
   Dunn HK, 1940, J ACOUST SOC AM, V11, P278, DOI 10.1121/1.1916034.
   Fletcher H, 1929, BELL SYST TECH J, V8, P806, DOI 10.1002/j.1538-7305.1929.tb01246.x.
   FLETCHER H, 1950, J ACOUST SOC AM, V22, P89, DOI 10.1121/1.1906605.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   GRANT KW, 1991, J ACOUST SOC AM, V89, P2952, DOI 10.1121/1.400733.
   HOUTGAST T, 1973, ACUSTICA, V28, P66.
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224.
   HOUTGAST T, 1991, P EUR 91 GEN, P285.
   KRYTER KD, 1960, J ACOUST SOC AM, V32, P547, DOI 10.1121/1.1908140.
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1689, DOI 10.1121/1.1909094.
   Licklider J.C.R., 1959, PSYCHOL STUDY SCI, V1, P41.
   PAVLOVIC CV, 1987, J ACOUST SOC AM, V82, P413, DOI 10.1121/1.395442.
   POLLACK I, 1948, J ACOUST SOC AM, V20, P259, DOI 10.1121/1.1906369.
   Steeneken H. J. M., 1992, Digital speech processing, speech coding, synthesis and recognition, P127.
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464.
   STEENEKEN HJM, 1991, P EUR 91 GEN, P1133.
   STEENEKEN HJM, 1986, U98620 IZF TNO HFRI.
   STEENEKEN HJM, A13 TNO I PERC IZF.
   STEENEKEN HJM, 1992, THESIS U AMSTERDAM A.
   STUDEBAKER GA, 1987, J ACOUST SOC AM, V81, P1130, DOI 10.1121/1.394633.
   VANRAAIJ JL, 1991, 1991A7 IZF TNO HFRI.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{66}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{205RT}},
Unique-ID = {{ISI:000080834900002}},
DA = {{2020-12-06}},
}

@article{ ISI:000080669300003,
Author = {Yegnanarayana, B and Avendano, C and Hermansky, H and Murthy, PS},
Title = {{Speech enhancement using linear prediction residual}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{1999}},
Volume = {{28}},
Number = {{1}},
Pages = {{25-42}},
Month = {{MAY}},
Abstract = {{In this paper we propose a method for enhancement of speech in the
   presence of additive noise. The objective is to selectively enhance the
   high signal-to-noise ratio (SNR) regions in the noisy speech in the
   temporal and spectral domains, without causing significant distortion in
   the resulting enhanced speech. This is proposed to be done at three
   different levels. (a) At the gross level, by identifying the regions of
   speech and noise in the temporal domain. (b) At the finer level, by
   identifying the regions of high and low SNR portions in the noisy
   speech. (c) At the short-time spectrum level, by enhancing the spectral
   peaks over spectral valleys. The basis for the proposed approach is to
   analyze linear prediction (LP) residual signal in short (1-2 ms)
   segments to determine whether a segment belongs to a noise region or
   speech region. In the speech regions the inverse spectral flatness
   factor is significantly higher than in the noisy regions. The LP
   residual signal enables us to deal with short segments of data due to
   uncorrelatedness of the samples. Processing of noisy speech for
   enhancement involves mostly weighting the LP residual signal samples.
   The weighted residual signal samples are used to excite the time-varying
   all-pole filter to produce enhanced speech. As the additive noise level
   in the speech signal is increased, the quality of the resulting enhanced
   speech decreases progressively due to loss of speech information in the
   low SNR, high noise regions. Thus the degradation in performance of
   enhancement is graceful as the overall SNR of the noisy speech is
   decreased. (C) 1999 Elsevier Science B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yegnanarayana, B (Corresponding Author), Indian Inst Technol, Dept Comp Sci \& Engn, Madras 600036, Tamil Nadu, India.
   Indian Inst Technol, Dept Comp Sci \& Engn, Madras 600036, Tamil Nadu, India.
   Oregon Grad Inst Sci \& Technol, Dept Elect Engn, Portland, OR USA.
   Indian Inst Technol, Dept Elect Engn, Madras 600036, Tamil Nadu, India.}},
DOI = {{10.1016/S0167-6393(98)00070-3}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{speech enhancement; linear prediction residual signal}},
Keywords-Plus = {{COLORED NOISE; SIGNALS}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{yegna@iitm.ernet.in}},
Cited-References = {{ANANTHAPADMANABHA TV, 1979, IEEE T ACOUST SPEECH, V27, P309, DOI 10.1109/TASSP.1979.1163267.
   Avendano C, 1996, THIRD IEEE WORKSHOP ON INTERACTIVE VOICE TECHNOLOGY FOR TELECOMMUNICATIONS APPLICATIONS - IVTTA-96, PROCEEDINGS, P65, DOI 10.1109/IVTTA.1996.552760.
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   CHEN JH, 1995, IEEE T SPEECH AUDI P, V3, P59, DOI 10.1109/89.365380.
   CHENG YM, 1991, IEEE T SIGNAL PROCES, V39, P1943, DOI 10.1109/78.134427.
   COOPER FS, 1980, J ACOUST SOC AM, V68, P18, DOI 10.1121/1.384620.
   Deller JR, 1993, DISCRETE TIME PROCES.
   EPHRAIM Y, 1992, P IEEE, V80, P1526, DOI 10.1109/5.168664.
   EPHRAIM Y, 1995, IEEE T SPEECH AUDI P, V3, P251, DOI 10.1109/89.397090.
   Erell A, 1994, IEEE T SPEECH AUDI P, V2, P1, DOI 10.1109/89.260328.
   FANT G, 1993, SPEECH COMMUN, V13, P1.
   GIBSON JD, 1991, IEEE T SIGNAL PROCES, V39, P1732, DOI 10.1109/78.91144.
   Hamon C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P238, DOI 10.1109/ICASSP.1989.266409.
   Haykin S., 1991, ADAPTIVE FILTER THEO.
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616.
   Jayant N.S., 1984, DIGITAL CODING WAVEF.
   Junqua J.-C., 1996, ROBUSTNESS AUTOMATIC.
   LeBouquin R, 1996, SPEECH COMMUN, V18, P3, DOI 10.1016/0167-6393(95)00021-6.
   Lee KY, 1996, IEEE SIGNAL PROC LET, V3, P196, DOI 10.1109/97.508163.
   LEON SJ, 1990, LINEAR ALGEBRA APPL.
   LIM JS, 1978, IEEE T ACOUST SPEECH, V26, P197.
   MERMELSTEIN P, 1982, J ACOUST SOC AM, V72, P1368, DOI 10.1121/1.388440.
   MURTHY PS, 1998, IN PRESS IEEE T SPEE.
   Rose RC, 1994, IEEE T SPEECH AUDI P, V2, P245, DOI 10.1109/89.279273.
   SMITS R, 1995, IEEE T SPEECH AUDI P, V3, P325, DOI 10.1109/89.466662.
   Yegnanarayana B, 1998, IEEE T SPEECH AUDI P, V6, P1, DOI 10.1109/89.650304.
   Yegnanarayana B, 1998, INT CONF ACOUST SPEE, P405, DOI 10.1109/ICASSP.1998.674453.
   Yegnanarayana B, 1996, IEEE T SPEECH AUDI P, V4, P133, DOI 10.1109/89.486063.
   YEGNANARAYANA B, 1992, P ESCA WORKSH COMP S, P411.
   YEGNANARAYANA B, 1994, 1029 I PERC RES.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{56}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{202TY}},
Unique-ID = {{ISI:000080669300003}},
OA = {{Green Published}},
DA = {{2020-12-06}},
}

@article{ ISI:000079641300009,
Author = {Ellis, DPW},
Title = {{Using knowledge to organize sound: The prediction-driven approach to
   computational auditory scene analysis and its application to
   speech/nonspeech mixtures}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{1999}},
Volume = {{27}},
Number = {{3-4}},
Pages = {{281-298}},
Month = {{APR}},
Note = {{2nd Workshop on Computational Auditory Scene Analysis at the
   International Joint Conference on Artificial Intelligence, NAGOYA,
   JAPAN, AUG, 1997}},
Abstract = {{Computational auditory scene analysis - modeling the human ability to
   organize sound mixtures according to their sources - has experienced a
   rapid evolution from simple implementations of psychoacoustically
   inspired rules to complex systems able to process demanding real-world
   sounds. Phenomena such as the continuity illusion and phonemic
   restoration show that the brain is able to use a wide range of
   knowledge-based contextual constraints when interpreting obscured or
   overlapping mixtures: To model such processing, we need architectures
   that operate by confirming hypotheses about the observations rather than
   relying on directly extracted descriptions. One such architecture, the
   `prediction-driven' approach, is presented along with results from its
   initial implementation. This architecture can be extended to take
   advantage of the high-level knowledge implicit in today's speech
   recognizers by modifying a recognizer to act as one of the `component
   models' providing the explanations of the signal mixture. A preliminary
   investigation indicates the viability of this approach while at the same
   time raising a number of issues which are discussed. These results point
   to the conclusion that successful scene analysis must, at every level,
   exploit abstract knowledge about sound sources. (C) 1999 Elsevier
   Science B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ellis, DPW (Corresponding Author), Int Comp Sci Inst, 1947 Ctr St,Suite 600, Berkeley, CA 94704 USA.
   Int Comp Sci Inst, Berkeley, CA 94704 USA.}},
DOI = {{10.1016/S0167-6393(98)00083-1}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{computational auditory scene analysis; nonspeech; prediction; top-down;
   auditory illusion; phonemetic restoration}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{dpwe@icsi.berkeley.edu}},
Cited-References = {{Bregman A. S., 1998, COMPUTATIONAL AUDITO, P1.
   Bregman A. S., 1990, AUDITORY SCENE ANAL.
   BROWN GJ, 1994, COMPUT SPEECH LANG, V8, P297, DOI 10.1006/csla.1994.1016.
   BROWN GJ, 1992, CS9222 SHEFF U.
   CARVER N, 1992, SYMBOLIC KNOWLEDGE B, P205.
   COOKE M, 1997, P IEEE INT C AC SPEE, V2, P863.
   COOKE MP, 1993, THESIS SHEFFIELD U.
   COOKE MP, 1996, P INT WORKSH AUD BAS, P186.
   DARWIN CJ, 1984, J ACOUST SOC AM, V76, P1636, DOI 10.1121/1.391610.
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467.
   Ellis D. P. W., 1998, COMPUTATIONAL AUDITO, P257.
   ELLIS DPW, 1993, P IEEE WORKSH APPS S.
   ELLIS DPW, 1997, P IEEE INT C AC SPEE, V2, P1307.
   ELLIS DPW, 1997, P IEEE WORKSH APPS S.
   ELLIS DPW, 1996, THESIS DEP EECS.
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616.
   HOUTGAST T, 1972, J ACOUST SOC AM, V51, P1885, DOI 10.1121/1.1913048.
   KLASSNER F, 1996, THESIS U MASSACHUSET.
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082.
   MOORE RK, 1986, 3931 ROYAL SIG RES E.
   MORGANTI R, 1995, PUBL ASTRON SOC AUST, V12, P3, DOI 10.1017/S1323358000019962.
   OKUNO HG, 1996, P INT C SPOK LANG P, V4, P2356.
   Patterson R. D., 1996, ADV SP HEAR A\&B, V3, P547.
   QUINLAN JR, 1989, INFORM COMPUT, V80, P227.
   SERRA X, 1989, THESIS STANFORD U.
   SLANEY M, 1995, COMPUTATIONAL AUDITO, P27.
   SLANEY M, 1992, VISUAL REPRESENTATIO, P95.
   STEVENS K, 1967, P S, P88.
   Summerfield Q., 1992, J ACOUST SOC AM, V92, P2317.
   VARGA AP, 1990, P ICASSP, V2, P845.
   Warren R. M., 1996, PRINCIPLES EXPT PHON, P435.
   WARREN RM, 1970, SCI AM, V223, P30, DOI 10.1038/scientificamerican1270-30.
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392.
   WEINTRAUB M, 1985, THESIS STANFORD U DE.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{32}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{184YL}},
Unique-ID = {{ISI:000079641300009}},
DA = {{2020-12-06}},
}

@article{ ISI:000076648700014,
Author = {Pham, TD and Wagner, M},
Title = {{A geostatistical model for linear prediction analysis of speech}},
Journal = {{PATTERN RECOGNITION}},
Year = {{1998}},
Volume = {{31}},
Number = {{12}},
Pages = {{1981-1991}},
Month = {{DEC}},
Abstract = {{This paper presents a geostatistical model as a new approach to the
   linear prediction analysis of speech. The autocorrelation method of
   autoregressive modeling, which is widely applied in the linear
   predictive coding of speech, is used as a benchmark for comparison with
   the present algorithm. Before discussing the proposed model, we will
   briefly describe the concepts of linear prediction analysis of speech
   and how this is solved by the well-known method of autocorrelation.
   Following is the introduction of geostatistics including the ideas of
   regionalized variables, semi-variograms and kriging equations. We then
   propose a geostatistical model to the linear prediction modeling of
   speech signals. Examples on speech data are given to illustrate the
   effectiveness of the present algorithm in comparison with the
   autocorrelation method. Advantages offered by the proposed
   geostatistical algorithm over the autocorrelation method in the linear
   prediction analysis of speech are summarized as follows: (1) it is more
   effective due to the optimization of the kriging equations taking into
   account the biased condition; (2) it is more flexible by allowing
   different biased values for the fitting of the signal spectrum, and
   therefore may provide a means for adaptive LPC; (3) it can give a good
   estimate of the number of poles used in the LPC by means of the
   theoretical semi-variogram. (C) 1998 Pattern Recognition Society.
   Published by Elsevier Science Ltd. All rights reserved.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Pham, TD (Corresponding Author), Univ Canberra, Fac Informat Sci \& Engn, Canberra, ACT 2601, Australia.
   Univ Canberra, Fac Informat Sci \& Engn, Canberra, ACT 2601, Australia.}},
DOI = {{10.1016/S0031-3203(98)00084-3}},
ISSN = {{0031-3203}},
Keywords = {{linear prediction; speech signal processing; geostatistics; kriging;
   autocorrelation}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Cited-References = {{BURRUS CS, 1994, COMPUTER BASED EXERC.
   Clark I., 1979, PRACTICAL GEOSTATIST.
   David M., 1977, GEOSTATISTICAL ORE R.
   Davis J. C., 1986, STAT DATA ANAL GEOLO.
   Journel AG, 1981, MINING GEOSTATISTICS.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Matheron G, 1963, ECON GEOL, V58, P1246, DOI {[}10.2113/gsecongeo.58.8.1246, DOI 10.2113/GSECONGEO.58.8.1246].
   Pham TD, 1997, MATH GEOL, V29, P291, DOI 10.1007/BF02769634.
   PHAM TD, 1998, IN PRESS MATH GEOL, V30.
   Proakis JG, 1996, DIGITAL SIGNAL PROCE.
   Rabiner L., 1993, FUNDAMENTALS SPEECH.
   Rabiner L. R., 1978, DIGITAL PROCESSING S.
   SEN Z, 1998, IN PRESS MATH GEOL, V30.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Pattern Recognit.}},
Doc-Delivery-Number = {{132UM}},
Unique-ID = {{ISI:000076648700014}},
DA = {{2020-12-06}},
}

@article{ ISI:000075022300014,
Author = {Baltersee, J and Chambers, JA},
Title = {{Nonlinear adaptive prediction of speech with a pipelined recurrent
   neural network}},
Journal = {{IEEE TRANSACTIONS ON SIGNAL PROCESSING}},
Year = {{1998}},
Volume = {{46}},
Number = {{8}},
Pages = {{2207-2216}},
Month = {{AUG}},
Abstract = {{New learning algorithms for an adaptive nonlinear forward predictor that
   is based on a pipelined recurrent neural network (PRNN) are presented. A
   computationally efficient gradient descent (GD) learning algorithm,
   together with a novel extended recursive least squares (ERLS) learning
   algorithm, are proposed, Simulation studies based on three speech
   signals that have been made public and are available on the World Wide
   Web (WWW) are used to test the nonlinear predictor. The gradient descent
   algorithm is shown to yield poor performance in terms of prediction
   error gain, whereas consistently improved results are achieved with the
   ERLS algorithm, The merit of the nonlinear predictor structure is
   confirmed by yielding approximately 2 dB higher prediction gain than a
   linear structure predictor that employs the conventional recursive least
   squares (RLS) algorithm.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017-2394 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Baltersee, J (Corresponding Author), Rhein Westfal TH Aachen, Integrated Syst Signal Proc Lab, D-5100 Aachen, Germany.
   Rhein Westfal TH Aachen, Integrated Syst Signal Proc Lab, D-5100 Aachen, Germany.
   Imperial Coll Sci Technol \& Med, Dept Elect \& Elect Engn, Signal Proc Sect, London, England.}},
DOI = {{10.1109/78.705435}},
ISSN = {{1053-587X}},
Keywords = {{adaptive algorithms; neural networks; nonlinear prediction}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Cited-References = {{HAYKIN S, 1995, IEEE T SIGNAL PROCES, V43, P526, DOI 10.1109/78.348134.
   Haykin S., 1996, ADAPTIVE FILTER THEO.
   Kay S. M., 1989, FUNDAMENTALS STAT SI.
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792.
   Shynk J. J., 1989, IEEE ASSP Magazine, V6, P4, DOI 10.1109/53.29644.
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270.}},
Number-of-Cited-References = {{6}},
Times-Cited = {{39}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Trans. Signal Process.}},
Doc-Delivery-Number = {{104PE}},
Unique-ID = {{ISI:000075022300014}},
DA = {{2020-12-06}},
}

@article{ ISI:000075611300013,
Author = {Ma, N and Nishi, T and Wei, G},
Title = {{On a code-excited nonlinear predictive speech coding (CENLP) by means of
   recurrent neural networks}},
Journal = {{IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND
   COMPUTER SCIENCES}},
Year = {{1998}},
Volume = {{E81A}},
Number = {{8}},
Pages = {{1628-1634}},
Month = {{AUG}},
Abstract = {{To improve speech coding qualify, in particular, the long-term
   dependency prediction characteristics, we propose a new nonlinear
   predictor, i.e., a fully connected recurrent neural network (FCRNN)
   where the hidden units have Feedbacks not only from themselves but also
   from the output unit. The comparison of the capabilities of the FCRNN
   with conventional predictors shows that the former has Less prediction
   error than the latter. We apply this FCRNN instead of the previously Fro
   posed recurrent neural networks in the code-excited predictive speech
   coding system (i.e., CELP) and shows that our system (FCRNN) requires
   less bit rate/frame and improves the performance for speech coding.}},
Publisher = {{IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ma, N (Corresponding Author), Kyushu Univ, Dept Comp Sci \& Commun Engn, Fukuoka 8128581, Japan.
   Kyushu Univ, Dept Comp Sci \& Commun Engn, Fukuoka 8128581, Japan.
   SCUT, Dept Elect \& Commun Engn, Guang Zhou 510641, Peoples R China.}},
ISSN = {{0916-8508}},
EISSN = {{1745-1337}},
Keywords = {{nonlinear prediction; fully connected recurrent neural networks; vector
   quantization; speech coding}},
Keywords-Plus = {{ALGORITHM}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Engineering, Electrical \& Electronic}},
Cited-References = {{BOURLARD H, 1989, P ICASSP, P33.
   CATFOLIS T, 1993, NEURAL NETWORKS, V6, P807, DOI 10.1016/S0893-6080(05)80126-1.
   CHEN JH, 1992, IEEE J SEL AREA COMM, V10, P830, DOI 10.1109/49.138988.
   {*}CO LTD INT EL COM, 1996, ATR SPEECH DAT RES.
   COMMOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240.
   HAYKIN S, 1995, IEEE T SIGNAL PROCES, V43, P526, DOI 10.1109/78.348134.
   KROON P, 1988, IEEE J SEL AREA COMM, V6, P353, DOI 10.1109/49.612.
   Kumar A, 1997, IEEE SIGNAL PROC LET, V4, P89, DOI 10.1109/97.566697.
   Lin TN, 1996, IEEE T NEURAL NETWOR, V7, P1329, DOI 10.1109/72.548162.
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577.
   RAMACHANDRAN RP, 1989, IEEE T ACOUST SPEECH, V37, P467, DOI 10.1109/29.17527.
   THYSSEN J, 1995, P ICASSP, P265.
   THYSSEN J, 1994, P ICASSP, pI185.
   TSOI AC, 1994, IEEE T NEURAL NETWOR, V5, P229, DOI 10.1109/72.279187.
   Williams R. J., 1995, GRADIENT BASED LEARN, P433.
   WU L, 1993, P IEEE SP WORKSH NEU, P372.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Fundam. Electron. Commun. Comput. Sci.}},
Doc-Delivery-Number = {{114LQ}},
Unique-ID = {{ISI:000075611300013}},
DA = {{2020-12-06}},
}

@article{ ISI:000076198500004,
Author = {Gales, MJF},
Title = {{Predictive model-based compensation schemes for robust speech
   recognition}},
Journal = {{SPEECH COMMUNICATION}},
Year = {{1998}},
Volume = {{25}},
Number = {{1-3}},
Pages = {{49-74}},
Month = {{AUG}},
Note = {{Workshop on Robust Speech Recognition for Unknown Communication
   Channels, PONT A MOUSSON, FRANCE, APR 17-18, 1997}},
Organization = {{European Speech Commun Assoc (ESCA); NATO Res Study Grp on Speech
   Processing}},
Abstract = {{For practical applications speech recognition systems need to be
   insensitive to differences between training and test acoustic
   conditions. Differences in the acoustic environment may result from
   various sources, such as ambient background noise, channel variations
   and speaker stress. These differences can dramatically degrade the
   performance of a speech recognition system. A wide range of techniques
   have been proposed for achieving noise robustness. This paper considers
   one particular approach to model-based compensation, predictive
   model-based compensation, which has been shown to achieve good noise
   robustness in a wide range of acoustic environments. The characteristic
   of these schemes is that they combine a speech model with an additive
   noise model, a channel model and, in the general case, a speaker stress
   model, to generate a corrupted-speech model. The general theory of these
   predictive techniques is discussed. Various approximations for rapidly
   performing the model combination stage have been proposed and are
   reviewed in this paper. The advantages and the limitations of such a
   predictive approach to noise robustness are also discussed. In addition,
   methods for combining predictive schemes with schemes which make use of
   speech data in the new environment, adaptive schemes, are detailed. This
   combined approach overcomes some of the limitations of the predictive
   schemes. (C) 1998 Published by Elsevier science B.V. All rights
   reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gales, MJF (Corresponding Author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.}},
DOI = {{10.1016/S0167-6393(98)00029-6}},
ISSN = {{0167-6393}},
EISSN = {{1872-7182}},
Keywords = {{noise robustness; hidden Markov models; predictive model-based
   compensation; parallel model combination}},
Keywords-Plus = {{HIDDEN MARKOV-MODELS; NOISY SPEECH; WORD RECOGNITION; COMBINATION;
   ADAPTATION}},
Research-Areas = {{Acoustics; Computer Science}},
Web-of-Science-Categories  = {{Acoustics; Computer Science, Interdisciplinary Applications}},
Author-Email = {{mjfg@watson.ibm.com}},
Cited-References = {{BEATTIE VL, 1992, P ICSLP, P519.
   Bellegarda JR, 1997, P EUROSPEECH.
   BERSTEIN AD, 1991, P ICASSP, P913.
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209.
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   EPHRAIM Y, 1989, IEEE T ACOUST SPEECH, V37, P1846, DOI 10.1109/29.45532.
   EPHRAIM Y, 1992, IEEE T SIGNAL PROCES, V40, P1303, DOI 10.1109/78.139237.
   FURUI S, 1986, IEEE T ACOUST SPEECH, V34, P52, DOI 10.1109/TASSP.1986.1164788.
   FURUI S, 1992, ADV SPEECH SIGNAL PR.
   GAGNON L, 1992, P ESCA WORKSH SPEECH, P139.
   GALES MJF, 1995, COMPUT SPEECH LANG, V9, P289, DOI 10.1006/csla.1995.0014.
   Gales MJF, 1996, IEEE T SPEECH AUDI P, V4, P352, DOI 10.1109/89.536929.
   Gales MJF, 1996, COMPUT SPEECH LANG, V10, P249, DOI 10.1006/csla.1996.0013.
   GALES MJF, 1993, SPEECH COMMUN, V12, P231, DOI 10.1016/0167-6393(93)90093-Z.
   GALES MJF, 1992, P ICASSP, P233.
   GALES MJF, 1995, THESIS CAMBRIDGE U.
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278.
   GAUVAIN JL, 1996, P IEEE INT C AC SPEE, P73.
   GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J.
   Gopinath R.A., 1995, P ARPA WORKSH SPOK L, P127.
   HANSEN JHL, 1995, IEEE T SPEECH AUDI P, V3, P169, DOI 10.1109/89.388143.
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616.
   JUANG BH, 1985, IEEE T ACOUST SPEECH, V33, P1404, DOI 10.1109/TASSP.1985.1164727.
   JUNQUA JC, 1990, P ICASSP, P841.
   KLATT DH, 1979, P ICASSP, P573.
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010.
   MARTIN F, 1993, P EUR, P1031.
   MILNER BP, 1994, IEE P-VIS IMAGE SIGN, P280.
   MINAMI Y, 1996, P IEEE INT C AC SPEE, P327.
   MINAMI Y, 1995, P ICASSP, P129.
   Moreno P. J., 1996, THESIS CARNEGIE MELL.
   MORENO PJ, 1996, P ICASSP, P733.
   MORGAN N, 1992, P ESCA WORKSH SPEECH, P115.
   NEUMEYER L, 1995, P EUR C SPEECH COMM, P1127.
   OPENSHAW JP, 1994, P ICASSP, V2, P49.
   Rose RC, 1994, IEEE T SPEECH AUDI P, V2, P245, DOI 10.1109/89.279273.
   SANKAR A, 1995, P ICASSP, P121.
   Seymour C. W., 1994, P ICSLP, P1595.
   Varga A. P., 1990, P ICASSP, P845.
   VARGA AP, 1988, P ICASSP, P481.
   WOODLAND PC, 1996, P ICASSP ATL GA MAY, P65.}},
Number-of-Cited-References = {{41}},
Times-Cited = {{26}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Speech Commun.}},
Doc-Delivery-Number = {{124TQ}},
Unique-ID = {{ISI:000076198500004}},
DA = {{2020-12-06}},
}

@article{ ISI:A1996UY19000002,
Author = {Hasib, A and Hacioglu, K},
Title = {{Source combined linear predictive analysis in pulse-based speech coders}},
Journal = {{IEE PROCEEDINGS-VISION IMAGE AND SIGNAL PROCESSING}},
Year = {{1996}},
Volume = {{143}},
Number = {{3}},
Pages = {{143-148}},
Month = {{JUN}},
Abstract = {{The conventional linear predictive analysis in pulse-based coders is
   replaced by the so-called source-combined linear predictive method to
   match the excitations considered in two steps: synthesis filter
   determination and excitation search. It differs from Atal's two-pass
   approach in that the synthesis filter is optimised jointly with the
   excitation prior to the ABS excitation search. However, it is a
   difficult task eo obtain the optimum solution, and, thus, a suboptimal
   algorithm is developed. Initially, the algorithm starts with the
   covariance method and then corrects the synthesis filter using an
   estimate of the excitation. This is accomplished by using two coupled
   equations originally developed. The effectiveness of the approach in
   multipulse and regular pulse excited coders is demonstrated. Extensive
   simulation results, at several bit rates, with different excitations,
   are presented. Comparisons are made with the standard coder and the
   coder that employs Atal's approach. In all conditions, the proposed
   coder is found to give better results.}},
Publisher = {{IEE-INST ELEC ENG}},
Address = {{MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD, ENGLAND SG1 2AY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hasib, A (Corresponding Author), EASTERN MEDITERRANEAN UNIV,DEPT ELECTR \& ELECT ENGN,TR-10 MERSIN,TURKEY.}},
DOI = {{10.1049/ip-vis:19960367}},
ISSN = {{1350-245X}},
Keywords = {{speech coders; linear predictive analysis; algorithms; noise; filtering}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Cited-References = {{Atal B. S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P614.
   Fratti M, 1993, IEEE T SPEECH AUDI P, V1, P463, DOI 10.1109/89.242492.
   HACIOGLU K, 1993, ICSAT, P1365.
   KROON P, 1988, IEEE J SEL AREA COMM, V6, P353, DOI 10.1109/49.612.
   KROON P, 1986, IEEE T ACOUST SPEECH, V34, P1054, DOI 10.1109/TASSP.1986.1164946.
   PICONE J, 1986, SPEECH COMMUN, V5, P253, DOI 10.1016/0167-6393(86)90012-9.
   RAMACHANDRAN R, 1986, IEEE T ASSP, V35, P937.
   RAMACHANDRAN RP, 1989, IEEE T ACOUST SPEECH, V37, P467, DOI 10.1109/29.17527.
   Salami R. A., 1991, Advances in Speech Coding, P145.
   Singhal S., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P781.
   SINGHAL S, 1984, P ICASSP.
   Tremain T. E., 1982, Speech Technology, V1, P40.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEE Proc.-Vis. Image Signal Process.}},
Doc-Delivery-Number = {{UY190}},
Unique-ID = {{ISI:A1996UY19000002}},
DA = {{2020-12-06}},
}

@article{ ISI:A1996UH00400009,
Author = {Zhou, M and Nakagawa, S},
Title = {{Succeeding word prediction for speech recognition based on stochastic
   language model}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{1996}},
Volume = {{E79D}},
Number = {{4}},
Pages = {{333-342}},
Month = {{APR}},
Abstract = {{For the purpose of automatic speech recognition, language models (LMs)
   are used to predict possible succeeding words for a given partial word
   sequence and thereby to reduce the search space. In this paper several
   kinds of stochastic language models (SLMs) are evaluated - bigram,
   trigram, hidden Markov model (HMM), bigram-HMM, stochastic context-free
   grammar (SCFG) and hand-written Bunsetsu Grammar. To compare the
   predictive power of these SLMs, the evaluation was conducted from two
   points of views: (1) relationship between the number of model parameters
   and entropy, (2) predictive rate of succeeding part of speech (POS) and
   succeeding word. We propose a new type of bigram-HMM and compare it with
   the other models. Two kinds of approximations are tried and examined
   through experiments. Results based on both of English Brown-Corpus and
   Japanese ATR dialog database showed that the extended bigram-HMM had
   better performance than the others and was more suitable to be a
   language model.}},
Publisher = {{IEICE-INST ELECTRON INFO COMMUN ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO 105, JAPAN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhou, M (Corresponding Author), TOYOHASHI UNIV TECHNOL,DEPT INFORMAT \& COMP SCI,TOYOHASHI,AICHI 441,JAPAN.}},
ISSN = {{0916-8532}},
Keywords = {{stochastic language model; bigram; trigram; HMM; bigram-HMM;
   context-free grammar; entropy; perplexity; prediction rate}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
ResearcherID-Numbers = {{nakagawa, seiichi/L-5543-2019}},
Cited-References = {{BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278.
   BLACK E, 1993, P INT S SPOKEN DIALO, P77.
   FUJISAKI T, 1989, P 1 INT WORKSH PARS, P85.
   GUPTA V, 1992, COMPUTER SPEECH LANG, P331.
   ITO T, 1987, P AUT M AC SOC JAP.
   KAWABATA T, 1994, P ICSLP94, V2, P787.
   KEMPE A, 1994, P COLING, P161.
   Kupiec J., 1992, Computer Speech and Language, V6, P225, DOI 10.1016/0885-2308(92)90019-Z.
   Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X.
   LIN AC, 1994, P COLING, P148.
   MURAKAMI J, 1992, JAPANESE SOC ARTIFIC, P17.
   Nakagawa S., 1989, Computer Speech and Language, V3, P277, DOI 10.1016/0885-2308(89)90023-5.
   NAKAGAWA S, 1991, IEICE TRANS COMMUN, V74, P1897.
   NAKAGAWA S, 1994, J ACOUSTICAL JAPAN, V50, P126.
   NAKAGAWA S, 1992, FUNDAMENTALS APPL IN, pCH6.
   NAKAGAWA S, 1988, SPEECH RECOGNITION B, pCH3.
   NAKAMURA M, 1989, P INT C AC SPEECH SI, P731.
   NELSON FW, 1962, STANDARD SAMPLE PRES.
   OBOYLE P, 1994, COMPUTER SPEECH LANG, P337.
   RICCARDI G, 1995, P ICASSP 95, P237.
   TAKAHASHI S, 1992, P INT C AC SPEECH SI, P553.
   Tomita M., 1986, EFFICIENT PARSING NA.
   WRIGHT JH, 1992, P ICASSP.
   ZHOU M, 1995, IPSJ, P1.
   1967, BROWN CORPUS.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{UH004}},
Unique-ID = {{ISI:A1996UH00400009}},
DA = {{2020-12-06}},
}

@article{ ISI:A1996UE60100018,
Author = {Olswang, LB and Bain, BA},
Title = {{Assessment information for predicting upcoming change in language
   production}},
Journal = {{JOURNAL OF SPEECH AND HEARING RESEARCH}},
Year = {{1996}},
Volume = {{39}},
Number = {{2}},
Pages = {{414-423}},
Month = {{APR}},
Note = {{Symposium on Child Language Disorders Research, UNIV WISCONSIN, MADISON,
   WI, 1992}},
Abstract = {{Initial language assessments are used not only to determine the presence
   of a language problem and establish eligibility for intervention, but
   also to provide information about a child's readiness for immediate
   change in language growth. This study explored static assessment
   profiling (specific variables and discrepancies in performance) and
   dynamic assessment results to determine their relative effectiveness for
   predicting immediate change. Correlation data were used to examine how
   well each assessment measure predicted upcoming language production
   changes for children with specific expressive language impairment.
   Results indicated that dynamic assessment outcomes were most highly
   correlated with immediate language growth, followed by discrepancy in
   receptive and expressive language age. Findings are discussed in terms
   of their clinical and theoretical importance.}},
Publisher = {{AMER SPEECH-LANG-HEARING ASSN}},
Address = {{10801 ROCKVILLE PIKE RD, ROCKVILLE, MD 20852-3279}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Olswang, LB (Corresponding Author), UNIV WASHINGTON,DEPT SPEECH \& HEARING SCI,1417 NE 42ND ST,SEATTLE,WA 98105, USA.
   IDAHO STATE UNIV,DEPT SPEECH PATHOL \& AUDIOL,POCATELLO,ID 83209.}},
DOI = {{10.1044/jshr.3902.414}},
ISSN = {{0022-4685}},
Keywords = {{dynamic assessment; prediction; language change; readiness; static
   assessment}},
Keywords-Plus = {{IMPAIRED PRESCHOOLERS; LATE TALKERS; CHILDREN; VOCABULARY; TODDLERS;
   DELAY}},
Research-Areas = {{Linguistics; Rehabilitation}},
Web-of-Science-Categories  = {{Language \& Linguistics; Rehabilitation}},
Funding-Acknowledgement = {{NIDCD NIH HHSUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness \& Other Communication Disorders (NIDCD) {[}R29-DC00431]
   Funding Source: Medline; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness \& Other Communication Disorders (NIDCD) {[}R29DC000431,
   R29DC000431, R29DC000431, R29DC000431] Funding Source: NIH RePORTER}},
Cited-References = {{Bain B., 1995, AM J SPEECH-LANG PAT, V4, P81.
   Bain B. A., 1991, LANG SPEECH HEAR SER, V22, P264, DOI DOI 10.1044/0161-1461.2204.264.
   BAIN BA, 1992, TOP LANG DISORD, V12, P13, DOI 10.1097/00011363-199202000-00004.
   BILLINGSLEY F, 1980, BEHAV ASSESS, V2, P229.
   Bowers J. W., 1984, COMMUNICATION RES ME.
   BOYD R, 1974, BOYD DEV PROGR SCALE.
   BRIAN J, 1995, UNPUB PRODUCTIVITY E.
   Brown AL, 1983, HDB CHILD PSYCHOL, P77.
   CAMARATA SM, 1994, J SPEECH HEAR RES, V37, P1414, DOI 10.1044/jshr.3706.1414.
   CAMARATA SM, 1992, CLIN LINGUIST PHONET, V6, P167, DOI 10.3109/02699209208985528.
   CAMPIONE JC, 1989, J LEARN DISABIL, V22, P151, DOI 10.1177/002221948902200303.
   Casby M. W., 1992, LANG SPEECH HEAR SER, V23, P198.
   COGGINS T, 1987, ASSESSING PRELINGUIS, P107.
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104.
   Cole K. N., 1994, LANG SPEECH HEAR SER, V25, P25.
   COLE KN, 1990, APPL PSYCHOLINGUIST, V11, P291, DOI 10.1017/S0142716400008900.
   CRYSTAL D, 1982, PROFILING LINGUISTIC.
   Dunn L. M., 1981, PEABODY PICTURE VOCA.
   Fenson L, 1993, MACARTHUR COMMUNICAT.
   Feuerstein R, 1979, DYNAMIC ASSESSMENT R.
   FISCHEL JE, 1989, PEDIATRICS, V82, P218.
   GERTNER BL, 1994, J SPEECH HEAR RES, V37, P913, DOI 10.1044/jshr.3704.913.
   HADLEY PA, 1991, J SPEECH HEAR RES, V34, P1308, DOI 10.1044/jshr.3406.1308.
   HEDRICK DL, 1984, SEQUENCED INVENTORY.
   KEMP J, 1983, ASHA REPORTS, V12, P183.
   MCCAULEY RJ, 1984, J SPEECH HEAR DISORD, V49, P34, DOI 10.1044/jshd.4901.34.
   MILLER J, 1990, SALT SYSTEMATIC ANAL.
   MILLER JF, 1981, J SPEECH HEAR RES, V24, P154, DOI 10.1044/jshr.2402.154.
   Miller JF, 1981, ASSESSING LANGUAGE P.
   OLSWANG L, 1988, ASSESSMENT DEV DISAB, P285.
   OLSWANG LB, 1991, LANG SPEECH HEAR SER, V22, P255.
   OLSWANG LB, 1992, CAUSES EFFECTS COMMU, P187.
   PAUL R, 1991, TOP LANG DISORD, V11, P1, DOI 10.1097/00011363-199111040-00003.
   RESCORLA L, 1990, APPL PSYCHOLINGUIST, V11, P393, DOI 10.1017/S0142716400009644.
   RICE ML, 1991, J SPEECH HEAR RES, V34, P1299, DOI 10.1044/jshr.3406.1299.
   Rogoff B., 1990, APPRENTICESHIP THINK.
   SCHERER NJ, 1989, J SPEECH HEAR DISORD, V54, P383, DOI 10.1044/jshd.5403.383.
   SNOW D, 1994, J SPEECH HEAR RES, V37, P831, DOI 10.1044/jshr.3704.831.
   SWISHER L, 1994, LANG SPEECH HEAR SER, V25, P235.
   THAL D, 1991, J SPEECH HEAR RES, V34, P604, DOI 10.1044/jshr.3403.604.
   THAL DJ, 1992, J SPEECH HEAR RES, V35, P1281, DOI 10.1044/jshr.3506.1289.
   THORNDIKE R, 1986, STANFORDBINET TEST I.
   Vance R, 1994, LANG SPEECH HEAR SER, V25, P15, DOI DOI 10.1044/0161-1461.2501.15.
   VYGOTSKII LS, 1978, MIND SOC.
   WATKINS RV, 1993, FIRST LANG, V13, P133.
   WEISMER SE, 1994, J SPEECH HEAR RES, V37, P852, DOI 10.1044/jshr.3704.852.
   WEISMER SE, 1993, J SPEECH HEAR RES, V36, P1037, DOI 10.1044/jshr.3605.1037.
   WOLERY M, 1983, EXCEPT CHILDREN, V50, P167, DOI 10.1177/001440298305000208.}},
Number-of-Cited-References = {{48}},
Times-Cited = {{39}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{J. Speech Hear. Res.}},
Doc-Delivery-Number = {{UE601}},
Unique-ID = {{ISI:A1996UE60100018}},
DA = {{2020-12-06}},
}

@article{ ISI:A1996UL77200012,
Author = {Black, AW and Kondoz, AM and Evans, BG},
Title = {{Improved pulsed residual excited linear prediction: A new excitation for
   CELP based speech coders}},
Journal = {{ELECTRONICS LETTERS}},
Year = {{1996}},
Volume = {{32}},
Number = {{6}},
Pages = {{520-521}},
Month = {{MAR 14}},
Abstract = {{The authors present a new secondary pulse excitation for linear
   prediction based analysis by synthesis speech coders. The structure of
   the excitation has been specifically designed to model characteristics
   in the speech waveform which the LTP memory fails to adequately
   represent. This is achieved using an excitation vector simply consisting
   of two pulses.}},
Publisher = {{INST ENGINEERING TECHNOLOGY-IET}},
Address = {{MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Black, AW (Corresponding Author), UNIV SURREY, CTR SATELLITE ENGN RES, GUILDFORD GU2 5XH, SURREY, ENGLAND.}},
DOI = {{10.1049/el:19960401}},
ISSN = {{0013-5194}},
EISSN = {{1350-911X}},
Keywords = {{linear predictive coding; speech coding}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Cited-References = {{KONDOZ AM, 1995, IEE P-VIS IMAGE SIGN, V142, P105, DOI 10.1049/ip-vis:19951801.
   LAFLAMME C, 1990, INT CONF ACOUST SPEE, P177, DOI 10.1109/ICASSP.1990.115567.
   SALAMI R, 1994, IEEE T VEH TECHNOL, V43, P808, DOI 10.1109/25.312763.
   Schroeder M. R., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8), P937.}},
Number-of-Cited-References = {{4}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Electron. Lett.}},
Doc-Delivery-Number = {{UL772}},
Unique-ID = {{ISI:A1996UL77200012}},
DA = {{2020-12-06}},
}

@article{ ISI:A1996VW99600001,
Author = {Magnusson, L},
Title = {{Predicting the speech recognition performance of elderly individuals
   with sensorineural hearing impairment - A procedure based on the Speech
   Intelligibility Index}},
Journal = {{SCANDINAVIAN AUDIOLOGY}},
Year = {{1996}},
Volume = {{25}},
Number = {{4}},
Pages = {{215-222}},
Abstract = {{The Speech Intelligibility Index (SII) was used as a basis for
   predicting the performance of elderly hearing-impaired subjects on a
   speech-in-noise test. The standard SII calculation scheme was compared
   with modified schemes, and correlations were obtained between measured
   and predicted scores. The results suggested that a modified calculation
   scheme, which includes corrections for sensorineural hearing impairment
   and age, is appropriate for evaluating individual speech recognition
   scores. Based on the results, a computer program has been developed for
   clinical prediction and evaluation of speech recognition scores.}},
Publisher = {{SCANDINAVIAN UNIVERSITY PRESS}},
Address = {{PO BOX 2959 TOYEN, JOURNAL DIVISION CUSTOMER SERVICE, N-0608 OSLO,
   NORWAY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{SAHLGRENS UNIV HOSP,DEPT AUDIOL,S-41345 GOTHENBURG,SWEDEN.}},
DOI = {{10.3109/01050399609074957}},
ISSN = {{0105-0397}},
Keywords = {{Articulation Index; elderly; prediction; presbyacusis; sensorineural
   impairment; speech audibility; speech in noise; Speech Intelligibility
   Index; speech recognition}},
Keywords-Plus = {{ARTICULATION INDEX; RECEPTION THRESHOLD; NOISE; LISTENERS; YOUNG; AGE}},
Research-Areas = {{Otorhinolaryngology}},
Web-of-Science-Categories  = {{Otorhinolaryngology}},
Cited-References = {{{*}ANSI, 1993, S379199X ANSI.
   ANSI, 1969, S351969 ANSI.
   ARLINGER S, 1990, ACTA OTOLARYNGOL S S, V469, P30.
   COX RM, 1993, EAR HEARING, V14, P275, DOI 10.1097/00003446-199308000-00006.
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011.
   FLETCHER H, 1950, J ACOUST SOC AM, V22, P89, DOI 10.1121/1.1906605.
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407.
   HAGERMAN B, 1984, SCAND AUDIOL, V13, P57, DOI 10.3109/01050398409076258.
   Hagerman B., 1976, SCAND AUDIOL, V5, P219, DOI 10.3109/01050397609044991.
   HARGUS SE, 1995, J SPEECH HEAR RES, V38, P234, DOI 10.1044/jshr.3801.234.
   IVARSSON US, 1994, SCAND AUDIOL, V23, P159, DOI 10.3109/01050399409047502.
   JERGER J, 1989, EAR HEARING, V10, P79, DOI 10.1097/00003446-198904000-00001.
   KAMM CA, 1985, J ACOUST SOC AM, V77, P281, DOI 10.1121/1.392269.
   LIDEN G, 1954, ACTA OTOLARYNGOL S S, V114.
   LUDVIGSEN C, 1987, J ACOUST SOC AM, V82, P1162, DOI 10.1121/1.395252.
   Magnusson L, 1995, SCAND AUDIOL, V24, P217, DOI 10.3109/01050399509047539.
   Magnusson L, 1996, SCAND AUDIOL, V25, P59, DOI 10.3109/01050399609047557.
   PAVLOVIC CV, 1984, J ACOUST SOC AM, V75, P1253, DOI 10.1121/1.390731.
   PAVLOVIC CV, 1986, J ACOUST SOC AM, V80, P50, DOI 10.1121/1.394082.
   PEKKARINEN E, 1990, SCAND AUDIOL, V19, P31, DOI 10.3109/01050399009070749.
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554.
   POULSEN T, 1991, SCAND AUDIOL, V20, P245, DOI 10.3109/01050399109045971.
   SCHUM DJ, 1991, J SPEECH HEAR RES, V34, P636, DOI 10.1044/jshr.3403.636.
   SMOORENBURG GF, 1992, J ACOUST SOC AM, V91, P421, DOI 10.1121/1.402729.
   Studebaker G A, 1995, J Am Acad Audiol, V6, P173.
   STUDEBAKER GA, 1989, EAR HEARING, V10, P101, DOI 10.1097/00003446-198904000-00004.
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455.
   SUTER AH, 1985, J ACOUST SOC AM, V78, P887, DOI 10.1121/1.392919.
   TOWNSEND TH, 1980, SCAND AUDIOL, V9, P245, DOI 10.3109/01050398009076359.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{16}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Scand. Audiol.}},
Doc-Delivery-Number = {{VW996}},
Unique-ID = {{ISI:A1996VW99600001}},
DA = {{2020-12-06}},
}

@article{ ISI:A1995RF59000012,
Author = {TSUBOKA, E and TAKADA, Y},
Title = {{NEURAL PREDICTIVE HIDDEN MARKOV MODEL FOR SPEECH RECOGNITION}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{1995}},
Volume = {{E78D}},
Number = {{6}},
Pages = {{676-684}},
Month = {{JUN}},
Note = {{1994 International Conference on Spoken Language Processing (ICSLP 94),
   YOKOHAMA, JAPAN, SEP 18-22, 1994}},
Abstract = {{This paper describes new modeling methods combining neural network and
   hidden Markov model applicable to modeling a time series such as speech
   signal. The idea assumes that the sequence is nonstationary and is a
   nonlinear autoregressive process whose parameters are controlled by a
   hidden Markov chain. One is the model where a non-linear predictor
   composed of a multi-layered neural network is defined at each state,
   another is the model where a multi-layered neural network is defined so
   that the path from the input layer to the output layer is divided into
   path-groups each of which corresponds to the state of the Markov chain.
   The latter is an extended model of the former. The parameter estimation
   methods for these models are shown, and other previously proposed
   models-one called Neural Prediction Model and another called Linear
   Predictive HMM-are shown to be special cases of the NPHMM proposed here.
   The experimental result affirms the justification of these proposed
   models.}},
Publisher = {{IEICE-INST ELECTRON INFO COMMUN ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO 105, JAPAN}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{TSUBOKA, E (Corresponding Author), MATSUSHITA ELECT IND CO LTD,CENT RES LABS,KYOTO 61902,JAPAN.}},
ISSN = {{0916-8532}},
Keywords = {{HMM; NEURAL NETWORK; SPEECH PROCESSING; NONLINEAR PREDICTION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Number-of-Cited-References = {{0}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{RF590}},
Unique-ID = {{ISI:A1995RF59000012}},
DA = {{2020-12-06}},
}

@article{ ISI:A1995RF59000024,
Author = {SERIZAWA, M and OZAWA, K},
Title = {{4 KBPS IMPROVED PITCH PREDICTION CELP SPEECH CODING WITH 20 MSEC FRAME}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{1995}},
Volume = {{E78D}},
Number = {{6}},
Pages = {{758-763}},
Month = {{JUN}},
Note = {{1994 International Conference on Spoken Language Processing (ICSLP 94),
   YOKOHAMA, JAPAN, SEP 18-22, 1994}},
Abstract = {{This paper proposes a new pitch prediction method for 4 kbps CELP (Code
   Excited LPC) speech coding with 20 msec frame, for the future ITU-T 4
   kbps speech coding standardization. In the conventional CELP speech
   coding {[}5]-{[}7], {[}9], {[}22], synthetic speech quality deteriorates
   rapidly at 4 kbps, especially for female and children's speech with
   short pitch period. The pitch prediction performance is significantly
   degraded for such speech. The important reason is that when the pitch
   period is shorter than the subframe length, the simple repetition of the
   past excitation signal based on the estimated lag, not the pitch
   prediction, is usually carried out in the adaptive codebook operation.
   The proposed pitch prediction method can carry out the pitch prediction
   without the above approximation by utilizing the current subframe
   excitation codevector signal, when the pitch prediction parameters are
   determined. To further improve the performance, a split vector synthesis
   and perceptually spectral weighting method, and a low-complexity
   perceptually harmonic and spectral weighting method have also been
   developed. The informal listening test result shows that the 4 kbps
   speech coder with 20 msec frame, utilizing all of the proposed
   improvements, achieves 0.2 MOS higher results than the coder without
   them.}},
Publisher = {{IEICE-INST ELECTRON INFO COMMUN ENG}},
Address = {{KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO 105, JAPAN}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{SERIZAWA, M (Corresponding Author), NEC CORP LTD,INFORMAT TECHNOL RES LABS,KAWASAKI,KANAGAWA 216,JAPAN.}},
ISSN = {{0916-8532}},
Keywords = {{SPEECH CODING; PITCH PREDICTION; CELP; VECTOR QUANTIZATION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Number-of-Cited-References = {{0}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEICE Trans. Inf. Syst.}},
Doc-Delivery-Number = {{RF590}},
Unique-ID = {{ISI:A1995RF59000024}},
DA = {{2020-12-06}},
}

@article{ ISI:A1994PT07900014,
Author = {CHAN, CF and CHUI, SP},
Title = {{EFFICIENT CODEBOOK SEARCH PROCEDURE FOR VECTOR-SUM EXCITED LINEAR
   PREDICTIVE CODING OF SPEECH}},
Journal = {{ELECTRONICS LETTERS}},
Year = {{1994}},
Volume = {{30}},
Number = {{22}},
Pages = {{1830-1831}},
Month = {{OCT 27}},
Abstract = {{An efficient codebook search method for the EIA/TIA IS-54 vector-sum
   excited linear predictive (VSELP) speech coder is described. The method
   uses a two-stage search procedure. In the first stage, diagonal
   approximation of the correlation matrix of the filtered basis vectors is
   assumed and a simple sign detection procedure is used to identify a
   codeword which is close to the optimum codeword. In the second stage, a
   refinement search is carried out on those codewords which have a Hamming
   distance of one from the codeword obtained in the first stage. The new
   search procedure has a complexity only proportional to the bit rate
   which is much faster than the Gray code search employed in the IS-54
   VSELP coder. Simulation results show that the SNR obtained using the
   proposed fast procedure is the same as that obtained in the standard
   VSELP coder.}},
Publisher = {{IEE-INST ELEC ENG}},
Address = {{MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD, ENGLAND SG1 2AY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{CHAN, CF (Corresponding Author), CITY POLYTECH HONG KONG,DEPT ELECTR ENGN,83 TAT CHEE AVE,KOWLOON,HONG KONG.}},
DOI = {{10.1049/el:19941271}},
ISSN = {{0013-5194}},
Keywords = {{LINEAR PREDICTIVE CODING; SPEECH CODING}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
ORCID-Numbers = {{CHAN, Cheung Fat/0000-0002-8665-3971}},
Cited-References = {{CAMPBELL JP, 1989, P IEEE INT C AC SPEE, P735.
   GERSON IA, 1990, APR INT C AC SPEECH, P461.
   TRANCOSO IM, 1990, IEEE T ACOUST SPEECH, V38, P385, DOI 10.1109/29.106858.}},
Number-of-Cited-References = {{3}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Electron. Lett.}},
Doc-Delivery-Number = {{PT079}},
Unique-ID = {{ISI:A1994PT07900014}},
DA = {{2020-12-06}},
}

@article{ ISI:A1994NC41700012,
Author = {DENG, L and HASSANEIN, K and ELMASRY, M},
Title = {{ANALYSIS OF THE CORRELATION STRUCTURE FOR A NEURAL PREDICTIVE MODEL WITH
   APPLICATION TO SPEECH RECOGNITION}},
Journal = {{NEURAL NETWORKS}},
Year = {{1994}},
Volume = {{7}},
Number = {{2}},
Pages = {{331-339}},
Abstract = {{A speech recognizer is developed using a layered feedforward neural
   network to implement speech-frame prediction. A Markov chain is used to
   control changes in the network's weight parameters. We postulate that
   speech recognition accuracy is closely linked to the capability of the
   predictive model in representing long-term temporal correlations in
   speech data. Analytical expressions are obtained for the correlation
   functions for various types of predictive models (linear, compressively
   nonlinear, and jointly linear and compressively nonlinear) to determine
   the faithfulness of the models to the actual speech data. Analytical
   results, computer simulations, and speech recognition experiments
   suggest that when compressive nonlinear prediction and linear prediction
   are jointly performed within the same layer of the neural network, the
   model is better at capturing long-term data correlations and
   consequently improving speech recognition performance.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{DENG, L (Corresponding Author), UNIV WATERLOO, DEPT ELECT \& COMP ENGN, WATERLOO N2L 3G1, ONTARIO, CANADA.}},
DOI = {{10.1016/0893-6080(94)90027-2}},
ISSN = {{0893-6080}},
EISSN = {{1879-2782}},
Keywords = {{TEMPORAL CORRELATIONS; JOINT LINEAR NONLINEAR PREDICTION; MULTILAYER
   PERCEPTRON; HMM}},
Keywords-Plus = {{HIDDEN MARKOV MODEL; WORD RECOGNITION}},
Research-Areas = {{Computer Science; Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Neurosciences}},
ORCID-Numbers = {{Hassanein, Khaled/0000-0002-5902-1717}},
Cited-References = {{Baum LE, 1972, INEQUALITIES, V3, P1.
   BOX GEP, 1976, TIME SERIES ANAL FOR, P67.
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420.
   DENG D, 1990, COMPUTER SPEECH LANG, V4, P345.
   DENG L, 1990, J ACOUST SOC AM, V87, P2738, DOI 10.1121/1.399064.
   DENG L, 1992, SIGNAL PROCESS, V27, P65, DOI 10.1016/0165-1684(92)90112-A.
   DENG L, 1992, J ACOUST SOC AM, V92, P3058, DOI 10.1121/1.404202.
   DENG L, 1991, IEEE T SIGNAL PROCES, V39, P1677, DOI 10.1109/78.134406.
   Fant G., 1960, ACOUSTIC THEORY SPEE.
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8.
   ISO K, 1990, P IEEE INT C SIGNAL, V1, P441.
   JONES DA, 1976, THESIS U LONDON.
   KENNY P, 1990, IEEE T ACOUST SPEECH, V38, P220, DOI 10.1109/29.103057.
   LEVIN E, 1990, P INT C AC SPEECH SI, V1, P433.
   LI D, 1992, IEEE T SIGNAL PROCES, V40, P265, DOI 10.1109/78.124937.
   MINORSKY N, 1962, NONLINEAR OSCIL, pCH9.
   PORITZ AB, 1988, P IEEE INT C AC SPEE, V1, P7.
   PRIESTLEY M, 1988, NONLINEAR NONSTATION, P140.
   TEBELSKIS J, 1990, P INT C AC SPEECH SI, V1, P437.
   Tong H., 1990, NONLINEAR TIME SERIE.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Neural Netw.}},
Doc-Delivery-Number = {{NC417}},
Unique-ID = {{ISI:A1994NC41700012}},
DA = {{2020-12-06}},
}

@article{ ISI:A1993MP75100006,
Author = {CHEN, H and WONG, WC and KO, CC},
Title = {{LOW-DELAY HYBRID VECTOR EXCITATION LINEAR PREDICTIVE SPEECH CODING}},
Journal = {{ELECTRONICS LETTERS}},
Year = {{1993}},
Volume = {{29}},
Number = {{25}},
Pages = {{2164-2165}},
Month = {{DEC 9}},
Abstract = {{A hybrid approach in determining the excitation vector in a low-delay
   code excited linear predictive coder is proposed. By a judicious
   division of the composite excitation vector into long-term and
   short-term components, and the use of switched quantisation, substantial
   improvement in coding quality is obtained.}},
Publisher = {{IEE-INST ELEC ENG}},
Address = {{MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD, ENGLAND SG1 2AY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{CHEN, H (Corresponding Author), NATL UNIV SINGAPORE,DEPT ELECT ENGN,10 KENT RIDGE CRESCENT,SINGAPORE 0511,SINGAPORE.}},
DOI = {{10.1049/el:19931452}},
ISSN = {{0013-5194}},
Keywords = {{LINEAR PREDICTIVE CODING; SPEECH CODING}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
ORCID-Numbers = {{Wong, Lawrence/0000-0001-6581-234X}},
Cited-References = {{CHEN JH, 1991, DEC IEEE GLOB COMM C, P1894.
   CHEN JH, 1990, APR P IEEE INT C AC, P453.}},
Number-of-Cited-References = {{2}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Electron. Lett.}},
Doc-Delivery-Number = {{MP751}},
Unique-ID = {{ISI:A1993MP75100006}},
DA = {{2020-12-06}},
}

@article{ ISI:A1993KV41800008,
Author = {YANG, G and LEICH, H and BOITE, R},
Title = {{MULTIBAND CODE-EXCITED LINEAR PREDICTION (MBCELP) FOR SPEECH CODING}},
Journal = {{SIGNAL PROCESSING}},
Year = {{1993}},
Volume = {{31}},
Number = {{2}},
Pages = {{215-227}},
Month = {{MAR}},
Abstract = {{This paper presents a new speech coding model targeted at the bit-rate
   above 4 kbit/s, referred to as multiband code-excited linear prediction
   (MBCELP). The analysis and synthesis of speech are accomplished in the
   time domain by comparing the original to the synthetic speech while a
   perceptual criterion is used. A usual short-term linear predictive
   filter is employed as the synthesis filter; the excitation signal is
   modelled as a linear combination of a long-term predictive excitation,
   periodic multiband excitations and a noise-like excitation; no
   voiced/unvoiced decision is required. The periodic multiband excitation
   is produced by convoluting a periodic impulse sequence with a sinc
   function corresponding to a frequency band; the noise-like excitation is
   represented by a codebook. We estimate a pitch which is appropriate not
   only to the long-term predictive filter but also to the periodic
   multiband excitations and to the `pitch' prefilter in the decoder.
   Several CELP vocoders are developed as a reference to test the property
   of the MBCELP vocoder. Listening tests clearly indicate that this
   vocoder reconstructed very high quality speech without `buzziness' or
   `hoarseness' for both clean and noisy speech. A 4.8 kbit/s MBCELP
   vocoder is shown as an example. Its perceptual quality is virtually
   identical to the original 8 kbit/s CELP vocoder and the improved 7.2
   kbit/s CELP vocoder. Since less subframes are used for the MBCELP
   vocoders, their complexity is not greater than that of usual CELP
   vocoders with the same type of codebook. A lot of techniques used to
   simplify CELP coding can be also adopted for the MBCELP coding.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{FAC POLYTECH MONS,THEORIE CIRCUITS \& TRAITEMENT SIGNAUX LAB,31 BLVD DOLEZ,B-7000 MONS,BELGIUM.}},
DOI = {{10.1016/0165-1684(93)90067-K}},
ISSN = {{0165-1684}},
Keywords = {{SPEECH CODING; LINEAR PREDICTIVE CODING; CELP CODING; SPEECH PERCEPTION;
   SIGNAL PROCESSING}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Number-of-Cited-References = {{0}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Signal Process.}},
Doc-Delivery-Number = {{KV418}},
Unique-ID = {{ISI:A1993KV41800008}},
DA = {{2020-12-06}},
}

@article{ ISI:A1992JF37400005,
Author = {KIM, RC and LEE, SU},
Title = {{ENTROPY CONSTRAINED PREDICTIVE VECTOR QUANTIZATION OF SPEECH}},
Journal = {{SIGNAL PROCESSING}},
Year = {{1992}},
Volume = {{28}},
Number = {{1}},
Pages = {{77-90}},
Month = {{JUL}},
Abstract = {{This paper describes a form of predictive vector quantizer that makes
   use of the entropy constrained quantizer, i.e., an entropy constrained
   predictive vector quantizer (ECPVQ). An algorithm for designing the
   ECPVQ is presented, and an approximate theoretical analysis for the
   performance of the proposed ECPVQ is also provided. It is found that the
   performance is closely related with the correlation of the input source
   and the vector dimension. Simulation results on the Gauss-Markov source
   and real sampled speech data are given and comparisons are made between
   the new technique presented here and other similar coding techniques,
   such as entropy constrained VQ and predictive VQ.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{SEOUL NATL UNIV,DEPT CONTROL \& INSTRUMENTAT ENGN,SIGNAL PROC LAB,SHINLIM DONG,KWANAK KU,SEOUL 151742,SOUTH KOREA.}},
ISSN = {{0165-1684}},
Keywords = {{LLOYD-MAX QUANTIZER; ENTROPY CONSTRAINED QUANTIZER; VECTOR PREDICTOR;
   ENTROPY CONSTRAINED PREDICTIVE VECTOR QUANTIZER; SPEECH CODING;
   CLASSIFIER; MULTIVARIATE MARKOV PROCESS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Number-of-Cited-References = {{0}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Signal Process.}},
Doc-Delivery-Number = {{JF374}},
Unique-ID = {{ISI:A1992JF37400005}},
DA = {{2020-12-06}},
}

@article{ ISI:A1992HU22500004,
Author = {WARD, S},
Title = {{THE PREDICTIVE-VALIDITY AND ACCURACY OF A SCREENING-TEST FOR LANGUAGE
   DELAY AND AUDITORY PERCEPTUAL DISORDER}},
Journal = {{EUROPEAN JOURNAL OF DISORDERS OF COMMUNICATION}},
Year = {{1992}},
Volume = {{27}},
Number = {{1}},
Pages = {{55-72}},
Abstract = {{Infants (321) who had been screened for language delay and auditory
   perceptual problems at 9 months of age were evaluated 1 year later. Of
   these infants 88.6\% were correctly classified as at-risk or not-at-risk
   of delayed linguistic development. The correlation between performance
   on the screen and on a language scale was 0.49. The great majority of
   those with receptive and expressive delay continued to show problems at
   2 years of age, whereas half of those with expressive delay alone were
   within normal limits. No evidence was found that a history of
   fluctuating hearing loss contributed to the development of either
   language delay or auditory perceptual problems.}},
Publisher = {{WHURR PUBLISHERS LTD}},
Address = {{19B COMPTON TERRACE, LONDON, ENGLAND N1 2UN}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{WARD, S (Corresponding Author), LONGSIGHT HLTH CTR,DEPT SPEECH THERAPY,526-528 STOCKPORT RD,MANCHESTER M13 0RR,ENGLAND.
   MANCHESTER CENT HOSP,COMMUNITY SPEECH THERAPY SERV,MANCHESTER,ENGLAND.}},
ISSN = {{0963-7273}},
Keywords = {{LANGUAGE DELAY; AUDITORY PERCEPTUAL PROBLEMS; PREDICTIVE VALUE;
   SCREENING}},
Keywords-Plus = {{SPEECH; CHILDREN}},
Research-Areas = {{Communication; Rehabilitation}},
Web-of-Science-Categories  = {{Communication; Rehabilitation}},
Cited-References = {{ALLEN D, 1978, N01NS612355 NINCDS N.
   BAKER L, 1982, CHILD LANGUAGE, V3.
   BATTIN R, 1981, AUDITORY DISORDERS S.
   Bayley N, 1969, BAYLEY SCALES INFANT.
   BEITCHMAN JH, 1986, J AM ACAD CHILD PSY, V25, P528, DOI 10.1016/S0002-7138(10)60013-1.
   BISHOP DVM, 1986, BRIT J DISORD COMMUN, V21, P321.
   BLISS LS, 1984, J COMMUN DISORD, V17, P133, DOI 10.1016/0021-9924(84)90019-4.
   BURR H, 1952, NZ MED J, V51, P239.
   BZOCH KR, 1971, ASSESSING LANGUAGE S.
   CANTWELL DP, 1977, ARCH GEN PSYCHIAT, V34, P583.
   COLE P, 1978, PAEDIATRIC AUDIOLOGY.
   COOPER J, 1974, BRIT J DISORD COMMUN, V9, P81.
   COOPER J, 1978, HELPING LANGUAGE DEV.
   DAVIS M, 1980, SEMINARS SPEECH LANG, V1, P141.
   DAVIS S, 1983, AUDIOLOGY J CONTINUI, V8, P45.
   DRILLIAN C, 1983, CLIN DEV MED, V86.
   EISENSON J, 1968, J SPEECH HEAR DISORD, V33, P3, DOI 10.1044/jshd.3301.03.
   EISENSON J, 1986, HUMAN COMMUNICATION, V10, P5.
   Fundudis T, 1979, SPEECH RETARDED DEAF.
   GALLAGHER J, 1972, EARLY CHILDHOOD ED.
   GRAHAM P, 1980, CLIN NEUROEPIDEMIOLO.
   HALL D, 1989, HLTH ALL CHILDREN RE.
   Head H., 1926, APHASIA KINDRED DISO.
   HUNTLEY RMC, 1988, BRIT J DISORD COMMUN, V23, P127.
   INGRAM TTS, 1972, F LANGUAGE DEV, V2, P295.
   JANSKY JJ, 1977, DYSLEXIA.
   JEFFREE D, 1984, HDB CLIN AUDIOLOGY.
   KATZ J, 1984, HDB CLIN AUDIOLOGY.
   KATZ J, 1985, J CHILDHOOD COMMUNIC, V9, P65.
   Keith R, 1981, CENTRAL AUDITORY LAN.
   KIRK SA, 1968, ILLINOIS TEST PSYCHO.
   LESKE MC, 1981, ASHA, V23, P229.
   LOWE H, 1964, J SPEECH HEAR DISORD, V8, P313.
   LUBERT N, 1981, J SPEECH HEAR DISORD, V46, P3, DOI 10.1044/jshd.4601.03.
   MACINTYRE M, 1983, FOLIA PHONIATR, V35, P3.
   MATKIN N, 1983, CENTRAL AUDITORY PRO.
   MENYUK P, 1971, ACQUISITION DEV LANG.
   Morley M. E., 1972, DEV DISORDERS SPEECH.
   MYKLEBUST H, 1971, HDB SPEECH PATHOLOGY.
   MYKLEBUST H, 1954, AUDITORY DISORDERS, V1.
   NAKAZIMA S, 1971, ACQUISITION DEV LANG.
   PETRIE I, 1975, BRIT J DISORD COMMUN, V10, P123.
   REES NS, 1973, J SPEECH HEAR DISORD, V38, P304, DOI 10.1044/jshd.3803.304.
   RICHMAN N, 1982, PRESCHOOL SCH BEHAVI.
   RUTTER M, 1970, CLIN DEV MED, V43.
   SHERIDAN MD, 1973, BRIT J DISORD COMMUN, V8, P9.
   SILVA P, 1983, FOLIA PHONIATRICA, V35.
   SILVA PA, 1980, DEV MED CHILD NEUROL, V22, P768.
   SLOAN C, 1984, HUMAN COMMUNICATION, V9, P117.
   STEVENSON J, 1984, DEV MED CHILD NEUROL, V26, P528.
   TALLAL P, 1976, J SPEECH HEAR RES, V19, P561, DOI 10.1044/jshr.1903.561.
   TAYLOR IG, 1964, NEUROLOGICAL MECHANI.
   TURTON L, 1974, LANGUAGE PERSPECTIVE.
   WARD S, 1984, BRIT J DISORD COMMUN, V19, P237.
   WARD S, 1980, BRIT J DISORDERS COM, V17, P35.
   WARNOCK M, 1978, REPORT COMMITTEE INQ.
   Willeford J, 1985, HDB CENTRAL AUDITORY.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{24}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Eur. J. Disord. Commun.}},
Doc-Delivery-Number = {{HU225}},
Unique-ID = {{ISI:A1992HU22500004}},
DA = {{2020-12-06}},
}

@article{ ISI:A1991FF70500012,
Author = {SOMMERS, RK},
Title = {{APPROACHES TO THE PREDICTION OF LANGUAGE ABILITIES IN A SAMPLE OF
   CHILDREN WHO HAVE DEVELOPMENTAL DELAYS}},
Journal = {{JOURNAL OF SPEECH AND HEARING RESEARCH}},
Year = {{1991}},
Volume = {{34}},
Number = {{2}},
Pages = {{317-324}},
Month = {{APR}},
Publisher = {{AMER SPEECH-LANG-HEARING ASSN}},
Address = {{10801 ROCKVILLE PIKE RD, ROCKVILLE, MD 20852-3279}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{SOMMERS, RK (Corresponding Author), KENT STATE UNIV,KENT,OH 44242, USA.}},
DOI = {{10.1044/jshr.3402.317}},
ISSN = {{0022-4685}},
Keywords = {{LANGUAGE PREDICTION; LANGUAGE DISORDERS; LANGUAGE ASSESSMENT; COGNITIVE
   FACTORS; NEURODEVELOPMENTAL FACTORS}},
Keywords-Plus = {{DISORDERED CHILDREN; PERCEPTION; MOTOR; APHASIA}},
Research-Areas = {{Linguistics; Rehabilitation}},
Web-of-Science-Categories  = {{Language \& Linguistics; Rehabilitation}},
Cited-References = {{ARAMDM, 1984, J SPEECH HEAR RES, V27, P232.
   ARAMDM, 1989, SCH PSYCHOL REV, V18, P487.
   AYERS AJ, 1977, AM J OCCUPATIONAL TH, V20, P335.
   BOWERMAN MF, 1974, LANGUAGE PERSPECTIVE, P191.
   CARROW E, 1985, TEST AUDITORY COMPRE.
   DAILEY K, 1979, LANGUAGE SPEECH HEAR, V1, P6.
   DAVIS K, 1978, THESIS KENT STATE U.
   GOLDMAN R, 1969, GOLDMANFRISTOE TEST.
   GRIFFITHS CPS, 1969, BRIT J DISORD COMMUN, V4, P46.
   HUGHES MA, 1983, BRAIN LANG, V19, P48, DOI 10.1016/0093-934X(83)90055-X.
   INGRAM D, 1978, PHONOLOGICAL DISABIL.
   LASSMAN FM, 1980, EARLY CORRELATES SPE.
   LUND N, 1983, ASSESSING CHILDRENS.
   MCLOUGHLIN CS, 1982, PERCEPT MOTOR SKILL, V55, P1038, DOI 10.2466/pms.1982.55.3f.1038.
   NAGAFUCHI M, 1970, ACTA OTOLARYNGOL, V6, P409.
   NEALE M, 1965, 6TH MENTAL MEASUREME, P831.
   OBRZUT JE, 1980, BRAIN LANG, V11, P181, DOI 10.1016/0093-934X(80)90119-4.
   OJEMANN G, 1980, EBBS WORK S PAPER GO.
   PAUL R, 1984, J AUTISM DEV DISORD, V14, P405, DOI 10.1007/BF02409831.
   ROSENBLUM DR, 1978, BRAIN LANG, V6, P378, DOI 10.1016/0093-934X(78)90070-6.
   SCHERY TK, 1985, J SPEECH HEAR DISORD, V50, P73, DOI 10.1044/jshd.5001.73.
   SCHIRMER G, 1973, PERFORMANCE OBJECTIV.
   SESSIONS JT, 1975, THESIS KENT STATE U.
   SIEGEL LS, 1979, CAN J PSYCHOL, V33, P382, DOI 10.1037/h0081734.
   SKOVRAN SK, 1977, THESIS KENT STATE U.
   SNYDER LS, 1971, AM J OCCUP THER, V25, P105.
   Sommers R K, 1972, Cortex, V8, P224.
   SOMMERS RK, 1977, AM J MENT DEF, V82, P44.
   SOMMERS RK, 1976, J SPEC EDUC, V10, P5, DOI 10.1177/002246697601000102.
   SPRINGER SP, 1977, NEUROPSYCHOLOGIA, V15, P287, DOI 10.1016/0028-3932(77)90037-9.
   STANLEY JC, 1965, 6TH MENTAL MEASUREME, P694.
   STARK R, 1982, SPEECH LANGUAGE ADV, V7, P149.
   Stark R., 1988, LANGUAGE SPEECH READ.
   TALLAL P, 1973, NATURE, V241, P468, DOI 10.1038/241468a0.
   TALLAL P, 1974, NEUROPSYCHOLOGIA, V12, P83, DOI 10.1016/0028-3932(74)90030-X.
   Templin M., 1957, CERTAIN LANGUAGE SKI.
   TERMAN LM, 1960, STANFORDBINET INTELL.
   TIEGERMAN E, 1989, LANG COMMUN, P44.
   TYACK D, 1974, LANGUAGE SAMPLING AN.
   VANKLEECK A, 1984, LANGUAGE LEARNING DI, P129.
   Wechsler D., 1974, WECHSLER INTELLIGENC.
   WILKINSON L, 1988, SYSTEM STATISTICS.
   WITELSON SF, 1977, LANGUAGE DEV NEUROLO, P117.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{J. Speech Hear. Res.}},
Doc-Delivery-Number = {{FF705}},
Unique-ID = {{ISI:A1991FF70500012}},
DA = {{2020-12-06}},
}

@article{ ISI:A1991FU70500007,
Author = {MOREAU, N},
Title = {{PREDICTIVE SPEECH CODING AT LOW BIT RATES - A UNIFIED APPROACH}},
Journal = {{ANNALES DES TELECOMMUNICATIONS-ANNALS OF TELECOMMUNICATIONS}},
Year = {{1991}},
Volume = {{46}},
Number = {{3-4}},
Pages = {{223-239}},
Month = {{MAR-APR}},
Abstract = {{At this moment different speech coders at low bitrates are being defined
   and normalized.  These speech coders are all based on an analysis by
   synthesis procedure.  Different methods have been proposed in recent
   litterature to construct the excitation signal.  The goal of this
   article is to present in a unified formalism these different algorithms
   and to estimate their costs in terms of complexity.  In a first step the
   basic principle of these speech coders is described.  It is shown that a
   generalized description of the excitation covers different classical
   coding techniques and results in a most general iterative standard
   algorithm.  The complexity of this algorithm is evaluated in terms of
   the number of multiplications/accumulations per second and different
   possible simplifications are analyzed.  This article concludes with a
   presentation of the coders that are actually submitted for
   normalization.}},
Publisher = {{PRESSES POLYTECHNIQUES ET UNIVERSITAIRES ROMANDES}},
Address = {{EPFL-ECUBLENS, CENTRE MIDI, CH-1015 LAUSANNE, SWITZERLAND}},
Type = {{Article}},
Language = {{French}},
Affiliation = {{MOREAU, N (Corresponding Author), TELECOM PARIS,DEPT SIGNAL,46 RUE BARRAULT,F-75634 PARIS 13,FRANCE.}},
ISSN = {{0003-4347}},
Keywords = {{SPEECH CODING; PREDICTIVE CODING; PASSBAND COMPRESSION; MODELING;
   COMPARATIVE STUDY; ALGORITHM COMPLEXITY; CODEC}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Cited-References = {{AAL B, 1982, P INT C ACOUST SPEEC, P614.
   Adoul J., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1957.
   ATAL B, 1979, IEEE T ASSP      JUN.
   BEROUTI M, 1984, P INT C ACOUST SPEEC.
   CAMPBELL JP, 1989, P IEEE INT C AC SPEE, P735.
   CHEN JH, 1990, P IEEE ICASSP APR, P453.
   CUPERMAN V, 1985, IEEE T C         JUL.
   Davidson G., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P2189.
   DAVIDSON G, 1988, P INT C AC SPEECH SI, P163.
   DAVIDSON G, 1986, P INT C ACOUST SPEEC, P3055.
   DEPRETTERE EF, 1985, P ICASSP TAMPA, P965.
   Dymarski P, 1990, P INT C AC SPEECH SI, P485.
   FOURNIER N, 1990, P INT C ACOUST SPEEC, P173.
   GALAND G, 1986, EUSIPCO.
   GERSON I, 1990, P ICASSP 90, P461.
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229.
   IRETON M, 1989, P INT C ACOUST SPEEC.
   ITAKURA F, 1975, J ACOUST SOC AM, V57.
   Jayant N.S., 1984, DIGITAL CODING WAVEF.
   JAYANT NS, 1990, IEEE COMMUN MAG  JAN, P10.
   JAYANT NS, 1986, IEEE SPECTRUM    AUG, P58.
   Kay S. M., 1988, MODERN SPECTRAL ESTI.
   KLEIJN W, 1988, SPEECH COMMUN    OCT, P305.
   KLEIJN W, 1990, IEEE T ASSP      AUG.
   KROON P, 1990, P ICASSP, P661.
   KROON P, 1985, THESIS DELFT U.
   KROON P, 1986, IEEE T ASSP      OCT.
   LAFLAMME C, 1990, P ICASSP, P177.
   LEFEVRE JP, 1985, P INT C AC SPEECH SI, P957.
   LEGUYADER A, 1986, P INT C AC SPEECH SI, P857.
   Lin D., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1354.
   LINDE Y, 1980, IEEE T COMMUNICA JAN.
   MALHOUL J, 1985, P IEEE           NOV.
   Markel JD, 1976, LINEAR PREDICTION SP.
   Marques J. S., 1989, Eurospeech 89. European Conference on Speech Communication and Technology, P509.
   MENEZ J, 1989, P INT C ASSP GLASGOW, P132.
   Moreau N., 1989, Eurospeech 89. European Conference on Speech Communication and Technology, P322.
   OFER E, 1989, P IEEE INT C AC SPEE, P41.
   OMNESCHEVALIER MC, 1985, 3 C TRAIT SIGN APPL.
   OZAWA K, 1986, P IEEE INT C AC SPEE, P1689.
   PERROT V, 1990, CODAGE PAROLE DEBIT.
   RAHIKKA D, 1990, P INT C ACOUST SPEEC, P465.
   RAMACHANDRAN R, 1989, IEEE T ASSP      APR.
   ROSE R, 1990, IEEE T ASSP      SEP.
   Rose R. C., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1637.
   ROSE RC, 1986, P INT C ASSPY TOKYO, P453.
   SALAMI R, 1990, P INT C AC SPEECH SI, P473.
   SHROEDER MR, 1985, P ICASSP, P937.
   Singhal S, 1986, P INT C AC SPEECH SI, P2363.
   SINGHAL S, 1984, P INT C ACOUST SPEEC.
   SINGHAL S, 1989, IEEE T ASSP      MAR.
   SOONG FK, 1990, P IEEE INT C AC SPEE, P185.
   TRANCOSO I, 1990, IEEE T ASSP      MAR.
   TRANCOSO IM, 1986, P IEEE INT C AC SPEE, P2375.
   TREMAINT T, 1982, SPEECH TECHNOLOG APR, P4.
   VANLOAN GG, 1989, MATRIX COMPUTATIONS.
   VARY P, 1988, P ICASSP, P227.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Ann. Telecommun.-Ann Telecommun.}},
Doc-Delivery-Number = {{FU705}},
Unique-ID = {{ISI:A1991FU70500007}},
DA = {{2020-12-06}},
}
